[["index.html", "Example Comprehensive Exams for Ph.D. students in Public Administration and American Politics Chapter 1 Structure of the Book 1.1 A Gentle Warning 1.2 Copywrite 1.3 Software Information and Session Capture", " Example Comprehensive Exams for Ph.D. students in Public Administration and American Politics Ian T. Adams Scott M. Mourtgos Samuel R. Baty 2021-01-13 Chapter 1 Structure of the Book I have arranged two large chapters, one for each of the major subfields covered in the book. First, in the Public Adminstration Pre-Write chapter, we provide many of the possible questions you might encounter in Public Administration exams. In the next chapter, we do the same for American Politics. In both these early chapters, we are providing you with examples of full comprehensive pre-writes. In the next two chapters, we provide the actual comprehensive exam answers for full exams, one for Public Administration and one for American politics. The closing chapter wraps up with some general information and strategy going into your own exams. 1.1 A Gentle Warning Because this book is easily available on the internet, I strongly suggest you do not plagiarize from it. Synthesize it, gently massage it, and use whatever you can make useful to your own views on the relevant academic fields. Dont tempt the TurnItIn monster - it wont end well! Further, remember that every Ph.D. program has its own flavor. My program at the University of Utah, for example, is relatively less quantitatively focused than some other programs, and places a tremendous amount of focus on developing thoughtful scholarship on equity in public policy and administration. Your program will be different, and you should consider those differences as you read through the supplied answers. 1.2 Copywrite Copyright Â© 2021 by the authors All rights reserved. This book or any portion thereof may not be reproduced or used in any manner whatsoever without the express written permission of the author except for the use of brief quotations in a book review. Printed in the United States of America First Printing, 2021 ISBN GET IF NECESSARY Corresponding author information and contact available at https://ianadamsresearch.com 1.3 Software Information and Session Capture This book was written in Rstudio using the bookdown package. The following session information is provided: sessionInfo() ## R version 4.0.3 (2020-10-10) ## Platform: x86_64-w64-mingw32/x64 (64-bit) ## Running under: Windows 10 x64 (build 19042) ## ## Matrix products: default ## ## locale: ## [1] LC_COLLATE=English_United States.1252 ## [2] LC_CTYPE=English_United States.1252 ## [3] LC_MONETARY=English_United States.1252 ## [4] LC_NUMERIC=C ## [5] LC_TIME=English_United States.1252 ## ## attached base packages: ## [1] stats graphics grDevices utils datasets methods base ## ## loaded via a namespace (and not attached): ## [1] compiler_4.0.3 magrittr_2.0.1 bookdown_0.21 htmltools_0.5.0 ## [5] tools_4.0.3 rstudioapi_0.13 yaml_2.2.1 stringi_1.5.3 ## [9] rmarkdown_2.6 knitr_1.30 stringr_1.4.0 digest_0.6.27 ## [13] xfun_0.19 rlang_0.4.10 evaluate_0.14 "],["intro.html", "Chapter 2 Introduction 2.1 Acknowledgments 2.2 About the Authors", " Chapter 2 Introduction Every Ph.D. student lives the first few years dreading comprehensive exams, and the rest of their academic careers trying to convince more junior scholars that everything will be okay. These exams have the very-real capability of derailing your career plans, and should not be overlooked. One of the most common requests I get from more junior scholars is for examples of comprehensive exams. This should not be surprising. As members of the academy, we are trained to build carefully upon the shoulders of giants - i.e., beg, borrow, and steal, but add a little action to the pot while youre at it. Its been said that if you have to teach something twice, write it down. In that spirit, and having freely given these examples away in the past, I put together this book to help Ph.D. students make the difficult transition to Ph.D. candidates. I hope you find it useful. 2.1 Acknowledgments My own path through comprehensive exams, like every one of my academic efforts, was only made possible because of the mentorship and love of those around me. My dissertation chair, Dr. Sharon Mastracci, is ultimately responsible for giving me a shot at an academic world I didnt even realize existed. Dr. James Curry always left his office door open for me to drop in and learn more about the profession. Dr. Steve Nelson insisted Id be a happier Ph.D. student than a law school student - he was right as usual. Scott Mourtgos has proven to be the most exciting and productive partner in crime criminal justice that I could have hoped for. 2.2 About the Authors 2.2.1 Ian T. Adams Ian Adams is a Ph.D. candidate in Political Science at the University of Utah, where he also completed a Masters of Public Administration. His research interests include body-worn cameras and policing. Ian is a 2018 American Society of Public Administration Founders Fellow, and a 2020/2021 doctoral fellow of the Academy of Criminal Justice Sciences. Personal website (and current CV) available at https://ianadamsresearch.com Dedication Time slips, men fall. Academia is but a sliver of life, and for the rest I rely on the love and support of my partner Annette. Therefore this book is dedicated to you Annette. Id die for you, writing a dedication is too easy. 2.2.2 Scott M. Mourtgos Scott M. Mourtgos is a Ph.D. candidate in the Department of Political Science at the University of Utah. His research focuses on policing and criminal justice policy. Scott is a 2020 National Institute of Justice LEADS Scholar. More information on his research is available at https://smourtgos.netlify.app/. 2.2.3 Samuel R. Baty Samuel R. Baty is a Ph.D. candidate in the Department of Political Science at the University of Utah, and also has a Bachelors of Science in Mathematics from the University of California Los Angeles. His research focuses on nuclear security and public administration. "],["pa-pre.html", "Chapter 3 Public Administration: Pre-Written Examples 3.1 Bureaucracy 3.2 Policy Frameworks and Police Technology: The Case of Body-Worn Cameras 3.3 Dune and Public Administration Theory 3.4 At Will Employment (Human Resources Management) 3.5 Ethics Case Study: The Nevada Four 3.6 Externalities &amp; Non-Profits 3.7 Charity &amp; Non-Profits 3.8 Non-profits as mediating structures 3.9 Public Administration &amp; War 3.10 Nationalism versus Patriotism  John H. Schaar 3.11 Policy Paradox (Stone, 1997), Trump, &amp; Environmental Policy 3.12 The Foreign Intelligence Surveillance Act (FISA) of 1978 (also Stone, Policy Paradox) 3.13 Public Administration: Traditions &amp; Roots 3.14 Five Public Administration Theories 3.15 More? Stay tuned!", " Chapter 3 Public Administration: Pre-Written Examples This chapter is constructed around PA themed questions. The questions you encounter will by nature not be exactly the same as these, or other previous comprehensive exams, even within your own program. There is always at least a little variability. Therefore, I suggest students construct a variety of written answers that are built around themes. These themes are common to the study of public adminsitration, and generally will hold across academic contexts. Once youre caught up here, you may want to check out the examples of real-world comprehensive exams found in a later chapter. 3.1 Bureaucracy 3.1.1 Example Questions 3.1.1.1 Bureaucratic Responsiveness While the courts are often described as reactive, other institutions, such as Congress and the bureaucracy are assumed to be more proactive. Given the large and constantly growing literature on agenda-setting in the policy process as well as the various frameworks explaining interest group activity and Congressional action, how true is it that the bureaucracy in particular can be seen as truly proactive? Do bureaucrats shape their policy domains or do they primarily attempt to balance and accommodate outside pressures? 3.1.1.2 Bureaucracy, Administrative State Scholars of American politics often neglect the single largest element in U.S. government, the bureaucracy, leaving it to scholars of public administration as if less important. However, there have been some Americanists who have taken an active interest in explaining how the need to control and even motivate the enormous federal bureaucracy has shaped such constitutional branches as Congress and the Presidency. Explain how the development of large and complex federal bureaucracy in the post-World War II (and perhaps especially post Great Society) era has led to new understandings of Congress and the Presidency. How has the regulatory welfare state changed the nature of political leadership, the different roles of legislators and chief executives, and the relationship between the constitutional branches? 3.1.1.3 Bureaucratic Autonomy Perhaps unsurprisingly, the Trump Administration has already prompted great attention to the scope of bureaucratic autonomy and discretion in policy making and implementation. What does the scholarly literature tell us about the nature, sources, and degree of bureaucratic autonomy in the policy process? Will this be an Achilles heel for the Trump Administration or a source of strength? 3.1.2 Potential Bureaucracy Short Answers and Prompts 3.1.2.1 Principal Agent Theory Principal-agency theory holds that democratic hierarchies shape the output of public bureaucracies. 3.1.2.2 Street Level Bureaucracy, Wicked Problems, Police The American publics view of the police officer is deeply mediated through the images presented to it via two competing visions: that of the iconic Hollywood policeman, tough, heroic, unfeeling, and hardened to the street; and that of the news media, in which it is shown a clouded, violent man visiting unlawful violence upon vulnerable communities. The American police officer is at once the most iconic of public servants, haloed in film, and yet in the modern moment also the clearest symbol associated with a public grown discomfited with the violence of authority. Lost in these two inimical views is the human who inhabits the uniform. A paradoxical tension between myth and reality is stubbornly American. We are able to believe that our government is weak, stupid, overbearing, dishonest, and inefficient, and at that same time we are deeply convinced that it is the best government in the world, and we would like to impose it upon everyone else, writes John Steinbeck (Steinbeck, 2003, p. 330), We speak of the American Way of Life as though it involved the ground rules for the governance of heaven. Nowhere is the paradox of American thought about their government and its administration more evident than in policing. Raised on Andy Griffith only to be horrified by Rodney Kings abuse; taught the hazards of drug use by Officer Friendly in elementary school only to be shocked by the brutality of officers captured on cell phone video. Who could blame a skeptical public for fractured views on police? The public, largely educated on policing reality via Hollywood and the crisis-of-the-day coverage promulgated by a news cycle obsessed media, is starved for information about the people inside the uniform, and the impossible work they confront every day. The public is asked to embrace a hero-worship of our first responders, a worship shaped so successfully by film and television. Yet when that worship is confounded by the same instruments which built it, this paradoxical, rigid view shakes along fault lines of profession, race, class, and location. Public administration gathers information among the fields of each, processing the information through theory, and producing solutions of its own. In avoiding sole reliance on either dogma or experiment, public administration enables a transition to a more humanistic understanding of the front-line law enforcer; we blunt the sharpest edges of the paradox. A realistic, humanistic view allows a moderation of both the exaggeratedly heroic view of police work, as well as the crippling disappointment when the nightly news once again reminds us of the awful acts a human is capable of, even one in uniform. That is not to say that the institution of policing is not responsible for failure. As noted in other works (Epp, Maynard-Moody, &amp; Haider-Markel, 2014; Maynard-Moody &amp; Musheno, 2012a), the impacts of officer discretion are nuanced. While individual officer behavior is better explained by agency policy and legalistic guidance than by individual attitude and bias, the policies themselves can perpetuate inequity, and the juridical bounds may grant so much latitude that they take on the nature of a farce (Maynard-Moody &amp; Musheno, 2012a, p. S18). The tension inherent in the American view of the police officer is a long-standing, complex, and wide-ranging problem, qualifying it easily within the ranks of the wicked problems (Rittel &amp; Webber, 1973) for which public administration is best situated to address. A social science isolated from the problems it purports to study has hobbled itself unnecessarily; public administration, uncomfortable from birth with rigid academic boundaries, finds its most sure footing in addressing the big, wicked problems: The field of public administration, broadly defined, confronts the wicked problems of society (Shields, 2008, p. 212). Through its embrace of practical solutions unbound by rigid definitions of academic taxonomy, public administration is best suited to address complex public problems through its tradition of pracademics, a practice which has been a fundamental aspiration of public administration since its founding (Posner, 2009, p. 12). The marriage of academic and practitioner worldviews to address the wicked problems is not without precedent. In fact, there is a strong argument that the founding of our academic tradition used the same coupling to address the pressing public administration issues of that time in a similar way. As noted by Patricia Shields (2008), grounding reformers aspirations in the reality of the people working on the frontlines was a common goal of both Jane Addams and John Dewey, a reflection of theories of street-level bureaucrats sixty years later (Lipsky, 1983). These contemporary Progressives pushed back on a reformation whose inquiry was unguided by the input of those most affected by both the crisis and solution. Addams was suspicious of ideas uninformed by the underlying humanity of those involved, and in her view of democracy, we must (Addams, 2002, p. 51) take pains to keep common ground in our human experiences. Inspired by Jane Addams, John Dewey echoes the sentiment (Dewey &amp; Rogers, 2012, p. 20): The man who wears the shoe knows best that it pinches and where it pinches, even if the expert shoemaker is the best judge of how the trouble is to be remedied. 3.1.2.3 Frederickson, Social Equity During the same general period as Lipsky was publishing his report, H. George Frederickson (1971) was calling for scholars to adopt social equity as a basic value of public administration. Frederickson e argues that social inequity constitutes a fundamental, if long-range, threat to the viability of this or any political system and concludes, [I]t appears that new Public Administration is an alignment with good, or possibly God. One possible synthesis of Lipsky and Frederickson is seeing the discretionary powers of street-level bureaucrats as increasing social equity. After all, as Lipsky (1983) writes, The poorer people are, the greater the influence street-level bureaucrats tend to have over them. Yet that imagined synthesis of Lipsky and Frederickson does not appear to have convinced modern scholars, who see line-officer discretion as hard to control and even a root cause of social inequity. For example, Caldero and Crank (2018) see police departments as upside-down bureaucracies where police managers have little or no control over line officers and their discretionary decisions. Because street level bureaucrats are tasked with impactful discretionary decisions with little direct supervision, they are invisible to managers and thus difficult to correct. Maynard-Moody and Musheno (2012b) are especially leery of police officers discretion, arguing it is within this discretionary power that social inequity is allowed to propagate: Racial disparities, then, occur in investigatory stops in which law enforcement personnel are granted substantial legal autonomy and are least subject to administrative oversight. 3.1.2.4 Principal-Agent Problems, Principled Agent? Dilulio (1994) Two competing views of discretion in BWC activation emerge. In the first, situated within the principal-agent problem literature (Miller, 2005), officers are likely to choose to activate a BWC according to their desires and attitudes rather than acting as required by their principals, the agency and the community. The principal-agent problem, then, arises when public employees act not as public-spirited souls but as self-seeking slugs who are disposed to shirk, subvert, and steal whenever and wherever they can get away with it (Dilulio Jr, 1994, p. 278). At the extreme of this view, officers will subvert the intended benefit of BWCs through their control of the cameras activation, specifically (Kerrison, Cobbina, &amp; Bender, 2018, p. 281) their ability to turn [the BWC] off or position a partner to block the view finder frame. Even in the absence of motivation to hide outright criminal behavior, in the principal-agent problem view, officers with cynical attitudes towards BWCs because of perceptions that camera footage will be used against them, or negatively impact their professional practices and discretion (Katz, Choate, Ready, &amp; NuÃ±o, 2014) may opt to activate the cameras less, as (Newell &amp; Greidanus, 2018, p. 4) officer perceptions and interpretations of the technology may impact how they use it. The second view of discretion in the BWC context can be situated with the Principled Agent theory advanced by John D. Dilulio (1994). Dilulio argued that principal-agent theory is useful in explaining the relatively rare instances where public employees chase their self-interest, subverting their principals wishes and guidance. What principal-agent theory lacks, argues Dilulio (p. 277), is sufficient explanatory power to help us understand what motivates public employees to perform thankless tasks, go above and beyond the call of duty, and make virtual gifts of their labor even when the rewards for behaving that way are highly uncertain at best. Following Dilulios work (1994), research has consistently found weak or non-existent links between officer attitudes and behavioral outcomes. Arrest decisions are not predicted by job satisfaction (Smith &amp; Klein, 1983), nor DUI arrests by attitudes about enforcement (Mastrofski, Ritti, &amp; Snipes, 1994; Meyers, Heeren, &amp; Hingson, 1989). Officer attitudes towards domestic violence are not strongly linked to domestic violence arrests (Stith, 1990), and officer attitude fails to predict coercive behavior by officers (Terrill &amp; Mastrofski, 2002). Engel and Worden (2003) directly investigate the link between officer attitude and behavior and find no link, concluding that agency policy and supervision is predictive of officers problem-solving. 3.1.2.5 Early PA writers The most recognized early writings on the role of bureaucracy in American politics come from Woodrow Wilson (Wilson, 1887), who would later go on to attain the presidency. Wilson held that politics and administration are, and should be, completely separate spheres of governing. This view prevailed for several decades in American political thought. This view flowed easily from the Madisonian view of American political structure (Madison, 1787) that was preoccupied with avoiding the evils of factions. Madison and other pluralistic writers hoped to balance the wheel of democracy by incentivizing electoral competition among competing interest groups. Wilsons (1887) initial conception of the politics-administration dichotomy was later enhanced by Frank Goodnow (2017), who sought harmony between the expression of the will of the state (politics) and execution of the same (administration). Goodnow believed that political control of the administrative functions was important, and pointed to constitutional separation of powers as driving conflicts between the two. Goodnow further believed that political parties therefore filled the void, spending time lobbying for their own administrators. The dangers of too much political control of the bureaucracy became clear in the wake of the Watergate era. In Moshers (1974) view Watergate was an aberration, and extension, and a culmination of events that had their root in a lack of bureaucratic independence. The overwhelming drive to re-elect Nixon subsumed all other ethical and legal considerations for many in the administrative agencies. There was a purge of top-level officials following Nixons first term, where anyone deemed too hesitant or lacking pure loyalty was removed. The Watergate climate was a result of too close a relationship between the political and administrative spheres, with the political side pressuring the administrative side to take action designed solely to enlarge presidential power. 3.1.2.6 Frederick Taylor and Scientific Management Taylor argued for better management decisions through the development of laws, rules, and even to mathematical formulae. He ends the selected article with an example of managing a baseball team, and states: Every single element of the game of baseball has been the subject of the most intimate, the closest study of many men A modern way of reading Taylors approach is to assume a statistical approach to public management. Taylors approach to management, particularly his desire to produce a larger output per manas well as an output of better and higher quality, was a science of the laboring body. The embrace of Taylorism was intextribly linked to an abstraction of the laborer, a view that has been called the productivism of early late 19th and early 20th century management (Rabinbach, 1992). Productivism was a view of human labor as (Scott, 1999, p. 98) a mechanical system which could be decomposed into energy transfers, motion, and the physics of work. In America, Taylor is responsible for establishing the technocratic framework in which to measure and administer that mechanical system (Maier, 1970). Taylorism was not a political system, or even a democratic one, but instead played to the high modernist, utopian visions (Scott, 1999) in America and beyond (Rabinbach, 1992, p. 272): Taylorism and technocracy were the watchwords of a three-pronged idealism: the elimination of economic and social crisis, the expansion of productivity through science, and the reenchantment of technology. The vision of society in which social conflict was eliminated in favor of technological and scientific imperatives could embrace liberal, socialist, authoritarian, and even communist and fascist solutions. Productivism, in short, was politically promiscuous. The promise of technological solutions was attractive to Progressives as they sought to alleviate class struggle and suffering. The classical public administration born in the pragmatic and Progressive early 20th century was one that embraced scientism. This embrace had the unintended effect of silencing the important voices of women who ran the settlement houses of the period. Science was understood to be a masculine pursuit, while the human centered approaches of the settlement women were left behind by Progressive men who tired of being slandered as long haired men in emasculated service of short haired women (Stivers, 2002). 3.1.2.7 The Modern Taylorism Taylorism did not disappear when classic public administration was replaced by behavioral, and then modern, conceptions of public administration. The Enlightenment endowed us with a modern tendency to prescribe transparency for all that ails our governing and government. A Panoptic Taylorism (Adams &amp; Mastracci, 2019) can be seen in modern policy making, for example, in placing body-worn cameras on police officers. Panoptic refers to the additional Foucauldian gaze (Foucault, 1977; Vickers, Birch, Galovic, &amp; Kennedy, 2016) of the public, policy makers, media, courts, and agency administration  upon officers, who are constantly aware of the possibility of being watched, even if no one ever actually watches the recording (p. 401). One can also detect the influence of Taylor in the policies that seek ever more control of when officers activate their cameras (Lawrence, McClure, Malm, Lynch, &amp; La Vigne, 2019). These policies are born in the (unlikely) hope of imposing perfect order and outcomes on what is at its taproot a profession imbued with chaos (Adams &amp; Mastracci, 2019, p. 401). 3.1.2.8 Representative Bureaucracy The politics-administration dichotomy is sometimes seen as a quaint or naÃ¯ve view of the shape of bureaucracy by scholars, but the normative value of a neutral bureaucrat still has a powerful hold on Americans view of the bureaucracy. 3.1.2.9 Big Data &amp; Bureaucracy Surveillance is a social process that invokes power (Foucault, 1977) that has to be understood through more than the decisionist or technocratic lenses (Comte, 1855; Habermas, 1970; Simon, 1972). Habermas (1970) distinguishes between what he deems the decisionist, pragmatist, and technocratic theories of expertise, arguing against the rational choice (decisionist) and technocratic conceptions of bureaucratic and political problem solving that reduces problems to the merely technical (Simon, 1972). Instead, he argues, we ought to adopt the early pragmatism of John Dewey and see problem solving as an ongoing conversation (Dewey &amp; Rogers, 2012). 3.1.2.10 Big Data, Policing, Public Admin, Ethics, Marx Between 2012 and 2018, New Orleans Mayor Mitch Landrieu contracted with big data analytics firm Palantir, using the companys predictive policing technology to address the citys murder rate, which was sixth highest in the nation. The partnership between city government and private sector big data provides fertile ground for the public policy questions swirling around the big data, algorithmic bias, and the future of public service work. On the one hand, the partnership was born and lived in secrecy, and the powers of surveillance it granted were out of balance with what is commonly expected for local government. As one critic summed up, Its almost as if New Orleans were contracting its own version of the NSA to conduct 24/7 surveillance of the lives of its people, (Winston, 2018). By other measures, the program was successful in its aim. New Orleans used Palantirs data and methods to identify the top 1% of violent crime drivers (Ferguson, 2017, p. 34) as well as those most likely to be the victims of homicide. The murder rate in New Orleans fell by nearly 22%, while gang-related murders fell by 55%, all in a relatively short span between 2011 and 2014. The comparative murder rates during the same period fell nationally by 4%, while the rate for the regional South was unchanged (FBI, 2012, 2015). Big data is new technology, but some of the questions it poses for public administration are old  how do we craft public policy which is effective, efficient, and equitable? Simple questions do not suggest simple answers, however. The big data in question is held privately but proxied through governmental use, research in this area is notably difficult. In Fergusons typology of big data , this is a form of black data, so named because it is opaque, has disproportionate effects on communities of color, and is the latest in-fashion technology. The data and algorithms used by companies such as Palantir hide behind patents and other commercial protections, and despite having a tremendous impact on public policy are not easily forced into the public (and scholarly) view through traditional means such as the Freedom of Information Act (FOIA). Framing the New Orleans example with public ethics values in mind, the rapid and significant reduction of homicides is undoubtedly effective, but there are reasons to suspect the big data solution was also an equitable one. Homicides in New Orleans disproportionately victimized black men. Analysis of the sharp drop in homicides between 2012 and 2015 (Asher, 2016) shows that Murder was down citywide almost exclusively because of drops in murder among African Americans. How should public administration scholars weigh the policy implications of thirty-two fewer black men killed in 2015 compared to 2012 against the disproportionate impact of big data policing on those who reside in a community targeted for high risk offenders and victims? Big data influences how, who, and where we police (Ferguson, 2017). The policy questions posed by the rapid rise of big data across public agencies, including police agencies, have been slow to gather the scholarly attention needed to shape the policy answers effectively. The expanding gap between the use of technology and public administration values (Battaglio &amp; Hall, 2018, p. 826) poses risks to privacy and performance as decisions are increasingly autonomous, and as technological advances outpace governments ability to regulate them. Gary Marx (Marx, 1998) is admirable for his far-seeing scholarship focused on structuring ethical approaches to surveillance, and his work is well-suited to help public administration scholars address the questions posed by governments use of big data. While Marx twenty-nine questions to interrogate the ethics of surveillance are too long to replicate here, his insistence on respecting the dignity of the individual, and focusing on the means, context, and conditions of data collection is a useful place to begin policy debates about government and big data. A theme throughout Marx writing on surveillance (Marx, 1998, 2003, 2016) is that surveillance is neither good nor bad. The World Health Organizations (WHO) massive surveillance programs are qualitatively different than similarly scaled efforts by national security organizations prying into the communications of citizens. Before we can draw substantive conclusions about a particular surveillance regime, we should understand and articulate the setting, means, and goals of the surveillance. The risk that algorithms will amplify the implicit biases of their human programmers is real, but so is the possibility of reduced explicit biases. New Orleans big data choices have been rightfully and widely critiqued for the decision to hide the program from public sight  but a 20% reduction in overall homicides and a 55% reduction in gang-related homicides, if replicable, is a tempting outcome for mayors across the country grappling with violent crime. The privacy critiques leveled by Ferguson and others concerned about the disproportionate effects of increased police surveillance on communities of color are no less salient in public policy debates, but with the New Orleans program titled NOLA For Life, the focus of practitioners on saving lives must be acknowledged. Big data policing poses risks, but given the history of disproportionate effects of traditional policing on communities of color, it begs the question: Compared to what? 3.1.2.11 Ethics Triad  Bowman &amp; West Three ethical approaches for public administration have been described as the ethics triad (Bowman, West, &amp; Beck, 2014). The ethics triad uses a results-based approach, a rule-based approach, and a virtue-based approach. Using a results-based approach is generally a utilitarian approach, and seeks the greatest good for the greatest number. The rules based approach is based in applying legal principles, court rulings, constitutional law, and regulations to an issue. The ethics triad is the virtue-based approach, which centers around ones own character, and nurtures individual and collective well-being (Bowman &amp; West, p. 119). Each of the three approaches can be used independently, but using all three is especially helpful in examining ethical issues wherein there is no clear sense of right and wrong (Bowman et al., 2014, p. 119). 3.1.2.12 Bureaucratic Ethics? OLeary  Could be its own thing with a bit more, or a good closing to an ethics essay? It is tempting to imagine a government bureaucracy in which all decisions are just ones, the policies equitable ones, and the outcomes simply a matter of fiat. Unfortunately, such a paradise does not exist. Our government is, crucially, of the people. And by virtue of being populated by the people, in all their flaws, our government is necessarily going to make flawed decisions, implement flawed policies, and have outcomes which range between problematic and disastrous. In this reality, the expectation that all public servants must always follow all orders is dangerous, and conflicts with the very ideals of our American experience. The response here will proceed first in answering the implicit ethic found commonly in pseudo-militaristic organizations, but prevalent across government agencies (OLeary, 2013): public servants should obey the orders they are given, and that political control of the administrative agencies is essential (Goodnow, 2017). Second, the value of dissent within government will be examined (OLeary, 2010). 3.1.2.13 To Obey or Not Obey The critics preference for unthinking obedience intends to normalize an idealized militaristic ethic into a context it does not belong. The critics base assumption here is that unfailing obedience is endemic to militaristic organizations, presumably informed by notions of military obedience. However, not only is the context wrong, the idea that the military is full of robotic yes sirs is to misunderstand the military and organizations organized along pseudo-militaristic lines (Caldero et al., 2018; Cowper, 2000). Perhaps the most famous American general of the 20th century, George S. Patten, famously said, If everybody is thinking alike, then somebody isnt thinking. The military thrives on the creativity of its members at every rank. In combat, under fire, facing imminent death  perhaps this is the time for unthinking response to orders. Yet even then, the military recognizes there are higher oaths and responsibilities every soldier has which supersede the need to follow orders. The Uniform Code of Military Justice (UCMJ, 1956), while making it clear that a service member must follow all legal orders (Articles 90 and 92), also is equally clear that service members have a duty to not follow obviously illegal orders (Reeves &amp; Wallace, 2016): Still, the UCMJ articles make clear that obedience is only required for lawful orders. Patently or manifestly illegal orders impose no duty of obedience on the service member and instead mandate disobedience. In fact, a service member who obeys an illegal order is individually culpable for the crime and cannot later assert following orders as a defense. In fact, this mandate to disobey illegal orders is the result of, and in response to, far too many atrocities committed by those who were just following orders. Both American and international courts have consistently found that there are human rights which are so protected, that to violate them in the pursuit of obedience simply cannot be allowed (Balfour, Adams, &amp; Adams, 2014). The My Lai Massacre, the genocides of WWII, and the Abu Ghraib atrocities all have the same lesson: The presumption of obedience, such as that found in articles 90 and 92, cannot be used to justify torture, commit war crimes, or participate in other unconscionable activities. These are examples of the manifestly illegal orders contemplated within the UCMJ itself. 3.1.2.14 Dissent So, the implied ethic of unfailingly loyal obedience to orders is not even a truth in the most militaristic of settings  the military itself. It follows, then, that to apply that ethic in less structured environments is inappropriate as well. What then is the value of dissent in the American public service? Rosemary OLeary (2013) covers this question with great depth. OLeary is not pollyannish regarding dissent  she is not arguing it is always appropriate, or even good, and provides plenty of support for the idea that there is a potential dark side of guerilla government (2013, p. 126). However, it is in her willingness to accept the middle ground that she is so convincing (p. 118): Just as it is difficult to argue that there is not a need for obedience by employees, it is difficult to argue overall that acting on ones strongly held personal and spiritual beliefs in certain contexts is improper. Most would agree that a public employee is not compelled by duty to obey obviously illegal orders, OLeary is more comfortable in exploring the marginal cases where answers are not so clear, and concludes (p. 110) that not all guerilla government is created equal  some dissenters are a canary in the coalmine while others are simply delusional single-issue fanatics. OLeary is comfortable in not finding some final, clear answer: most cases are not so easy to judge (p. 110) and the fact is (p. 117) that the tensions inherent in guerilla government will never be resolved. Her doubts are more convincing than the surety of those who suspect a robotic response by public employees. Government needs to be efficient, and therefore needs to exert hierarchal control over employees in order to ensure that efficiency. However, hierarchal control inevitably clashes with the federalist priority on local autonomy (Elazar, 1984; Madison, 1787). As illustrated in the Nevada Four case (OLeary, 2013, pp. 2741), sprawling federal agencies must rely on employees who are local, and some of those front-line employees will eventually begin to prioritize what they see as important over dictates from their bureaucratic superiors in faraway offices, who may have never even been to the areas they are attempting to wrest control over. While OLeary does not argue all dissent is good, nor can dissent be so easily dismissed as inherently flawed, or that it does not hold an important place in public governance. Dissent is itself an American ideal (OLeary, 2010; Ragosta, 2010; Sunstein, 2003). John Steinbeck (1952) captures this feature of Americana well: And this I believe: that the free, exploring mind of the individual human is the most valuable thing in the world. And this I would fight for: the freedom of the mind to take any direction it wishes, undirected. And this I must fight against: any idea, religion, or government which limits or destroys the individual. This is what I am and what I am about. So long as there is an American government which employs Americans, there will be a need to find ways to include the dissenter in public service. 3.1.2.15 Strategic Human Resources Management In the past, the human resources responsibilities within a public organization were warehoused within one department. However, as strategic human resources management (SHRM) has become the new standard, and the more of the previously core responsibilities of HR have been shifted to the front-line managers and supervisors of the organization. These responsibilities include recruitment, development, and promotion of employees, which are conducted by supervisors with the HR department generally in an advisory and policy role. Public administration authors have described best practices in new employee selection (Berman, Evan M., et al., 2015). 3.1.2.16 Differences in Managing Public &amp; Private Organizations Human resources management (HRM) has been defined as all management decisions that affect the relationship between the organization and employees  its human resources (Beer, et. al, 1985). Managing human capital in both private and public organizations has many of the same baseline tasks, and this essay focuses on two of them: recruitment of talent, and management of legal liabilities related to employees. While these discrete tasks retain similar functions across the private and public spheres, the management of public organizations differs broadly in that public organizations are constrained by civil service legal obligations. While some civil service protections have been under attack over the last two decades, the core protections remain in place and continue to enhance the function of public organizations as a model employer. Recruitment of employees to a public organization remains a core function of HRM. Compared to private sector management, in general public sector organizations differ in that the concept of civil service is central to the entire process. Civil service requirements are a positive, in that they demand the organization remain politically neutral, transparent, and committed to hiring the most professionally qualified. Of course, private sector employers want to hire the best candidate as well. However, they are not required by law to do so, and a private sector organization is allowed broad discretion in determining what factors go into deciding which candidate will be hired. For example, in a public organization there are clear prohibitions on nepotism, the hiring of employees based on familial relationships. However, in a private organization it is not unusual for the head of a firm to hire, groom, and eventually appoint a family member to lead the organization. This kind of nepotism is seen in private organizations from small firms to large organizations such as multi-billion conglomerate News Group, headed by Rupert Murdoch. In 2013, Mr. Murdoch appointed one son as deputy director of News Group and his other son as CEO of British Sky Broadcasting Group (a subsidiary of News Group). The protections afforded by the civil service requirements of public organizations is one of the strongest, and most positive, differences between public and private HRM, in that it prevents public organizations from becoming vehicles dedicated to personal dynasties. Civil service requirements are not found only within the recruitment of new employees. Public HRM must also operate carefully in the discipline and firing of employees, which is affected by another aspect of civil service: due process, generally defined as the protections an employee has for continued employment. While a private sector employee is almost always an at will employee, and can be terminated for any, or no, reason, a public employee has a property interest in continued employment, and a public organization must show the employee has been given due process before stripping the employee of that property interest. While this property interest has been stripped in some sectors of government employment (Georgia, Florida, and Wisconsin for example), for the most part due process is still very much part of the public HRM landscape. The due process requirements have historically been a bedrock principle of public employment and a positive aspect of the civil service. 3.1.2.17 Current Trends in Public Workforces The most significant trend in the current workforce is the impending generational shift as Baby Boomers, prepare to retire. Preparing our public organizations for this generational shift is among the most important strategic planning we can do. With careful planning and introduction of family/work programs, we can address the concerns of each generation, ensuring public employment remains an attractive option for each. Baby Boomers, born between 1946 and 1964, are not simply retiring to a life of leisure. In fact, as their parents have reached advanced age, up to 35% of workers this age are responsible for providing elder care. This responsibility has been estimated to cost up to $3 trillion in aggregate lost wages and support (Berman, Evan M., et al., 2015), up to $33 billion in lost productivity (Dobkin, 2007), and constitutes a tremendous time and financial burden on the caregiver. In fact, up to 15% of employees faced with primary care of their elderly parents left the workforce (Dobkin, 2007). Public administrators, looking to keep some of their most experienced employees in the workforce as long as possible, should be looking at policies to help address this concern for baby boomers. By crafting formal elder care policies, such as those found at IBM, public administrators can begin to meet the challenge. IBM developed the nations first corporate elder care policy, as the companys leaders recognized the increased burden and cost of the care to their employees. IBM offers management seminars to help their supervisory staff better understand and respond to their employees needs, up to six hours a year of paid elder-care-specific leave, external resource referrals, and even training on how to give better caregiving for the employee. Dobkin (2007) argues these are the types of low-cost interventions have high internal and external value, and help increase retention of employees who find themselves in the position of primary caregiver of an elderly family member. Managing for different generational needs is a relevant topic for public managers to consider. The discussions and text readings on the subject reminded me of how important the shift is, especially in regards to the sheer numbers of Baby Boomers and Millennials versus Generation X employees. With Generation X at approximately one-quarter the number in the other two generations combined, I begin to wonder at what the future of leadership in our organizations will look like. As the boomers retire, there are simply far fewer Generation X employees to advance to the unfilled positions, leaving organizations with a difficult choice: do we fill those positions with some relatively unskilled Generation X employees, or advance some hotshot Millennials who may have the skillsets, but lack the wisdom of life-experience to use those skills wisely? Of course, this is a wide-angle, strategic issue, and in any individual selection the optics may be different. But strategically, it appears organizations must start to come to terms with the idea that increased training and early mentorship may be the only answer. 3.1.2.18 Disparate Treatment versus Disparate Impact Disparate treatment is intentional employment discrimination, based on a persons race, color, religion, sex, national origin, age, or disability. Known as Title VII protections, employers cannot make employment decisions based on these categories. Title VII laws are decades old, and intentional discrimination relatively rare. However, under the theory of disparate impact, employers may also be held liable for employment decisions which have a negative, disproportionate effect on one of the protected Title VII classes. This theory is based in a 1971 US Supreme Court decision in Griggs v. Duke Power Co. The court held that employers who make employment decisions which disproportionately affect a protected class can be held liable. This protection was further incorporated into the Civil Rights Act of 1991. Employers, forced to respond to increasing numbers of both disparate treatment and disparate impact legal claims, increasingly relied on bona fide occupational qualification, or BFOQ. This legal defense relies on the employers claim that there is an essential job requirement which requires discriminate treatment. For example, while it is normally illegal to discriminate based on sex, a movie producer is allowed to audition only female performers for a female role in the film. 3.1.2.19 Law &amp; Public Administration Case Study: Borough of Duryea, Pennsylvania, et al. v. Guarnieri This case involves Charles Guarnieri, police chief (respondent), and the Borough of Duryea (petitioner). Chief Guarnieri was fired by the Borough, but an arbitrator later awarded the Chief his job back. Upon his return, the Borough issued a set of directives to the Chief setting out his duties, and also denied the Chiefs request for overtime. The Chief filed a second complaint, and again the arbitrator found mainly for the Chief, ordering some of the directives withdrawn and/or altered. The Chief then filed a civil rights lawsuit against the Borough, alleging he was being retaliated against for petitioning for his job back, in violation of the Petition Clause of the First Amendment. The case began in a Federal District court, where the jury found for Chief Guarnieri. The Borough appealed to the Third Circuit Court, which upheld the jurys decision, although the appeals court reversed punitive damages. The Borough appealed again to the US Supreme Court, which granted certiorari (Borough of Duryea, Pa. V. Guarnieri, 2011). The Court here is considering whether a public employee can sue their employer for retaliation under the First Amendment (petition clause) if the matter for which the employee was retaliated against was a private concern. In a unanimous decision, the court held a public employees rights to petition are not violated when they petition for a private concern and are thereafter (allegedly) retaliated against. In the holding, the court decided: A government employers allegedly retaliatory actions against an employee do not give rise to liability under the Petition Clause unless the employees petition relates to a matter of public concern. The Courts holding here protects the ability of public administrators to make the required daily personnel decisions without every decision being automatically turned into a constitutional fight overseen by courts. In protecting administrators ability to make personnel decisions, the Court also freed the lower court systems from being overwhelmed by lawsuits from employees upset with administrators decisions. The Court sidestepped an important question: whether a lawsuit constitutes a petition as set out in the First Amendment. The Court only answered whether the issue at stake must be public matter, versus a private matter, leaving administrators in the uncomfortable position of attempting to determine whether any future lawsuits can be construed as a public matter. For instance, does a lawsuit with more than one petitioner start to become more likely a public lawsuit? What about a union suing a public entity on behalf of its 2000 members, does that now become a public matter? 3.2 Policy Frameworks and Police Technology: The Case of Body-Worn Cameras 3.2.1 Introduction The rapid adoption of body-worn cameras in American policing between 2014 and 2018 presents many exciting research questions. Top among those questions: How did up to 90% of the more than 18,000 individual police departments come to adopt the technology (Hyland, 2018) in such a short period? This essay will proceed in two sections. In the first section, three mapping exercises will explore the stakeholder, policy, and regulatory maps in police body-worn cameras. The second section continues as three policy frameworks are evaluated and applied to research questions involved in investigating the unforeseen effects of the technology, concluding with a critique of the most common theory applied in body-worn camera research, the theory of deterrence, which is a model of linear policy outcomes. 3.2.2 Policy in Policing Policing is an aspect of government that affects everyone in a community, whether or not an individual has direct contact with officers or not. The Bureau of Justice Statistics report on their triennial Police-Public Contact Survey (Davis, Whyde, &amp; Langton, 2018) estimates that 53.5 million persons over age 16  representing a fifth of the population of the same age  had direct contact of any kind with police officers in the previous twelve months. The data suggests that every member of the community has a stake in policing, and can be considered at least a secondary stakeholder. Policing in the United States remains a state and local government affair predominantly, and with rare exception, police regulation is a function of municipal and county officials. The decision to implement body-worn cameras is typically made by the chief executives of an agency  either a police chief or county sheriff  along with local politicians such as mayors, city councils, and city managers. However, the rapid adoption of body-worn cameras by these policymakers is at least partially explained by the federal funding made available by President Obama in 2015, which set aside up to $75 million in grants to local agencies to purchase the equipment (Edwards, 2015). There is currently no federal regulatory agency charged with overseeing body-worn cameras. In some cases, the Department of Justice has required body-worn cameras as part of consent decrees with agencies operating under their auspices (Newark Police, 2018). Still, this type of federal oversight accounts for a vanishingly small number of the more than 18,000 police agencies in the U.S., let alone those that have adopted body-worn cameras. While the stakeholder map above suggests there are a large number of primary and secondary stakeholders in body-worn camera policy, the reality of American policing has precluded national policy and regulation. Except for the funding mechanism pushed by President Obama in 2015, there is no other national policy to turn attention to in the body-worn camera policy environment. Because of the balkanized nature of policing in the United States, constructing a clear policy and regulatory map is impossible at this time. The most robust tracking of body-worn camera policy at the state and municipal level is done by The Leadership Council on Civil and Human Rights (LCCHR). The LCCHR report  titled BWC Scorecard, (Yu, Cook, &amp; Paluch, 2017)  tracks a number of measures related to body-worn cameras. These measures include whether individual agencies are funded by the Department of Justice, have a policy available to the public, allow officer discretion in camera activation, protect privacy, allow officer review of footage, prohibit footage misuse, allow public access to footage, and limits the use of biometric technologies (such as facial recognition). While robust, the policy tracker is limited in that it has not been updated in over a year, likely due to the overwhelming task of tracking this kind of information. A further limitation is that the measures used are strongly influenced by the LCCHR organizational values, which are tied to their Civil Rights Principles on Body-Worn Cameras statement (Yu et al., 2017, p. 322). The values in that statement tie certain policies to civil rights positions which have changed dramatically since they were first constructed in May 2015. Just one example is the demand that police departments consider individual privacy concerns before making footage available to broad audiences (p. 322). While my research position agrees with this assessment (I. Adams &amp; Mastracci, 2017), the majority of policy research in this area equates broad availability of body-worn camera footage to be a public good which increases transparency and accountability. Regardless, the assessment of the BWC Scorecard that certain departments are failing to implement a specific policy should be evaluated against the values bias of the organization, as it is likely there is a policy, but it happens not to include the policy prescriptions prized by LCCHR. At the state level, some legislatures have mandated that all agencies within their jurisdiction use body-worn cameras. Nevada passed such a law in 2017 (Whaley, 2017), which ordered all police departments to equip officers with the technology by July 1, 2018. Here locally, the Utah legislature has relatively little guidance on police use of body-worn cameras, requiring only that the agency have a policy guiding their use (if they are implemented) and that the cameras be used during forced-entry warrants (again, if the agency has implemented the cameras). The Utah legislature also passed rules prohibiting police officers from using body-worn cameras in hospitals unless for a normal police call (Gessel, 2017), and protecting any footage (under HIPPA and GRAMA guidance) which is recorded to restrict its distribution. These context-based rules are among the most common type of state legislation related to body-worn cameras, with lawmakers aiming to regulate and restrict how the cameras are used, how the resulting footage is distributed, how long the footage is stored, and if the public has a presumption of access to the footage (Lei, 2018). 3.2.3 Policy Frameworks Any number of theoretical frameworks can be fruitfully applied to the research questions presented by police body-worn cameras. To date, research into the effects of body-worn cameras has been focused on testing theories of deterrence, most with a focus on testing empirical data at the department and community level. However, within this paper, I will concentrate on three which I believe are most useful for addressing specific research questions: What are the unintended effects of police body-worn cameras on communities, people, and organizations? 3.2.4 Social Construction of Target Populations In the third quarter earnings call by corporate leaders of Axon Enterprise, Inc., the largest manufacturer of police body-worn cameras in the world, CEO and founder Patrick Rick Smith explained why the company made the core functionality of Axon Records free to police agencies (Axon, 2018, p. 4): We see the real value in Records is in the data, not in the form-filling software. We have the largest data set in public safety. Were now at over 40 petabytesthats 40 million gigabytes. What are the implications of a single corporate actor retaining the data of government? How do policymakers and the public ensure such data is used appropriately (if any use is allowed at all), including body-worn camera footage? Unfortunately, the academy has been almost silent on these issues, which are appropriately investigated by policy and public administration scholars. One way to inquire into a policy is to examine the silences and assumptions within it (Foucault, 1991), and social construction of target population (SCTP) theory (A. Schneider &amp; Ingram, 1993) can help explain how body-worn camera implementation has disproportionately affected different stakeholders. One such considerable silence in both the academic and popular literatures has been the big data, big technology implications of body-worn cameras. The questions raised by huge, persistent databases of body-worn camera footage, biometric technologies, and disproportionate uses of the cameras in communities of color have all been mostly overlooked, and as a result, few policy solutions have been proposed, let alone implemented. Between 2012 and 2018, New Orleans Mayor Mitch Landrieu contracted with big data analytics firm Palantir, using the companys predictive policing technology to address the citys murder rate, which was sixth highest in the nation. The partnership between city government and private sector big data provides fertile ground for the public policy questions swirling around the big data, algorithmic bias, and the future of public service work. On the one hand, the partnership was born and lived in secrecy, and the powers of surveillance it granted were out of balance with what is commonly expected for local government. As one critic summed up, Its almost as if New Orleans were contracting its own version of the NSA to conduct 24/7 surveillance of the lives of its people, (Winston, 2018). Big data influences how, who, and where we police (Ferguson, 2017). The policy questions posed by the rapid rise of big data across public agencies, including police agencies, have been slow to gather the scholarly attention needed to shape the policy answers effectively. In a recent editorial in Public Administration Review, Paul Battaglio and Jeremy Hall warn about the expanding gap between the use of technology and public administration values (2018, p. 826), with risks to privacy and performance as decisions are increasingly autonomous, and as technological advances outpace governments ability to regulate them. The widening of police surveillance tactics risks transforming police officers bodies into mobile surveillance tools (I. Adams &amp; Mastracci, 2017) and is a crucial ethical challenge to be addressed by public administration scholars. Gary Marx (1998) is admirable for his far-seeing scholarship focused on structuring ethical approaches to surveillance, and his work is well-suited to help public administration scholars address the questions posed by governments use of big data. While Marx twenty-nine questions to interrogate the ethics of surveillance are too long to replicate here, his insistence on respecting the dignity of the individual, and focusing on the means, context, and conditions of data collection is a useful place to begin policy inquiries into government surveillance, body-worn cameras, and big data. 3.2.5 Multiple Streams analysis The sharp rise of body-camera adoption in a relatively short period of time suggests punctuated equilibrium (PE) theory (Baumgartner et al., 2009; True, Jones, &amp; Baumgartner, 1999) as an understandable framework to turn to, but in the end PE relies too strongly on assumptions of rational, linear theory. Multiple streams analysis (MSA), first put forth by John Kingdon (1995) contains many of the advantages of PE, while deviating from linearity and offering a more compelling way to conceptualize the complexity of policy. MSA remains one of the most cited policy theories and is a key influence on the study of public policy (Cairney &amp; Jones, 2016, p. 1). A strength of MSA is its focus on policy entrepreneurs, which in the context of body-worn cameras appears important in explaining the rapid adoption of the technology across the United States. MSA is best known for the metaphor of three streams within the policy process  the problem stream, the politics stream, and the policy stream. Within the broad policy environment, these three policy streams do no often align. When they do align  naturally or more often with the assistance of policy entrepreneurs  policy change can happen. Policy entrepreneurs are the individuals and organizations who recognize when there is an opportunity to bring the MSA streams into sync with one another, in pursuit of a preferred policy outcome. In the case of body-worn cameras, one critical policy entrepreneur is the company Axon Enterprise, Inc. (formerly Taser International), the largest manufacturer of police body-worn cameras in the world, and owner of the repository for the vast majority of footage recorded by police body-worn cameras (Axon, 2018). The American tale of body-worn cameras begins with an incident for which there was no video. In August 2014, Michael Brown was killed by Ferguson police officer Darren Wilson. In the immediate aftermath of the shooting, witness accounts of the incident were broadcast widely, and as witnesses recounted Michael Brown being shot on his knees, or with his hands in the air, or both, the incident quickly picked up national urgency. Despite contemporary witness accounts being later disproven or retracted during the most extensive federal investigation into a police shooting in modern history, the belief that Michael Brown was the victim of racist police brutality was soon turned to rage as Ferguson and nearby St. Louis were the site of widespread rioting and protest. Into this context, President Obama announced the formation of the Presidents Taskforce on 21st Century Policing. The final report of the taskforce (Office of COPS, 2015) called for the adoption of body-worn cameras by policing agencies, and as President Obama announced the findings of the task force he simultaneously announced federal funding of $75 million dollars to assist agencies in purchasing the camera hardware. The announcement of federal dollars was a boon for Axon, which had so far had limited success in selling the technology to police agencies. At the time, less than 25% of agencies had even experimented with the cameras in testing scenarios (Miller &amp; Toliver, 2014), and only one academic study (the Rialto Study) of body-worn cameras had been published (Ariel, Farrar, &amp; Sutherland, 2015), the results of which showed substantial reduction in the use of force by police. Despite no other study being able to reproduce the results of the Rialto study, media coverage of the study was intense (Schneider, 2017), and the report was highlighted in the Presidents taskforce report (Office of COPS, 2015). Even with federal funding, increased public demand for transparency, some academic research support, Axon still needed to convince police executives that body-worn cameras were a viable policy solution. Separate investigations by The New York Times (Gelles, 2017), the Wall Street Journal (Frosch &amp; Elinson, 2016), alleged that Axon had bought their way to domination of the market through expensive trips and post-retirement jobs for police chiefs who pushed through non-competitive bids in the wake of the 2015 federal funding. The Associated Press (Foley, 2015) connected Salt Lake City Police Department head Chief Chris Burbank to the scandal, though Chief Burbank insisted his selection of Taser (later Axon) as the sole body-camera supplier through a non-competitive bid had nothing to do with personal gain. Axon continues to maintain their practices were commonplace despite competitors alleging the company awarding police chiefs lucrative contracts after they retire (Gelles, 2017, pp. 31). Regardless, Axon was successful in dominating the market and is estimated to control approximately 75% of the nearly $1 billion per year in American police agency spending on body-worn cameras (Gelles, 2017). Understanding the companys moves to control the market in the wake of a crisis is a classic example of policy entrepreneurship. The company had a pre-existing solution and recognized a moment when the policy stream (federal funding), the problem stream (public demand for accountability), and politics stream (presidential taskforce call for cameras, support from nonprofit and advocacy organizations). In recognizing the streams had converged, Axon aggressively marketed their solution by implementing a sales strategy of making the cameras free to departments and charging instead for their storage solution for the resulting petabytes of camera footage. Axon body-worn camera contracts for large agencies are expensive, with the Los Angeles County Sheriffs Department planning $84 million over five years (Times Editorial, 2018), while the New York Police Department pays $6.4 million per year for 3,000 cameras (Southall, 2018), and Philadelphia signed a four-year, $12.5 million agreement with Axon without even consulting competitors (Allyn, 2017). The flexibility of multiple streams analysis is useful when examining body-cameras and their rapid adoption, but the theorys strength is in understanding events in a post-hoc analysis and it not predictive, doing little to prove or disprove the hoped-for effects of the cameras  to reduce police use-of-force. The rational man underpinnings of those hopes were validated in the Rialto Study (Ariel et al., 2015), but have been challenged in other large research studies (Yokum, Ravishankar, &amp; Coppock, 2017), sometimes even by the same researchers (Ariel et al., 2016, 2018). Understanding how the rational man framework of deterrence theory is key to understanding how even rigorous experimental studies can fail to establish consistent results. 3.2.6 The Rational Man, Linear Theory, and Deterrence In the context of body-worn cameras, public and policymaker beliefs regarding police use-of-force and academic misapplication of the theory of deterrence both contributed to the turn to body-worn cameras. Incidents involving the use of force account for less than 1% of interactions between police officers and the public (Lersch &amp; Mieczkowski, 2005), and incidents of unlawful (excessive) force only a small fraction of those incidents. As tricky as establishing how often police use force, attempting to define (and thus count) excessive force incidents in research may be impossible to answer, however, because applications of definitions to incidents will always be open to challenge (K. Adams, 1996, p. 53). This difference equates to more than sophistry and interpretation. Deterrence theory is centuries old (Beccaria, 1764), and forms the basis for mainline body-worn camera research. Simply put, deterrence theory expects to alter police use-of-force with the expectation that officers will rationally respond to camera surveillance by following the rules when they believe they are being observed, and that detection of rule-breaking is likely (Nagin, 2013). Body-camera researchers propose that the cameras act to ensure that the probability of apprehension for officers using illegitimate force is high, thus deterring them from such unlawful acts. As the degree of deterrence increases, officers are less likely to use force (Ariel, Sutherland, Henstock, Young, &amp; Sosinski, 2017, p. 2). This theoretical stance is problematic at the conceptual and operational level  police officers do not consider use-of-force to be an illegitimate behavior, and therefore are not likely to be deterred from it. To be sure, there may be a deterrent effect on illegitimate and excessive force, but that is not what is being measured by body-camera researchers, and may explain why the most extensive experimental study of body-camera outcomes to date  the Washington DC study  did not detect a single statistically significant effect on any outcome, including use-of-force, prompting the authors to conclude we should recalibrate our expectations (Yokum, Ravishankar, &amp; Coppock, 2017, p. 22) regarding body-worn cameras. The failures of the rational man approach to body-worn cameras are evident in the equivocal research record since the Rialto Study (Ariel et al., 2015). While four works have shown statistically significant reduction in use-of-force by police officers wearing the cameras (Braga, Sousa, Coldren Jr, &amp; Rodriguez, 2018; Henstock &amp; Ariel, 2017; Jennings, Fridell, Lynch, Jetelina, &amp; Reingle Gonzalez, 2017; Jennings, Lynch, &amp; Fridell, 2015), none of the studies have established a magnitude of effect similar to the ones found in Rialto. Contrasting those three reports are the eight since the Rialto Study which have not found a reduction in use-of-force (Ariel et al., 2016; Braga, Barao, McDevitt, &amp; Zimmerman, 2018; Headley, Guerette, &amp; Shariati, 2017; Peterson, Yu, La Vigne, &amp; Lawrence, 2018; Stratton, Clissold, &amp; Tuson, 2015; Toronto Police Service, 2016; White, Gaub, &amp; Todak, 2017; Yokum et al., 2017), and in at least one (Ariel et al., 2016) the authors find that not only is there no reduction in police use-of-force, but assaults on officers rose 15%. 3.2.7 Conclusion Overall, the picture emerging from body-worn camera research is that the anticipated effects of [body-worn cameras] have been overestimated (Lum, Stoltz, Koper, &amp; Scherer, 2019). Despite the mixed research record, the reality is that body-worn cameras are here, and are likely to stay a part of the American police officers toolkit. Future research to uncover the silences in what outcomes are researched, and what is not, is key to understanding the full effect of the technology. 3.3 Dune and Public Administration Theory I include this one because its important to keep some writings that are a bit off-the-wall ready to employ. I never did manage to use this anywhere, but it was more fun to write at the time than another electoral theory piece! Do not depend only on theory if your life is at stake. Bene Gesserit commentary Chapterhouse: Dune Universally lauded at the time of its publication in 1965, Frank Herberts novel Dune won the Nebula Award in 1965. Considered among the best American speculative fiction novels, Dune is the best-selling science fiction novel of all time. Susan McLean presents the novel Dune well, [Herbert] suggests that the human longing for absolutesis doomed to failure because any tendency carried to the extreme will eventually lead to its opposite. This paper will attempt to supplement McLeans idea of balance through a focus on political leadership and gender politics, seen through several classic theories in the field of public administration. I begin with an examination of whether Dune provides a fitting canvas upon which we can draw lessons of politics and administration. I will then continue with the primary examinations of political leadership and gender politics in the novel. First, by examining Dune as essentially a political novel, the issue of leadership in the political context will be examined through the public administration theories of Douglas McGregor, Woodrow Wilson, Frank Goodnow, and A.H. Maslow. The second main thrust of this paper will directly address one of the core themes of Dune: gender politics. Using the ideas set forth by Camilla Stivers in her book Bureau Men, Settlement Women: Constructing Public Administration in the Progressive Era, this paper uncovers direct similarities between two organizations: the settlement women in Stivers work and the Bene Gesserit in Herberts. 3.3.1 Dune as Political Novel This paper is not the first to draw connections between science fiction and the study of politics. Science fiction critic Clyde Wilcox commented, Science fiction allows political scientists to expand their thinking about the ways that different cultures develop different politics. ... Such thought experiments can stretch the imagination, and help us rethink our theories, categories, and hopes. The field of science fiction can be seen as the literature of ideas, or as writer Kingsley Amis wrote, Idea as hero. Dune, sitting atop this literature of ideas, is a novel which takes place on the desert planet Arrakis, aka Dune. Arrakis is the sole source of melange, or spice, which sustains a galactic empire in decline. This spice is at the center of the byzantine House politics, intrigue, religious war, and gender clash fleshed out in the novel. Spice is effectively a stand-in for power, in all the different connotations of the word. Thus politics both small and large are at the center of the novel. As Kevin Mulcahy observes, There is in Dune an explicit and conscious engagement with political issues. 3.3.2 Paul Atreides, aka the Kwisatz Haderach The hero of Dune is Paul Atreides, and he will be examined in some detail throughout this paper. The heir to the House of Atreides, he is raised in a privileged space before becoming the prophesied messiah figure, the Kwisatz Haderach. Literary critic Scott Sanders writes that science fiction is the home of invisible men and women and the field as a whole reproduces the experience of living in a regimented, rationalized society, within which the individual has become anonymous: persons are interchangeablethe individual is subordinated to the system. Herbert introduces Paul Atreides within that context, an adolescent whose own desires are subjugated to the expectations of his father Duke Leto Atreides, the needs of his family, and the desires of the empire. However, Paul rises above expectations, becoming the Kwisatz Haderach and eventually leading a native tribesfolk (the Fremen) into jihad, gaining independence for the natives from the Empire by controlling the spice upon which it depends. 3.3.3 Dune and the Administrative State The worlds of Dune are ruled by aristocratic families, comprising the Empire. Byzantine court politics reminiscent of those found in middle history Europe rule the political landscape. The administration of such a power structure is predictably bureaucratic, relying on a very strict chain-of-command. Woodrow Wilson would have recognized much in Dune, especially his statement all sovereigns are suspicious of their servants. During a conversation with his father, Duke Leto Atreides, Paul Atreides is told: Give as few orders as possible. Once youve given orders on a subject, you must always give orders on that subject. But whereas his elders may rely on simply giving orders and trusting in their autocratic bureaucracy, Paul sees government differently, implicitly understanding administration will be required. Paul states, A plan depends as much on execution as it does upon concept. Woodrow Wilson would recognize Pauls impulse. In his foundational text The Study of Administration, Wilson writes: Administration isgovernment in action. Wilson again: Public administration is the detailed and systematic execution of public law. A quarter-century later, Frank Goodnow echoes Wilson, drawing a distinction between politics and administration: Politics has to do with policies or expressions of the state will. Administration has to do with the execution of these policies. The elite ruling class in Dune does not see in its workers any ability to rise above their station. In a particularly telling sequence, the main antagonist Baron Vladamir Harkonnenn seems pleased with himself as he readies his army for battle against House Atreides: The whole universe sat there, open to the man who could make the right decisions. The uncertain rabbits had to be exposed, made to run for their burrows. Else how could you control them and breed them? He pictured his fighting men as bees routing the rabbits. And he thought: The day hums sweetly when you have enough bees working for you. Both Duke Atreides and Baron Harkonnens view of leadership is clearly Theory X, as Douglas McGregor explains the basic beliefs of that theory: The average man is by nature indolenthe works as little as possible. He lacks ambition, dislikes responsibility, prefers to be led. He is gullible, not very bright, the ready dupe of the charlatan and the demagogue. However, true to McLeans observation regarding Dunes focus on balance, Pauls approach to leadership is not limited to an autocratic, bureaucratic style. He is tutored from a young age not only by his father the Duke, but by various teachers, including Thufir Hawat, a mentat or human computer (a deeper discussion of mentats is included later in this paper). Whereas the Duke identifies power and fear as the tools of statecraft, Thufir Hawat teaches Paul that, A ruler must learn to persuade, not compel. Further conflicting Paul is a lesson from another of his tutors, and religious leader, the Bene Gesserit Reverend Mother: Grave this on your memory, lad: A world is supported by four things she held up four big-knuckled fingers. the learning of the wise, the justice of the great, the prayers of the righteous and the valor of the brave. But all of these things are as nothing She closed her fingers into a fist. without a ruler who knows the art of ruling. Make that the science of your tradition! These conflicting lessons are in fact Herberts attempt to allow the reader to see the different forces which will eventually be fused together as Paul Atreides becomes the messiah figure, the Kwisatz Haderach. Paul synthesizes this art of ruling, diverting from his fathers traditional view of power and fear. In both the Reverend Mothers and Thufirs maxims we see McGregors Theory Y move to the forefront, relying on leaders who do not simply sit atop a bureaucratic machine of rabbits and humming bees, moving the machinery of people through power and fear. Instead Paul is being taught a competing type of leadership, where people matter, and where motivation and persuasion are more effective in accomplishing the leaders goals. McGregor explains this theory is not the abdication of responsibility, but the willingness of the manager (in Herberts context: royal leadership) to engage and participate. Whereas Baron Harkonnen sees his bees humming along from afar, atop a parapet, Paul eventually flees into the desert, inserting himself among the native Fremen. There he takes a wife among the Fremen, trains in their guerilla warfare tactics, and leads them into battle at the head of their army. Along the way he improves what McGregor would characterize as their living conditions, their physiological and safety needs. Where the Baron is a distant manager, Paul is in the midst of his men practicing participation and allowing self-direction. Of course, the conflicting maxims and proverbs taught to a young Paul Atreides would no doubt severely disappoint Herbert Simon, who questioned the usefulness of such statements in his essay The Proverbs of Administration. After all Simon argued, what use are proverbs when they explain everything, and yet nothing at all? Simon saw the use of proverbs not as decision making devices, but as a convenient tool of self-justification: If it is a matter of rationalizing behavior that has already been decided upon, proverbs are ideal. Since one is never at a loss to find one that will prove his point  or the precisely contradictory point, for that matter  they are a great help in persuasion, political debate, and all forms of rhetoric. Paul would not see Simons critique as too useful however, as Paul needs persuasion and rhetorice on his journey. Frank Herbert eventually develops Pauls leadership approach as a balance, for as a leader of the Fremen, Paul abandons neither power nor fear, using both to great effect. However, Paul also uses insights into human needs and desires to both motivate his own Fremen forces, and bring ruin to his Empire enemies. In his paper A Theory of Human Motivation, A.H. Maslow identifies a hierarchical theory of human motivation, with physiologic and safety needs comprising the base needs. Maslow identifies self-actualization as the highest need a man can obtain: What a man can be, he must be. Pauls need to transform into the Kwisatz Haderach is a direct example of this self-actualization. But if he is to obtain that status, he must first enlist the Fremen to his cause, and destroy the Empires ability to pillage Arrakis. Perfectly adapted to the austere desert planet, the Fremen care only for water, and using Maslows analysis, are therefore motivated by the same. Conversely, the Empire is only on Dune in order to harvest spice, which functions in the Dune universe as a stand-in for power. Spice allows interstellar travel for the Empire, grants the Bene Gesserit (described in some detail later in this paper) their mind-reading and other super-human powers, and the Mentat their ability to function as human super-computers. Maslow would argue that both spice and water function as base physiologic needs, and until they are satisfied no other higher needs can be met. Herbert recognizes this, and in fact the base needs or both people and organizations for water and spice drive all other political dramas which unfold during the novel. Directly addressing the Fremens desire for freedom from Empire domination, Maslow comments on esteem needs in the notes section of his essay: Whether or not this particular desire is universal we do not know. The crucial question, especially important today, is Will men who are enslaved and dominated inevitably feel dissatisfied and rebellious? We may assumethat a man who has known true freedomwill not willingly or easily allow his freedom to be taken away from him. But we do not know that this is true for the person born into slavery. Herbert, through Paul Atreides, answers Maslows question. The Fremen, exploited for centuries by an Empire who values them only as slaves and laborers, turn to Paul in their struggle for self-direction and freedom. By the end of the novel Paul Atreides has completed his inner and outer journey, and is the messiah figure, the Kwisatz Haderach. This title has been thought to be a derivation of the Hebrew phrase kefitzat haderech, which is literally translated as to shorten the way. In becoming the Kwisatz Haderach, Paul is the only character to achieve what Maslow would describe as self actualization, in which an individual is doing what he is fitted for. Paul, the product of a millennia-long breeding program planned by the Bene Gesserit, is not only doing what he is fitted for, he is then elevated above any base needs, shortening the way towards enlightenment, above all spice, water, or other needs. 3.3.4 Bene Gesserit, the Guild, and Mentats: Gender in Dune Dune has been critiqued by feminist writers almost since its inception. First-wave feminist critics found the novel especially wanting. Writers such as Kathy Gower argued the female characters in Dune appear with less frequency than men, and in her view the women are relegated to passive mothers of men, given only to domestic duties. This paper will argue that critiques such as those offered by Gower are overly simplistic and ignore Herberts treatment of the Bene Gesserit as a character of its own, standing equal with and sometimes above the male dominated power structures sharing the stage. Three schools in the Dune universe serve as examples of the gender dynamics of the novel. 3.3.4.1 The Fulcrum and the Schools Frank Herbert writes in Dune: Schools were started to train human talents The Guild emphasizes almost pure mathematics. Bene Gesserit performs politics. The organization known as the Bene Gesserit dominates the political landscape in Dune. An ancient and mysterious order of women, the Bene Gesserit train (almost exclusively female) acolytes in diplomacy, espionage, sex, martial arts, lie detection, and mind control. The Emperors primary advisor, the Truthsayer, is the Reverend Mother, head of the Bene Gesserit, and his wife is an acolyte as well. The hero Pauls mother Jessica Atreides is a high ranking member, and has an incredible influence on him throughout the novel, training him in Bene Gesserit ways against the orders of her leadership. The Bene Gesserit both create and destroy royal Houses through minutely planned machinations. The Kwisatz Haderach, a messiah prophecy fulfilled by Paul, is the result of a breeding program controlled and planned by the Bene Gesserit for millennia. Far from being the weak mother figures criticized by early authors, women stand atop the power structure, guiding mostly guileless men towards their own ends. The Guild is a male-dominated school, playing foil in some ways to the Bene Gesserit. The male-dominated Guild is a space travel monopoly, charged with development of pure mathematical analysis in its pilots, who are responsible for interstellar travel and the movement of goods across the empire. Like the Bene Gesserit and the Mentats, the Guild pilots rely on spice for their duties. This mutual reliance on a limited product produces a zero-sum game of politics, and this struggle is the heart of conflict in the Dune universe. Spice is power, and the struggle for both is played out through the organizational gender dynamics set up by Herbert. In addition to his training at the hands of his Bene Gesserit mother, Paul is also trained by tutors from the Mentat school. The Mentats are best understood as human computers, highly desired due to an Empire-wide ban on thinking machines after a historical war between Empire and robotic enemies. As the Bene Gesserit represent a female-only organization, the Mentats are exclusively male. Author David M. Miller considered Herberts approach to gender, and how the author reconciles both power and gender exclusively in Paul Atreides. Miller writes in Frank Herbert: Paul has been trained in disparate disciplines: mentat (male) and Bene Gesserit (female). Thus Pauls early training prepares him to be androgynous, for his mother pursues the Bene Gesserit goal: To breed a Kwisatz Haderach who will have access to both male and female genetic memory. While Miller approaches Herbert with more sophistication than other authors, he misses the mark with seeing androgyny as the goal. Paul is trained in both Bene Gesserit and Mentat techniques, preparing him not as a gender-neutral hero, but a gender-optimized one, fluent in the best of male and female traits to be a revolutionary leader in a time of empire-wide decline. Herberts text offers a clear response to critics in a pivotal scene in which Paul Atreides has achieved his penultimate status as Kwisatz Haderach. His mother Jessica, having trained him in Bene Gesserit ways, confronts her son, setting up a clear example of Pauls balancing of gender dynamics: Paul said: There is in each of us an ancient force that takes and an ancient force that gives. A man finds little difficulty facing that place within himself where the taking force dwells, but its almost impossible for him to see into the giving force without changing into something other than man. For a woman, the situation is reversedThese things are so ancient within usthat theyre ground into each separate cell of our bodiesIts as easy to be overwhelmed by giving as by taking. And you my son, Jessica asked, Are you the one who gives or the one who takes? I am the fulcrum, he said. Frank Herbert, in an epigraph from another religious text in the Dune universe, makes Pauls place of balance even more explicit later. He writes: How to define the Kwisatz Haderach? The male who is everywhere simultaneously, the only man who can truly become the greatest human of all of us, mingling masculine and feminine ancestry with inseparable power. 3.3.5 Stivers Settlement Women and Herberts Bene Gesserit Camilla Stivers book, Bureau Men, Settlement Women: Constructing Public Administration in the Progressive Era offers a gender based analysis of public administration. Stivers convincingly argues the methods and accomplishments of the settlement women were effectively ignored by scholars, and puts forth an alternative frame to the scientific (i.e. bureau men) study of public administration adopted by traditional theorists. Stivers recounting of the settlement women offers a compelling lens through which we can examine the women of Dunes Bene Gesserit. In her discussion of Hull House, among the most famous of the settlement houses, Stivers quotes British Fabian socialist Beatrice Webb in a diary entry: the residents consist in the main of strong-minded, energetic women, bustling about their various enterprises and professions, interspersed with earnest-faced, self-subordinating and mild-mannered men who slide from room to room apologetically. Herbert describes the Bene Gesserit similarly, women of great energy and power, guiding the men around them towards the organizations goals. As Stivers points out, the settlement women were responsible for development of the survey method of research, but credit was inaccurately given to the bureau men. Similarly, the Bene Gesserit planned for and conducted genetic research for millennia, only to have the final product (Paul) stolen and credit for his success given to the male dominated Noble House structure, i.e. his father, Lord Atreides. Stivers points out, the residents of Chicagos Hull House conducted the first full-blown social survey in the United States. She furthers the point that bureau men took credit for the work of settlement women: ..it is likely that several ideas that became central to the research bureau movement had their origins in settlement houses. In both Herberts and Stivers works, roles in society and governance are split along gender lines. Stivers writes: men and women who shared a commitment to public service found themselves organizing into separate professions the men in public administration, the women in social work. Similarly in Dune, the most powerful women have organized into the Bene Gesserit, and the most powerful men into Mentats, Guild pilots, and political leaders. The comparison between Bene Gesserit and settlement women sharpens when we consider the faction of Bene Gesserit known as the Missionaria Protectiva. This faction is tasked with going into the local tribes of various worlds, including Dune, and cultivating religious beliefs in messiah figures consistent with Bene Gesserit goals. On Dune, this is accomplished through the indigenous tribes, known collectively as the Fremen. The women of the Missionaria are sent out to live among the tribes to conduct their studies and implement the goals of the Bene Gesserit. This is comparable with the settlement womens beliefs. For settlement residents, physical location in the neighborhoods they served made possible their brand of science. They operated on the premise that only that which is lived can be understood and translated to others. The settlement women believed that Science demandedthe kind of sympathy that came only from intimate knowledge of neighborhood life and thought. This allowed the settlement women to know first-hand the neighborhoods at what Stivers calls the micro level. This close physical placement within the community in turn made possible what settlement resident Katherine Bement Davis described as knowledge learned, block by block learning the location of all the public buildings, the charitable agencies, the schools, the saloons, the disorderly houses, all of which allowed the settlement women to know in some instances better than the police, what each house represented. Returning to the Mentats, gender foils of the Bene Gesserit, we can see another interplay with Stivers work. The Mentats are human computers, valuing numerical efficiency above all else, whereas the Bene Gesserit often rely on genetic memory, mind-reading, and emotional manipulation. As Mentat Piter De Vries states, I let emotion cloud reason. Bad policy for a Mentat. Stivers would see much wrong with the Mentats exclusive focus on numerical efficiency. She critiques the bureau mens similar short-sightedness: Suffused with a faith in science, in the power of facts to sway peoples minds, the bureau men never understood why the world somehow failed to fall in line. Quintessential expert rationalizers and systemizers, they could not acknowledge how fundamentally public life entails the non-rational and non-systematic, or where the appropriate boundaries of their expertise lay. In the Mentats failure to understand anything outside their narrow world-view, we can see echoes of what Stivers characterizes as the bureau mens focus on rational structures and efficient procedures [which] would contribute to the public good by reducing corruption and saving money. The bureau mens narrow focus on efficiency and scientific research is contrasted with the settlement womens focus on a more sophisticated understanding of community good. This contrast is a central theme of Stivers book. The settlement women saw their work as public motherhood and municipal house-keeping, and had a goals which encompassed far more than simple numerical efficiency. Herbert does not necessarily raise one value over another, relying on Pauls balance between the gendered groups to make his final argument instead. 3.3.6 Conclusion Stivers is especially critical of a continuing reliance on what she sees as the bureau mens outsized influence of the study of public administration: As long as scientific legitimacy, defined in terms derived from the laboratory and the controlled experiment, is the first goal of a professional field, adherents will exhaust themselves trying vainly to make life conform to the standards of science, rather than working to put science to the service of life. Herbert echoes Stivers sentiment with an entry in Dune from the Orange Catholic Bible, described as the primary orthodox religious text of the Bene Gesserit, when he writes in a chapter preamble: Scientists seek the lawfulness of events. It is the task of Religion to fit man into this lawfulness. In Herberts construction, Religion is in fact the organization known as the Bene Gesserit, and in the end they prevail in obtaining the Kwisatz Haderach, the final balance between man and law, religion and numbers. Dunes own text provides the answer to feminist critics concerned with only how often female characters appear in relation to men. Paul Atreides, the fulcrum of masculine and feminine ancestry with inseparable power, the Kwisatz Haderach stands as Herberts final answer to those critics who found Dunes gender politics wanting. 3.4 At Will Employment (Human Resources Management) Employment at Will (EAW) is just one aspect of civil service reform, and is commonly understood by researchers as stripping employees of their property interest in their employment (Gertz, 2007; Battaglio Jr. and Condrey, 2009). This fundamental change removes much of the due process traditionally expected in human resource management, especially in cases of workplace discipline and firings (Hays and Sowa, 2007; Battaglio Jr. and Condrey, 2006). A belief that the public sector would benefit from private sector employment practices led to adoption of EAW first in Sunbelt states such as Georgia and Florida, as well as more limited implementation in Wisconsin (Jordan and Battaglio Jr., 2014). Early experimentation at the state level has led to some very limited Federal adoption of EAW (Battaglio Jr. and Condrey, 2006). Proponents argued this would give agencies more flexibility due to complaints of time delays to fill positions, cumbersome procedures, massive paperwork, and a protracted appeals process.  (West, 2002). Critics of this strategy worry that without merit status, public employees are more susceptible to political pressure, and are less likely to speak truth to power. Following reforms efforts in Kentucky, one author found a quick return to the patronage system, although the traditional merit protections appeared to have protected the system in the end (Koven, 2007). Despite strong beliefs from pundits on both sides, there was little research on the impact of EAW on public employees themselves (Bowman and West, 2006; Rubin and Kellough, 2011). In our review of the literature on the outcomes of EAW, we have focused on the research focused on the reforms employee-centered results. Studies of perceived organizational support have found employees form opinions regarding how their employers value their contribution and care about their well-being, and that employees repay organizational support with increased performance (Eisenberger, et al., 1986). As perceived organizational support decreases, so does performance. 3.4.1 EAWs Effect on Managerial and Organizational Trust Managerial flexibility is the cornerstone of EAW reforms, and the employee perceptions regarding the good intentions of managers in public organizations can become important. While research by Battaglio Jr. and Condrey (2009) found that in Georgia employees were generally initially receptive to the aims of EAW, over time became more distrustful of both managers and the organization itself. The same researchers reported this decline in managerial and organizational trust was the result of employees seeing the return of spoils-era-type excesses such as patronage appointments (Battaglio Jr. and Condrey, 2009; see also Koven, 2007). 3.4.2 EAWs Effect on Turnover and Burnout Employee turnover within public organizations can have significant impact on service delivery and organizations. Turnover is associated with increased hiring costs and other economic costs, and has been correlated with increased employe burnout, work-related stress, and other negative psychosocial impacts (Allisey, Amanda F., et al., 2013). Burnout is the phenomenon of employees experiencing heightened emotional exhaustion, feelings of depersonalization, and a lack of personal accomplishment. No direct research on the impact of EAW on rates of burnout was located in our review of the literature. Burnout, though experienced at varying rates in employees, can have adverse physical and mental consequences including increased illness, withdrawal, and job dissatisfaction (Alarcon, 2011) as well as adverse professional outcomes such as turnover (Abraham, 1999). After Wisconsin passed the Budget Repair Bill there was a significant spike in public employee retirements (Jordan and Battaglio Jr., 2014). This spike was seen by some as positive, as they saw the increased retirements as an example of underperforming employees moving on so higher performing employees could move up in their respective organizations. Others however saw the retirements as a negative outcome of EAW, as the state lost institutional knowledge as experienced employees left public employment. 3.4.3 EAWs Effect on Employee Complaints and Motivation Rubin and Kellough (2011) first looked at the impact of civil service reform on employee perceptions of procedural justice and employee complaints. The authors found that agencies who had undergone reform had lower rates of complaints as compared to agencies with more traditional human resources structure. Recent research has found the implementation of EAW has significant negative impact on the motivation of public employees, particularly minority employees. (Battaglio, Jr., 2010). In the five-years after Georgias adoption of EAW, research found that employee attitudes were significantly and negatively impacted (Battaglio Jr. and Condrey, 2006) with employees reporting increased pessimism, discontent, and frustration with the reforms. This negative perception of reforms was not only found in front-line employees. Managers and agency heads in Georgia reported similar frustrations, telling the authors (Battaglio and Condrey, 2006) they were aghast to learn Governing magazine had named Georgias human resources management as the best in the country (Barrett, Greene, Patton and Keeling, 2005). 3.5 Ethics Case Study: The Nevada Four When the Nevada Four (OLeary, 2014, p. 27-41) chose to work outside the formal bureaucratic structures of the Department of the Interior and the Nevada Department of Wildlife, they did so ethically. While the group chose to engage in many violations of their organizations rules, their decision can be examined using an accepted method of ethical inquiry. Using Stones framework for testing when a breach of ethics is acceptable (2009), we see the Nevada Four were justified in their long-term effort to protect Nevadas wetlands. Stone uses three tests to determine if rule breaking is ethical: whether there is personal benefit, whether the rule breaking is simply the easy way out of a difficult situation, and whether the rule violation serves a greater cause of justice. The Nevada Four did not personally benefit from their decision, and in fact risked their own personal and family stability and employment. All members of the group reported there were professional repercussions, and some almost lost their careers, only to be saved by further ethical resistance and pressure from allies on senior bureaucrats. None of the members appear to have gained any financial advantage, and actually lost income due to their failure to advance within the organization. The Nevada Four pass the second test easily: they routinely chose the decisions which were not the easy way, and they did so over a period of many years. The easy decision would have been to simply comply with what they saw as immoral and unjustifiable decisions which threatened an important environmental resource. They persisted in the face of administrative consequence, when the easy way would have been to disengage. The final test, whether their decisions served the interest of greater justice, hinges on whether their goal of saving an environmental resource can be construed as a justice interest. Importantly, this test rests within the individual, and all four members of the Nevada Four reported that protecting the wetlands was the right thing to do. Further, they all lived in the area, had the scientific credentials to make the judgement, and one even reported a spiritual connection to the area. On balance, all four clearly believed their decision to resist was in the interest of greater justice. Therefore, using Stones framework, their decision to resist was done ethically. 3.5.1 A Different Look The Nevada Four may have had the best of intentions, but their actions were unethical, as they undermined the explicit expectations of our representative democracy. First, when they accepted a position within their respective organizations, they were accepting that their identity and personal moral beliefs were to be subordinate to the governments, short of clear illegality. While on a micro-level anyone might admire their commitment to their little corner of the world, when we allow for individual bureaucrats to supplant official political decisions with their own best judgement, we risk a nation where our well intentioned human impulses can reign awful consequence upon the public. Should we simply accept that a police officer, who knows a serious criminal is going to hurt someone eventually, but doesnt have probable cause for the arrest, to manufacture evidence? Would we allow a group of four immigration inspectors to impose their own truly held belief that certain religious beliefs are not compatible with American values, in lieu of the politically approved guidelines for entry? In admiring the ends of the Nevada Four, we risk ignoring the consequences of their moral resistance to the ethical demands of government work. The second major fault within the Nevada Fours actions is the loss of trust by politicians in the career service bureaucracy. Sure, the Nevada Four attained their goal, but none of the politicians and appointed leadership went away, and they likely felt the sting of betrayal. The Stillwater Sanctuary is comprised of only 24,000 acres; midsized fires wipe out far more acreage every day, and on average we lose 1.5 million acres every single year, with 2.46 million acres lost in the first six months of 2017 (National Fire Interagency Information, 2017). This is all to say  Stillwater is a small backwater. The agency heads who are in charge of balancing the needs of vast, interdependent systems and ecologies need to be able to trust that their high-level political decisions will be enacted with fidelity at the career-service levels of the organization. In violating that trust, the Nevada Four have likely cost the other dedicated career service employees throughout the US and its territories the ability to engage openly with top leadership. To be trusted, one must first be trustworthy, and the Nevada Four decided their issue trumped the needs of all other employees who may have even more ecologically important areas to protect. 3.5.2 Going Forward Government employees have an ethical duty to comply with the rules of their organization, an obligation that can conflict with their ethical duty to break those rules which threaten the organization or its mission. The Nevada Four faced this exact dilemma, and on balance I feel their decision was ethically sound. First and foremost, the Nevada Four were right on the issues, a finding underlined by the passage of the Fallon Paiute Shoshone Indian Water Rights Settlement Act in 1990, which gave legal protection to the Stillwater area as sought by the Nevada Four. In passing the bill, the legislative branch effectively granted the peoples political approval for the Nevada Fours actions, and the President signed the bill, granting the pinnacle of bureaucratic approbation. These acts affirmed the Nevada Four had successfully protected both mission and organization. Secondly, and in opposition to my own argument in the con section above, Stillwater matters. A persons decision can only be made from where they stand. The agents of the Nevada Four were not in charge of the United States and its territories, they lived and worked in the Stillwater area. A moral agent, in short, is only responsible for problems he can do something about (Bowman &amp; West, 2015, p. 78). The Nevada Four cannot be faulted for failing to sacrifice their 24,000 acres in the name of organizational efficiency, and in fact had they done so they would have been ethically deficient. In a vast representative democracy like ours, no single American can possibly hold all competing interest in their minds at once. It is in the synthesis of political directive, agency rulemaking, and the strained voices of the most concerned advocates that we somehow muddle through. While being objectively right in the end isnt a necessary ethical test, it doesnt hurt either. Some rules were broken, some egos pierced, but in the end, they did not physically harm anyone nor anyplace, and in doing so upheld their mission and acted conscionably. Whether through application of academic ethical framework or common-sense gut check, the Nevada Four were justified in their actions. 3.6 Externalities &amp; Non-Profits In response to a question like that below: Why are the concepts of externalities and the nondistribution requirement so important for understanding the roles and functions of the nonprofit sector in the U.S.? In other words, what questions about the sector do these concepts help answer? For each, give an example or two of types of questions that they do not help answer. Externalities are often unintended side-effects, or consequences, of an activity, the costs of which are not reflected in the cost of the activity. As an economic concept, externalities help explain why nonprofit organizations exist in the first place, due to market failures in addressing the externality. An example of a negative externality is air pollution. As the Salt Lake valley grew rapidly in the last few decades, industrial and vehicle pollutants produced vast amounts of air pollution. This pollution negatively affected the health of residents, but continued to grow year after year. The business sector was unwilling to address the issue, as the market was not providing a profit to motivate private companies to act, and government sectors were too bogged down with pluralistic interests to act convincingly. Into this gap sprung nonprofit organizations, which could operate without a profit motive unlike the business sector, and able to act along clear organizational goals without answering to everyone, unlike the governmental sector. Externalities also, at least in part, help explain the increasing professionalization of the nonprofit sector. Nonprofit organizations, founded in answer to market and governmental failures, must still conduct activities in the highly professionalized business and governing arenas if they are to be successful, and can achieve more when using the same language, education, dress, and cultural norms found in the other two sectors. Externalities are considered a type of market failure, and have been a motivator for many nonprofits, but do not answer other important questions about the sector. Externalities do not provide a convincing answer for the longevity of certain nonprofit organizations, particularly religious organizations. Some churches represent among the longest-lived human structures (both literal and figurative), and do not appear primarily motivated by addressing externalities. Religious organizations, whether of the long-lived institutional variety or the evanescent neighborhood hall variety, appear to answer a different, more humanistic need, and do not fit neatly into an economic or market failure argument. Externalities also dont answer how nonprofits continue to thrive in areas where the business sector is also being successful, such as health centers and hospitals. Many communities have a nonprofit driven community recreation center, often located geographically near several private gyms. Similarly, both nonprofit and for-profit hospitals continue to provide very similar services. While there are other economic and social models for understanding this phenomenon, externalities is not one of the satisfactory ones. The non-distribution requirement is well-accepted as an essential trait of the US nonprofit sector, and is what sharply divides the nonprofit sector from the business sector (Frumkin, 2002). This concept is well-suited to explaining some aspects of the nonprofit sector, particularly those organizations which provide health related services and services to the poor. There is a gut-level feeling among many that organizations serving, for instance, mentally disabled adults should not be doing so in search of individual profit. Many donors would hesitate before giving money to such an organization if the potential donor knew the company would eventually be balancing profit against care. The concept of non-distribution is clearly one characteristic of the nonprofit sector, but cannot be seen as the defining characteristic. First, the concept doesnt do enough on its own to differentiate between the government sector and nonprofits, because under that definition the State of Utah, the San Diego city council, and the US Department of Finance would all be considered nonprofit organizations. Second, the concept doesnt explain the driving energy behind nonprofit organizations: voluntarism. Deemed the coin of the realm by Frumkin (2002), free, non-coerced, and voluntary participation is what starkly differentiates the [nonprofit] sector from government, which can levy taxes, imprison violators of the law, and regulate behavior in myriad ways. The non-distribution requirement is most useful in explaining why organizations exist in the nonprofit sector as opposed to the business sector, but is less useful in understanding how nonprofits differ from the governmental sector. 3.7 Charity &amp; Non-Profits In response to a question such as that below: Sociologist Nathan Glazer argues that the Unites States has become overly dependent on government for addressing community and individual problems; in his view nonprofit organizations are the key to reinvigorating community and individual responsibility, which will in turn produce salutary results for the American economyBy contrast, Robert Reich believes that the reliance of the United States on the ideology of charity has produced inadequate, fragmented social programs because citizens in need of relief are not regarded as entitled to social benefits (Smith &amp; Lipsky, 1993, p. 18). Who is right, Glazer or Reich? Defend your answer.Is there a middle-ground  is there room for a compromise  between these two views? Explain. Glazer is more right than Reich, but both are merely representing realities of American history, and their individual places in it. Glazers argument is rooted in a Jeffersonian tradition of self-reliance and upward mobility, both still powerful motivators and with plenty of success stories to back them up. In his view, government entitlements tend to de-motivate individuals, eventually leading to less achievement. Starting in the 1930s, US government entitlements have grown from approximately two percent of GDP to 2015s incredible 48.7%. Glazers concern echoes Tocquevilles original critique: Everywhere the state acquires more and more direct control over the humblest members of the community and a more exclusive power of governing each of them in his smallest concern. Glazer saw expanding state entitlement spending as expanding state control. His argument was not that the spending aid wasnt needed, but that the spending should come from the nonprofit sector, where a pluralistic approach would allow for a maximal benefit to those in need, while minimizing risk of greater state control. Reich, answering Glazers claims while Reich was Secretary of Labor under President Clinton (1993-1997), argues that through a unifying of services and aid under the umbrella of the federal government, society could more fairly address the needs of the poor and their communities. To his credit, from the lofty perches of the highest offices of federal government, it likely does appear that the demands of fairness and equity could only be answered through a large, uniform approach; and of course the largest, most uniform supplier is the US federal government. Unfortunately for Reich, his answer fails on two major points. First, he is not actually answering the critique of Glazer that a large federal spending response risks a large growth of federal control, with negative effects on individuals self-reliance and mobility. Second, by steadily moving towards federal government as the provider of first (and last) resort, Reichian policy fails to consider the benefits of the American tradition of pluralism. By allowing states to consider, enact, and reform policies in a pluralistic manner, Reichian policy prevents local solutions, targeted at local problems, from discovering better ways of addressing long-term problems. Not only is there compromise available, it is likely inevitable. Just as Hamiltonian and Jeffersonian traditions have ebbed and flowed throughout American policy over several centuries, so too are the positions represented by Glazer and Reich more likely to end in a muddling middle rather than the poles. Glazer began as a Trotskyist in the 1930s, broke with traditional liberalism by the end of the 1970s, and ended the 1990s with a book-length tormented reconsideration of many of his previous views (We Are All Multiculturalists Now, 1997). Though detractors may see him as ultimately uncommitted to any specific ideology, it is his willingness to fit ideology to reality that ends up a winning argument, closely mirroring the American history of evolving thought. As entitlements have now grown to represent nearly 50% of GDP, there will inevitably be a reckoning, a pullback, and a reborn intellectual interest in how to best support a tradition of American individualism, while still supporting those most in need. 3.8 Non-profits as mediating structures Over the long haul, can nonprofit organizations be expected to live up to Berger and Neuhaus vision for them as mediating structures or buffers between individuals/families and large government/business organizations; or will funding needs and pressures eventually cause them to become mere extensions of these government/business organizations? Churches and universities represent some of the longest-lived organizations in human history, and fit comfortably into the definitions of mediating structures as envisioned by Berger and Neuhaus; these organizations ability to survive modern needs and pressures should not be in doubt. Organizations such as the Catholic church (1st century AD to present) and Oxford University (1096 to present) have survived the worst political, economic, and military excesses of their times, and adapted to survive. Surely funding needs and pressures are unlikely to see these foundational mediating structures devalued to the point they are mere extensions of anything but the innate human needs the structures have evolved to meet. The authors correctly identify the tendency for liberal states to construct large, impersonal, abstract structures in answer to nearly all societal problems. While some can be successful, the reality is that the alienating effects of these structures does little to answer the personal needs for fraternity, family, and spirituality that pervade humanity. For every large governmental institutional success, there is an individual cost. Often, paternalistic and authoritarian policy springs from good intentions to limit risk individuals, but there is always a commiserate cost to individual freedom; without risk there is little to gain. Berger and Neuhaus theory is a middle ground, and is not usefully understood as an ideological pole. Only in the presence of alternative extreme views can the authors view be seen as anything but that of a rational middle. In evaluating policy prescription to address the need for affordable daycare, for example, the authors delineate the poles: that government should stay out, versus a federally-funded, comprehensive child-care system attached to public schools. The authors scratch out the rational middle-ground, as the need is real, and must be addressed. The best solution is found in mediating structures, as they address the need in an inexpensive and un-intrusive way. Innate human needs brought mediating structures to life, and just as they will not disappear simply due to new funding stressors, nor will the nonprofit organizations which serve those needs. 3.9 Public Administration &amp; War To be used in the common tell us about the development of public administration  but this is an alternate view, and one that is very much under development in that Im tying together a bunch of loose, disconnected ends in other pieces. 3.9.1 Paravit in Bello: How American Public Administration was Prepared by War There are many possible stylized accounts of American Public Administration. In this essay I will trace a thread that in my education and reading is not often followed  the effect of war on the development of American public administration theory and practice. Pre-eminent theorists of public administration were shaped by war (and shaped) war. Wilson was the first to take public administration serious as a proper political science pursuit, and as president took the country into its first world war. Dwight Waldo reshaped his dissertation at Yale after serving as a civil servant in World War II. The resulting manuscript was published in 1948 as The Administrative State (Waldo, 2017). Many of the 44 men who have served as President were shaped by war. Twenty-six had military experience, at least six were soldiers by profession (Weaver, 2018). But not only presidents and philosophers have shaped public administration, and as I briefly trace throughout this essay, the strengthening of the administrative apparatus of the nation has often taken place at the hands of men who were shaped by war. The Latin phrase si vis pacem, para bellum is a time-tested warning that if you want peace, prepare for war. This essay will instead take on the task of roughing out an American public administration paravit in bello: Prepared by war. This essay proceeds in three parts. I begin with a sketch from the American Revolution through the second World War of how we might begin to think about the influence of war on the American administrative state. This section is not oriented towards scholarly detail, and is proposed as a brief alignment towards the idea that just as the political state was shaped by war, so must have been the administrative state. In the second section I sketch the influence of war on Americas first believer in the need for strong public administration, Alexander Hamilton. 3.9.2 Presidents, Pragmatists, and Progressives: Briefly The American Revolutionary War gave rise to its first spymaster and chief executive in George Washington. Following the American victory, the signal public agencies of the first decades of the new republic were administered by one of its genius war leaders, Alexander Hamilton (who deserves and receives more detail in the second part of this essay). The early 19th century expansion into the American west, and the accompanying growth in administrative agencies to oversee the new holdings, as overseen by a fiery, battle-tested war leader who preferred the title General to President (Somit, 1948). Their experiences as soldiers with the horrors of the American Civil War led a generation of pragmatic leaders to draw away from the religious and mystical, and closer to modern scientific ideals of law and administration (Menand, 2001). The United States entered World War I under the presidential leadership of Woodrow Wilson, who is also often recognized the first formal scholar of public administration. The bureau men of public administration embraced Progressive era ideals that were born in rejection of the atrocities of World War I, and further, an optimism that industry and science that would lead the country to a new golden administrative age (Stivers, 1995, 2002). Progressive reformers were informed by the pragmatists of an earlier decade such as John Dewey, who was distrustful of the absolute reason imposed by the Hegelian ideal of the state (Dewey, 1915), and especially its institutional form found in the Prussian and Germanic military states. As Spicer (2005) reminds us, there is a clear link between the Prussian military state and foundational public administrative thought  what Spicer deems the purposive state: a nation that turns its power, resources and citizens towards certain ends; as opposed to the state as a civil association. Spicer succeeds in showing the influence of Prussian and German thinking on modern American administration through their influence on Woodrow Wilson and others. Dewey was wary of the militarism that he saw in Wilson and others, particularly a warlike mentality and nationalism he felt was ultimately destructive to his normative view of what the American state could be, arguing that (Dewey, 1915, p. 118) philosophical justification of war follows inevitably from a philosophy of history composed in nationalistic terms. History is the movement, the march of God on earth through time. . . . War is the signally visible occurrence of such a flight of the divine spirit in its onward movement. The idea that friendly intercourse among all the peoples of the earth is a legitimate aim of the human effort is the basic contradiction of such a philosophy. Though Wilson expressed disquiet about Prussian state theory almost thirty years earlier (Wilson, 1887), he believed Americans could safeguard against the excesses, that we could borrow their methods of sharpening a knife without engaging in their murderous ends. Though foundational, Wilsons propensity to engage in self-evident truths would be replaced by public administration scholars wary of easy answers based on clever metaphors (Ostrom, 2000; Simon, 1946). Dewey would fill in his own normative view of what the state should be in 1927 with The Public and Its Problems (Dewey &amp; Rogers, 2012). The book laid out a modest vision compared to the purposive state (Spicer, 2005). The progressive state existed to act against and control the negative consequences of technology, and to harness the benefits with the instrumental goal of enhancing the lives of the public. Deweys account provided the foundation of Progressivism and the good society (Lippman, 1937), and has been influential throughout American political thought, including Habermas pragmatist conceptions of technology, which promotes a mutually shaped science and politics in service of the practical needs of the citizenry (Habermas, 1970). It has also been argued that Deweys pragmatism set the guideposts for pragmatic, solutions-oriented Black American political thought after the civil-rights movement (Glaude, 2007). Pragmatism, in Deweys view, is an account of how people think  the way they form ideas and beliefs, and how those translate to decisions. This idea can be seen in the formative legal philosophy of US Supreme Court Justice Oliver Wendell Holmes, especially his conception of the reasonable man (Mendelson, 1951). Holmes was scarred by his experiences in the Civil War (Menand, 2001), and pragmatism gave him the philosophical case for rejecting the metaphysics and transcendentalism that he saw as morally bankrupt following such destruction. Holmes jurisprudence relied on and synthesized the pragmatism of Emerson, Peirce, and Dewey (Menand, 2001; Mendenhall, 2015). Pragmatism focused on practicality and experience, and was soon adopted by the Progressive era reformers who sought to use that approach to highlight human progress. Dewey was important to a great many areas of scholarship, including education scholarship, but for public administration we might consider his most immediate effect was on the pragmatic progressives depicted in Bureau Men, Settlement Women (Stivers, 2002). The books central theme is the establishment of the scientific-analytic and business-like public administration in the Progressive Era. Stivers sees there were two competing, gendered visions of public administration heading into the progressive era - women who were working with the people they were serving, and men who were attempting to professionalize and used the language of science to deflect political attacks on them as effeminate: Long haired men and short haired women. The bureau men and their vision of a scientific approach to governance won out, but we lost out on the path of public administration that works closely with practitioners and those affected by our policy and research. That lost vision would eventually be redeemed somewhat in Dwight Waldos 1948 vision of the administrative state (2017), and echoes of it would be found in the largest modern expansion of the public administrative state. Roosevelts New Deal would eventually make good on Progressive promises, instituting the largest expansion of the American administrative state in history. Despite his Progressive alignment, he did not embrace the progressive glass firewall theory that civil administrators could largely leave military matters to the military (Stever, 1999), or that war was anachronistic to the Great Society (Lippman, 1937, p. 159). War support became somewhat of a litmus test within Progressive circles, and even Deweys status was called into question after he voiced support for US entry into World War II. As an early supporter of Wilsons presidential bid, Roosevelt was repaid for his loyalty with an appointment as Assistant Secretary of the Navy during World War I. As Assistant Secretary of the Navy Roosevelt instituted civil reforms of the Navy including merit-based promotions, and his reforms extended civilian control of the military broadly (Smith, 2007, see pp. 102106). His experience there also exposed him to the difficulties in managing the relationships between union workers and public agencies. He handled the difficulty well, and in his seven years in post not a single strike was called (Burns, 1956, p. 52). Now President Roosevelt would call on that military, and the combined American public apparatus, as he led the country into World War II. A leading hero of that war was soon turned into the pre-eminent exporter of American public administration as the Military Governor of post-war Japan, and his administrative style may have had a more lasting impact on current world events than his military exploits (Tehan, 2002, p. v). At this point, there is at least a clear argument to be made that a useable past (Stivers, 1995, p. 522) is available to us to structure our understanding of American public administration. 3.9.3 Hamiltons Public Administration Hamilton echoes the sentiment of the Latin phrase that this essay takes its motivation (quoted by Green, 2019, p. 155) in his speech to the Constitutional Convention: Unless your government is respectable, foreigners will invade your rights; and to maintain tranquility, it must be respectable  even to observe neutrality, you must have a strong government. Richard Green (2019) devotes a chapter of his portrait of Hamiltons vision of public administration to how Hamiltons experience with war framed his views on military and foreign affairs. Much of Hamiltons life revolved around war or the threat of war (Green, 2019, pp. 155156), and those experiences gave birth to a fierce patriotism for the new American nation, and a deep desire to protect it. Hamiltons early military career as an artillery officer caught the attention of General George Washington, who promoted Hamilton to his aide-de-camp. After the war, Hamilton was installed as Secretary of the Treasury. His successes in that post are the focus of Greens work showing the deep influence Hamilton would have in founding a strong central public administration. Hamilton saw that the young nations survival would require an intricate bonding of the commercial and military functions of the state. Critical to that bonding was a strong defensive military capability, and as Secretary of the Treasury Hamilton oversaw many of the first efforts in that domain. Green gives a sense of Hamiltons influence and scope as he shaped American defensive capabilities in a variety of administrative contexts (Green, 2019, p. 156): he attended to the organization and management of the Department of War, and through his management of the Customs Service and a fledgling Coast Guard, he oversaw the protection of harbors from French privateering as the French Revolution ensued. He also equipped militias and helped Washington lead in the successful effort to quell the Whiskey Rebellion in western Pennsylvania in 1794. When war loomed with France in the late 1790s, he returned to the military as a major general, second-in-command to General Washington, serving also as inspector general of the Provisional Army until 1800. He laid extensive plans and lobbied hard for the establishment of the navy, for the outfitting of a small standing army, and for professional military academies in which to train military leaders and subordinate officers in matters ranging from broad military policy to the technology of warfare. As he discusses in Federalist essays 23-29 (Hamilton, Madison, &amp; Jay, 2009), Hamilton believed a permanent military establishment would eventually become necessary to secure the republic. However, distrust of centralized federal power among Anti-Federalists was strong. 3.9.4 Conclusion At the close of David Mayhews (2002) takedown of the theory of American political realignments, he proposes three possible explanations for political scientists still interested in constructing large scale theories of political process. One of the possibilities he suggests is to re-engage with American bellicosity  our long history with war. I have aimed at making a similarly simple argument here: that war has influenced how public administration is theorized and practiced. Two predominant themes suggest themselves. First, an experience with war directly as a military actor, as in the cases of pragmatists horrified by the Civil War, or Alexander Hamilton in the Revolutionary War. 3.10 Nationalism versus Patriotism  John H. Schaar Patriotism is not nationalism, though they have become conflated. Patriotism too often sounds like nationalism, patriotisms bloody brother writes John Schaar . Written in the closing days of the Vietnam War, Schaars words are not limited by the time in which he wrote, and seem pointedly aimed at an audience of today. Schaar bemoans the fact that thoughtful people have come to misunderstand patriotism: The intellectuals are virtually required to repudiate it as a condition of class membership. The radical and dropout youth loath it. Patriotism comes from a family of words that help us understand its meaning: legacy, covenant, reverence, loyalty, nurture, roots, citizen, debt, gift, republic. Reverence in particular has strong definitional power, as reverence defines life by its debts: one is what one owes, what one acknowledges as a rightful debt or obligation. Patriots move through the world understanding they have been granted great gifts, grateful to the people and places through which they come, and determined to defend the legacy against enemies and pass it unspoiled to those who will come after. Unfortunately, We are not taught to define our lives by our debts and legacies, but by our rights and opportunities. Shaars definition of patriotism reconnects to a humanistic, natural one: Patriotism means love of ones homeplace, and of familiar things and scenes associated with the homeplace. In this sense, patriotism is one of the basic human sentiments. He stops short of defining it as an innate feature of humanness, but instead a proclivity produced by realities basic to human life. Land patriotism is the base example, but Americans are historically removed from this type. City patriotism is another type, though more artificial, but is also in decline. These have been replaced with covenanted patriotism, which bonds Americans together through political ideas and ideals. In Shaars conception, President Abraham Lincoln embodies and articulates this ideal. In Lincolns words This covenanted patriotism assigns America a teaching position among the nations, rather than a superiority over or a hostility toward them. This patriotism is compatible with the most generous humanism. However, Lincolns ideal patriotism has given way in the face of rampant consumerism, and a giving way of the concept of public good to aggregation of particular goods. Liberalism and capitalism corrupted the covenant, while racism denied it to large groups of the population. Even corrupted, Schaar sees Lincolns conception of covenanted patriotism as the one available to us any longer, and offers the noblest rationale for active citizenship (govt of, by, and for the people) resident in our tradition. However noble, covenanted patriotism is not our reality  nationalism is. The moral thrust of patriotismis inherently ambivalent. It simultaneously unites and divides, encourages both concord and discord. This is not a unique feature of patriotism, but rather a commonality among human devotions. Division and conflict are built into the dialectic of devotion. Love, faith, and loyalty all have similar ambivalences. With patriotism, then, the dark face turns away from strangers, and a preference for our country morphs into a belief that our way is not just a great way, but the best way, and then finally into the only way. Where patriotism is natural, nationalism is contrived and artificial. The rise of nationalism is due to the successes of liberalism in breaking the bonds among men and new bonds were needed to replace the old, broken links. Two myths replaced the broken bonds. First, he state, the coldest of cold monsters (Nietzsche), successfully set itself up at the sole legitimate object of patriotic attachment, with results that have on the whole been disastrous. The second myth is the cult of progress, which Schaar seemingly abandons mid-thought, or perhaps felt it was beyond the scope of this already too-long answer. Nationalism is so prevalent in our lives that it is difficult to understand just how recent a phenomenon it is. Schaar points out that when George Washington used the phrase, my country, he was referring to his home state of Virginia, not the United States. His was more of the natural patriotism, found in his attachment to the land, and a city patriotism, though in this case the city-state of Virginia was his referent. As nations were successful in growing and centralizing power, in the UK, France, Sweden, Russia, and the United States for example, each nation produced a similarity of character across their populations. Where before a wide range of American attitudes and customs had existed, a difficult to define American character sprang to life, and was adopted throughout the republic. Schaar sees the hot ideology of nationalism ebbing a bit, particularly in Europe but in America as well, and is being replaced with a cool logic of technology and rationalization. He sees this as the most important political task of the patriot today. We must sever the connection between nationality and nationalism, and depoliticize it. He compares it to religion, which over time was also successfully pried from the grasp of the state. Schaar sees this task as an important goal of education, and wants to see fragmentation of power and education  Everything possible should be done to dismantle educational bureaucracy and break the stranglehold of officialdom on education. Encourage nonpublic educational ventures; let a hundred flowers bloom. 3.11 Policy Paradox (Stone, 1997), Trump, &amp; Environmental Policy Observers across the political and partisan spectrums have noted that President Donald Trumps presidency is extraordinarily contentious, even beyond the normally high-temperature politics of the modern presidency. Among the most contentious policy areas during the Trump presidency have been reinterpretations of environmental and conservation policies. Discussion of the Trump administrations substantive environmental policy approaches will focus on the reinterpretation of the Migratory Bird Treaty Act of 1918, reduction of the Bears Ears National Park, and relaxation of regulations on oil drilling in the Arctic Wildlife Refuge. Each of the three policy areas addressed have at their core the long-term battle between environmental and conservation groups on one side, and economic and energy interests on the other, but all three also have their own unique dimensions which complicate the policy and create great controversy. In contrast to almost every other policy area the Trump presidency has interest in, the administrations space directive policy for increased human space exploration received almost no broad critical response. Why the lack of policy heat in the area might be is explored in the second section. Finally, the paper concludes with a brief overview of insights which help understand the policy environment of the Trump presidency Deborah Stones Policy Paradox: The Art of Political Decision Making (1997). 3.11.1 Migratory Bird Treaty Act In December, 2017, the Trump administrations Department of the Interior issued memorandum M-37050, effectively announcing it would no longer enforce key provisions of the Migratory Bird Treaty Act of 1918 (MBTA). The move to reinterpret the MBTA is contentious for both symbolic and substantive reasons. Symbolically, the MBTA was one of the first environmental protection laws in the United States, and was passed after the extinction of several common birds. The act served as a model for other conservation acts, and helped solidify conservation as a hallmark of federal administration of natural and wildlife resources. Substantively, the MBTA has been successful in the intervening 100 years in providing legal structure for the protection of hundreds of species of birds. This year is the 100th anniversary of the MBTA, and to honor the contributions of the act, the Audubon Society named 2018 the Year of the Bird, and other important voices such as the National Geographic Society followed suit with magazine covers and events to celebrate the progress that has been made in protecting important bird species, including the Bald and Golden eagles. Since the 1970s the MBTA has been interpreted to strictly prohibit the unregulated killing of birds (Scarlett, et al., 2018). For a century, the clear language of the MBTA is that (emphasis added) it shall be unlawful to hunt, take, capture, or killby any means whatsoeverat any time or any mannerany migratory bird has served to hold companies and individuals accountable for actions that result in bird death. In the past, when companies have even inadvertently killed birds protected under the act, such as eagles striking wind farms, or in oil spills that kill literally millions of birds. Under the new interpretation by the Department of the interior, so long as a company can reasonably claim that their purpose was something other than killing or capturing wildlife, then it would be impossible to hold the organization responsible for even grossly negligent actions. Environmental and wildlife protection groups have vigorously protested the Trump administrations reinterpretation of the MBTAs key protection provisions. Whereas the language in the act appears straightforward to wildlife advocates, the Trump administration issued new guidance in December, 2017, indicating that the act is only violated when (emphasis added) the actor [is] engaged in an activity the object of which was to render an animal subject to human control. Advocacy groups have criticized the administrations new language, with one group of former appointees to the Department of the Interior calling it an ill conceived opinion and a contrived legal standard that creates a huge loophole in the MBTA, allowing companies to engage in activities that routinely kill migratory birds so long as they were not intending that their operations render an animal subject to animal control (Scarlett, et al., 2018). This group of advocates appears to value a balanced approach to conservation, as the signees worked for both Democrat and Republican presidents between 1971 and 2017. The Audubon Society is perhaps the most publicly visible organization with a focus on birdlife, and is greatly concerned with the Trump administrations policy change. The Audubon Society credits the MBTA with saving numerous species from extinction, such as the Snowy Egret, Wood Duck, and Sandhill Crane, and millions, if not billions of other birds (Audubon Society, 2018). On May 24, 2018, multiple groups concerned with bird protection, including the Audubon Society, the American Bird Conservancy, Center for Biological Diversity, Defenders of Wildlife, National Wildlife Federation, and the Natural Resources Defense Counsel combined efforts to file a federal lawsuit against the Department of the Interior. The lawsuit alleges that as a result of the Trump administrations move to reinterpret MBTA, protections will apply only to activities that purposefully kill birds. Any incidental takeno matter how inevitable or devastating the impact on birdsis now immune from enforcement under the law. Given the slow nature of federal litigation, it is unlikely the lawsuit will prevent the administration from overlooking significant bird kill before the judicial system weighs in. 3.11.2 Bears Ears National Park No single environmental issue so clearly shows the policy schism between President Trump and his opponents than the administrations decision to reduce the size of the Bears Ears National Monument by 85%. The decision to establish Bears Ears was taken very late in President Obamas presidency in 2016, as he prepared to exit office. Obamas unilateral decision to establish the monument was hailed by both environmental and tribal advocates, but was controversial among western state politicians and energy producer organizations, who expressed concern with perceived federal overreach, and dissatisfaction that their concerns were not taken into account. President Trump signaled early in his term that he was open to eliminating or reducing the Bears Ears monument, and in December, 2017, Secretary of the Interior Ryan Zinke announced the Bears Ears monument would be reduced from 1.35 million acres to just 200,000 acres. The decision to reduce Bears Ears continues to be controversial for three main reasons  political, environmental, and legal. First, some see the policy decision as purely political, designed to undermine the accomplishment of President Obama. This view was bolstered by the simultaneous decision to also reduce the Grand-Escalante National Monument, also in Utah, which had been an accomplishment of President Clinton. By drastically cutting the size of the two monuments, both put in place by Democrat presidents, some saw an effort by Republican President Trump to politically erase his predecessors. Trump supporters, such as Utah Senator Mike Lee, argue against this perception, as he sees the unilateral moves by Obama and Clinton as exemplars of overreach by federal politicians into state lands. [President Trump] has been sympathetic to the fact that weve been mistreated, said Senator Lee, and Im grateful he is willing to correct it (Turkewitz, 2017). While both President Obama and President Trump may disavow the political motivations that led them to their respective decisions to establish and reduce the Bears Ears National Monument, there are reasons to believe otherwise. President Obama established Bears Ears on December 28, 2016, with less than a month to go in his presidency, and knowing he would be replaced by a Republican president unlikely to take the same action. The timing of the decision was immediately attacked by Utah politicians, who had long favored establishing some protected lands in the same area, but without the same prohibitions on economic and energy development. Utah Governor Herbert stated he was more than disappointed and deeply disturbed by President Obamas unilateral decision (Griffin, 2016). This exact concern from local politicians was highlighted by Secretary Zinke, stating via the press release that (Boxall, 2017), For years, the people of Utah and other rural communities have voiced concern and opposition to some monument designations. But too often in recent history, exiting presidents make designations despite those concerns. The blend of environmental and cultural politics is the second primary reason the decision to shrink Bears Ears was, and remains, controversial. In his proclamation creating Bears Ears, President Obama (White House, 2016) explicitly invokes the Native American names for the land in the first sentence, describing the sight of twin buttes so distinctive that in each of the native languages of the region their name is the same: HoonNaqvut, Shash JÃ¡a, Kwiyagatu Nukavachi, Ansh An Lashokdiwe, or Bears Ears, and noting the land is profoundly sacred to many Native American tribes, including the Ute Mountain Ute Tribe, Navajo Nation, Ute Indian Tribe of the Uintah Ouray, Hopi Nation, and Zuni Tribe. For many on the pro-monument side, the cultural heritage of the indigenous tribal people in the area demands action to protect the lands, and President Trumps decision to shrink the boundaries of the Bears Ears National Monument was a moral mistake (McBrayer &amp; Roberts-Cady, 2018). For others, the Presidents proclamation noticeably fails to pay attention or tribute to any of the non-tribal peoples who inhabit the area. While the proclamation goes to great length to describe the ancestral, cultural, paleontological, and wildlife resources of the area, there is no mention at all of the lives of many locals who call the area home. These local voices felt their concerns werent heard by President Obama, and felt vindicated by President Trumps decision to diminish the monuments boundaries. San Juan County Commissioner Rebecca Benally summed up the local feeling when she wrote (Weber, 2017), Thank you President Trump. Thank you for not being a typical politician and passing us over. The third reason Trumps reduction policy on Bears Ears is so controversial is legal in nature. Simply put, while presidents can create national monuments under authority granted to them under the 1906 Antiquities Act, the ability for any president to unilaterally reduce or remove national monuments has not been clearly tested in court. Presidents have only rarely exercised the power, and even then, the changes were fairly limited (Meyer, 2017) and the lack of legal clarity means that advocates on all sides of the issue do not know the legal ground they stand on. The move to reduce Bears Ears was immediately met by lawsuits by environmental groups to stop the Trump administrations reduction. Some legal scholars argued that the lawsuit strategy was doomed to fail, as the ability for a president to undo a national monument was implicit in the ability of a president to create it in the first place. Todd Gaziano of the Pacific Legal Foundation and John Yoo of the University of Berkeley law school argued even prior to the decision to reduce the monuments that (2017), Prior presidents acted unilaterally to create or vastly expand several national monuments. Its simply unrealistic to pretend that acts created by unilateral presidential decrees cannot be undone in the same manner. Others disagree, including conservationists, environmentalists, and California state Attorney General Xavier Becerra, who argues that while the president has unilateral authority to establish national monuments, only Congress has the authority to diminish their boundaries (Boxall, 2017). Attorney General Becerra (2017) writes that Trump simply has no legal authority to question monument designations made by a predecessor under the Antiquities Act. Though Becerra states the position as a matter of fact, he does not indicate the legal standard by which he came to that conclusion, leading Gaziano and Yoo (2017) to mock Becerras position as magical legal thinking and noting that Presidents Coolidge, Taft, Wilson, Truman, and Eisenhower all reduced national monuments without court challenge or reversal. 3.11.3 Arctic Wildlife Refuge The largest span of protected wilderness in the United States is the Arctic National Wildlife Refuge (ANWR), composed of 19 million acres along the northern coast of Alaska. The US Congress created ANWR in 1980 through the passage of the Alaska National Interest Lands Conservation Act, and as part of that bill included language to defer a decision on the ability of energy companies to drill in a subsection of the refuge which totals 1.5 million acres. Ever since deferring that decision, a political fight has been waged between environmental groups and energy companies over that smaller subsection. In late 2017, Alaska Senator Lisa Murkowski was successful in including language in the tax-reform bill which finally opened up ANWR to oil drilling. President Trump signed the bill, and specifically called attention to the ANWR provisions, stating (Cama, 2017), Were going to start drilling in ANWR, one of the largest oil reserves in the world, that for 40 years this country was unable to touch. Environmental groups were predictably upset with what could be viewed as a historic defeat. Protecting the area from oil and gas development has long been a core issue for the American environmental movement, an issue that until the Trump administration they had been successful in prevailing on. Conservationists have long maintained that energy exploration in the area threatens multiple species, including thousands of migratory birds, but have highlighted two in particular, the caribou and the polar bear (National Wildlife Refuge Association, 2018). Caribou migrate through the ANWR, and every spring calve their offspring there, making the land there particularly sensitive to continued protection of the animal. ANWR is also the only national conservation area in which polar bears, a species deemed vulnerable with a decreasing population, den overwinter, again raising the environmental stakes. The World Wildlife Foundation (2018) lists oil exploration as a critical threat to polar bears, with oil development risking reduced insulation, poisoning, disturbance, disruption of biological functions, danger to cubs, and habitat destruction all highly concerning. Like the Bears Ears controversy, the element of tribal rights advocacy is also involved in the ANWR energy development policy debate. However, whereas in Bears Ears the voices of Native Americans appear united behind the side for protecting the lands from development, in the ANWR debate there are indigenous voices on both sides. Matthew Rexford, tribal administrator for the Village of Kaktovik, argued for allowing oil drilling, and testified before Congress that (Shankman, 2017), The oil and gas industry supports our communities by providing jobs, business opportunities and infrastructure investments, has built our schools, hospitals, and has moved our people away from third-world living conditionswe refuse to go backward in time. Presenting the opposing view is Robert Thompson, a resident of the only town within the refuge, worries that any (Shankman, 2017) exploitation could impact his ability to hunt. We get most of our food from the land, Thompson said, and added that he didnt want to live in an oil field. Given the long history of the battle over oil drilling in the ANWR, it is likely that even with Congress directing the Department of the Interior to finally open up pieces of the refuge to drilling, the fight will continue for many years to come. Environmentalists have already announced their intent to seek legal remedies to continue protecting ANWR from drilling, were there even to be companies interested in seeking to drill there, which none have publicly expressed interest in to date. 3.11.4 Expanding NASAs Space Program There is no doubt that finding non-controversial, substantive policies in the Trump presidential era is difficult. While there are small proclamations and narrow fixes that dont seem to have captured the ire of opponents, it is rare for a substantive Trumpian policy to escape high-temperature partisan politics. However, President Trumps call for expansion of the National Aeronautics and Space Administrations (NASA) space exploration program has generally been met with bipartisan support. In 2017 President Trump signed Space Policy Directive 1 (NASA, 2017). While the directive leaves NASAs topline budget unchanged, it substantially changed priorities for the agency by zeroing out funding for the International Space Station (ISS) by 2025, and restructuring those funds into an expanded human space exploration program, with the intent of landing on both the moon and Mars. The directive Im signing today will refocus Americas space program on human exploration and discovery, said President Trump, This time we will not only plant our flag and leave our footprint  we will establish a foundation for an eventual mission to Mars and perhaps someday to many worlds beyond. Despite some dissenting voices within the space industry, who complained that defunding the ISS will hamper any hoped-for expansion of human presence to the moon and beyond (Roberts, 2018), on the whole, response to the policy was incredibly muted when compared to other Trumpian initiatives. The reason for the silence of opposition is rooted in the deep American character of space exploration, combined with the non-partisan nature of space policy. Americans still deeply identify with the success of the moon landing, and the fact that the United States continues to lead the world in both public and private space exploration and science. This gives political opponents little motivation to put effort into attacking the program, an act which many Americans would find at least vaguely unpatriotic. With the exception of President Clinton, every president has availed himself of the boost that comes from tinkering with space policy. There are no political losers in such a policy, as the money isnt being shifted from other programs outside the agency, and in general the success or failure of any such program is far in the future, past when the originating president may have to pay any political price for failure of the policy. 3.11.5 Insights from Policy Paradox (Stone, 1997) Deborah Stones classic Policy Paradox (1997) offers students of American policy two important lessons for policy scholarship, which helped inform this paper. First is the lesson contained within the title of the book, pardox, a theme developed within the authors preface. Rationality is a narrow conception of how humans think and feel, and that we are often forced to entertain paradox, Stone writes (p. xi). Most American policy reporting is presented with a thin veneer of rationality applied over it, which tempts most observers into vain attempts to explain the various sides of a policy through models of efficiency, or economics, or equality. But at a very basic level, the reality is that all policy positions rely on unstated beliefs, not facts, many of which will conflict with one another and with attempts to prove policy facts rationally. Even the idea that rationality and emotion (or belief) are two bifurcations of the mind is an old myth, perhaps one of the longest-lived ones. Put in motion by Descartes, the notion that reason lives separate from emotion persists strongly in both our everyday talk and our scientific conceptions, despite having been thoroughly undermined by Rye (1949), permanently made nonsensical by Damasio (2006), and finally (for me) destroyed by primatologist and neurobiologist Sapolsky (2017). And although Damasios work has been cited over 26,000 times (!) now, even now prominent policy writers insist that their conception of a policy is the rational one; that they have somehow risen above the fray of being human, and returned with facts unsullied by such things as fear, desire, or other human frailties. Stone underlines the necessity of owning up to the impossibility of examining policy and politics through a lens of objectivity. I dont believe there are objective tests of goodness, or rules ofr human behavior that can automatically produce the best, Stone writes (p. xiii), but then offers an alternative vision: But even though I dont believe in an objective standard of equityneither do I believe that all distributions are morally equivalent. Stone does not run away from demanding that a policy analyst must put herself into the analysis, and that rather than pretending at an impossible objectivity, the policy analyst or decision maker must bring his or her values into the picture. This lesson was important to me in examining the issues in this paper. Like most, if not all Americans, I find it difficult to put aside a belief that we can persuade through facts. But as Stone quotes jurist Jerome Frank (p. 311), facts are guesses. I am a birder, and so President Trumps decision to reinterpret the MBTA strikes me more closely than does the decision to open ANWR to oil drilling and exploration. And while I made an attempt to present some balance to the picture, invariably that MBTA section will read as more advocating a position against Trumps policy than does the ANWR section. Unwinding reason and emotion is an impossible task. Yet, impossibility is not the end of the policy discussion, and there is much worth pursuing. We must be open to seeing alternative points of view if we hope to persuade those who disagree, Stone says, and it is this lesson that I think is the most enduring and helpful to me. The second lesson from Stone relevant here is her eight challenges (p. 40) found in chapter two. Stone uses a chocolate cake, and the impossibility of distributing it fairly in the eyes of all involved, to teach her policy students how it is possible to have competing visions of an equitable distribution (p. 39). The different challenges to equity can be systematically though of in three dimensions: recipients, items, and process. Her theoretical framework becomes more complex, but these three, high-level dimensions are useful for me when I begin to examine the policy debates around any topic. When asking why didnt President Trumps space exploration policy invoke the heated partisan response we are used to seeing? I can use Stones three dimensions to arrive at a preliminary conception: Q: Who are the recipients with a stake in the policy? A: Mostly NASA contractors, who will see a shift in priorities, but their contracts likely stay in place, as the policy outcomes will not be emplaced for some time, and even then, the universe of space contractors is small enough that most contractors are likely to simply gain new contracts. Q: What is being distributed? A: Trumps space exploration directive keeps intact overall NASA funding, only shifting program funding a bit, and even then the bigger change of defunding the space station is many years away, past the sunset of the senior management at the agency. No one is losing today. Q: What is the process of distribution? A: No competition, lottery, or voting mechanism can be pointed at in process terms. There is no notion of fairness for some parties to gain traction on, as pointed to in the recipients and items questions above. Stone notes that (p. 52) processes of distribution create or destroy things of valueapart from the things they explicitly value. But in the case of Trumps space policy, little of value is at stake. The decisions have a long-time before becoming reality (leaving time for subsequent presidents to alter or retract the policy, as seems likely given the popularity of new presidents changing NASA funding priorities), and the biggest loser will be by then a 40-year-old project that is likely to have been retired soon anyway. 3.12 The Foreign Intelligence Surveillance Act (FISA) of 1978 (also Stone, Policy Paradox) The Foreign Intelligence Surveillance Act (FISA), and the resulting establishment of the Foreign Intelligence Surveillance Court (FISC), was passed in 1978, following revelations that President Nixon had used domestic law enforcement resources to spy on his political opponents. FISA represented a grand policy bargain between the executive, legislative, and judicial branches of US government, and both granted and restrained the powers of each. The purpose of the act was to prevent such illegal surveillance, while simultaneously creating a separate mechanism for foreign intelligence activities to retain their ability to surveil potential threats. Substantively construed as a piece of legislative reform, FISA now enters its 40th year as law, and far from being simply a piece of historical interest, has become the object of significant policy debate, particularly in the years since the terrorist attacks of September 11, 2001. This essay begins with a review of the original formulation of FISA, the administrative organs it brought into being, and the political climate which birthed it. In the second section, I discuss the two primary amendments to the original act, first in 2001 by the Patriot Act, and again shortly after with the FISA Amendments Act of 2008. The third section covers the interest groups which both support and oppose aspects of FISA, both originally and in its amended forms. Finally, the essay concludes with theoretical framing from Deborah Stones (1997) Policy Paradox, which casts FISA in conflicting views of security and process. 3.12.1 The Foreign Intelligence Surveillance Act of 1978 The Fourth Amendment of the US constitution provides protection for Americans from unreasonable search and seizure at the hands of the government and its agents. Key to these protections is judicial review of search warrant applications, which are intended to insure that prior to governmental intrusion into the person, places, papers, and property of an American, a judge must review the reason, the probable cause, for why the proposed search is legally reasonable. However, the 1970s brought a host of (Mayer, 2002, p. 249) sinister programs which embarrassed the nation. While President Nixons use of domestic law enforcement resources to spy on his political opponents was at the forefront of these embarrassments, other missteps and outright violations by federal agencies through programs such as (Mayer, 2002, p. 249) the FBIS COINTELPRO, the NSAS Shamrock and Minaret, and the CIAs Chaos contributed to the call for reform. These concerns eventually led to the several US Senate committee investigations by Senators Sam Ervin and Frank Church. Somewhat ironically, given the concern for overly secretive governmental activity, following these investigations a series of closed-door legislative meetings eventually gave life to the original Foreign Intelligence Surveillance Act (FISA). The original bill was sponsored by Senator Ted Kennedy (MA) and had nine co-sponsors, including Utahs Senator Jake Garn. The FISA bill was passed into law with the signature of President Jimmy Carter on October 25, 1978. 3.12.2 Political Context of FISA (1978) The original FISA law aimed to both solidify the protection of Americans from unwarranted surveillance and intrusion, while still allowing for the robust foreign counter-intelligence required to protect a country which was still engaged in an active Cold War with its Communist enemy states, primary the USSR. On the one hand, it was argued, to simply require foreign intelligence agencies to apply through traditional Fourth Amendment channels  that is, traditional judicial review  profoundly risked national security. On the other hand, to trust in the unmitigated and unreviewed judgment of foreign intelligence agents had already exposed innocent Americans to violations of their constitutional rights. When the Supreme Court of the United States was presented in 1972 with the opportunity to carve out a 4th amendment exception for domestic security in the United States v. United States District Court (also known as the Keith decision), their 8-0 upholding the warrant requirement was clear in Justice Lewis majority opinion: The price of lawful public dissent must not be a dread of subjection to an unchecked surveillance power. Nor must the fear of unauthorized official eavesdropping deter vigorous citizen dissent and discussion of Government action in private conversation. For private dissent, no less than open public discourse, is essential to our free society. While the Supreme Court was clearly placing limits on executive authority to surveil without a warrant, the Keith ruling failed to prescribe a comprehensive solution to the very real and conflicting demands of maintaining domestic order and yet leaving the privacy of Americans untrammeled. The answer lay in FISAs establishment of the Foreign Intelligence Surveillance Court. 3.12.3 The Foreign Intelligence Surveillance Court (FISC) The FISC specifically, and FISA generally, represented a grand bargain between the all three branches of the federal government. The executive agreed to allow its surveillant powers to be curtailed and reviewed through a court established by Congressional act, and Congress allowed that judicial review to take place out of public view, in secret courts. The FISC itself was a new agency, a specialized court whose judges would be directly appointed by the Chief Justice of the US Supreme Court to staggered, seven-year terms, allowing for the appointment of one judge per year. In the event a warrant is denied by a FISC judge, the government may seek appeal to the entire FISC panel of judges, or to a panel of three sitting circuit judges (known as the Foreign Intelligence Surveillance Court of Review, and has only held two sessions, in 2002 and 2008), or to the Supreme Court itself. Thus, all three branches were activated and engaged in the reform policy. Under FISA rules intelligence agencies may conduct warrantless operations without FISC approval, but only and exclusively against foreign targets, and only for up to one year (assuming Presidential authorization through his Attorney General). In the event the target of the surveillance is a US citizen, or the operation extends further than a year, or any other set of facts falling outside the relatively narrow scope of the classic FISA definitions, then a warrant for the surveillance operation must be sought through the FISC. FISC judges hear only cases related to foreign surveillance. During their seven-year terms, they serve one week of every eleven, as demanded by law, in Washington D.C. (and there must always be at least three FISC judges within 20 miles of the capitol). FISC cases are heard ex parte, with only the government providing evidence and testimony  putting it quite outside the normal operation of other courts hearing warrant requests. Outside of the FISC, a judge can be relatively sure that the issuance of an ex parte warrant stands a credible chance of being challenged through eventual defense counsel. Foreign intelligence warrant applications, on the other hand, do not have that same assurance, as it is often unlikely (though not impossible) that foreign intelligence operations will result in criminal charges, particularly if the foreign agent is working on behalf of another nations own intelligence service. The focus of FISA is to facilitate foreign intelligence investigations  and not criminal prosecutions, (Vladeck, 2015, p. 1167) and this focus served to lessen resistance to the court using a relatively lower probable cause standard in deciding whether to issue the warrants applied for. Congress appeared to believe the creation of the specialized court was beneficial for two primary reasons: specialized knowledge and familiarity with the foreign intelligence concerns brought before it, and expediency. To the first, the court would (Vladeck, 2015, p. 1166) be able to put claims of national security in better perspective than would judges who do not have occasion to deal with the foreign surveillance issues considered under FISA. To the second, Congress placed specific geographic requirements for the judges, at least three of them at any time, to be quickly available in Washington DC, so that agents seeking time-sensitive warrants were able to quickly access a FISC magistrate. 3.12.4 Classic FISA and its Amendments So far, this essay has only briefly covered FISA in its original form, sometimes referred to as Classic FISA. In reality, FISA was almost immediately met with calls from foreign intelligence agencies to update the law. In 1979, the first year after FISA became law, FISC judges heard 199 applications for surveillance, and issued 207 orders for foreign surveillance (Senate Report, 1980, p. 2). Despite what seemed a high success rate for surveillance applications, heads of agencies charges with foreign surveillance asked Congress for revisions to the emergency surveillance portions of the law, as they thought the 24-hour window in which such surveillance could be conducted sans warrant was too small, as NSA Director Inman testified that (Senate Report, 1980, p. 7) we were not farsighted enough to recognize in the bureaucracy, with weekends and things like that, 24 hours is not very long for emergency; 48 would be better. Director Stansfield of the CIA was less prosaic, noting in his testimony that the 24-hour period is inadequate, leading to the necessity of delaying implementation of emergency surveillances. Small amendments such as those found in the 1980 amendments (Senate Report, 1980)  extending the time frame of emergency surveillance, expanded definitions of agent of a foreign power, and whether US agents could make physical entry into the property of certain foreign state actors  were typical of FISA amendments for the first 24 years of its existence. Through the end of 2001, FISA was rarely the target of media interest, and the regulations settled quietly into the quiet, orderly existence of most federal regulation. However, that comfort was seriously upended with the terrorist attacks of September 11, 2001. 3.12.5 The USA Patriot Act of 2001 The Uniting and Strengthening America by Providing Appropriate Tools Required to Intercept and Obstruct Terrorism Act of 2001 (USA PATRIOT Act, hereafter Patriot Act) was passed into law less than two full months after terrorists flew two commercial airliners into the Twin Towers of New York City, killing 2,996 people, injuring over 6,000 more, and causing at least $10 billion dollars in direct infrastructure damage, between $40 an $70 billion dollars in insured damage, and even more (but inestimable) in uninsured loss (Cummins &amp; Lewis, 2003). While the Patriot Act of 2001 is a large comprehensive policy, here the discussion will be limited to the provisions contained within Title II of the act, entitled Enhanced Surveillance Procedures. Title II of the Patriot Act primarily amended FISA, and the substantive changes were unsurprisingly related to the phenomenon of non-state terrorist actors. Under the classic FISA definitions these actors were not subject to surveillance without warrant, as classic FISA was written in an age where the clandestine efforts of state actors were the primary concern of policy makers and intelligence services. In addition to expanding the definition to terrorist actors, the most controversial provision allowed for the collection of foreign intelligence information from those residing in the United States, both non-citizens and US citizens alike. Title II also gave expanded scope of searches to agencies, including so-called sneak and peek warrants, and roving wiretaps, both of which proved controversial. The Title II amendments also allow for any federal district court judge to issue surveillance orders, where as discussed earlier this was originally the sole jurisdictional purview of FISC judges. 3.12.6 Protect America Act of 2007 President Bushs War on Terror continued apace through 2007, as did the intelligence agencies work to protect the country from further attack. As the intelligence gathering techniques of the nations intelligence agencies continued to grow in sophistication, so did the counter-intelligence techniques of the foreign and terrorist targets of surveillance, and President Bush urged Congress to overhaul FISA in order to avoid restricting the ability of intelligence agencies to do their critical work. In 2007 Congress complied and passed the Protect America Act (PAA). While construed as an amendment, the PAA was in effect a complete overhaul of FISA, and allowed for even greater surveillance without warrant so long as it was it was directed at one or more persons reasonably believed to be outside the US. This had the effect of removing from FISC supervision much of the surveillance conducted by US agencies, as the acting agency had only to report through their own chain of command the reasonable belief that at least one of the surveillance targets resided outside the US. The PAA also compelled communication companies  internet service providers and cell phone companies included  to comply with administrative orders from the intelligence agencies, and in turn granted civil immunity to those providers acting under the color of the same. The Foreign Intelligence Surveillance Act of 1978 Amendments Act of 2008 followed the PAA of 2007 with additional strengthening of the warrantless surveillance activities of the US intelligence services. Its provisions increased even further the window for emergency surveillance (complaints about this time window stretch back to the days immediately following original passage of FISA in 1978, see Director Ingram and Director Stansfields Senate testimony earlier), gave civil immunity to telecom providers who were compelled to provide information to requesting intelligence agencies, and finally added more ability for US agents to use emergency eavesdropping to gather foreign intelligence absent court supervision. The final legislative activity related to FISA occurred in late 2017 and early 2018, as provisions of both the PAA and the amendments of 2008 were set to expire at the end of 2017. Despite a great deal of controversy surrounding government surveillance since the Patriot Act, and continuing in the sixteen years after, Congress was convinced by the intelligence community of the need for an extension of the provisions. On January 18, 2018, the Senate passed the FISA Amendments Reauthorization Act of 2017, and the next day the bill was signed into law by President Trump. The substantive effects of FISA and its amendments were thus extended for six years, through December 31, 2023. 3.12.7 Critics and Supporters of FISA As FISA exists in both its classic and modern forms (Vladeck, 2015), with its most controversial aspects enacted in the post-September 11, 2001 forms, this section will only briefly touch on the relatively uncontroversial nature of its original 1978 passage. As noted earlier, the political atmosphere in the 1970s was one where the passage of FISA was relatively uncontroversial given the nature of the surveillant intrusions by federal agencies, and by President Nixon himself. There was a clear sense, especially following the Keith decision by the US Supreme Court, that all three federal government branches had to come up with a structure which both reified the Fourth amendment protections for Americans, while simultaneously allowing the intelligence agencies to protect against foreign intelligence operations without undue interference. The negotiations which led to FISA were closed-door affairs, as Senators consulted with intelligence agency heads to construct a lasting solution. Given the secretive nature of those negotiations, controversy was relatively muted. For the most part, the original crafters succeeded in their aims, and the FISA bill of 1978 survived in its original form through the rest of the century. In the tension and fear which followed the attacks of September 11, 2001, the Patriot Act passed without much controversy. However, in 2005, with the publication by the New York Times (Risen &amp; Lichtblau, 2005) of details of warrantless surveillance by the NSA on Americans, FISA became a highly visible policy, with the expected resultant criticism. The New York Times article revealed that at any given time, up to 500 Americans were surveillance targets, and that the surveillance was ofttimes conducted without a warrant, under the relaxed constraints granted by the Patriot Act. The most common criticism, leveled by organizations such as the American Civil Liberties Union (ACLU) and the Electronic Frontier Foundation. Broadly, these organizations remain committed to the ideals of a 4th amendment unsullied by considerations of national security  that is, that they seek to meaningfully reform our broad surveillance authorities (ACLU, et al., 2017). One such reform that is popular outside just the activist community is the creation of a special advocate (Vladeck, 2014) within the existing FISC structure. Such an advocate would (Vladeck, 2015, p. 1176) appear opposite of the government in at least some cases before the FISC and to argue on behalf of the public, those whose communications are being targeted by the government application at issue, or some combination of the two. The special advocate would, theoretically, be able to contest the governments case for surveillance, introducing the ability for the FISC judge to consider more than just the governments assertions. Some critics of the surveillance powers of the US, including Glen Greenwald, have tied those historical concerns to their portrayal of President Trump as unstable, and likely to abuse the powers of FISA. Given those concerns, Greenwald (2018), in his typically restrained prose, argued that The same Democrats who denounce Donald Trump as a lawless, treasonous authoritarian just voted to give him vast warrantless spying powers. On the whole, those in favor of continuing the paradigm of FISA tend to have had the stronger voices, at least in the legislative forums which make decisions related to FISA. Even politicians who are aligned strongly against the current presidential administration, including Democrats Nancy Pelosi and Adam Schiff, supported the extension of the FISA amendments in the 2017 bill. Many have endorsed the broad FISA regime as emblematic of the potential for good policy to protect both privacy interests and national security, due to how carefully controlled it is (Goldsmith &amp; Hennesy, 2018, pp. 5), and even privacy proponents and critics of President Trump: have a high degree of confidence that the National Security Agency and the U.S. intelligence community more broadly cannot and will not abuse the 702 tool even if they harbor concerns that Trump might desire to do so. They know that 702 is deeply embedded in a reticulate legal system run mostly by career public servants and supervised by all three branches of government, including numerous agencies in the executive branch, the congressional intelligence committees and the life-tenured members of the FISA court. In short, the answer to Greenwalds puzzle about Trump critics voting for 702 reauthorization is that the NSA and FBI are remarkably immune from inappropriate presidential meddling. With the extension of FISA and its modern amendments through the last day 2023, there does not appear to be any realistic threat to its viability as the ruling policy on foreign surveillance in the United States. 3.12.8 FISA Through Stones Policy Paradox Deborah Stones (1997) formulation of legal rights in the polis offers a useful scaffolding for working through the complex balance of securities inherent in discussion of FISA. Rights are not solid objects, they require interpretation, and in the US system that interpretation takes place in the legal system. The myth of legal rights holds that all are equal before the law (Stone, 1997, p. 344), and rights are tested and enforced in a unbiased legal system, where defendants are able to meet the government on equal ground, where the best argument between equals wins the day. But of course, in the system of FISA, none of this is exactly true. FISA laid the administrative structure for FISC, and has the trappings of a neutral, unbiased court, with the appointment of magistrates who (theoretically) are able to hold the government accountable by denying agents application for surveillance warrants. However, it is important to take into account the actual process in FISC courts. They are held in camera, without the benefit of the public eye to correct oversteps or collusion. The hearings are by their nature ex parte, and only rarely are defendants ever notified through criminal hearings, let alone given the opportunity to confront the government and test the probable cause of the surveillance warrants. Stone differentiates between the identities of parties, one-shotters and repeat players, in the legal system. One-shotters enter the legal system once, or at least rarely, and are focused on the tangible outcome of the legal case rather than establishment of favorable rulings to govern future cases. Repeat players, on the other hand, are frequently litigants, and are much more likely to have great legal resources to engage in protracted, strategic legal battles. In battles between one-shotters and repeat players, the parties are not equal before the law (Stone, 1997, p. 346) and the repeat players are likely to dominate through their resource advantage. Further, they hold the balance of bargaining power, and are more likely to fight to the end rather than bargain in order to force the court to produce a rule change as well as a tangible remedy (Stone, 1997, p. 346). Stones formulation here is both helpful in examining the FISC system, as well as somewhat blind to the realities of the specialized courts found under FISA, and her conclusions dont go far enough to adequately describe the power imbalance. It is useful to the extent that in FISC hearings, the government has virtually unlimited resources, and can engage in ongoing, repeated attempts to attain the result they want. However, the extreme imbalance wrought by FISC hearings held both in camera and ex parte results in legal imbalances so large that Stones concepts dont envision them at all. The defendants in FISC hearings are not truly one-shotters  they are no-shotters who never appear before FISC judges, nor rarely even criminal court judges. And yet, simultaneously, the government and the judge are not only repeat players, they are repeat players with each other, as the universe of intelligence agencies, their intelligence lawyers and agents, and the eleven FISC judges is quite small indeed. This results in the same judges making decisions about warrant applications made by the same agents, over and over. While it is hard to imagine any of these legal players anything but the most professional, ethical, and high-minded individuals the civil service has to offer, they are human, and humans are social creatures prone to the mistakes of social creatures. Asking that none of those players take on beliefs about the other based on their previous interactions is to ask them to set aside their humanness. A FISC judge, who has seen forty superb surveillance applications from the same Department of Justice lawyer representing the FBI can be imagined to have developed some sense that she can trust the probable cause representations of that lawyer. Stones theoretical approach to rights led to my support for the idea of an independent special advocate to act as an additional check upon the governments case during FISC applications. The concept of a devils advocate stretches back to ancient times, with the position filled at the Vatican by a senior Cardinal, who, though he remained loyal to the Pope and Council, was also bound to challenge decisions by both to the best of the advocates ability, even in those tiems where the advocate personally would have endorsed the decision. Similarly, in the FISC system, a special advocate would be charged with providing the best challenge he could to the governments case. Properly designed, such a position would strengthen both the governments case in the event of later challenge, but also the public perception that decisions by the FISC court were undertaken in the best spirit possible. This, in turn, would strengthen the ability of the FISA laws themselves to protect the privacy of Americans which provided the impetus for the laws original passage in 1978. 3.13 Public Administration: Traditions &amp; Roots As a discipline, public administration is a study in unresolved, and unresolvable, tensions. The term public administration itself is hard to define perfectly: Is it the professional practice of running public and non-profit services, or the academic study of that work that seeks to (Marini, 2000, p. 3) understand, develop, criticize, and improve that professional practice as well as train individuals for that professional practice? Does running government differ from running a business? How intertwined are politics and administration? How intertwined should they be? As we confront the difficult tradeoffs in public policy, should we pay more attention to facts, or values? This essay will review the traditions of primarily academic public administration, though its practitioners make appearances as well  like attempts to divide politics from public administration, attempting to describe American public administration through only its theorists is a doomed effort. John Rohr (1986) laid out three foundings he saw as important milestones in American public administration: the founding of the Republic (1787-1795); the founding of modern modes of public administration (1883-1889); and the founding of the administrative state (1933-1941). For the most part I will follow those signposts in the early sections of the essay, though I extend into the modern era as well as the essay presses into the influence of Herbert Simon and the future of public administration. The essay proceeds as follows. In the first section I review the co-founding of America with the founding of the first public administration norms of George Washington and administrative structures of Alexander Hamilton. In the second section the essay recounts the foundation of academic public administration through the works of Wilson, Taylor, Gulick, and Barnard. In the third section the foundation of American pragmatism is shattered as Wilson leads the US into World War I, giving rise to a progressive movement that embraced an overlooked influence on public administration, John Dewey. This section concludes with the New Deal, a vast expansion of the administrative state through the leadership of Roosevelt 3.13.1 The Founding The dilemmas and tensions that the field of public administration is concerned with today are to a great degree the same that have been of concern from the moment of the nations founding. The Constitution set forth the tenets and framework that the nations Founders believed gave the nation a coherent way of addressing those dilemmas. George Washington, and Alexander Hamilton provide two institutionalized views of how to run a constitution: A system that holds service to the public as its first principle, and a blended economic, commercial, and military union that could prevail in the storm of state-based interests that would confront the nation. George Washington was Americas first president, and the nations first executive administrator. Without binding precedent to guide him, Washingtons actions would themselves become the guide for all that followed. Key among his challenges was the creation of the tools to run the constitution, a challenge that for many public administration scholars remains the highest calling for the field. Washington was well aware that as first president, his actions would reverberate throughout the nations future history. As such, he believed the foundation of his actions needed to be firmly set in principle. As he wrote to James Madison (quoted in Cook &amp; Klay, 2015, p. 76), As the first of everything, in our situation, will serve to establish a Precedent, it is devoutly wished on my part, that these precedents be fixed on true principles. Among his first actions was establishing a public administration, and the true principle Washington tied it to was the public wishes and affection. In other words, public administration should rest upon service of the public will. In his 1791 address to Congress, Washington tied the establishment of the direction of the nations public administration directly to the public will (Cook &amp; Klay, 2015, p. 77): It is desirable on all occasions, to unite with a steady and firm adherence to constitutional and necessary Act of Government, the fullest evidence of a disposition, as far as may be practicable, to consult the wishes of every part of the community, and to lay the foundations of the public administration in the affection of the people. The constitution did not directly provide for a public administration, and Washington was to sketch out the institutional foundations that were necessary to run a constitution. In the centennial year of the Constitution, Woodrow Wilson, known as the first scholar of public administration, would highlight the challenge (W. Wilson, 1887): It is getting to be harder to run a constitution than to frame one. The rough sketch of how to establish a public administration may have been penciled in by George Washington, but it was the hand of Alexander Hamilton that inked in depth and detail. Like Washington, Hamilton was a hero of the Revolutionary War, and he would establish and administer the signal public agencies of the first decades of the new republic (Green, 2019). Much of Hamiltons approach to public administration is not found in the Constitution he helped create, but in the Federalist papers (Hamilton, Madison, &amp; Jay, 2009) that defended the Constitution to a nation distrustful of a new Federal nation. Hamilton was responsible for authoring approximately 50 of the Federalist Papers, and he saw that the government could not solely be about checking power among the three branches, it would also have to enable action. Hamiltons concept of partial agency meant that powers should be blended among the executive, legislative, and judicial branches, such that the three institutions would collaborate to address the problems of the nation. His Federalist co-conspirator James Madison was a patrician elite who was focused on keeping the federated states civil especially in regards to interstate trade, but it was Hamilton who saw that the federal government should seek that civility explicitly through the development of a complex economic union. To accomplish that vision, Hamilton spent a great deal of his time enhacing executive power. Hamilton saw that the young nations survival would require an intricate bonding of the commercial and military functions of the state. Critical to that bonding was a strong defensive military capability, and as Secretary of the Treasury Hamilton oversaw many of the first efforts in that domain. Green gives a sense of Hamiltons influence and scope as he shaped American defensive capabilities in a variety of administrative contexts (Green, 2019, p. 156): he attended to the organization and management of the Department of War, and through his management of the Customs Service and a fledgling Coast Guard, he oversaw the protection of harbors from French privateering as the French Revolution ensued. He also equipped militias and helped Washington lead in the successful effort to quell the Whiskey Rebellion in western Pennsylvania in 1794. When war loomed with France in the late 1790s, he returned to the military as a major general, second-in-command to General Washington, serving also as inspector general of the Provisional Army until 1800. He laid extensive plans and lobbied hard for the establishment of the navy, for the outfitting of a small standing army, and for professional military academies in which to train military leaders and subordinate officers in matters ranging from broad military policy to the technology of warfare. As he discusses in Federalist essays 23-29 (Hamilton et al., 2009), Hamilton believed a permanent military establishment would eventually become necessary to secure the republic. However, distrust of centralized federal power among Anti-Federalists was strong and able to prevent the establishment of a fulltime federal military until after the Civil War. We should not underestimate Hamiltons impact on public administration based on whether an institution was or was not established, because it is his vision that so strongly permeates how we think about public administration even today. The controversies Hamilton confronted were often left unresolved, and persist today. Hamilton was born to the lower class, and knew what it meant to be treated like a second-class citizen. Hamilton suggested that indigenous and Black Americans should be treated as citizens (though he famously did not include women in his progressive vision). Of course, even today America has not resolved its racial or gender inequality. Hamilton sought social revolution through commercial and economic revolution. His successes come to us today as unresolved questions on public versus business administration. Perhaps the most lasting unresolved controversy is Hamiltons view that there was no politics and policy dichotomy: Administration and policy merged seamlessly in his mind, each conditioning the other (Green, 2019). 3.13.2 Founding of Academic Public Administration The founding of the American nation and its first administrative scaffolding was successful. A system of addressing the controversies resulted in regularized processes of administrative law. The Constitutions framers created a certain ambivalence in the status and direction of American public administration (OToole, 1987). The Constitution embedded the concept of separation of powers the American consciousness, and so it should be no surprise that as the administrative state was founded, there were efforts to imbue a similar balance by dividing politics and policy. The Pendleton Act, also known as the Civil Service Act of 1883, is an example of attempts to divide politics from administration (Theriault, 2003). The act aimed to insulate the bureaucracy from political influence, and even more obviously represented an effort to enact the dichotomy (OToole, 1987). Before Wilson introduced his own dichotomy to public administration there were efforts to legislatively do the same to the practice of administration, such as the Budget and Accounting Act of 1821 - probably the greatest landmark of our administrative history except for the Constitution itself (Emmerich, 1971). Similarly, the Hatch Act of 1939 legislated the dichotomy even further by prohibiting federal employees (and some state and local by 1940 amendment) from participating in most partisan political activities. Public administration scholars have generally been hostile to the principles of separation of powers(Waldo, 2017). The field itself was founded in a Wilsonian tradition that held up the separation of politics and administration. While we have moved away from that dichotomy, have we really confronted what our field tends to do - calling for greater and greater executive powers? We are a field of the executive branch, and many of our prescriptions are overtly hostile to the legislative process and for an expansion of the executive branch. The first century of the nation established a public administration apparatus, but it took that century before any scholarly attempt to study it began. Woodrow Wilson was the first to do so in 1887. Though much later he would become president himself, at the time he was interested in government and how to best understand how a government should organize its efforts. In his article Study of Administration (W. Wilson, 1887), he argued that the complexity of government meant that the best was to study it was from two perspectives: the politics found in the legislative function, and the public administration found in the executive functions of government. This gave birth to a politics and policy dichotomy that would dominate our academic understanding of public administration until late in the 20th century. Though Wilson acknowledged that the two areas of government were intertwined, his contribution of the dichotomy was a convenience to simplify the study of it. Wilson argued that the politics of governing could best be understood when it was intentionally isolated from the administration of political decisions. In this early Wilsonian view, decisions about who gets what, when, and how (Lasswell, 1936) are best understood by studying the political and legislative (who gets what, when), separate from the executive actions to complete politics decisions (how). Wilson sought to scientifically uncover the principles that would enable public officials to run the Constitution, by establishing the study of public administration as a field of study separate from politics. Classic public administration scholarship was dominated by this kind of thinking, exemplified in Frederick Taylors (1914) scientific management, and Luther Gulicks (1937)acronym POSDCORB: (planning, organizing, staffing, directing, coordinating, reporting, and budgeting). Neither of these outlooks on public administration are completely unuseful or unused, even today. Taylor was an engineer interested in applying the scientific method towards management, and finding the one best way to organize human effort. He scientific management as putting greater demands on management and easing the work of the worker. Taylor advocated a scientific approach, to move the knowledge contained in workmans heads onto paper where it could be studied, and best practices extracted and then propagated to other systems. In his view, this would lead to very little conflict between workmen and management. Gulick attempted to move beyond Taylors scientific management, with an effort to more logically divide work. Gulick proposed there are limits to division of work, and that proper coordination among the divisions of labor are necessary: If subdivision is necessary, so is coordination of that work. Gulick was an early positivist who believed empirical research would be necessary to understand a range of questions, including the proper span of control, or how many laborers a manager could be expected to manage well. He did not approve of multiple command, but rather urged unity of command. Finally, he was not a technocrat and did not trust experts to stay within their own field: experts on tap, not on top. Organization must be approached from both bottom-up and top-down perspectives. Gulick combined his insights into a theory of the proper executive: A chief executives job is PODSCORB planning, organizing, staffing, directing, coordinating, reporting, budgeting. 3.13.3 Pragmatism, War, and Progressivism The United States entered World War I under the presidential leadership of Woodrow Wilson, who is also often recognized the first formal scholar of public administration (Wilson, 1887). The bureau men of public administration embraced Progressive era ideals that were born in rejection of the atrocities of World War I, and further, an optimism that industry and science that would lead the country to a new golden administrative age (Stivers, 1995, 2002). Progressive reformers were informed by the pragmatists of an earlier decade such as John Dewey, who was distrustful of the absolute reason imposed by the Hegelian ideal of the state (Dewey, 1915), and especially its institutional form found in the Prussian and Germanic military states. As Spicer (2005) reminds us, there is a clear link between the Prussian military state and foundational public administrative thought  what Spicer deems the purposive state: a nation that turns its power, resources and citizens towards certain ends; as opposed to the state as a civil association. Spicer succeeds in showing the influence of Prussian and German thinking on modern American administration through their influence on Woodrow Wilson and others. Dewey was wary of the militarism that he saw in Wilson and others, particularly a warlike mentality and nationalism he felt was ultimately destructive to his normative view of what the American state could be, arguing that (Dewey, 1915, p. 118) philosophical justification of war follows inevitably from a philosophy of history composed in nationalistic terms. History is the movement, the march of God on earth through time. . . . War is the signally visible occurrence of such a flight of the divine spirit in its onward movement. The idea that friendly intercourse among all the peoples of the earth is a legitimate aim of the human effort is the basic contradiction of such a philosophy. Though Wilson expressed disquiet about Prussian state theory almost thirty years earlier (W. Wilson, 1887), he believed Americans could safeguard against the excesses, that we could borrow effective methods of sharpening a knife without engaging in the same murderous ends. Though foundational, Wilsons propensity to engage in self-evident truths would be replaced by public administration scholars wary of easy answers based on clever metaphors (Elinor Ostrom, 2000; Simon, 1946). Dewey would fill in his own normative view of what the state should be in 1927 with The Public and Its Problems (Dewey &amp; Rogers, 2012). The book laid out a modest vision compared to the purposive state (Spicer, 2005). The progressive state existed to act against and control the negative consequences of technology, and to harness the benefits with the instrumental goal of enhancing the lives of the public. Deweys account provided the foundation of Progressivism and the good society (Lippman, 1937), and has been influential throughout American political thought, including Habermas pragmatist conceptions of technology, which promotes a mutually shaped science and politics in service of the practical needs of the citizenry (Habermas, 1970). It has also been argued that Deweys pragmatism set the guideposts for pragmatic, solutions-oriented Black American political thought after the civil-rights movement (Glaude, 2007). Pragmatism, in Deweys view, is an account of how people think  the way they form ideas and beliefs, and how those translate to decisions. This idea can be seen in the formative legal philosophy of US Supreme Court Justice Oliver Wendell Holmes, especially his conception of the reasonable man (Mendelson, 1951). Holmes was scarred by his experiences in the Civil War (Menand, 2001), and pragmatism gave him the philosophical case for rejecting the metaphysics and transcendentalism that he saw as morally bankrupt following such destruction. Holmes jurisprudence relied on and synthesized the pragmatism of Emerson, Peirce, and Dewey (Menand, 2001; Mendenhall, 2015). Pragmatism focused on practicality and experience, and was soon adopted by the Progressive era reformers who sought to use that approach to highlight human progress. Dewey was important to a great many areas of scholarship, including education scholarship, but for public administration we might consider his most immediate effect was on the pragmatic progressives depicted in Bureau Men, Settlement Women (Stivers, 2002). The books central theme is the establishment of the scientific-analytic and business-like public administration in the Progressive Era. Stivers sees there were two competing, gendered visions of public administration heading into the progressive era - women who were working with the people they were serving, and men who were attempting to professionalize and used the language of science to deflect political attacks on them as effeminate: Long haired men and short haired women. The bureau men and their vision of a scientific approach to governance won out, but we lost out on the path of public administration that works closely with practitioners and those affected by our policy and research. That lost vision would eventually be redeemed somewhat in Dwight Waldos 1948 vision of the administrative state (2017), and echoes of it would be found in the largest modern expansion of the public administrative state. Roosevelts New Deal would eventually make good on Progressive promises, instituting the largest expansion of the American administrative state in history. Despite his Progressive alignment, he did not embrace the progressive glass firewall theory that civil administrators could largely leave military matters to the military (Stever, 1999), or that war was anachronistic to the Great Society (Lippman, 1937, p. 159). War support became somewhat of a litmus test within Progressive circles, and even Deweys status was called into question after he voiced support for US entry into World War II. As an early supporter of Wilsons presidential bid, Roosevelt was repaid for his loyalty with an appointment as Assistant Secretary of the Navy during World War I. As Assistant Secretary of the Navy Roosevelt instituted civil reforms of the Navy including merit-based promotions, and his reforms extended civilian control of the military broadly (Smith, 2007, see pp. 102106). His experience there also exposed him to the difficulties in managing the relationships between union workers and public agencies. He handled the difficulty well, and in his seven years in post not a single strike was called (Burns, 1956, p. 52). Now President Roosevelt would call on that military, and the combined American public apparatus, as he led the country into World War II, an feat dubbed administrative mass organization that relied heavily on the scientism and technocratic abilities established by Taylor a generation earlier (Kasza, 1995). Following the Allied victory, a leading hero of that war was turned into the pre-eminent exporter of American public administration as the Military Governor of post-war Japan, and his administrative style may have had a more lasting impact on current world events than his military exploits (Tehan, 2002, p. v). 3.13.4 Behavioralism and Beyond The end of World War II brought about the end of orthodox (or classical) public administration, and the beginning of behavioral, empirical public administration (Marini, 2000). The behavioralist bent was not unique to public administration scholarship, and was sweeping across the social sciences broadly. In public administration, the behavioralist turn was simultaneously taking place alongside a hew humanistic, values-oriented approach. This essay will explore the most visible debate between those two views later in recounting the Simon/Waldo debates (Simon, Drucker, &amp; Waldo, 1952). First, however, I trace how the bureaucratic approach was converted or an organizational one. The post-WWII period brought a new energy to the study of public administration and efforts to diversify its theoretical and empirical study. Gulicks (1937) bureaucratic approach covered earlier is still alive and well in the practice of public administration, even as its academic study leaves the acronym behind as too simplistic. Even in Gulicks day other scholars thought his prescription was unrealistic, and too unfocused on the people that make organizations work. Charles Barnard (1938) recognized the importance of individuals, and that organizations cannot be well understood without understanding people. While Gulick focused on the formal lines of command, familiar to us today as org charts, Barnard highlighted the importance of informal organizations. Informal organizations are based on personal rather than joint purposes, and promote uniform states of mind by crystallizing mores and customs. Barnard set out several ways informal and formal organizations are interdependent: Informal organizations give rise to formal organizations; formal organizations are necessary to any large informal organization; formal organizations make explicit the states of mind developed within the informal organizations; formal organizations in turn also create new informal organizations. Finally, informal orgs are necessary to formal organizations as means of communication, cohesion, and of protecting integrity of the individual. A sociologist at Columbia University, Robert Merton (1939) stressed how the study of bureaucracy misses the importance of personalities within the bureaucratic structure. Merton saw how bureaucracies infuse the employees with certain rules in order to maximize efficiency, but these rules become the end, instead of a means to the end (i.e. red tape). Merton called on other social scientists to begin studying public administration. Many soon did, and relied on a Maslows hierarchy of needs as a basis for understanding human motivation in organizations. Also at Columbia University, Maslow (1943) described a basic structure of human needs, arranged in hierarchies of prepotency: Basic needs, safety needs, love needs, and self-actualization. Though not substantiated empirically, Maslows hierarchy proved crucial to the beginnings of motivational and human-focused theories in the study of administration. 3.13.4.1 Human Centered Approaches The human focus for some public administration scholars can be seen in MacGregor (1960) and his Theory X and Theory Y approach to motivating employees. Most of public administration had been based on expectations that employees would shirk their responsibilities and therefore needed close supervision and clear punishments to keep them in line. MacGregor saw that another approach based on Maslows hierarchy of needs (Maslow, 1943) was better suited to the evolving workplace. In this Theory Y, MacGregor advocated that the individual worker is creative and driven, and a good manager encourages employees to problem-solve on their own, gives them the tools to do so, and then gets out of the way. Theory Y is management by objectives rather than the carrot and stick management of Theory X, and MacGregor saw this as the necessary adjustment to an evolving workforce that expected more out of work than mindless micromanagement: This is a process primarily of creating opportunities, releasing potential, removing obstacles, encouraging growth, providing guidance. In MacGregors view, this was not leadership for public managers, but management for both public and private agencies. 3.13.4.2 Divorcing Public from Private, Proverbs from Positivism The application of business principles to public administration practice was a taken-for-granted good in public administration, and even today there are consistent efforts to imbue government with the magical efficiency of public markets. One early effort to separate public and private management was made in the book Government is Different (Appleby, 1945). Three aspects differentiate running a government versus a business. First, government has a vastly expanded scope and impact. Second, government is publicly accountable to everyone, not just a small pool of shareh0lders. Third, the political character of public administration means that government must take into account the will and wishes of the people, a factor that recounts Washingtons founding principle of public administration. Appleby saw that government, in its people, attitude, and function, is different than any other activity, including business. He was especially critical of those who would come from the business world and expect government to be a good fit for them: Only a politician can be president. Government is different because government is politics, and while businesses are able to carefully select their market, government has no clearly delineated border: Statecraft - government - is different than all other professions because it is broader than anything else in the field of action. As late as 1955, with the publication of the first public administration textbook, business and public administration were still seen as somewhat synonymous, and the textbook called for a public administration that is more than the time-honored approach of muddling through (White, 1955). Public administration was seen as the great problem of government, and like the original call for more exacting study (W. Wilson, 1887), White (1955) suggested that American democracy could learn better administration techniques from the autocrats in Europe. There was growing focus on the longest-lived organizations, churches and universities (Downs, 1967), and Europe was home to the oldest of both (at least to the Western-centric scholars of public administration at the time). Even as Downs theorized the lifecycle of bureaus resulted in highly conservative institutions, however, the landscape of American public administration was shifting. Civil service unions were gaining power as their membership grew massively at both the federal and state level (Mosher, 1968). Bureaucrats were no longer the heroes of the progressive era and a new, negative connotation was taking hold. The unending cycle of reform in American public administration (Kaufman, 1969) was due to the uniqueness of the American experience, especially the constitutional nature of power separation that led to a succession of shifts in focus on three core values: representativeness, politically neutral competence, and executive leadership. Kaufman argued from a pluralist perspective, and saw that none of the three was ever truly absent from the American consciousness, but the focus changed. And as the focus changed, pressure from groups interested in the other two brought pressure and calls for more reform. Kaufman saw the calls for decentralization of government power in his time as the result of racial and youth power groups who felt under represented in the current regime. The constant reform was not a negative, however, as Kaufman wrote that wheels turning on their own axes still advance. 3.13.5 Simon and Waldo Debates The most critical inflection point in the modern study of public administration came from Herbert Simon. Simon was an organizational theorist who urged scholars to think carefully about what a methodology of public administration should be (Simon, 1946): How do we acquire scientific or empirical knowledge about public organizations? Webers (1946, 2015) ideal bureaucracy does not exist in the real world, so how can we compare and contrast the types of bureaucracy in a scientific sense? Herberts wide-ranging critique of the study of administration was born from the positivist and post-positivist debates (Popper, 1959) that sought to replace the verifiability claims of empiricists with a demand for falsifiability. Herbert likened what came before to proverbs, not scienceArmchair philosophizing about administrationhas gone about as far as it can profitably go in this particular direction. Herbert provided the push to turn the study of public administration towards positivist science. Dwight Waldo disagreed with Simons positivist prescription for the direction of public administration scholarship going forward, and the two engaged in an exchange of ideas in the pages of the American Journal of Political Science. The Simon-Waldo debate was structured on two differing philosophical perspectives that continue to define the study of public administration today (Harmon, 1989). The debate was quite ugly, and a full understanding of the importance of the debate only became clearer with the passage of time, and as Herberts unique genius became even more noticed with the awarding of the Nobel Prize in Economics in 1978 (March, 1978). However, two decades earlier the first punch in defining debate in public administration scholarship began with the fortieth footnote in Waldos essay Development of Theory of Democratic Administration. Waldo maintains that to follow arguments for efficiency in administration to their logical ends is to engage in nihilism, and then while he emphasizes the need for democratic values in making administrative decisions, he manages to slight Simons accomplishments as being unscientific (Waldo, 1952, p. 97): In this contention, the present weight of authority is against me. But I believe that there is no realm of factual decisions from which values are excluded. To decide is to choose between alternatives; to choose between alternatives is to introduce values. Herbert Simon has patently made outstanding contributions to administrative study. These contributions have been made, however, when he has worked free of the methodology he has asserted. Until this point, Waldo and Simon had been complimentary of one another, and both attacked the naÃ¯ve scientism that had dominated the study of administration to that point. However, beginning with Waldos salvo, it was clear that two competing visions had emerged. On the one hand, Simon drew analytic distinctions between facts and values, and then another distinction between administration and policy. On the opposing hand, Waldo insisted that administration and policy were both impossible to separate from normative values (Harmon, 1989, p. 440): Waldos project was, after all, to warn of the limits of science in human  and, in particular, administrative affairs, while Simons was to inform us of its power. Where Herbert sought efficiency, Waldo asked efficiency for whom? Many a barrel of ink has been spilled evaluating the Simon/Waldo debates, and it is outside the scope of this essay to cover the differences in full, nor is it particularly helpful to understand either Simon or Waldos philosophical orientation to public administration through a handful of their papers in the early 1950s. Some of the draw of this debate is no more than the dramatic counter-punching and name-calling that took place. For instance, consider this exchange opened by Simon in his first reply to Waldo, (Simon et al., 1952, p. 495): Quite apart from whether Mr. Waldos premises are right or wrong, I do not see how we can progress in political philosophy if we continue to think and write in the loose, literary, metaphorical style that he and most other political theorists adopt. The standard of unrigor that is tolerated in political theory would not receive a passing grade in the elementary course in logic, Aristothelian or symbolic. Waldo does not back down from his literary, metaphorical style in responding (Waldo, 1952, p. 501): Professor Simon charges me with profaning the sacred places of Logical Positivism, and I am afraid I have. I use this figure of speech because Professor Simon seems to be that rare individual in our secular age, a man of deep faith. His convictions are monolithic and massive. His toleration of heresy and sin is nil. The Road to Salvation is straight, narrow, one-way, and privately-owned. We must humbly confess our sins, accept the Word, be washed pure in the Blood of Carnap and Ayer. Then, he says, we will no longer be enemies. I do not mean to suggest the two did not engage with the substantive issues that had brought them to loggerheads in the first place. However, the visceral, pointed debates were more fun to watch because of the high personal stakes each was willing to bring to bear in defense of their philosophical orientations. This was not a removed, dry, and academic debate most were used to in the low-stakes scholarly pages of American Journal of Political Science. A stylistic dichotomy has persisted in how we think about the Simon/Waldo debate, however, and that difference is that Simon has come to represent the unrepentant logical positivist, while Waldo plays the foil as the artistic, normative, and value-concerned philosopher. Neither caricature is true  but both are helpful in understanding the mens influence on the ensuing development of public administration scholarship into a post-normal field of inquiry (Riccucci, 2010). 3.13.6 The New Public (Administration, Management, Governance) The logical positivism of Simon and the values orientation of Waldo have been replicated in contemporary conflicts between the two main theoretical orientations of scholars: New Public Management (NPM) and New Public Governance (NPG). Simons scientific, efficiency-centered outlook underpinned the rise of NPM to a dominant approach by the 1980s, while Waldos vision is seen in NPG, which makes value conflicts a legitimate function of administrative work Morgan &amp; Shinn, 2014, p. 9). The traditional views of public administration put forth before the 1970s elevated increased efficiency, economy, and coordination as its primary goals. In his essay Towards a New Public Administration, Frederickson (1971) added social equity (defined as activities designed to enhance the political power and economic well-being of disadvantaged minorities) to the mix. Frederickson was providing an overview of the 1968 Minnowbrook Conference, a gathering of public administration scholars in which Dwight Waldo played an important role. Minnowbrook attendees sought to define the normative orientation for public administration scholarship by focusing on equity (Frederickson, 1971): Simply put, new Public administration seeks to change those policies and structures that systematically inhibit social equity. In a departure from the logical positivism of Simon, New Public Administration did not elevate neutrality as a value: public administrators should be committed to both good management and social equity as values. The New Public Administration (NPA) framework would return with a fuller theory of public administration eventually in New Public Governance (Morgan &amp; Cook, 2015; Osborne, 2006), but at the time its most apparent contribution was to add equity to the traditional formula of efficiency, effective, and economic management of public agencies. Between Minnowbrooks innovation and its eventual translation to the New Public Governance (NPG) came an intervening acronymic regime of public administration: New Public Management (NPM) (Hood, 1991). Though similar in acronym to New Public Administration, its goals and emphases are quite different. NPM attempted to once again inject the responsive, customer centric management perspective found in business management into public administration. To do so, NPM applied business management techniques such as a focus on customer satisfaction, performance measurement, and competition into the public sector. The approach first emerged in New Zealand, but soon found willing practitioners in the United Kingdom and the United States (S. H. Mastracci, Adams, &amp; Kang, 2019). Though the critiques of the approach are manifest and will become evident momentarily, NPM was successful in some areas. The focus on measures of efficiency and effectiveness gave public managers and street-level employees (Lipsky, 1983) the capacity to use their expertise to diagnose and correct operational problems (Ammons &amp; Rivenbark, 2008). NPM also emphasized performance management, and the resulting visibility of performance data broadly increased interest in systems of accountability in government (Pandey &amp; Moynihan, 2006; Wholey &amp; Hatry, 1992), as well as the role of selection and motivation of public employees to improve organizational performance (Moynihan &amp; Pandey, 2007). Finally, the emphasis on systems of performance management expanded the array of values that were considered important in public administration to include cost, efficiency, outputs, outcomes, impacts, satisfaction, responsiveness, and quality of life (Morgan &amp; Shinn, 2015). However, though NPM saw some successes, it can not overcome two fundamental problems. First is that there is no common denominator that can be applied in a cross-cultural context, and so there is no common basis for comparison. Relatedly, even the modest expansion of values that can be measured pales in comparison to the values available and important to the study of public administration: fairness, equity, protection of rights, and transparency play important roles in determining the legitimacy of political institutions, processes, and outcomes (Morgan &amp; Shinn, 2015, p. 4). The second shortcoming of NPM is its over-reliance on models of business administration to structure the governance of public institutions. Consider just the American example of public administration, with overlapping spheres of authority and influence at the federal level, to say nothing of the balkanized state and local government, reliance on non-profit entities, and contractual relationships between public and private sectors (Morgan, Green, Shinn, &amp; Robinson, 2013, pp. 115118). These critical flaws in classic administration were not overcome by NPM, which in turn led to the founding of NPG. As the failures of NPM became apparent, scholars noted a new approach was needed, one that acknowledges the existence and likely persisitence of third-party government and that brings the new tools of public action that are now in widespread use to the center of public and professional attention (Elliott &amp; Salamon, 2002, p. 8). From that call was born NPG, which begins with acknowledging the pluralist nature of the state (Dahl, 1982), and sees that to manage such a state demands acknowledging the co-production of values among the participants in that state. Co-production in turn leads to value conflicts, and it is the role of public administration to mange those value conflicts. The second main advantage of NPG over NPM is in the formers focus on an engaged citizenry, enabling the efficiency found in co-production. NPG moves well beyond the limited, dichotomous view of public versus private sectors in the classical public administration to a networked, holistic concept of public and private and non-profit (Pestoff, Brandsen, &amp; Verschuere, 2013). This integrates the polycentric theories of the Ostroms work (E. Ostrom, 1982; 2011; V. Ostrom, 1987). The polycentric concept was originated in studies that looked at conflicting studies of municipal police departments (Parks et al., 1981), which could not parse why small city police departments had less costs, while they enjoyed more trust and satisfaction from the residents they served when compared to large police agencies. Theory at the time predicted that the efficiencies of large metropolitan police agencies should improve trust and satisfaction among residents. The answer was found in what was deemed co-production of public safety (Parks &amp; Ostrom, 1999). In smaller jurisdictions, residents knew their public safety officials and felt safe reporting suspicious activity and crimes to a degree that residents of large metropolitan areas did not. The close relationship between public and private actors co-produced public safety, and accordingly the costs of public safety were less in smaller jurisdictions. This model of co-production was soon modeled in areas of local governance other than public safety (Michael D. McGinnis &amp; Ostrom, 2012). Co-production is a core value of NPG, and means that successful public managers are able to interact with a public that is citizen, customer, and partner (Thomas, 2013). 3.13.7 The Post-Normal, Algorithmic Future of Public Administration Looking back on the first century-and-a-half of the formal study of American public administration, one can easily see how the field has consistently been drawn to consistent dichotomies. Wilson saw it as a division between policy and politics. Simon and Waldo drew distinctions between science and values. New Public Management sought the adoption of private market theories into the management of the public weal. New Public Governance reinvigorated public management with a call to blend public and private. The seduction of epistemic communities continues to drive much of current scholarship as well, as sub-communities of the public administration field hew close to their preferred traditions and methods of uncovering T/truth (Riccucci, 2010). These divisions can undermine how the field advances, as academic sectarianism produces less understanding rather than moreEpistemologically, we should recognize there are multiple valid and perhaps even complementary paths to understanding (Lake, 2011, p. 465). Norma Riccucci (2010) suggests answer dogmatism lies in recognizing that the applied nature of public administration means it operates outside the paradigmatic strictures of Kuhn (1970, 1974): maintaining some semblance of methodological pragmatism, matching method to research question, and triangulating on answers with multiple methods. One of the areas that public administration scholars will be critical to is the effect of big data, machine learning, and artificial intelligence in public governance. The voice represented by public administration scholarship is necessary to surface the realities confronted by the practitioners confronted with overseeing the intersection of the public sector and big data, machine learning, and other technologies. There is no doubt that scholarship needs to be multidisciplinary  international power, regime studies, war theory, genocide, administrative evil, and ethics, every field of scholarship will be impacted. These theoretical visions begin though with adoption of big data technology and machine learning at the municipal level  an adoption that is already occurring (Coglianese &amp; Lehr, 2016, 2018). Machine learning and big data are already used in criminal sentencing, policing strategies, and identification of lethality in domestic violence (Adams, 2019; Ferguson, 2017), among others, all of which fits squarely within traditional domains of public administration scholarship. Public administration offers the natural voice to help guide the ethical considerations and responses to the inhuman, or at least non-human, politics of the future (Agarwal, 2018; Battaglio &amp; Hall, 2018). Sara Jordan frames the public-sector impact implicit in a shift towards big data (2014, p. 276): How ought government protect the public against the use of their data but also protect the public through the use of their data? If public administration scholars do not direct their energy and interests towards investing the human mind into questions of how big data, machine learning, and artificial intelligence interact with governing, it risks becoming outmoded and irrelevant. Public administration is well situated to offer solutions to these questions, however, due to its strengths in multiple methodological and ontological approaches in the field (Riccucci, 2010). In their recent review of literature investigating big data and the public sector, Cecilia Fredriksson and her coauthors reveal the complexity and importance of big data, and the critical importance of scholarship (2017, p. 47): Governments are central to both creating and managing knowledge. Gary King, director of the Institute for Quantitative Social Science at Harvard University, is clear in his assessment of the changes that big data and artificial intelligence promise (Lohr, 2012, p. 1): Its a revolution. Were really just getting underway. But the march of quantification, made possible by enormous new sources of data, will sweep through academia, business, and government. And as political scientists have noted, revolutions tend to have some bloodletting, at least metaphorically, as scientific revolutions look a lot like political revolutions (Farr, 1995). Public administration, concerned with both government and governance, theory and practice, should not consider itself safe from the big data revolution; no matter ones preferred isms (Lake, 2011), it seems an unlikely outcome. Recall, however, Kings assertion of the underlying questions being quantitative ones. Even allowing for rhetorical excess, as large as his claims are, they are not encompassing enough. It is a mistake to see big data, which is essentially a descriptor of quantitative information, as having only quantitative implications. Recent advances have made sophisticated quantitative analysis of even very large text corpora a manageable task (S. M. Mourtgos &amp; Adams, 2019b; Roberts, Stewart, &amp; Tingley, 2014). A metaphor can be drawn to other historically recent revolutions. If a scholar were to posit that neither the industrial nor internet revolutions were particularly impactful to how public administration is performed and studied, would any reader take them seriously? The industrial revolution, with massive gains to efficiency, was not limited to only affecting industry  political, governance, and ethical implications followed. Even the very recent internet revolution, just a few decades old, has wrought social changes in the rise of populism (Bruce Bimber, 1998; Chadwick &amp; Howard, 2009), among countless other consequences to governing. While a comprehensive review of the changes to polities brought by the industrial and internet revolutions is outside the scope of this paper, it is also unnecessary, if one accepts the simple premise that a similarly situated revolution is underway in the move towards big data, machine learning, and artificial intelligence. These shifts in turn bring shifts in political priorities, in class struggles, in institutions. It is this insight which underlines the need for public administration scholarship to bring its varied methodological tools to bear on the issues, as well as look for every opportunity to engage with other disciplines. The questions about big data stretch beyond mere quantification, and Sarah Jordan (2014, p. 375) sees the value of public administrations methodological plurality: The future of public administration lies in its ethical knowledge work and expertise. The ethical implications of government use of information technology is one sketchily researched area deserving more scholarship (Menzel, 2015, p. 363). Some work is beginning to appear, with research papers and publications in legal journals beginning to address the role of machine learning in administrative agencies (Coglianese &amp; Lehr, 2016), questions about algorithmic ethics and fairness (Ferguson, 2017; Friedler et al., 2019; Joseph, Kearns, Morgenstern, &amp; Roth, 2016), and emerging legal definitions of personhood among artificial entities (Karanasiou &amp; Pinotsis, 2017). However, these questions, which are necessarily multi-disciplinary, and despite having the potential for grave impact on the public sector (Battaglio &amp; Hall, 2018; Fredriksson et al., 2017), so far lack the input from public administration scholars that would leverage the strength of our focus on merging the theoretical insights of political science with the realities of practice (Guy, 2003). Within the next several decades, deep learning neural networks and artificial intelligence will begin to replace two of the four pillars of what Keohane (2009) identifies as the core functions of political science: descriptive inference and causal inference. Retooling public administration through old ontological debates will not answer the question faced by political scientists in the coming years: what are we for? To reframe Rogers Smith (2015, pp. 366367): perhaps public administration is not so exceptional, and is not alone in facing profound change in how scholarship will be done. Does public administration see itself so different in scope and complexity that it can escape what other human-centered fields have already begun to cede core functions to? If machinated intelligence comes to dominate descriptive and causal inference, what public administration scholars should get better at is the puzzling (Keohane, 2009, p. 360)  observing what does not fit with theory  and conceptualizing, particularly as it relates to translating scholarly arcana to ordinary usage. We must become better data scientists and qualitative researchers and puzzlers and conceptualizers  all at once. Alongside those, society will be in need of intense scholarly focus on instilling our ethical knowledge work into the machine learning, neural networks, and artificial intelligences that are the future of both governance, and the study of governance. 3.13.8 Conclusion In celebration of the 50th anniversary of the signing of the Declaration of Independence, John Adams wrote John Whitney to decline an invited appearance. In his letter, John Adams (1826) warns how things can still go wrong in a United States that is (emphasis in original) destined in future history to form the brightest or blackest page, according to the use and abuse of those political institutions by which they shall in time come to be shaped by the human mind. Adams appears prescient nearly 200 years later, in a society increasingly shaped by big data and machine learning, with artificial intelligence on the horizon. Innovative solutions in the coming decades will involve putting aside the ontological debates of the first century in public administration scholarship (Riccucci, 2010), and leveraging the multiple methodological and ontological traditions of the field to address what are likely to be revolutions in both how government uses data, and how data influences government. The public administration scholar twenty years hence will be charged with inserting the ethical, the human, and the workable into models derived by machinated intelligence; or, put another way, in resolving the cerebra of Simon by inserting the viscus of Waldo, in reuniting the two cultures (Snow, 1963). Though he is the godfather of the science of artificial intelligence, Herbert Simon is not robotic. At least by the end of his life, Simon writes both about the beautiful and true  the wonderful and the comprehensible  merging humanity and science. While early Simon works emphasized the quantitative and measurable, he grew to see the ontological divisions as somewhat of an artificial distinction, and both he and Waldo fought against what can be seen now as a naÃ¯ve scientism. Bounded rationality was not a line drawn in concrete, beyond which stood the incomprehensible, but one drawn in sand, pushed backwards with the winds of science over time. The movement towards more big data, more sophisticated and predictive machine learning algorithms, and artificial intelligence will continue to push back that line. No perfect rationality may be possible, but the unbounded parcels shrink ever more. The changes to the public sector brought about by the artificial intelligence revolution will be vast and complex. That complexity, Simons work urges us to understand, even beauty found in overwhelming complexity, is not the same as inexplicable: Wonderful, he writes in the opening of one of his final works, but not incomprehensible (Simon, 2019, p. 1). Simon may seem an unrepentant positivist for some in public administration who embrace more qualitative methods, or at least a post-normal methodologic pluralism (Riccucci, 2010). But that represents an unfair, limited view of Simons work, who after all published for forty-nine years after his 1952 debate with Dwight Waldo in the pages of American Political Science Review (Simon et al., 1952). A more expansive and forgiving view of Simon can be found in Rortys view (Rorty, 1982, p. xvi): It is important to realize that the empirical philosophers  the positivists  were still doing Philosophy. There is no theorist more clever than the scholar claiming to have no theory write the authors of a primer on theories of public administration (Frederickson, Smith, Larimer, &amp; Licari, 2018, p. 3). Though they were gently chiding James Wilsons proclamation (Wilson, 1989, pp. xixii) that any grand organizational theories would be merely partial, place- and time-bound insights, I heed their advice. At this time, I am a scholar in the post-normal mode (Riccucci, 2010). Though I am a methodological pragmatist who is open to many ways of answering research questions, I instinctively reach for positivist, testable, falsifiable, and empirical answers in my scholarship. I am a public administration scholar because the field is multi-disciplinary and multi-methodological. Attempts to constrain the research questions and methods germane to the field are pointless because public administration practices are as old as civilization itself, even if the field of study that constitutes public administration is still young (Frederickson et al., 2018). To borrow an excellent turn-of-phrase , I work in the prose of Herbert Simon, but read and dream in the poetry of Waldo. Herbert Simon, because I value the clarity that constrained and falsifiable hypotheses bring to value-laden policy discussions, and the satisfaction of working within sophisticated statistical frameworks. Dwight Waldo  because the most interesting questions I explore are value-laden: the impact of public surveillance on wellbeing and street-level discretion (Adams &amp; Mastracci, 2017, 2019b, 2019a); the effect of street-level prosecutors on general criminal deterrence (Mourtgos &amp; Adams, 2019a); the alienation wrought by detaching emotional expression and public service (Mastracci &amp; Adams, 2018); the importance of listening to the voices of public servants rather than imposing our own scholarly suppositions (Mourtgos &amp; Adams, 2019b); and the difficulty of squaring public opinion and legal opinion regarding police use-of-force as the two rapidly diverge (Mourtgos &amp; Adams, forthcoming). I cannot bring to bear the post-positivist methodological weapons of Simon without first looking for targets through Waldos eyes. In her address to the Southern Political Association, Mary Guy (2003, p. 651) states: The field is served best when we remain self-consciously aware of the implications of our models and the information they produce. This highlighting of the importance of the subjective experience of the human mind is a timely reminder for the role of future public administration scholars, tasked with approaching a world of governance rapidly changed through greater and greater reliance on big data, machine learning, expert systems, and artificial intelligence. Herbert Simon saw intuition as a hidden thinking process; but in a hypothetical world where a machine intelligence achieved true, human or greater level intelligence, our ability to understand the subjective experience of that intelligence is not guaranteed. The human subjective experience represents the cash value of human ethics, of human inquiry, of human philosophy. John Adams is still correct: Two decades hence, the best of public administration scholars will be those who remain aware of the human and ethical implications of models and information produced by inhuman (or at least not human) minds. The field of public administration should be prepared to begin this undertaking today  for that is what we will be for tomorrow. 3.14 Five Public Administration Theories This essay is written from perspective of teaching a class on PA  what theories are important, what gets cut for time? Public administration is distinct from mere public policy; as Woodrow Wilson(1887) wrote: Administration isgovernment in action. The supplemental papers chosen for the upcoming Bolivian middle-management seminar were selected to provide context to the David Rosenbloom text which will be used as the underlying framework of the class. A potential danger of the using the Rosenbloom text alone is it relies on an assumption of a United States Constitution separation of powers. While most of the underlying lessons drawn from the Rosenbloom text are applicable in a foreign government context, I have chosen five theory readings which are focused on government in action. These readings are theoretically applicable in an international administration, with lessons for the students to draw on as they return to their respective positions. I have chosen the readings for their inter-applicability, their cohesion to one another, as well, which in the end provides the students with a robust theoretical foundation. I supplement the chosen readings with a shorter discussion of two additional readings, which while perhaps valuable in a different context, do not lend themselves well to the Bolivian seminar series. 3.14.1 Michael Lipsky: Street Level Bureaucracy Michael Lipskys importance to the study of public administration lies in his identification of what he calls street level bureaucrats. Lipsky defines these critical employees as: Public service workers who interact directly with citizens in the course of their jobs, and who have substantial discretion in the execution of their work Lipskys theory is critical to the idea of government in action, especially as it relates to mid-level managers. As these managers move towards greater responsibility in their respective agencies, there is also a danger their collective attention will necessarily turn towards broad policy and idea formation. However, as Lipsky makes clear, by re-focusing on street-level bureaucrats, our students will be better managers through service to the poorest citizens, and also through better budgetary management. First, as Lipsky writes: The poorer people are, the greater the influence street-level bureaucrats tend to have over them. Our students should recognize this important reality, especially as it relates to Rosenblooms discussion of the managerial focus in executive branch agencies. The managerial focus on efficiency has historically resulted in social inequity among minority groups. While our students are no doubt required to seek efficiency in their operations, they must also be able to pursue social equity where appropriate. To do otherwise disproportionately affects the poor negatively. The poor are forced to seek those benefits from the government which they are unable to afford in the private sector, and as the provider of last resort, the government will be judged by its ability to serve that population. On the subject of efficiency and fiscal responsibility, our students should learn from Lispky that the salaries of street-level bureaucrats will represent a huge portion of local government budgets. As as example, Lispky points out that in large cities over 90% of police expenditures is used to pay for salaries. This huge allocation is an indication of the importance of street-level bureaucrats have both within an organization, and a community. It also provides an opportunity for our student administrators to begin thinking about their responsibility to be effective and efficient with public monies. Rosenbloom puts efficiency, effectiveness, and economy as the guiding principles of the managerial approach to public administration, and with such a large part of the budget devoted to street-level bureaucrats, those salaries must take a commensurately large portion of administrators focus. 3.14.2 H. George Fredrickson: Toward a New Public Administration In a confident and influential essay explaining the New Public Administration, H. George Fredrickson adds social equity to the traditional public administration goals of efficiency, economy, and coordinated management. Social equity is defined as activities designed to enhance the political power and economic well-being of disadvantaged minorities. Frederickson does not just add social equity to the traditional goals, but raises it as a first among peers among the traditional goals. Our students will gain a more sophisticated view of public administration through the lens of Frederickson, especially in the context of Rosenblooms framing of managerial goals as discussed above in the Lipsky discussion. In line with our stated goal of expanding our students reading past a purely American context, social equity is a goal consistent with foreign governments. In fact, Frederickson sees social inequity as a fundamental, if long-range, threat to the viability of this or any political system. We may assume our Bolivian students accept governmental stability as a laudable goal; adding social equity as a goal of public administration helps them achieve it. Frederickson argues New Public Administration provides a real normative base. What he means here is that by promoting social equity as a goal, we are providing our students an actionable theory, wherein they can pursue measureable good. In line with Lipsky, Frederickson recognizes the importance of reaching into the professional schools where most public servants are trained and his new public administration aims to improve the management skillsets of those students. 3.14.3 J. Steven Ott: Understanding Organizational Culture Whereas Lipsky and Frederickson provide our students with a focus on providing social equity through governmental action at the street level, we must also not lose sight of the fact that our students are the future senior management of their respective organizations. To that end, J. Steven Otts critical essay on organizational culture is important. Besides being a pre-eminent emissary of the University of Utahs public management program, Ott gives our students a sound framework for understanding change within their organization, especially as related to what Ott describes as the unseen and unobservable force that is always behind organizational activities that can be seen and observed. Whether it originates internally or externally, our students can likely be expected to face serious organizational changes during their career. Through Ott we will train our students to be critical observers of their organizations shared values, beliefs, assumptions, perceptions, norms, artifacts, and patterns of behavior. By training our students while they are at the mid-management level, we give them the opportunity to begin their observational analysis at an earlier phase of their career. It seems logical that by increasing the length of time they are engaged in such critical analysis, they better prepare themselves for leadership at their organizations most senior levels. That preparation will prove useful as our future leaders encounter change within their organization. Otts essay is the most abstract of theories included in our students assigned readings, but no less valuable for it gives our students a strong foundation for navigating organizational change. Ott is fully aware of this need, as he writes the organizational culture perspective is especially useful for describing, explaining, andpredicting behavior when organizations are facing fundamental changes, particularly changes involving their identities. 3.14.4 Donald F. Kettl: Administrative Traditions At first glance, Kettls historical analysis of American public administration would seem to run counter to this papers stated goal of providing more international context to the Rosenbloom reading. However, by analyzing the historical roots of American administration through Kettls essay, our Bolivian students are better able to understand the branches of Rosenblooms constitutional analysis. The peculiar American tradition of public administration is full of conflicts, e.g. what government should do versus how government should do its business. Kettl provides a framework for understanding these conflicts by describing and comparing four formative theories: the Hamiltonian, Jeffersonian, Madisonian, and Wilsonian traditions of governance. Hamilton argued for a strong executive power, especially in respect to federal banking power, while Jefferson was a rural farmer with strong beliefs in the power of common people and a distrust of national government. Kettle points out that while Jefferson had philosophical notions of a weak executive, once he was president he exercised that power ruthlessly, based on Hamiltonian views of the executive. Madison had a subtler approach that hinged on balancing power among the major players This strategy will be familiar to our Bolivian students, as it reflects what Rosenbloom describes as a political approach to administration: a blending of powers rather than a strict separation. However, like Jefferson, once Madison became president, he exercised power in line with the strong Hamiltonian tradition. Wilson and the Progressives end up seeing the Hamilton prediction of a grand commerce state, and realized the need for a stronger government to effectively manage it. Wilson wanted politics out of administration and managed to explain for Progressives how to strengthen government without threatening democracy. As one of my stated goals for these supplemental readings was to focus on government in action, the Wilsonian tradition offers valuable wisdom, for a Rohr famously said, It is getting harder to run a constitution than to frame one. Kettl sees a big problem with the big players in government subscribing to the vending machine model of public policy: they assume that by piling money into the top of the machine, services will magically pop out of the bottom. They dont pay enough attention to the questions of how to accomplish the goals of government, only the goals themselves. Our students should be reminded of our earlier discussion of Lipsky, as the vending machine only runs through the actions of street-level bureaucrats. 3.14.5 Barzelay and Armajani: Breaking Through Bureaucracy While Rosenbloom makes the case that public management is different than private business management, we turn to Michael Barzelay and Babak J. Armajanis essay Breaking Through Bureaucracy to provide a realistic argument for taking lessons from some of the successes of the private sector in the late 20th century America and applying those lessons in a framework of public governance. This post-Bureaucratic paradigm focuses on quality and value, accountability and relationships, product and customers. As the authors point out, the bureaucratic structure grew in response to the American shift from an agrarian society to an urbanized one. Our Bolivian counterparts, as custodians of a government making a similar transition, should be aware of the potential pitfalls of a purely bureaucratic focus. Barzelay and Armajani bring a modern understanding of concepts covered in earlier readings, by redefining what efficiency and economy mean in a modern administrative context. For example, they will give our students a framework for understanding relationships by structuring that abstract concept through customer relationships, production relationships, oversight relationships, and membership relationships. Total quality management, a concept firmly rooted in private industry production for nearly a half-century, will already be familiar to our students, but now introduced into how they are examining public administration. This paper also fits seamlessly with our four previously discussed supplemental readings. Lipsky and Frederickson both push our students towards what Barzelay and Armajani call results citizens value; that is, to remain grounded in the front-line services of their agencies, by managing relationships between street-level bureaucrats and customers, and manage the delivery of social equity to those in society with most need of it. Otts theory on organizational culture fits well into a post-bureaucratic paradigm, as Barzelay and Armajani devote considerable thought to making public managers historically aware, able to diagnose unsatisfactory organizational structure and help other employees embrace a change to the post-bureaucratic paradigm. These historically aware public managers will be better prepared through Kettls explanation of the American historical context, especially how conflicts in administrative theory were rooted in the early founding visions of administrative thinkers. 3.14.6 Excluded Theories: Frederick C. Mosher I am specifically recommending two readings be left out of the Bolivian curriculum, both by Frederick C. Mosher: Watergate: Implications for Responsible Government and Democracy and the Public Service: The Collective Services. Both papers suffer from the same shortcoming, an over-focus on American public administration, with lessons too narrowly drawn for export to foreign administrators. Moshers Watergate essay was in response to a uniquely American controversy, and its recommendation that employees be required to sign ethical codes of conduct is a relatively lackluster response to a cataclysmic event. Mosher argues Watergate was an aberration, and extension, and culmination of events, which is useful for American students to understand. However, while our Bolivian students may be familiar with the Watergate scandal at a surface level, with the seminar lasting only five days, there does not appear to be as much to be gained from a deeper understanding of that singular event. In his second essay, Mosher provides a history of the labor movement in government organizations, and asks what is negotiable? and who bargains for whom? in respect to public sector unions. The essay is frankly brilliant in recounting the challenges to public sector unions, and the reasons for their growth at all levels of government. Yet, here again Moshers writing is almost exclusively of use to students of American governance, not public administration in an international context. While public sector unions may in fact be an important issue in other countries, Mosher focuses on the uniquely American aspects: presidential orders, labor boards, etc. In both essays, Mosher wades into the deep weeds of his topics, providing his American students with great material, but in the international context those deep weeds may be too tall to see over. 3.14.7 Conclusion As shown, the five readings selected and described in this paper work together to provide context to Rosenblooms Public Administrative Theory and the Separation of Powers. Lispky gives a focus on the street-level bureaucrats who make government work. Frederickson adds social equity to the goals of a public agency. Ott provides a theoretical framework for our students to examine the workings of their own agency. Kettl gives Rosenbloom historical context through an examination of the governance traditions which have predominated in American thinking. Finally, Barzelay and Armajani begin to usher our students away from a traditional bureaucratic focus on efficiency and towards a sophisticated, modern understanding of relationships, quality management, and value. All five readings are applicable in a variety of contexts, which is important to our international students. This paper recommends Moshers works be reserved for other classes with only students of American public administration, as both papers would prove less useful to our Bolivian students. 3.15 More? Stay tuned! "],["ap-pre.html", "Chapter 4 American Politics: Pre-Written Examples 4.1 Citizens as Political Beings 4.2 Recent Classics in American Politics 4.3 Congress and the Presidency: The Electoral Connection 4.4 Foundations of Congressional Action 4.5 Mancur Olson, Collective Action, and Police Unions 4.6 The Advocacy Coalition Framework 4.7 Policy Process in Comparative Context 4.8 Comparing and Combining Policy Theories 4.9 Five Policy Theories 4.10 Institutional Analysis and Development Framework 4.11 Ambiguity and Multiple Streams 4.12 The Narrative Policy Framework 4.13 Advancing the Narrative Policy Framework 4.14 Policy Feedback Theory 4.15 Punctuated Equilibrium Theory 4.16 Social Construction of Target Populations 4.17 Political Participation 1 4.18 Political Participation 2 4.19 The Weak American Presidency 4.20 Trump as Skowroneks Disjunctive President? 4.21 Public Opinion: Media Sources &amp; Public Policy Impacts 4.22 Voting and Elections 4.23 What do Americans Know about Politics? 4.24 What is Political Science For? 4.25 Partisan Hearts &amp; Minds: Political Parties and the Social Identities of Voters 4.26 Southern politics in state and nation  VO Key 4.27 More? Stay tuned!", " Chapter 4 American Politics: Pre-Written Examples This chapter provides a variety of shorter, themed responses to possible American Politics comprehensive exams. In the actual exams, you will likely be stitching together these shorter pieces as part of a larger effort. You can see an example of that in a later chapter, where an actual exam and answers are fully replicated. 4.1 Citizens as Political Beings Questions about how citizens develop their basic political beliefs, perceive political issues, and participate in the political process are at the heart of the study of American political behavior. This paper reviews how scholars have attempted to address these questions. The paper begins with the first sociological approaches to political behavior, follows through to the theories of political cognition which gained supremacy following the theoretical and empirical failures of the sociological approach, and finally ends with a review of the Zallers (1992) model of political belief formation and Delli Carpini and Keeters (1996) examination of the stratification of political information in the American public. Following that review of the most established findings on political citizenship, I review recent lines of scholarship that have begun to call into question a long held belief in American behavioral research, that Americans are generally ideologically innocent (Converse, 1964). Finally, while the essay mainly draws from the behavioral approach to American politics, in the closing section the connection from behavior and ideology to institutional scholarship is made clear with examples from presidential (Skowronek, 1997) and legislative (Lee, 2009) studies. 4.1.1 Learning Politics: The Socialization Approach Following the second world war, political scientists were attempting to understand why America and Great Britain were different than the Germany. How did the German people allow their country to be taken over politically by the Nazi party? The obvious answer for many was that there was something different about the American family, and that children were socialized by the family to value democracy. Political scientists, borrowing from theories of sociology, set out to try and test this theory. Fred Greensteins (1960) study The Benevolent Leader: Childrens Images of Political Authority, and Jennings and Niemis (1968) Transmission of Political Values from Parent to Child, typify what is now known as the socialization approach to political behavior. One positive aspect to the socialization approach is that it provides very predictions - your political attitudes should follow how you are socialized - first by parents, and then by friends, so by the time you reach adulthood, we would expect that political grounding will determine your own views. The socialization of political behavior was the primary theoretical framework for much of the scholarly work in the 1960s, but soon ran into both empirical and theoretical problems. Empirically, data became much harder to generate. Whereas Greenstein (1960) was able to simply begin interviewing elementary school aged children, in the era of Institutional Review Boards, the ethical implications of that type of research render it fairly impossible. Moreover, it soon became clear the evidence did not support the theoretical predictions. Jennings and Niemi (1968) in particular exposed the gap between theory and empirics: children did not simply adopt their parents political views. In addition to these empirical problems, the theory of socialization had a substantial challenge in that it expects that by adulthood our preferences (in this case political preferences) are fixed. This expectation was undermined however, with increasing evidence that people maintained a life-long openness, and socialization continued throughout adulthood, as individuals continued to try to fit-in with their work, neighborhood, and other social environments. By the 1970s, theories of socialization were still a going concern. But by the 1980s political scientists were looking back on the behavioralist approaches and finding them lacking. A new theoretical lens, rational choice, was beginning its dominance in political science (Aldrich, 1976; Downs, 1957). Downs (1957) sets out the basic rational choice model and uses it to try and understand voter turnout, arguing that because each individual vote has so little value, it is rational for voters to have little political knowledge, and to not seek out more. The theory of rational choice was soon exposed as having its own theoretical end-point problems (Green &amp; Shapiro, 1996; Waldo, 2017)  namely the expectation that rational people will not vote, which faced considerable empirical challenges. Still, rational choice variants such as prospect theory (Kahneman &amp; Tversky, 1984; Kahneman, 2003) continued to be a dominant theoretical lens for political scientists interested in political behavior (Hammond &amp; Bonneau, 2009; Shepsle, 2006; Simon, 1990). While socialization would never again gain favor as a pure theoretical approach to political behavior, it never completely disappeared either. Sears and Valentino (1997) use elements of socialization to examine a much narrower question then either Greenstein (1960) or Jennings and Niemi (1968). Sears and Valentino (1997) use the context of a presidential election and find that adolescents are socialized, but by exogenous events rather than the family. Empirically this makes sense, as generational shifts in political thinking can be seen in the aftermath of large exogenous events, such as the Great Depression impacting the life-long economic views toward thrift for those who lived through it, or how the terror of 9/11 shifted the political views on patriotism and war for that generation. Ronald Inglehart and Paul Abramson(1994) provide more evidence for this generational effect in political beliefs, using Ingleharts theory of post-materialism (Inglehart, 1990; Inglehart &amp; Norris, 2017). Using a vast amount of survey data from across Europe and the United States, the pair makes a grand generational argument that there is a cohort effect within generations that is affected by the environmental conditions the cohort experienced as children. In Ingleharts theory, as a society becomes more prosperous, and thus less likely to be worried about base survival needs, their political views as adults will tend to be post-materialist. This theory is not really a socialization theory, but is useful because it shows how socialization information can be used profitably in the context of political science. Ingleharts work also tends to undermine the purely rational choice approach to political behavior, as it suggests that individuals choices are determined by events outside of an immediate response to a given situation. Ingleharts theory and evidence point to the importance of understanding political culture, insofar as it impacts political belief formation. 4.1.2 Political Cognition Whereas political socialization asked how people formed their beliefs as they approached adulthood, the question of how Americans think about politics was still left unanswered. This became the central question motivating the scholars studying political cognition. In this field, the field of political science has been closely following the ideas best set out by Converse (1964). This theoretical line operates from a base assumption that voters have clear ideological positions (Downs, 1957), but update the earlier theories to better understand how voters make decisions on candidates and political issues. These theorists believed that for the vast majority of issues, voters can use ideology and partisan identification (Green, Palmquist, &amp; Schickler, 2002) as a shortcut to determine their views fairly quickly even when (Lupia, 1994). Converse undermines that assumption, and studies how Americans use and conceive of ideology, finding that on the whole, citizens do not clearly grasp ideology, nor do they use it effectively to form preferences. Instead, Converse argues that while elites have something resembling a consistent ideology, most Americans are not consistent in ideology, a feature of the electorate he famously named an ideological innocence. With Converse finding that most Americans dont have ideological principles from which their political beliefs follow, where those beliefs originate? This is where other political scientists pick up the argument. Feldman (1988), for example, tests an alternate theory that in the absence of ideology, people use value systems to form beliefs. Again though, the empirical evidence did not support the value theory. Lodge and Hamill (1986) provide the model that in many ways supplanted the sociological tradition. They borrow heavily from theories in psychology (Kahneman &amp; Tversky, 1984) and make the basic assumption that people are cognitive misers who operate in a very complex political environment with too much information to process fully, and so they want to make decisions as simply and easily as possible. Lodge and Hamill theorize that people use partisan schemas to handle most political decisions, with these schemas making complex political information easier to process, a form of heuristic thinking. The problem for these schemas becomes confirmation bias, as people tend then to dismiss information that does not fit easily with their already held notions, while simultaneously adopting information that confirms those same notions. A second outcome of this theory is the problem of heuristic processing, which occurs as people make errors and begin to fill in information that was never actually there. These problems leave the possibility of belief change somewhat unexplainable, short of massive exogenous shocks to the schema through overwhelming new information. Recent advances in measurement and a Bayesian view of belief updating suggest that the threats of backlash to non-conforming information is overblown, and that when confronted with politically persuasive messages, the receivers of that information update their views in the direction of the persuasion. In other words, information designed to persuade can and does change minds and those changes are positive, small, homogenous, and durable (Coppock, 2016, p. x). However, partisan schema theories continue to be explored in the literature, and Lodge and Hamills contribution has been long lasting. Their work also shows the beginning of a shift in methodology in political science, as they use experimental research methods, as opposed to the pure survey research that had dominated the field to that point. Arthur Lupia uses his (1994) Shortcuts versus Encyclopedias: Information and Voting Behavior in California Insurance Reform Elections to address some of the problems with partisan schema theories. Lupia demonstrates that low information voters dont have to be perfectly informed information depositories (encyclopedias) in order to mimic the political decisions of their better-informed counterparts. Instead, the low-information voters use information shortcuts, such as third-party endorsements of political positions and candidates, to form their opinions. This allows them to mimic the votes of the better-informed voters. Notions of information processing and heuristics has become a well-established theory in American political behavior. It probably provides a more realistic reflection of how Americans actually behave and operate in a complex political environment. Some problems remain, however, including problems of bias confirmation. Taber and Lodge (2006) address this problem with their model of motivated skepticism that helps explain when and why citizens are biased-information processors. Using a Bayesian-inspired information processing frame, they find evidence that those citizens who are the most politically sophisticated and with the strongest levels of prior belief are most subject to errors induced by confirmation and disconfirmation bias. The authors key argument is that most people are simply unaware of the strength of their own prior beliefs, and that these priors dictate to a large degree how citizens process information. Bolsen, Druckman, and Cook (2014) add to this literature, by examining the motivation process in how people form their political opinions. Their finding is that people are indeed biased processors of information, particularly in the context of in-party and out-party endorsements. The authors predict their finding will be troubling to people who worry that partisan motivated reasoning leads to lower quality opinions due to dogmatism and inflexibility. 4.1.3 Understanding Mass Opinion In some ways, John Zaller can be seen as modernizing and updating the The American Voter (Campbell, Converse, Miller, &amp; Stokes, 1960). Zallers (1992) book The Nature and Origins of Mass Opinion stands a classic in the field, and is centrally concerned with examining how citizens use mass media information to form political preferences. Zaller gives a good frame for understanding mass political opinion, and on balance the evidence which followed him tends to support his theory. Zaller provides a theory that allows for competing considerations to be held by a person at any given time as they confront political choices. He shows that elites do provide information that voters use to construct their own opinions, but that this process is mediated. Voters have a political awareness which filters elite (here, mass media) information in terms of issue salience and consistency. In other words, argues Zaller, voters do not have any single, true, political preference. Rather, voters have multiple political considerations, which he structures in his Receive-Accept-Sample model of voter preference. Voters must first receive information, that is they must be made aware of it. Next, the voter must accept (or reject) that information based on its consistency with their prior beliefs. Finally, the voter samples from the most recent information theyve been made aware of, with the information nearest in time given highest preference. Zaller uses his model to show that for the most part Americans use of elite cues in the form of political discourse, which they are exposed to by mass media, to form their own political opinions (Prior, 2013). Like Converse, Zaller disabuses political science of the belief that Americans possess consistent political ideology that forms the basis for their political beliefs. But Zaller permanently improved the model by, first, allowing for more sophisticated understanding of what elements the public does use to form political opinions; and second, by illustrating the primary cue for formation of political beliefs originates with exposure to elite discourse on political matters through the mass media. Finally, one of the lasting impacts of Zallers work has to raise fundamental questions about what political scientists are really measuring when they survey peoples attitudes (Prior, 2009). Given the importance of recency considerations for voter behavior (Panagopoulos, 2011), we should question the validity of opinion survey measures, as recent political events stand a good chance of having skewed respondents reported beliefs and opinions. Zallers model gives a good explanation for why people arent consistent in reported opinions over time. Political opinion formation is a dynamic process, and exposure and recency matter. Zallers book was impactful upon its release, and has continued to shape the study of American political behavior since. 4.1.4 Political Knowledge and Citizen Competence Also following and updating the early Michigan studies (Campbell et al., 1960; Converse, 1964) is Michael Delli Carpini and Scott Keeters (1996) What Americans Know about Politics and Why it Matters. The primary question confronted in the work is whether Americans have enough factual information to be able to participate meaningfully in the American democracy. The authors take a view contrary to the political cognition literature, in that they make a strong normative argument that heuristics are not good enough, and that voters need a strong background in meaningful facts in order to properly participate in a democracy. The main point of the book is that the distribution of meaningful political information is uneven, particularly along dimensions of race and socio-economic status (SES). They find that if a voter is a middle-aged or older white male from the upper half of the SES distribution, that person stands a fairly good chance of having the appropriate basis of political information to participate politically. However, if the voter is, for example, a black woman living in the inner-city and from the lower SES distribution, the likelihood is that she does not possess enough relevant political information to be able to participate politically. Delli Carpini and Keeter make a strong argument that there are institutional hurdles that are skewing political participation. Their normative statement is that if we are to thrive in a democracy, we must begin to address the structural elements which produce unequal distributions of political information. They do an excellent job of documenting the process by which they came to their conclusions, and make a convincing argument for why we should be concerned about what people know. 4.1.5 Relating Changing American Behavior to Institutions Recall that the most important early studies of American political behavior came out of the University of Michigan election studies beginning in 1956 (Campbell et al., 1960). Much of how we still conceive of political behavior is influenced by those initial studies. One of the main findings on public ideological alignment is that Americans generally do not understand the ideological differences that are important to political elites (Converse, 1964). The publics inattention is very high even in moments of great political conflict, their opinions are inconsistent, and do not cohere ideologically. On the whole, Converse concluded that Americans are ideologically innocent. However, recent research suggests that the ideological innocence is transforming as more Americans become ideologically sorted, with opinion surveys finding that non-elites are more ideologically aligned and constrained (coherent). Baldassari and Gelman (2008) use National Election Study (NES) data from 1974 to 2004 and find that the correlation between issue attitudes and party identification had grown significantly. In other words, we learn a lot about a voters stance on policy issues such as abortion, gay marriage, and social welfare programs simply by knowing whether identified as a Democrat or a Republican. But was the finding by Baldassari and Gelman (2008) just a short-term trend? Recent evidence suggests a longer-term trend is in play, as shown by Martin Wattenberg (2019) in his conference paper at the 2019 American Political Science Associations national conference. Wattenberg finds that the positive correlation trend has only increased in the decade since Baldassari and Gelman investigated it. The percentage of Americans (Wattenberg, 2019, p. 1)with well-developed belief systems based on a clear understanding of public policy choices has increased substantially even since 2000, and this increase accounts for virtually all of the increase in respondents whose partisanship matches their ideology. Wattenberg (p. 8) traces the start of this increasing ideological coherence to the presidential campaigns of Ronald Reagan, whose presidency was the first (at least in the American National Election Survey era) to promote a clear agenda that represented a major shift in the course of public policy issues such as tax and social welfare reductions alongside increased military funding. Two other research trends support Wattenbergs belief that we are in something in a weird moment in American political behavior, though both supports come from the American political institutionalist camp in presidential and senatorial studies. First, is presidential scholarship that shows presidential paradigms tend to dictate presidential leadership and success, rather than innate political skill (Skowronek, 1997, 2008). In Skowroneks telling, we are still in the Reagan era because presidential candidates still hew closely to the policy issue patterns developed by Reagan. For example, both of our most recent presidents overtly compared themselves to Reagan during their campaigns. For example, Senator Obama in 2008 made the comparison himself during the campaign (Murray, 2008, para. 3): I dont want to present myself as some sort of singular figureI think Ronald Reagan changed the trajectory of America in a way that Richard Nixon did not and in a way that Bill Clinton did not. He put us on a fundamentally different path because the country was ready for it. As a Democrat candidate still engaged in a primary fight, Obama was not campaigning for conservative values. But Obama was a political actor in a still resilient political environment shaped by Reagan, and so while he opposed the political order, he was not able to cast aside the vision of leadership offered by Reagan. The Reagan paradigm is what Skowrownek (2008) would call institutionally thick, and sets the terms of engagement for candidates from both parties, and Wattenberg is likely right to frame the increasingly ideological public as beginning with President Reagan. Further evidence for the findings of Wattenberg (2019) and Baldassari and Gelman (2008) comes from Frances Lee (2009, 2016) in her studies of elite polarization among politicians. Lee notes that we are living in a period of intense electoral competition that skews what is normally expected in terms of ideological polarization. Most of American political history was dominated by one party or the other, and only in the modern era is the partisan competition so balanced that the party in power must be constantly attending to the next election. Tied closely the electoral connection (Mayhew, 1974) but leveraged at the institutional level, Lee sees ideological polarization at the elite level is really partisan competition for power, rather than policy positions. This helps explain why issues can flip between parties in a relatively short period of time, such as Democrats moving from dismissing candidate Mitt Romney for his hawkish views on Russia in 2012 (Oppel, 2012) to embracing the view that Russia presents a credible threat to American democracy. On the same issue, traditionally hawkish, anti-Russian Republicans have seemed to lack urgency (Senate Democrats, 2019) to confront Russian threats (Sanger &amp; Edmondson, 2019). The issue realignment at the institutional level is a rational response for politicians who increasingly operate in a nationalized political environment. 4.1.6 Affective Ideology To return to political behavior, those institutional demands must be met by a coinciding increase in ideological coherence in the populace, a trend that appears supported by the evidence reviewed earlier (Baldassarri &amp; Gelman, 2008; Wattenberg, 2019). Which came first is unclear, but a least one line of research indicates that the issue and partisan polarization is more akin to a social identity than mere policy differences. In Partisan Hearts and Minds (Green et al., 2002, p. 13) partisanship is defined as a type of social identification: a psychological process of self-categorization and group evaluation. People identify as a Democrat or a Republican in the same way they identify as belonging to a religious denomination or ethnic group. Instead of the warmth indicators used by many partisanship researchers in surveys, the authors argue that people ask themselves two questions: What kinds of social groups come to mind as I think about Democrats, Republicans, and Independents? What assemblage of groups (if any) best describe me? (Green et al., 2002, p. 8). This a rejection of the rational choice version of partisanship which dominated the academic view of partisanship at the time(Green &amp; Shapiro, 1996). How a person answers this question to themselves produces a very stable partisanship. The authors see partisanship as a relatively non-dynamic phenomenon. That is, rather than elections producing a great deal of party choice change among voters, most people already have a partisan identification (at least to themselves) and that identification is rather unlikely to change in the short-term span of an election cycle. Elections are more of a cause for cheerleading ones own team, and less a competition between two (or more) choices of individual politicians: Elections are also forums for intergroup competition. Individuals who identify with these groups are drawn into this competition. Their interest and level of emotional engagement increase as they embrace the team as their own. Although not irresistible, the desire to see ones team prevail powerfully influences the probability of casting a vote for the candidate of ones party (Green et al., 2002, p. 202). This willingness to see past rivaling individual politicians and engage with politics as social identification is why partisanship matters  it matters because it affects electoral politics. The authors seek to provide empirical support for their theory not just in American politics through the case of the 2000 presidential election, but in comparative international contexts as well, with evidence from the United Kingdom, Canada, and Germany. This is an important claim from the authors, who position their theory of partisanship not as an American phenomenon, but a human one. The increasing salience of partisanship as a heuristic device for deciding policy stands goes beyond the political. While partisanship is traditionally seen in issue-based terms, there is evidence that partisanship has affective impacts as well (Iyengar, Lelkes, Levendusky, Malhotra, &amp; Westwood, 2019, p. 129): Ordinary Americans increasingly dislike and distrust those from the other party and this animus is leading Democrats and Republicans both say that the other partys members are hypocritical, selfish, and closed-minded, and they are unwilling to socialize across party lines. Partisan Hearts and Minds makes a clear methodological contribution as well, despite containing relatively sparse statistical analysis than other texts in the genre. Because of their underlying critique that party identification has been poorly measured in much of the partisanship research, the authors present and defend a way of accounting for measurement error (p. 231-234). Once models of partisanship allow for measurement error, the authors argue, party identification is revealed as a very stable pattern over multiple decades. While in this work they use mean-corrected panel analysis, this is just one example of how to correct for measurement error. Psychologists have long recognized that measurement error interferes with causal inference (Nesselroade &amp; Baltes, 1979). Green, Palmquist, and Schickler (2002) make good use of this insight to address pooled measurement error, which still remains relatively unaddressed in much of political science research. The next steps needed can already be seen in modern techniques and rapid development still taking place in developmental psychology (Deboeck, Nicholson, Kouros, Little, &amp; Garber, 2015), which uses derivatives of both inter- and intra-measurement error. Political science has not yet developed even the tools to collect the tools needed to build datasets capable of being tested in this way. Once (if) they are, however, further insights into the stability of partisanship over time, and its vulnerability to political events including elections, could be gleaned. As it is, the authors make a good case for including measurement error in partisanship studies, and more broadly political science. 4.1.7 Conclusion The evidence available suggests that the democratic theorists have been mistaken to assume that the average voter is in possession of highly structured, sophisticated ideological frameworks with which to navigate their duties as a citizen. Instead, voters live in a highly complex political world, and tend to only pay attention when highly relevant, current information which has direct impact on their world is provided. Zaller (1992) and Delli Carpini and Keeter (1996)continue to provide relevant theoretical lenses with which to examine the American voter and how they construct a political worldview. Modernization has vastly increased the amount of information available but it is unclear whether that information is salient enough for the average voter in order to constitute valuable information. Given the evidence that most voters continue to operate as politically naÃ¯ve, if not outright ignorant, one must begin to question the normative assumption that a well-informed public is necessary for a democracy to survive. However, early evidence is emerging that political knowledge is increasing, at least among some issue domains and partisan axes. While some scholars worry that the American voters lack of basic political information threatens democracy, other have held that people do not necessarily need to be in complete command of political knowledge in order to operate effectively as a voter (Shannon, McGee, &amp; Jones, 2019) because they use informational shortcuts (Lupia, 1994). Perhaps, given the centuries of relative democratic stability in the American context, it is time to give serious consideration to the idea that in fact the democratic experiment does not require a sophisticated electorate. While a democracy may be improved by one, there seems to be enough evidence at this point to at least conclude that the necessity of politically sophisticated and knowledgeable publics is not a prima facie requirement. 4.2 Recent Classics in American Politics 4.2.1 Introduction Does wealth inequality matter to running a democracy (Bartels, 2010)? What is the correct vote for a voter to make - and do they make it even in the face of poor information and even disinformation (Lau &amp; Redlawsk, 2006)? What comes next in the battle for American voter minds in a socially and technologically networked world that is increasingly vulnerable to artificial intelligence(Radford, Wu, Clark, et al., 2019)? Disinformation spreads through networks - how should we understand how the social networks of Americans affect how they vote ((Sinclair, 2012)? Finally, why should we be concerned about what American voters know in the first place (Delli Carpini &amp; Keeter, 1996)? In this essay, I review four political science books that are likely to be considered future classics in the field, and shape how I think about the questions facing political science broadly. In addition, I will identify a technology article covering advances textual prediction via machine learning, which will profoundly affect American politics soon and will be a classic turning point studies by American politics scholars for many years in the future. 4.2.2 Bartels: Unequal Democracy A long line of American political science scholarship is concerned with the effect of economic equality on democratic outcomes. Schattschneider (1960) famously noted that claims that the pluralist foundations of the US constitution protected against certain well-off groups having outsized political effects were not convincing: The flaw in the pluralist heaven is that the heavenly chorus sings with a strong upper-class accent. Since then, many scholars have found wealth and business interests have a biasing effect in political outcomes (Gilens, 2012; Gilens &amp; Page, 2014; Hall &amp; Wayman, 1990; Schlozman, 1984). In Bartels Unequal Democracy (2010), the central puzzle is: Why does income inequality in the US continue to expand, even some eighty years after an expanding welfare state (p. 31) sought to close the gap? Bartels answer lies in connecting the realms of politics and economic inequality, two areas which he contends only perfunctory attention (p. 35) has been paid. Economic equality is important because it poses a crucial challenge to Americas democratic ideals, (p. 32) and Bartels roots this belief in great political thinkers from two thousand years of political writings, from Aristotle (Lintott, 1992) to De Tocqueville (1969) to Krugman (1995). On the whole, given his starting position that economic inequality matters, Bartels is successful in showing how politics and policy drive increases in economic policies. He does so with clear theoretical propositions in the first half of the book and then turns to specific case studies of tax cuts, the estate tax, minimum wage legislation, and the political economy during the Great Recession. He concludes the book with a great deal of pessimism  inequality undermines democracy, and there is little hope for different outcomes. Even when presidential elections seem to provide political energy for policy changes to reduce inequality (such as the 2008 election of President Obama), the outcomes of the continued growth of inequality show that partisans of either major party have little to celebrate about. In chapter three, Bartels disposes of the class argument that social policy preferences trump economic ones for voters  the poorest Americans are no more conservative on social issues then they were in the pre-war period. Bartels finds instead that American voters are economically myopic, and that Republican presidential candidates have been able, through luck or skill, to preside over unusually good cyclical economic peaks during election years. Here, Bartels is unable to offer a compelling causal argument, though only because is limited to a correlative argument, as with only 16 post-war elections inferring causal links is quite difficult. Even so, the patterns he uncovers are fascinating and useful. Bartels is careful in selecting case studies that uniformly support his argument, and he investigates the Bush tax cuts (chapter 5), the Estate Tax Repeal (chapter 6), the minimum wage policy (chapter 7), and finally the Great Recession (chapter 9). Here, neither party fares well in Bartels estimation, with the bulk of economic policy benefits accruing to the wealthy, while the middle class is awarded in paltry ways, and the poor are left worse off  all while politicians and parties escape political consequence from the poor. The book closes with Bartels examining how his findings impact normative democratic theory (we should be worried) and how we might close the widening gulf between rich and poor (we shouldnt be optimistic it can be done). However, a more optimistic reader, before giving up, might examine the lengthy, complex argument Bartels is relying on for such pessimistic consequences, before giving up. Although I pick at Unequal Democracy a bit more in the next section, Bartels provides a critical contribution to understanding modern American political behavior. Wealth and income inequality continue to be a motivating force in American politics (Boix, 2010), and the issue is particularly salient in two frontrunners in the Democrat primary, Elizabeth Warren and Bernie Sanders. Alternate views of this problem are available. A recent review concludes that highly disparate levels of wealth and democracy are compatible (Scheve &amp; Stasavage, 2017) because 1) democracies cleave along important dimensions other than wealth, 2) some voters who are on the losing side of wealth inequality care more about those other cleavages, and 3) the wealthiest citizens may capture important critical parts of the democratic process, thus preventing policies that promote wealth redistribution. To Scheve and Stasavages second point, wealth distribution is not clearly connected to voting outcomes. Determining how people vote is perhaps the deepest literature in American political science, and a methodological turn towards experimental research in this area since the early 2000s has continued to build the findings. Of recent works, I find work by Lau &amp; Redlawsk (2006) compelling, as they investigate and undermine academic concepts of correct and incorrect voting. 4.2.3 Lau &amp; Redlawsk: How Voters Decide Taking on Bartels critically is not easy; he takes on a huge subject and does so well. As Page (2009, p. 148) notes, anyone who quibbles with his interpretations or suggests he has left important questions unanswered is likely to appear ungenerous, even churlish. With that risk in mind, there is some reason to quibble with Bartels general conception of voter decision making, as compared to the relatively more sophisticated treatment used by Richard Lau and David Redlawsk (2006) in their book How Voters Decide: Information Processing in Election Campaigns. Lau and Redlawsk (2006) use a unique method to test the idea of incorrect voting that is at the heart of Bartels research question. Voters are economically myopic in Bartels view, and so have voted incorrectly and against their own economic interests, which would in the aggregate be with Democratic presidents. Lau and Redlawsk use a clever experimental design to test for incorrect voting. They expose their experimental subjects to scrolling information about hypothetical election candidates, allowing the subjects to click on the information they want to know more about. This is done under a time-constrained environment, and at the end of the timed exposure subjects are asked to vote for one of the candidates. In the next phase, the same subjects are then allowed to delve into all the candidate information they want, without time constraint, and given the chance to vote again. Correct voting in this context is when a respondent chooses to vote for the same candidate in both phases, while incorrect voting is when a study subject switches their vote from phase one to phase two. Lau and Redlawsk find that approximately 30% of the subjects cast incorrect votes. Applying the incorrect voting findings of Lau and Redlawsk to Bartels findings that voters are myopic reveals a consistent theme through Bartels work, one which Page (2009, p. 148) characterizes as blaming the victims and the chief defect of Bartels book. This is not to say that Bartels sets out with any pejorative attempt to devalue those on the wrong side of the Gini curve  quite the opposite. But Bartels conception of what correct voting entails is rooted in a classic rational choice approach, which places perhaps impossible expectations on voters to process incredibly complex economic information in full, consider outcomes for competing policy alternatives, and then vote correctly. In reality, as shown by Law and Redlawsk, voters are more boundedly rational  they do not have complete information, nor the time to process it if they did. Bartels takes 363 pages, decades of academic expertise, and sophisticated methodology to come to the conclusions he does, and then asks the reader to wonder why people vote against their own economic interests as he sees them. What is amazing is that voters are ever able to make correct decisions given the volume of economic policy information  and disinformation  they are required to consider. As Lau and Redlawsk show, individuals must use psychological decision-making strategies, and those strategies are what allows for a substantial portion of the public to vote correctly in the first place. 4.2.4 Speaking of Disinformation: The GPT-2 Natural Language Model A consistent theme in American political scholarship is that Americans are not all that knowledgable about politics(Campbell, Converse, Miller, &amp; Stokes, 1960; Delli Carpini &amp; Keeter, 1996; Lodge &amp; Hamill, 1986; Lodge &amp; Taber, 2013; Zaller, 1991). However, little if any of this scholarship has accounted for the modern ability for actors to effectively deploy intentional disinformation. The 2016 presidential election was famously interfered with by Russian actors (Permanent Select Committee on Intelligence, 2019), and the intervening three years has seen an explosion in machine learning work that is likely to play a part in future elections. Perhaps the most important of these developments has been the ability to quickly generate fake news stories that are indistinguishable from the real thing. At the forefront of these developments is the GPT-2 text prediction algorithm. Simultaneously released as a blog post on the OpenAI site (Radford, Wu, Clark, et al., 2019), the scholarly article (Radford, Wu, Child, et al., 2019) announcing the development of the GPT-2 natural language prediction model will be seen as a turning point in political speech. The GPT-2 model, and the paper announcing it, are bound to be turning points in politics, broadly drawn, and more specifically the political and policy implications of artificial intelligence methods. The authors directly address the political and policy implications of their own technology, stating that along with synthetic audio and so-called deep fake videos, technologies are reducing the cost of generating fake content and waging disinformation campaignspoliticians may want to consider introducing penalties for the misuse of such systems. The authors decided to address their concerns about the potential misuse of such systems by publicly releasing truncated models in a staged strategy. Though the full model has 1.5B (billion) parameters, the authors decided to first release only the 114M (million) parameter model in February 2019; a 344M model in May 2019; and a 774M model in late August 2019. Reviewing the technical accomplishments of the GPT-2 language transformer is beyond the scope of this essay. However, it should suffice to note that the algorithm surpasses previous attempts in language prediction models, and in some cases approaches human-level capabilities. The model was trained on over 8 million English-language webpages, with the goal of simply predicting the next word in a sentence. A simple goal, but the output of the algorithm is convincing enough that 83% found it indistinguishable from New York Times articles (Kreps &amp; McCain, 2019). Scare tactics around technological innovation is nothing new, and political scientists are already primed to consider the effects of big data and artificial intelligence on political outcomes (Brady, 2019). Easy enough to claim an algorithm is dangerous to politics - what does it look like in practice and why would it be dangerous to an informed electorate? Consider the following fake news I generated for the purpose of this essay using the GPT-2 774M model. Bolded text is the input I used as a seed, and what the algorithm generated follows in normal text: Today, three University of Utah professors, Phillip Singer, Juliet Carlisle, and Matthew Burbank, published groundbreaking work supporting the case that Donald Trump is the most successful president in American history. In that study, the authors argue, Trumps presidency has been highly successful because he has been unusually willing to challenge the norms of traditional American political and economic institutions, including media and traditional power bases, and make big decisions. The New York Times quoted the authors conclusion, Mr. Trumps victory was an electoral shock delivered to an establishment that had been too comfortable to challenge him or take a stand against a movement that was increasingly winning national elections. The article continues, Yet the shock and anger that Mr. Trumps surprise victory has unleashed on Americans is a harbinger of the challenges to which he was bound  if, of course, he could survive them. For a populist leader who pledged to put a stop to big government and hold America on a golden platter, the election of Mr. Trump has provided a challenge to institutions, big business, and popular norms in ways that they have never been challenged before. A bit too cutesy? Consider the following as a perhaps more likely type of misinformation we might see in the 2020 election campaign. Again, I generated this in under ten seconds, and only for the purpose of this essay (bolded is me, unbolded is algorithmically generated): Presidential candidate Elizabeth Warren stumbled in an interview Tuesday morning, raising concerns about her ability to govern. Speaking with MSNBCs Andrea Mitchell Tuesday morning, Warren seemed to contradict herself, arguing she was not looking for a job, but rather a chance to build a dream team of people who can help transform Washington with her. What I am looking for is a team, not a job, Warren said. Im looking to build a dream team. To build a team that can get things done in an administration that has to be run with the knowledge and understanding that all of us who are members of Congress and federal officials, there is a reason we called it a team. Its not because Im looking for a job. There isnt an opportunity for me to get a job, and theres no reason this administration should be a team. Im looking for a team. That statement seemed to go over some heads on Twitter, with many questioning whether Warren was even qualified to be the President at all. At one point she claimed there are no openings in the White House staff. To be clear, I am not arguing that the GPT-2 paper is significant because it is the final word in this type of technology. In fact, the ability to generate large amounts of misinformation that is for all intents and purposes indistinguishable from authentic news will only become easier. Importantly, the two examples above were generated with a version of GPT-2 that is only approximately half as powerful as the full 1.5B parameter model. This is not the end of fake news and disinformation for political purposes, but the beginning. The American electorate (or at least some substantial portion of it) was misled by foreign powers in the 2016 presidential election by the intentional use of memes (Permanent Select Committee on Intelligence, 2019). How will they react to conceivable disinformation generated like the above? Despite the intent of the GPT-2 team to stage releases of the model so that the unintended effects could be judged, such a strategy inherently relies on the belief that either; 1) no one else can do the same work, or 2) those who are capable of re-creating the technology would also restrain themselves. Those premises are both doubtful, as shown by the full release of OpenGPT-2 by two graduate students at Brown University (Gokaslan &amp; Cohen, 2019) in a post titled OpenGPT-2: We Replicated GPT-2 Because You Can Too the same week the OpenAI authors released the watered-down model. Moreover, in their release of the 774M model, the OpenAI authors note that they have spoken to five groups that had already replicated GPT-2. These are only the groups willing to publicly admit they are developing the capability - what of the Internet Research Agency (IRA), a front for Russian intelligence agencies intent on destabilizing American elections (Permanent Select Committee on Intelligence, 2019)? With an ever more networked citizenry comes increased risk that those networks can be turned against democratic ideals. 4.2.5 Betsy Sinclair: The Social Citizen In her book The Social Citizen: Peer Networks and Political Behavior, author Betsy Sinclair (2012) sets out to theoretically and empirically expand how we understand political behavior in the context of the influence of social networks. Sinclair begins her prologue with a truism - Humans are inherently social  and yet our understanding of political behavior often ignores this outright, preferring to focus on the individual-level characteristics that determine political opinion and choice. However, even with decades of research into how race, income, education, and a host of other demographic factors, political scientists still have yet to lay out a satisfying explanation of political choice, belief, and behavior. Sinclair sets out to rectify this absence with a close examination of how social networks influence four political contexts  voter turnout, donating to political causes, vote choice, and political party identification. Each of the contexts is given focus in a single chapter, with sophisticated research designs to test each. To a great degree, Sinclair is successful in showing that social networks and connectedness influence political behavior in important ways. Social network effects must be taken into account by scholars attempting to construct a holistic theoretical view of political behavior. In chapter two, Sinclair turns to a question which has been the subject of interest to political scientists for decades  what causes people to turn out to vote in elections? Given the nature of Sinclairs interests, she tests how social networks can influence voter turnout. She does so with two field experiments, the first in Chicago and the second in South Los Angeles. Sinclairs Chicago experiment is closely modeled on Gerber, Green, and Larimers (2008) famous field experiment in which they used post-card mailers to show the positive effects of social surveillance on voter turnout. Sinclair takes that basic idea to experimentally test three treatment populations  individuals receiving the treatment, individuals socially proximate to the treatment, and individuals socially isolated from the treatment. Sinclairs design allows for the random treatment of both individuals and neighborhoods, generating estimates of direct effects on the individuals receiving the mailers, as well as those who are indirectly affected. Whereas the original study by Gerber, Green, and Larimer (2008) was not able to control for spillover effects, Sinclairs Chicago study was intended to measure those effects, which theoretically reflect the social network that potential voters reside within. Like the Gerber, Green, and Larimer (2008) study, Sinclair uses varying degrees of social surveillance on individuals, and replicates the earlier studys finding that turnout increases a few percentage points. Where Sinclair builds on the original study, however, is she also varies the level of social surveillance intensity by neighborhood, allowing her to test the hypothesis that the neighborhood social network will have effects on turnout on other members of that neighborhood, even if they didnt receive a mailer. While the findings overall for this part of the study did not reach statistical significance, the effect was in the hypothesized direction. At the household level, Sinclair found that in households where there are already frequent voters, other members of that household are more likely to vote as well, to a statistically significant degree. Even the within-household finding lacks a clear causal argument, as it might be argued that there are endogenous factors which would lead people to reside together which would also influence their likelihood to vote  they may have similar political interests which activated in a particular year which increased the likelihood that the typical non-voter would activate as a voter that election cycle. While Sinclair is more optimistic that the spillover effects are suggestive of a social network effect, more long-term work is needed to replicate and extend the findings of this particular claim. The second turnout-related field experiment Sinclair reports on takes place in South Los Angeles, and the findings here are more robust compared to those in Chicago. Here, Sinclair studies political canvassing in low-income neighborhoods and hypothesizes that canvassers from within the community will be more effective in increasing turnout than canvassers from outside the area. Sinclair randomizes which neighborhoods receive canvassing from either local or non-local canvassers, and finds that indeed the local canvassers were successful in increasing the turnout more than their non-local counterparts to a statistically significant degree. This finding supports the books larger argument, that the social pressure exerted by those known to us  in this case canvassers from our own neighborhood  is more effective than social pressure exerted by those more socially distant. 4.2.5.1 Political Donations Sinclair returns to Chicago and uses chapter three to examine the effects of social networks on political donations by individuals. She first reviews the literature in this area, pointing out that existing single-method research simply hasnt been able to tease out the effects of descriptive (what people do) and injunctive (what people ought to do) social norm appeals for donations, or the effects that social networks would have (which generally appear as spillover effects in other research, but Sinclair is specifically interested in measuring). Given that difficulty, Sinclair turns to a mixed-methods approach, first using aggregate survey data and then following up with in-depth interviews with both donors to explore the effect of social networks on donations. The study first sent out a mail-based survey to 1000 respondents asking about their donation activity. Sinclair uses data from that survey to classify respondents by levels of donations and their centrality to the donation social network, which is a co-donation measure of how many organizations a respondent donated to that others also donated to. Those respondents who were major donors  those with high centrality  were then interviewed about their donation activity. The Chicago study confirms that there is a small, positive, but statistically significant social network effect on an individuals decisions to donate. Interviews with the major donor confirmed the findings in the aggregate data, that their decision to donate to specific organizations was often strongly affected by their social network, as friends solicited donations to organizations they had already donated to for example. Sinclair leaves room for future researchers to confirm her findings outside the densely populated districts she investigated in this research. The findings here concentrated on the major donors in a highly urbanized environment, but it is not clear how those findings would apply in either a more suburban, or rural political environment, nor how non-major donors (or even those who report never donating) are affected by their social network. This is an increasingly important area of study, as the national presidential campaigns have reported increasingly rapid growth in small donations. This trend has begun, at least anecdotally, to spread down into smaller legislative races, as the national parties have been successful in raising the visibility of House of Representative candidates and raising money across traditional political subdivisions. Further replication and extension of Sinclairs findings could help provide the social network explanations, should they exist, for why small or first-time donors choose to give to political campaigns. Candidate Choice In chapters four Sinclair addresses candidate choice in voting using national election survey data. She concentrates on the surprising phenomenon of individuals who identify ideologically as either a conservative or a liberal, but vote for the candidate of the party not associated with that ideology. In the 2000 ANES data, for instance (Sinclair, 2012, p. 78), 11 percent of self-identified liberals voted for the Republican presidential candidate, and 29 percent of self-identified conservatives voted for the Democratic presidential candidate. Sinclair suspects that social networks play a role in driving these seemingly irrational candidate choices. She does so in two studies, the first using simple logit regressions to show that where these cross-voters live, that is their social context, matters. A great deal of the conservatives voting for Democrats, for instance, live in Republican-dominated areas, and vice-versa. Interestingly, Sinclair uses the example of a conservative respondent moving from St. George, Utah, one of the most conservative areas in the U.S., to Santa Monica, California, one of the most liberal. This simple, yet robust analysis highlights the social context effects on voting that Sinclair is interested in  where a voter lives can influence voting even in the face of ideological conviction. Sinclairs second candidate choice study uses national election survey data collected by a private opinion firm. The study attempts to locate a respondents discussion group and in similar way to how Sinclair used measures of centrality in the earlier donation chapter, she is able to demonstrate that the closer a member of the social network is to the respondent, the greater chance of that person swaying the respondents candidate choice. Both this finding and the geographic location study finding are not completely surprising, they have the feel of rigorous methodology highlighting what most of us would take for granted. Our closest friends are more likely to influence our political behavior than are more socially distant acquaintances, and our social network is likely to be comprised by those geographically close to us. These truisms are easy to state; however, they have proven difficult to show empirically, and Sinclair accomplishes much with these two studies. 4.2.5.2 Party Identification Chapter five is titled Peer-Pressured Party Identification: The Elephant in the Room, and deals with how party identification is influenced by ones social network. In very similar findings to chapter four, Sinclair finds that those closest to us socially are more likely to influence party identification than those more distant. However, party identification has higher salience than candidate choice, and is thought to persist more strongly over time, as candidates change often but party identification rarely does. Sinclairs most interesting finding related to party identification is that a persons social network, to the extent that those closest to a respondent were of differing party affiliation, was less likely to cause a change in party identification than it was to cause the respondent to remain publicly silent about party identification. In other words, a Republican who is surrounded socially by Democrats, particularly if those closest are Democrats, the Republican is more likely to become reluctant or unwilling to share their own party identification, but not change it. This finding was the same for Democrats whose social network was primarily comprised of Republicans. 4.2.5.3 Sinclair Conclusion Sinclair effectively takes on very big questions about the effects of social networks on political behavior. In four broad behavioral contexts  turnout, political donations, candidate choice, and party identification  she uses varied methodological tools to demonstrate the effects of social networks. Her research design choices in each are appropriate, and she is forthright regarding the relatively small magnitude of effect that is discernible, at least given the methods available. Citizens are social beings, and there remains much to explore for researchers interested in this area of political behavior. The strength of this book is not in exploring the depth that social ties have on political behavior, but on the breadth of effects. By focusing horizontally across the sub-discipline of political behavior, Sinclairs work should force other researchers to at least consider the social network effects that might be present in their own models and hypotheses. 4.2.6 Delli Carpini &amp; Keeter: What Americans Know Quite separate from the question of how we learn political information is the question of what Americans know about politics. In this area, normative democracy theorists will not find much peace of mind. Some of the original research in this area from Converse (1962) showed that Americans frequently have little political information with which to base their partisan identification, and lack coherence when asked open-ended political questions (Converse, 1964). In What Americans Know about Politics and Why it Matters, Michael X. Delli Carpini and Scott Keeter (1996) follow Converse, carefully and thoroughly undermining the idea that the average American knows much at all about politics. The crux of the book is that the distribution of political knowledge is very uneven. Americans from higher socio-economic backgrounds, older Americans, white and male Americans, in part or in sum, all have a fairly good basis of political information. However, if Americans who are young, from the inner city, black, or female, tend to fare worse in tests of political knowledge. These differences matter not only for knowledge, but for rates of participation, and even the effectiveness of that participation. One area where the authors have been critiqued is that they do not distinguish what types of knowledge might be more useful for different demographic groups. For instance, while a white, middle-aged male might have his political needs served by certain information (the type the authors test for), a young black woman may have very different political information needs. Delli Carpini and Keeter do an excellent job documenting their research process, and the methods used to come to their conclusions. While their argument stretches in some areas, overall they make a good case for why we should be concerned about what Americans know about politics. 4.2.7 Conclusion As demonstrated in the GPT-2 section of this essay, the tools to deceive are only getting more sophisticated, while there is little evidence that Americans are any more capable of remaining skeptical, especially when the fake news is intentionally aimed at taking advantage of the cognitive biases that define what it means to be human (Kahneman, 2011). Do Americans have enough factual information to be able to participate meaningfully in their American democracy? The findings of Delli Carpini and Keeter (1996) along with others would argue that Americans do not have the political knowledge to participate fully. Because political information is distributed unevenly across demographic groups, groups with less access to political information participate less, and when they do participate, they are less likely to attain the political results they seek. This is reminiscent of the findings of Larry Bartels (2010), who shows that while lower-income Americans tend to vote at similar rates as higher-income Americans, their vote counts for less because it is given less preference by politicians. The finding that socioeconomic status influences the impact of political participation is found across modes of participation, as lower-income Americans were less likely to become political activists, and even when they did they used different (although sometimes more effective) communication methods than did activists with more financial resources (Verba, Schlozman, Brady, &amp; Nie, 1993). However, some scholars would disagree with the stark findings in the works I have highlighted here. Lupia (1994) argues that voters dont need to be fully informed encyclopedias in order to vote, and that less-informed voters use heuristic shortcuts (Tversky &amp; Kahneman, 1974) to vote in ways very similar to their better-informed counterparts. Lupia uses empirical evidence from a California initiative on insurance reform, a topic that most typical voters will have very little information about. Low-information voters participate meaningfully by relying on cues from third-parties such as advocacy groups and political parties to form their political opinion. That information is then translated into voting that is not dissimilar to those who spend much more time delving deeply into political issues. However, this kind of partisan motivated reasoning has been found by other scholars to reduce the quality of political opinions (Bolsen, Druckman, &amp; Cook, 2014), and to be more shaped by the power of prior belief than the accuracy of new information (Lodge &amp; Taber, 2013; Taber &amp; Lodge, 2006). Americans must make political decisions in a complex, fluid environment, and much of the scholarship that finds lackluster participation and lower political efficacy is predicated on a somewhat elitist rational choice belief that correct participation or incorrect voting exists in the first place. Lau and Redlawsk (2006) undermine this assumption, as they use experimental methods to test four models of how voters process information and make voting decisions. They have subjects make voting decisions on hypothetical candidates in a time-pressured environment, and then in the second phase allow those same respondents to collect information for as long as they need before making a voting decision. Subjects who change their vote between the first and second phases are considered to have made an incorrect vote in the first phase, while those whose vote is consistent between phases made correct votes. They find that in up to three-quarters of the time, their subjects were able to make correct votes despite not knowing enough. The methods used by Lau and Redlawsk are subject to critiques that their experiments are artificial environments, and so dont necessarily tell us exactly how voters make decisions in real elections. However, the value of these experimental findings is that they closely mimic the frantic, bounded rationality (Simon, 1972) and heuristic shortcuts (Kahneman, 2003; Lodge &amp; Hamill, 1986; Taber &amp; Lodge, 2006) that real Americans in the real world must contend with when making political decisions. In many ways, Lau and Redlawsks findings are supportive of Lupia (1994) and others who reject the belief that democracy can only function properly when Americans are participating with rational, well-informed political knowledge. Americans are remarkable political creatures. They form political knowledge along socioeconomic cleavages, vote at low rates and participate in declining numbers in other participation modes, possess little accurate political information, and their political participation tends to have little impact. Yet, their political behavior is redeemed when the context of that political behavior is more fully considered. It is a privilege to have the time, resources, and desire to fully pursue political information, and that privilege is extended to relatively few in American society. Still, despite the privations of political knowledge, expertise, and participation, most Americans manage to get it right most of the time  they operate in political spheres remarkably well in the face of factors which in a more rational approach should convince them to not participate at all. That is not to attempt to dispose of the normative democratic ideal, but perhaps to soften the approach of its most ardent believers. We should still heed the warnings of scholars such as Bartels (2009), who rightly worry that growing economic inequality threatens democracy. While not yet a three-hundred-year proven success, the American democratic experiment has so far succeeded despite the flaws of its citizens political knowledge. Short of some unreachable ideal lies a political persistence in the American citizen which manages to know enough, participate enough, and succeed politically enough. 4.3 Congress and the Presidency: The Electoral Connection In Federalist 51, James Madison observes that the electoral connection is the publics primary control on government. Thinking broadly about political science scholarship on American political institutions, and focusing on at least two national governmental institutions (e.g., Congress, the Presidency, the bureaucracy, the courts), answer the following: Does the reelection incentive induce our national governmental institutions, and the actors within them, to be responsive to the public and public interests? Does the electoral connection create systematic biases in governmental action? Please provide a critical look at the scholarship underlying your answers. Or a similar question: In Federalist 51, James Madison observes that the electoral connection is the primary control on government. Does the reelection incentive induce members of Congress to respond to constituents policy preferences? Does the electoral connection create systematic biases in congressional policymaking that undermine Congresss capacities as a legislative institution? 4.3.1 Introduction The founding of the United States was consumed with debate and concern regarding the construction of a constitutional system that would protect citizens of the new nation from the tyranny of another monarch. James Madison (Hamilton, Madison, &amp; Jay, 2008, p. 257) wrote in Federalist 51 that the primary question in forming a representative democracy was to first enable the government to control the governed; and in the next place oblige it to control itself. Resolving this contradiction, he argued, was best done by ensuring governmental power was ultimately stored in the people, through elections. A dependence on the people is, no doubt, the primary control on the government, Madison writes (p. 257), but experience has taught mankind the necessity of auxiliary precautions. While few contemporary observers worry the country is on the verge of a resurgent monarchy, in over 241 years since its founding concerns about how the citizenry can best control its government have not abated. In this essay, I will argue that the electoral connection still provides the best incentive for our elected officials to respond to constituents policy preferences, with particular focus on two political institutions - the US Congress and the presidency. Systemic biases have existed and will continue to persist (Hall, 1987; Lee, 2015), which slows down governmental representativeness and responsiveness, but empirical evidence of these biases overcoming the urge for reelection among elected officials has not been convincingly found. Further, the biases are able to be adequately addressed in the long run through the electoral connection and collective action of opposing interests. While some other forces impede the electoral connection, they do not overwhelm it, and it is the system itself that allows for self-correction for the biases and forces which keep it from operating perfectly. 4.3.2 Reelection and Mayhew Do Members of Congress care about reelection? Do they respond to constituent policy preferences? David Mayhew (1974) and Richard Fenno (R. F. Fenno, 1978) are both preeminent scholars of Congress, and simultaneously they both decided to use new rational choice thinking to see what they could learn from Congress. Mayhews conception of Members of Congress as single-minded seekers of re-election is spelled out in his book Congress: The Electoral Connection (1974), which has remained a resilient theory of Congress. When written, rational choice theory was just starting to bubble up from the pure economics approaches into political ones. One way of reading Mayhew is that he is not actually claiming Members of Congress are motivated only by reelection, but to put forth that assumption and see what behaviors would be expected if it were true. He finds that given that assumption, we would expect Members of Congress to engage primarily in three activities: Advertising, credit claiming, and position-taking. These three activities correspond with what we see from Congress members, and so, Mayhew argues, we can accept the assumption that they are single-minded seekers of reelection. Mayhews theory is convincing and has remained a predominant explanation for understanding why Members act the way they do. In fact, Members of Congress spend a tremendous amount of time claiming credit for policies they had little to do with, advertising their personal biographies, and taking positions on issues. It has proved difficult if not impossible to argue that legislators are not intimately and intentionally connected to the voters they represent. However, Mayhews theory leaves some empirics unexamined and unanswered. The three most critical critiques leveled at Mayhew are: 1) If congressional members are only motivated by re-election how does Congress address common resource problems? 2) How to explain members serving on congressional committees? 3) Do all constituencies matter equally to a Congress member? 4.3.3 Responses to Mayhew Not every congressional committee assignment has particularized benefits for reelection - internal power, good policy, ability to actually get things done. There are institutional arrangements that just arent explained by reelection only - why did it take until like 1993 for the Post Office Committee to get disbanded, as it was useless for 80 years in terms of reelection? Fenno (1973) (1973) offers a slight correction to address these gaps in Mayhews theory in his article Congressmen in Committee. Fenno argues committee assignments are not well explained by immediate direct reelection benefits, so there must be other goals. Prestige, power, leadership goals, and future pursuit of higher political office may also matter. Goals are malleable, not static, and Congress members engage in committee work despite relatively little connection between some committees and reelection. Richard Hall (1987) also tests Mayhews theory that Congress members are single-minded seekers of election and provides evidence the members are motivated by other goals. Hall tests his hypothesis that Members participation in committees is influenced by motivational factors (goals) such as district service, making good policy, making a personal mark, and supporting the Presidents agenda. Halls evidence suggests there are participation biases earlier in the legislative process that have a larger influence than a standard preference-based model like Mayhews would presume. Fenno responds more fully to Mayhew in 1978 with Homestyle: House Members in Their Districts. Fenno answers a question left unexamined by Mayhew: which constituencies matter? Fenno agrees that Members of Congress are heavily incentivized by reelection, but in a far less deterministic way than that put forth by Mayhew. Members of Congress have different constituents, and thus different goals. Fenno names the different circles of Members constituencies the geographic, primary, and personal constituencies. How the Members define and understand these different constituencies shapes their activities in seeking their primary goal of reelection. In The Logic of Congressional Action, Douglas Arnold (1990) takes on the puzzle created by Mayhew: If congress members are only motivated by re-election, then how is it that Congress takes action on common goods and resource problems? Common good problems are at the heart of many modern problems (Ostrom, 2015), and addressing common good problems is at the heart of both politics and political science (Mansbridge, 2014). Arnold takes up this challenge not by directly critiquing Mayhew, but by beginning with the same assumptions and attempting to answer the puzzle created by it. Arnolds answer is that Members of Congress are motivated to solve some common pool resource problems, namely those that allow them to claim diffuse benefits without having connections to concentrated costs, a theory of policy that has become central to understanding many policy conflicts (Ostrom, 2011). Congress members choose different strategies of procedure to allow for decision which impose concentrated costs, like the closing of a military base, to be made by committees outside their control. Citizens have varying levels of preferences, from informed to potential, and Members of Congress attempt to estimate these preferences in order to determine which procedure strategies to select for common good problems. Many observers and citizens tend to blame ideological differences between the parties for a Congress that can at least appear from the outside to be in constant gridlock, and that there is increasing polarization between the parties that inhibit the electoral connection. In other words, legislators are more captured by partisan interests than the interests of their constituencies. Measures of ideology are a common correlate in studies of Congress, including the NOMINATE, D-NOMINATE, and DW-NOMINATE scores developed by Poole and Rosenthal (2001) to measure the role of ideology on roll-call votes. However, some congressional scholars have cast significant doubt that ideology plays a role, including Frances Lee (2010) in her book Beyond Ideology: Politics, principles, and partisanship in the US Senate. Lee operationalizes party conflict as two separate measures: true ideological differences (substantive), and those differences which are related to Senators wanting their own team to win (procedural). Lee shows that in fact it is the non-ideological procedural votes that tend to split the Senate, as these votes are more likely to be used to protect a partys agenda and help build complex agreements between the parties. Lee builds a convincing case that ideology and polarization are not the root of conflict and therefore does not undermine responsiveness or representativeness of the Senate. While she does not address the House of Representatives directly, it seems likely the same would be found there. There are harsh constitutional realities (Curry &amp; Lee, 2017, p. 5) which limit party government, and the best evidence is that bipartisan lawmaking persists. 4.3.4 Systemic Bias in the Electoral Connection A significant challenge to Mayhews Electoral Connection are arguments put forth in Theodore Lowis (1979) The End of Liberalism: The Second Republic of the United States. Congress has abdicated its responsibilities to interest groups and a growing administrative state, Lowi argues, advancing the country from the First Republic to the Second Republic. In the Second Republic, the people no longer control their government, and the electoral connection has been replaced the bureaucracy, interest groups, and congressional committees. Differing conceptions of this anti-electoral relationship have been the iron triangle, and agency capture, and is a modern example of the factional dangers warned against by Madison in Federalist 10 (1787). Congress no longer controls the administrative state, and so the people no longer have a realistic electoral connection to those agencies, which have incredibly powerful effects on the daily lives of citizens. The fundamental bias Lowi argues for is that Congress has essentially auctioned off oversight and the typical American does not have the resources to make themselves heard in the process. Modern scholars continue to agree with the broad outlines of Lowis work, and find ways to test for evidence of a fundamentally biased system, as seen in an influential piece by Gilens and Page (2014), who find evidence for economic elite domination and biased pluralism theory. However, despite the influential article, the data and methodology underlying the piece render it unconvincing. They define economic elites as those households earning $140,000/year, which is difficult to imagine as the elites dominating politics, particularly as a special interest group. To their credit, the authors acknowledge the diminished explanatory power of their argument particularly in relation to economic elites. One of the most sustained and convincing arguments against Lowis conclusions is provided by McCubbins and March (1984), who differentiate between police patrol and fire alarm oversight. Those who worry Congress has given over its oversight responsibilities, like Lowi, are looking for evidence of police patrol oversight  proactive, roving oversight that detects problems and curtails them before they grow out of control. However, as McCubbins and March argue, Congress has a rational interest in selecting fire alarm oversight, which is a less centralized and direct approach. Congress sets the rules and procedures to govern agencies and then allows for citizens and interest groups to set off alarms when the agency is not operating correctly within those rules. Congress members are rationally motivated to select for fire alarm oversight, which allows them to claim the credit (Mayhew, 1974) when problems are detected. Members of Congress do not get credit for simple maintenance checks on agencies (a form of police patrol) when everything is fine and nothing needs substantial change. 4.3.4.1 Pluralism, Parties, and Presidents Factionalism is commonly cited as negatively affecting the electoral connection. This idea is as old as the American system itself. Madison believed that in a nation with conflicted and competing interests, no one faction would attain political dominance. In Federalist 10 (Madison, 1787, p. 232) faction is defined as a number of citizens, whether amounting to a minority or majority of the whole, who are united and actuated by some common impulse of passion, or of interest, adverse to the rights of other citizens, or to the permanent and aggregate interests of the community. In Madisons view, the mischiefs of faction would be a risk to the representativeness and responsiveness of the newly formed republic, and so the solution was to either remove the causes of faction or structure the government such that the damaging effects of factionalism could be controlled. Unfortunately, Madison believed, it was impossible to remove the causes of faction, as liberty is to faction as air is to fire (p. 232). That option no longer available, the Constitution structured a system of checks and balances to ensure the executive, legislative, and judicial branches would remain in balance. Each branch would remain independent of the other, and contain levers of power which would allow it to counteract the other. Pluralist theory argues that the political balance is a common good for the American electorate, as it allows for interest groups, which represent the group interests of citizens, to compete for influence within government. This belief in pluralism holds its place as the dominant theory in American politics for a very long time. Truman (1971) contends that this competition of interests in pluralism is the balancing wheel of the American governmental structure. Where too great an imbalance occurs, small interest groups will be created to represent the interests of those on the threatened side. These interest groups grow in power, prestige, and usefulness, and eventually become part of the governmental policy machinery. Interest groups are therefore integral to the functioning of the American government, even surpassing the direct role of the electoral connection. Dahl (1961) is perhaps the most important early political scientist on the pluralist side. The pluralist view is that systemic bias does occur, but in a limited form. Further, group conflict driven bias (as in elite-dominated issues) is mediated by the government. Competing groups means that no one voice can dominate, and the conflict also ensures that policy change is usually incremental. Dahl found that power was fairly widely dispersed rather than concentrated in a single actor in his study of New Haven, Connecticut. Urban governing was a coalition-building exercise, and anyone willing to work hard enough at it could achieve influence in politics. Dahls work motivated a lot of academic interest in studying local politics. Even after the rise of theories that convincingly put the lie to normative pluralism (Schattschneider, 1960), artifacts of pluralism on the American political conscious could still be found. Neustadt (1990, p. 11) uses pluralism as a vehicle for his argument that presidents must bargain both externally and internally in order to wield the relatively weak power of the office: Presidential power is the power to persuade. Presidents bargain internally with competing factions of his own executive branch, and those heads of federal executive agencies, cabinet secretaries, and bureaucrats all have competing interests. Because power is decentralized in the American constitutional system, a president is required to marshall his resources around persuading the other branches to achieve his goals. These resources include his position, reputation, and prestige. Arguments against the pluralism of Truman and Neustadt are plentiful and convincing. Ultimately, Trumans reliance on the ability of small interest groups to overcome systematic bias fails to answer Olson (Olson, 1965). While small groups may form in response to a perceived need for policy change, as the group grows in size the collective interest is no longer able to overcome the free-rider problem. Kernell (2007) argues that Neustadts theory was only correct for his time, and that later presidents shifted to a more confrontational tactic he calls going public. Where Neustadt believed presidents rely on a Washington DC-based reputation, Kernell shows that modern presidents rely to a much greater extent on their reputation with the American public. Kernells theory seems more in line with modern presidential action, such as President Trumps daily use of Twitter to get his message to the American public. 4.3.5 Parties and Ideology Perhaps Mayhews greatest weakness is his disregard for political parties. Though he eventually softened his original argument that parties simply do not matter (Mayhew, 2005), the power of parties in the American political system is hard to deny, and has been the focus on many critiques on Mayhews electoral connection work. E.E. Schattschneider led the committee that produced the report (American Political Science Association, 1950) Toward a More Responsible Two-Party System: A Report of the Committee on Political Parties: Summary of Conclusions and Proposals. While this report ends up being more of a normative statement about what parties should be rather than a theory of what they are, it still serves as an accurate overview of Schattschneiders enduring belief that parties matter. But Schattschneiders better theoretical contribution is his (1960) The Semi-Sovereign People, which includes his criminally over-looked quote: The flaw in the pluralist heaven is that the heavenly chorus sings with a strong upper-class accent. Parties are the antidote to overly powerful interest groups that fail to represent the poorer classes, according to Schattschneider, because parties allow for a widening of the conflict (Valdimer Orlando Key, 1963). All conflict has about it some elements that go into the making of a riot, writes Schattschneider, Nothing attracts a crowd as quickly as a fight. Nothing is so contagious. His main insight is that parties allow for fights to expand their audience, effectively allowing for citizens from lower classes to elevate their fights to the national stage through parties. Mancur Olson (1965) goes further and more convincingly than Schattschneider to how small groups of isolated people with common problems to overcome can effectively challenge systemic bias in the political system. Olsons primary insight is that individual rationality is not the same as group rationality. Where Schattschneider is still using a reductionist and behavioralist approach, making comparison s between national parties and street riots, as if the group and individual levels are the same, Olson proceeds carefully through examples of unions, cartels, and firms (all of which can be thought of as interest groups) and how they form rationally according to their interests. The collective action problems that spring from this solution create solutions to systemic bias. In small groups, it is easier to identify free-riders, while large groups have more difficulty doing so. This creates a natural bulwark against the persistence of overly powerful interest groups, as smaller groups grow and larger groups decline. Coercion and incentives are variously used by all types of these groups to attempt to solidify their ability to hold together and consolidate power, such as mandatory union membership in closed shops and offering non-collective benefits to members. Olsons treatment is sometimes coarse and limited by the time period he is writing about, but his central insight remains valid. Small isolated pockets of individuals are motivated by common cause, resources, and costs to strategically come together to promote group interests, which allows for systemic biases to be overcome. ###$ Key Differences V.O. Key makes critical contributions to understanding how parties can skew the electoral connection is two books: Southern Politics in State and Nation (1949) and American State Politics: An Introduction (1963). Though the latter work is less famous, in it Key makes the important point that state and national politics are connected. Sectionalism in national politics has an affect on state politics. Key finds that national tides spill into state politics as cleavages driven by national party concerns are projected into state elections. This phenomenon can be important, as expanding the scope of conflict made the civil rights movement possible only as Democrats came under national party pressure, but it can also relieve local officials of performance pressure (and thus diminish the electoral connection) who are able to ride on the national tide of their party. In this way, parties become the solvent of federalism. Keys Southern Politics makes several contributions for the purposes of this essay. First, it is important to understanding how political elites bias the electoral connection by substituting other issues (race in his example) for economic issues, thus creating cross-cutting pressures that inhibit cohesive group formation among the disadvantaged. This insight has held up over time with evidence that voters who feel that cross-pressure are less likely to participate politically (Mutz, 2002). Though Keys contributions are much deeper, for the present purpose the second insight springing from Southern Politics is that not all groups are equal. Pluralist theory holds that the intense political conflict and competition ends up balancing interests in the polity. However, the cases of partisan competition are relatively limited in the South. In most states, one-party domination by Democrats was the rule. More than any other, Arkansas was the example of a pure one-party state, though the same general pattern could be found in most of the South. Extreme political conformity meant that no consistent factions arose, as political hopefuls were basing success on friends and neighbors in the areas they lived. This reified the power of black belt whites, who in turn were motivated to rule through non-redistributive policy. After all, if winning elections means keeping your (white) neighbors happy, and politicians are at least strongly motivated to win re-election (Mayhew, 1974), then making sure those neighbors are well taken care of by the party machine is a rational strategy. Keys study of the South generated broader implications for political study of states and parties. His genius was in deriving more general political hypotheses from close study of Southern state cases. The primary insight is that the closer a state comes to pure one-party rule, the more multi-factionalism will result within those parties. In states with more (though not equal) partisan competition, both parties will become more cohesive. This begs the question: What is the difference between party and faction? Key sees the differences as a continuum, from the most extreme one-party rule in Arkansas and South Carolina to states where the minority Republicans came close to establishing two-party rule, most identifiably in North Carolina. Key identifies at least five differential effects  things parties do that factions do not. First and primarily, when there is a unified and persistent minority party, the majority party rules more responsibly, redistributes benefits to compete for votes among blacks and minority party members, and is more disciplined. Fractured factional leaders do not do this. Second, parties can organize voters, and sustain those coalitions of voters around shared interests, whereas factions are too locally focused on merging interests with other outside factions. Thus, factional politicians end up having to rebuild any coalition around a new identity each election cycle, without continuity of effort or dedication. The third effect is that states with more than single-party rule, the minority party can sustain their opposition, whereas factional opposition cannot. Fourth, the sustained nature of parties means that leaders are vetted and experienced over time, whereas in factions, charisma becomes more critical as they attempt to build coalitions each cycle quickly. Fifth, corruption, nepotism, and political favoritism are more endemic to factional rule in one-party states because factional politicians must use whatever means are available (Key, 1949, p. 305) as they attempt to bribe friends and neighbors to stay loyal. In a cohesive party, leaders are still likely to rewards friends with a place in the unified party government, but again this is done in a more distributed manner. Because there is a unified opposition party with at least some governmental levers to pull, the risk of discovery of criminal behavior in the majority party serves to keep corruption relatively lower. The differences between parties and factions show how complex results can spring from the relatively simple difference that parties have internal cohesion and discipline, while factions do not. With some limited exceptions, the South was a political body comprised of factions, to the detriment of the electoral connection. Democrat rule was the rule. Whereas Key generally expects national politics to seep into local politics, if not dominate them, the South remained politically isolated from the nation. As he shows in later work (Valdimer Orlando Key, 1963), undoing this isolation was eventually what allowed for the civil rights movement to begin undermining Democrat single-party rule. Prior to that, however, the Souths atomized factionalism meant the governments were generally unable to provide the political leadership necessary to cope well with the governmental problems of the South (Key, 1949, p. 310). The South was primarily organized politically around the interests of black belt whites, who were primarily interested in preserving their power at the expense of the blacks who far outnumbered them. This was a political division that did not hold at the federal level and reinforced the political isolation of the South, which remained insular and overly focused on localism and racist traditions. 4.3.6 Conclusion Despite a laudable attempt by Lowi (1979), no single scholar or even collection of critiques is able to undermine Mayhews (1974) basic insight that our elected officials care a great deal about reelection, which reinforces the electoral connection of the American people to its government. Mayhew conceptions of legislator ambition, autonomy, responsiveness, and accountability serve to keep the electoral connection strong. While Mayhew originally held a fairly narrow scope of focus on post-World War II congressional behavior, recent work shows that the electoral connections stretches back further in time (Carson &amp; Jenkins, 2011). Mayhewian conceptions of ambition were present in the Civil War era (Kernell, 1977), as were examples of Members of Congress advertising their accomplishments to constituents (Cooper &amp; Young, 1989). It appears the electoral connection is in no current danger of being undermined, as politicians and parties continue to lobby furiously for votes, and the average tenure of legislators continues to grow over time(Glassman &amp; Wilhelm, 2017). Fenno (1978) sharpens Mayhews argument by providing a detailed rendition of how exactly members of Congress shape their goals through defining their constituencies in ever-expanding circles of relationship to the member. While complaining of the political domination of economic elites and party ideology has proven a time-tested populist appeal, there is only mixed empirical evidence to show it is true, and those studies which do make the claim (Gilens &amp; Page, 2014) end up failing to conceptualize and define the problem sufficiently to be convincing. Of course, imbalance in the power of specific interest groups exist, and at times there have been interest groups which have an oversized influence on policy. However, through Olsons The Logic of Collective Action, we can understand how systemic bias is addressed through the collective action decisions of small groups counteracting the larger groups. Where the pluralist dream of a perfectly balanced wheel of government has clearly been shown inaccurate, envisioning the system as a spinning gyroscope is perhaps more useful. It tilts from time to time and moves along its own wobbly path, but in the end, stays upright as long as there is enough energy in the system to continue. 4.4 Foundations of Congressional Action In some ways, this is just a short piece using Krehbiel (1998) Pivotal Politics: A Theory of U.S. Lawmaking. But it could also serve as the foundation for critiquing (or employing) rational choice theory. 4.4.1 Introduction In Pivotal Politics: A Theory of U.S. Lawmaking, Keith Krehbiel (1998) constructs a general theory of lawmaking. Krehbiel uses a rational choice approach to construct a game model, which takes into account both presidential and legislative players. While Krehbiel is satisfied with the his surprisingly simple (p. 1) and unabashedly elementary theory, in chasing elegance he commits errors in constructing the assumptions of his model, rendering the models explanatory power highly suspect. This paper will proceed through three sections. First, I will describe the basics of Krehbiels theory so as to orient the reader to the next two sections, which offer critiques of Krehbiels theory centered around errors in construction of his general model of lawmaking (p. 35). Krehbiel asks too much of the reader in asking them to assume away crucial realities of the legislative world as he builds game sequence and behavioral assumptions into the model. In the end, Krehbiels offering is useful as a thought exercise, but does little to convince me that his model explains much about U.S. lawmaking. 4.4.2 Krehbiel: Pivotal Politics What causes congressional action versus congressional deadlock? For Krehbiel, the answer is parties dont matter to how members of the US House of Representatives vote, only Member preference can provide answers. To test the theory, Krehbiel constructs a sophisticated game model, in which he defines the pivotal players. Included in his pivot model are the median member of the House, the President, the Senate filibuster pivot, and the veto override pivot. The model places these pivot players along a single axis, and attempts to construct ideal models of legislative action dependent on their relative position to one another, as well as to a point he defines as the ideological nature of the bill in question. Krehbiels model remains influential, though ends up rather unconvincing due to a host of problems, only some of which will be covered here, and which are selected in the context of what Lees explanations (2009, 2016) explain better. Overall, Krehbiels constructed game space does not accurately reflect the real-world context he intends to examine, and so the outcomes of that model should not be assumed to be applicable to the real-world context either. While all models simplified realities, Krehbiel makes model assumptions that he hopes are simplistic, but end up diametric. 4.4.3 Game Sequence Assumptions Tucked into a footnote, we discover Krehbiel defines the game sequence as assuming (p. 24), The game is finite, and noncooperative with full information. Noncooperative and full information assumptions will be addressed in the paper later, and I begin my critique with the assumption of finiteness. By finite, Krehbiel means his models assume a game, and thus the players strategy and decisions, are not repeated  an incredible oversight in a chamber where proposed bills are routinely brought up every session, if not more than one time per session. Even in the context of game theory, an unrepeated game is a laboratory thought experiment, and Krehbiels failure to include repeated games into his analysis severely undermines his conclusions, as repeated games introduce complexity and often have differing strategies and outcomes for the players when compared to single shot games. Krehbiel, in a footnote, later justifies his selection of a static, non-repeated game by noting that (p. 40) legislators have short time horizons. This justification is offered without further defense, and seems in direct conflict with the reality that the average tenure both Representatives and Senators has been rising since 1789, and as of 2017 the tenure for a sitting Representative was 9.4 years, and for a Senator was 10.1 years (Glassman &amp; Wilhelm, 2017). Even if Krehbiel is using the two-year election cycle for a Member of the House, the assumption that two years is a short time horizon is problematic, given a de minimis assumption of lawmaker preference for winning re-election (Mayhew, 1974). Under Krehbiels model assumptions, even this desire goes unaddressed. 4.4.4 Behavioral Assumptions Krehbiel sets up the players game behavior with the reality defying statement that Players know the game, know each others preferences, and understand who is the pivotal voter in any given setting (p. 25), and are therefore able to construct utility optimizing strategies, where utility for a player is defined as the ideal point in the policy spectrum that a player prefers. Taken in sequence, the pivot models failures become clear. First, for a player to know the game is simply a restatement, in game theory terms, that the players have full information preceding strategy selection. This is demonstrably untrue in the legislative context, as information flow and its intentional disruption has been demonstrated to be an integral component of legislative leadership, power, and function, and pervasive inequalities exist among members of Congress regarding the information they possess during the legislative process (Curry, 2015). Even forgiving Krehbiel for not anticipating work a decade later than his own, however, the simplistic assumption that full information is (or was) available to lawmakers at any historical point seems an avoidable error. Continuing to Krehbiels second behavioral assertion, that legislators know each others preferences, is as vulnerable as his first. Legislators, we are to assume, have a mental map whereupon every other Congress member, all 534 of them, stand on Krehbiels unidimensional policy preference construct (p. 35). Assuming [N -1] possible policy issues i, any combination of which could comprise any single B (bill) that all L (population of legislators), we can easily see that the policy preference space any single Li (legislator) must possess would quickly pass by unmanageable as it continued on towards impossible. Even without a made-up graduate student pseudo-formula, however, we know from the statements of legislators themselves that they are not fully aware of the contents of many bills, and thus cannot possibly be aware of where any individual colleague stands on the bills, let alone a bill comprising multiple issues about which that individual may have a preference. Even if we are to grant his assertions about full player game and competitor knowledge, we must also address Krehbiels final behavioral assumption, that players understand who is the pivotal voter in any given setting. Central to this assertion is that of the pivotal voter, a hypothetical Member whose policy preference lies at the center of the policy dimensional space. Of course, in reality no legislative median voter exists, but without the construction of one, Krehbiel has no way to illustrate how his game actually proceeds  and so he constructs one, noting only that he finds this hypothetical adoption of a plausible positive baseline (p. 26, emphasis in original) more helpful than that of an assumption that a presidential preference would happen to align with legislative outcomes. He notes that scholarly support for the median voter theory is nontrivial. Hardly a rousing endorsement, Krehbiels use of nontrivial appears to be the deliberate waving away of the reality that the median voter theorem has well established problems which directly undermine his assumptions and model. Directly to this concern, the absence of median voter equilibrium may also arise in in models where candidates can manipulate information and voter turnout and that in those cases chaos and indecision are predicted (Congleton, 2004). In the legislative context, as discussed already, manipulation and withholding of information is a key strategy (Curry, 2015). In this context, the ability to manipulate voter turnout may not be a fatal wound to the pivot model, but the ability for party leadership to control votes, and arrange for Members to be deliberately absent, seems to cast at least further doubt on an already problematic model. 4.4.5 Conclusion On balance, Krehbiel sacrifices too much accuracy in his seeking of model simplicity. In defining the lawmaking space as one where the game is finite, noncooperative, and with complete information, the model fails to reflect the Congressional body in whole. And in assuming full knowledge of the game, full knowledge of both competitor and ally preferences, and full knowledge of who the pivot voter is in all settings, Krehbiel ends up describing a collection of players too far removed from any US Congress member to be relied upon for understanding how the most intricate lawmaking system in the world (p. 21) really works. 4.5 Mancur Olson, Collective Action, and Police Unions 4.5.1 The Logic of Collective Action and the Tigers who Live on Oranges Those who tell you of trades unions bent on raising wages by moral suasion alone are like those who would tell you of tigers who live on oranges. Henry George, 1891 4.5.2 Introduction In The Logic of Collective Action (1965), Mancur Olson set out a rational-choice theory of collective action, and turned the field of political science away from the leading theory of the time, pluralism. The problem of collective action  how to minimize free riders who want to collect the benefit of group action without working towards the groups goals themselves  continues to be an active field of research today. Olson spends considerable time in his book on the subject of labor unions, and specifically in justifying the use of closed shops, the practice of requiring employees pay for membership in a union, regardless of their own personal stance or choice. Olsons arguments have held great sway, but are now under considerable attack with the current US Supreme Court considering Janus v. American Federation of State, County, and Municipal Employees. In Janus the Court is considering the plaintiffs claim that his First Amendment right to association (or dis-association) is violated through a governmental requirement that he pay union dues. If the Court finds for the plaintiff, some commentators predict the blow to organized labor organizations will be heavy, perhaps fatal. Certainly, Olson would agree, contending as he does that labor organizations survive only because closed shops solve for the free-rider problem. However, in this paper I will attempt to show Olsons conception of unions does not adequately account for public employee unions, specifically public safety employee unions. I will use the case of the Fraternal Order of Police (FOP) as a negative case example to show specific areas where Olsons assumptions of how labor unions are borne, survive, and attract new members are poorly theorized. Olson never acknowledges the existence of public sector unions, and therefore severely under- or wrongly theorizes how public-sector unions might differ from private sector ones. Indeed, despite Olsons disbelief, the Utah FOP and many other police labor organizations are tigers who live on oranges. 4.5.3 Is it fair to hold police unions against Olson? It is tempting to let Olson off the hook for not adequately theorizing a type of union which, after all, he never actually mentions. Some might be tempted to argue only after President Kennedy signed executive order 10988, extending protections of the Walker Act to federal employees, did many states even recognize the right of public sector employees to collectively bargain. This is an unsatisfactory explanation, however, because while many police labor organizations dont have collective bargaining powers, many do, with one researcher placing the number at 70% (Kadleck, 2003). Further, the FOP was first established in 1918, over forty years before the publication of Olsons work, suggesting he had time to orient himself to a union landscape which included public sector unions. It seems more likely that Olson is a victim of blinding himself. Tied as he is to the idea that unions are for collective bargaining (p. 76) it seems likely he just did not remain open to the idea that some labor organizations not only do not collectively bargain, but do not need to. And, as this paper will later show, police labor organizations provide enough evidence against Olsons theory of collective action that he was well served not to confront them directly, at least in the name of keeping his theory whole. To be fair to Olson, even decades after publication of The Logic of Collective Action, literature on police associations and unions is abnormally thin, and has tended to portray the organizations in undifferentiated, unchanging, and negative terms, usually as an impediment to progressive improvement of policing. Walker (2008,) finds only 19 published academic manuscripts of any type  peer-reviewed or not  on police unions in the 33 years previous to his study, and in his review of the literature finds it extremely limited and unbalanced (p. 97). Though beyond the scope of this paper, the neglect of the American police union is surprising, as is the generally negative academic take on what is, after all, an institution that has successfully fought for benefits and professional standardization of a middle-class occupation. The brief literature review I engaged in for this paper led me to agree with Walkers (2008, p. 103) analysis that most of the discussions are based on dated and unexamined assumptions. 4.5.4 Is the FOP even a union? Olson does not attempt to provide clear definition of a union, but instead ascribes certain attributes to them throughout his text. Perhaps the closest definition he attempts is (p. 76), A labor union works primarily to get higher wages, better working conditions, legislation favorable to workers, and the like. I argue the FOP does fit within Olsons broad conception, as the organizations founding impetus has been to improve wages and working conditions, as well as seeking favorable legislation at all levels of government. The FOP was founded in an era where police officers were working twelve-hour shifts, 365 days-a-year, and the founders message to their mayor indicated they sought to get many things through our legislature that our Council will not, or cannot give us (FOP, 2018a). Olson (p. 76) claims (emphasis in original), Unions are for collective bargaining. However, the FOP as a national organization has no collective bargaining  there is no national police department with which to bargain. Further, a substantial portion of the subordinate local lodges also lack any kind of ability to negotiate on labor contracts on behalf of their members. While exact numbers are difficult to come by, descriptive findings by Kadleck (2003) show that among police employee labor organizations, only 70.6% of the organizations have collective bargaining powers. For example, within Utah, not a single local lodge, nor the state lodge, has collective bargaining powers. Additional evidence the FOP is a union is found within the organizations historical information, which states the very name Fraternal Order of Police was chosen to avoid the politicization of the word union (FOP, 2018a): They decided on this name due to the anti-union sentiment of the time. However, there was no mistaking their intention. The sources Olson cites do not restrict themselves to a strict use of the word union. For example, Olson uses Henry George (p. 71) to show that the essence of a union is in its ability to use force, but George himself uses the phrase labor association. Finally, in some places Olson uses some broad definition which seems to easily accept the FOP as a union, such as when he asserts (p. 73), almost every union handles members grievances against the employer and (p.74), many national unions draw some strength from federation, that is from the fact that their members belong to small union locals, and thus at one stage have the advantages of the small group. The small groups, in turn, can be held in the national union through noncollective benefits provided to the locals by the national union. The FOP meets with both these formulations, as it is a federated organization with state organizations overseeing local lodge organizations, and provides representation for its members during administrative, civil, and criminal complaint proceedings. 4.5.5 Collective Benefits By far the most important single factor enabling large, national unions to survive was that membership in those unions, and support of the strikes they called, was to a great degree compulsory writes Olson (p. 68). Compulsory membership and picket lines, he writes (p. 71), are, of the essence of unionism. This may have been true some places, some of the time, but is hardly applicable in the public sector, which is generally prohibited from striking, let alone picket lines. Even more specifically, as noted earlier, in law enforcement contexts the strike is exceedingly rare; yet, still, membership has grown, and public-sector labor organizations have broadly seen great growth even in the face of a private sector labor movement which has declined in membership and power. In terms of critiquing Olson, the counter-examples of public sector unions are very troubling for Olsons claims. He ties his strong arguments for compulsory union membership directly to the success of the labor movement: If the conclusion that compulsory membership is usually essential for an enduring, stable labor movement is correct, then it follows that some of the usual arguments against the union shop are fallacious. Wage and benefit increases are generally part of any labor organizations central goals, no matter which sector they hail from. However, that similarity masks an important difference which Olson does not take into account. Olson claims, Employers often will not be able to survive if they pay higher wages than competing firms. (p. 67). Of course, in the public sector it is not as if the government agency often just folds up shop. For police labor organizations without collective bargaining, wage growth is more likely a counter-cyclical question for jurisdictions competing for law enforcement officers. In the current growth cycle, police departments in Utah are facing critical deficits in their manpower (Caldwell, 2018). In response, cities are overtly raising wages and benefits. Salt Lake City just announced they are adding fifty more officers and are continuing to increase wages well in advance of competing jurisdictions. Unified Police Department is also actively recruiting lateral transfers from other police jurisdictions, as well as increasing benefits or even adding ones that very few other agencies (if any) offer, such as 12% matching 401k contributions. This in particular is rare, if only because police officers still have pension benefits, in addition to so-called 457k accounts, which operate like a 401k for tax and savings purposes, but can be withdrawn when the officer retires, instead of age 65 Â½. 4.5.6 Noncollective Benefits Olson leaves a foothold for future scholars to expand his theory in the context of public safety unions such as the FOP (p. 67): Small unions may have a further advantage over larger unions stemming from the fact that they can be meaningful social and recreational units, and thus also offer noncollective social benefits that attract members. Olson may be underselling the social and recreational units here, at least in the context of public safety unions. The national FOP has within its mission statement that they seek (FOPb, 2018) to encourage fraternal, educational, charitable and social activities among law enforcement officers. While Olson tends to be dismissive of the importance of noncollective benefits in union growth and success, in police unions the noncollective benefits are extremely important, especially given the lack of features compulsory benefits, strikes, and picket lines. An empirical example can be found in the Utah FOP. One of the primary benefits the organization provides to its members is that of legal protection, especially in the face of increasingly brazen charging decisions by prosecutors in the aftermath of police use-of-force incidents. So, if the collective action problem to be solved is how do we best protect ourselves from legal threats resulting from on-the-job incidents the obvious answer is to secure the largest legal plan for FOP members. And, in fact, such a solution did eventually present itself, in the form of the FOPs national legal plan. Yet, due to concerns among the local Utah FOP leaders regarding the quality and cost of that national plan, in 2012 they formed the Utah FOP Legal Plan. Legal representation, especially in the aftermath of critical incidents (usually on-duty shootings) has proven to be the single greatest recruitment tool for the Utah FOP (source: me), and following the founding of a locally controlled legal plan and the high profile criminal cases against several officers after shootings, the Utah FOP increased its membership from approximately 800 officers in 2010, to just over 3300 officers today. Legal representation is clearly a noncollective benefit  it is not bargained for, is individually collected for upon need, and fits Olsons own definition (p. 73) of a noncollective benefit such as insurance. Olson (p. 75) contends that unions are strong because they are large, and small groups, and a unions noncollective benefits cannot usually be sufficient to bring in very many members. Here Olson clearly is relying on a conception of bargaining taking place on a national scale, such as a contract negotiation for all factory employees at General Motors for instance. But this is clearly an example where police unions such as the FOP have succeeded because of their noncollective benefits and members small local lodge affiliation, exactly opposite what Olson expects. There is no national American police department with which to bargain, and contract negotiations, where they are even available, take place within either a statewide or municipal context. Further, the noncollective benefits are indeed what have proven in the modern era to be the greatest recruitment tool for local FOP lodges, particularly in those areas without collective bargaining rights. Olson claims the the political strength of a large union is obviously greater than that of a small one. (p. 68). While there is obviously strength in numbers generally, the picture of large, national unions wielding political power is, again, more at home within private sector labor. Within state, county, and municipal public safety labor organizations, local groups tend to have more local political power, and be more effective with their city council than the state organization can be. But similarly, at the county or state level, the state is better equipped. Not every local lodge leader is effective on the larger stage, but this is not a limitation (necessarily) of the local lodge leader, as many of our better state and national leaders have not necessarily been effective at the granular local level. This may be because some of the tools that are effective at the state level, particularly the relationships with and use of news media, may not translate as well for a local lodge. It may be harder for a Nebo City police officer issue to gain traction with a media market dominated by Salt Lake City interests. This further justifies the umbrella organization model, for if a local lodge isnt able to use local tools, they can ask for assistance at the state level, which has the media experience and resources to change a local issue into a state-wide media issue. 4.5.7 Strike Three Olson contends that willingness to use force and the strike are the level with which unions accomplish their goals: the strike that is the unions major weapon (p. 67). There is very little evidence to suggest this is the case in the public safety union context generally, or the FOP specifically. Upon its founding in 1918 as a national organization, the FOP included an anti-strike provision in its constitution. That provision has been rarely tested, although some historical examples have occurred, such as a 1967 work-stoppage in Youngstown, Ohio by officers during a salary dispute with the city. It is because they are so rare that those that do occur stand out so strikingly. Still, the blue strike is incredibly rare within policing generally, and FOP lodges specifically, and cannot be considered seriously as the organizations major weapon as proposed by Olson. Olson endorses fully an idea put forth by Henry George (1891, p. 86) that unions must use force to attain their goals, and in fact this is the essence of unionism (p. 71): Labor associations can do nothing to raise wages but by forceThose who tell you of trades unions bent on raising wages by moral suasion alone are like those who would tell you of tigers who live on oranges. Moral suasion, though, appears to be exactly what the FOP national organization has used both historically and in the contemporary context. Left undefined by both George and Mancur, we can read into the phrase to assume moral suasion includes rhetoric, media pressure, and the like. This sounds very similar to the FOP founders letter to Mayor Joseph G. Armstrong, justifying the organizations goal to bring our aggrievances before the Mayor or Council and have many things adjusted that we are unable to present in any other waywe could get many things through our legislature that our Council will not, or cannot give us. Further, the modern FOP organizations formal language states (FOPc, 2018), We are committed to improving the working conditions of law enforcement officers and the safety of those we serve through education, legislation, information, community involvement, and employee representation. 4.5.8 Conclusion Olson was writing in a world of big corporations, big unions, big media, and big political parties (Rauch, 2013) and his book takes on those large interests, effectively doing away with the prevailing belief in a pluralism which dominated thinking at the time. In retrospect, his sections on unions effectively captured what had occurred, and why, in private labor organizations. But he was writing at a time when union membership was at its height, and within a decade of writing The Logic of Collective Action the American labor movement would have begun its long slow decline. Today, public employees are five times more likely to be a member of a labor organization than are private sector employees, and Olsons rational choice formulation of how labor organizations attempt to deal with free-riders do not translate easily to public employee labor organizations. More research is clearly needed to better theorize police unions specifically, and public-sector unions more generally. Given their relative importance in the modern labor movement, it is surprising more has not already been done to theorize exactly how these tigers survive on oranges. 4.6 The Advocacy Coalition Framework 4.6.1 Introduction The advocacy coalition framework (ACF) was developed by Paul Sabatier and Hank Jenkins-Smith (1993), primarily using environmental case studies from the United States. ACF attempts to develop a holistic theory of policymaking. Because it is designed to be applicable across a variety of policy contexts, and because it assumes that each policy environment is inherently intricate, the ACF framework is itself quite complex (see Pierce, Peterson, Jones, Garrard, &amp; Vu, 2017, fig. 1). In the ACF framework, policymaking takes place in a complicated environment which contains multiple actors across multiple levels of government (Weible, Sabatier, &amp; McQueen, 2009). Policy makers have very high levels of uncertainty, and so make decisions imbued with inherent ambiguity (Jones, 2002; Simon, 1972). Policy decisions take years to produce policy outcomes, and those outcomes are difficult to ascertain with any certainty. In the ACF framework, policy change takes place through either policy-oriented learning from accumulated technical and scientific information or external shocks or perturbations to otherwise stable scientific, social, economic, and political factors (Luxon, 2019, p. 106). ACF recognizes that there are also different types of policies at play, with some policies being fairly straightforward, others being very technical and complex and done outside public notice, while some policies are incredibly political, controversial, and evoke national partisan fights. These policy disagreements are primarily value driven, rather than by technical or analytic differences. ACF recognizes that because competing values and beliefs are at the heart of the policy agendas, understanding policy process demands scholars develop a good understanding of the political context of the problem being studied (Weible, 2006, p. 96). 4.6.2 Components of the Advocacy Coalition Framework Beliefs are a crucial concept in ACF, as individuals and coalitions compete in politics to turn their beliefs into implemented policy. In ACF, there are three types of fundamental beliefs (Pierce et al., 2017). Core beliefs are those that are so rooted in the individual that they are unlikely to change or be changed by external events. Core beliefs tend to be so broad that they are unlikely to provide precise rules for policy. Conversely, policy core beliefs are more likely to be changeable, and more likely to influence how an individual believes policy should be constructed. The third type, secondary aspect beliefs are far less important to the definition of the individual, and much more likely to shape their views on policy implementation, while being more easily shaped than the other types of belief by learning new information about a policy (Luxon, 2019). Individuals with shared belief systems are likely to be found together in coalitions, which form policy subsystems in ACF analysis. ACF treats policy subsystems as the unit of analysis. These subsystems are comprised of politicians, policy experts, advocates, and professionals. These subsystems are similar to the policy stream in the multiple streams framework (Kingdon, 1995), and in ACF the policy subsystem has within it coalitions of associated members all focused on a specific policy issue (Jenkins-Smith, Silva, Gupta, &amp; Ripberger, 2014). These coalitions are epistemic communities (Haas, 1989)  systems of shared belief and activity  and networks within the subsystem can cooperate or compete to bring their preferred policy solutions to the forefront during policy debates. Strong coalitions often dominate policy issues for long periods, and because ACF is concerned with policy cycles, the periods examined often stretch out a decade or more. Lawmakers, who are constrained in attention and time, often assign responsibility in a policy area to senior public administrators. In turn, these officials rely on the advice and consultation from policy subsystems and coalitions, which are framed as the experts in the area. Within a policy subsystem, coalitions compete in the policy space. In a pure hypothetical, Coalition A and Coalition B each has a preferred policy solution. Between the two coalitions is are policy brokers who are also part of the policy subsystem, and who work between coalitions and lawmakers. Each coalition has its own policy beliefs and resources to compete with the other with, and policy brokers help structure that competition. Eventually, a decision is taken by the governmental authority with jurisdiction over the policy space in question. The governmental decision has outcomes for new institutional rules (or removal of old rules), new resource allocations, and appointments to new institutional bodies. There are also policy outputs from the policy decision, which in turn lead to policy impacts. The new rules, resources, appointments, outputs, and impacts all exist in a feedback loop which in turn alter the existing coalition arrangements. In extreme cases, a policy coalition may cease to exist as the winning coalition solidifies itself as the dominant voice in the policy subsystem for years to come. More commonly, there is merely a shifting of resources and policy strategy among the advocacy groups which comprise the coalitions, and the game plays on. There are factors in the ACF framework outside of the policy subsystem, all of which have effects on the subsystems. There are relatively stable factors, reminiscent of the forces in punctuated equilibrium theory, which serve to produce a policy environment which favors the status quo against change. These stable parameters include the core and policy core beliefs of the policy actors, social values, the distribution of resources, the social structure in which the subsystems exist, and the core structures of the government (i.e., a constitutional democracy versus a communist state). The common theme of the stable factors is that they tend to be exogenous to the subsystem and other influencing factors. These stable factors influence the rest of the framework but tend not to be influenced themselves. Unlike the relatively stable factors, ACF also recognizes that there are endogenous factors which both significantly alter, and are altered by, the policy environment; these are events which are reminiscent of the shocks in punctuated equilibrium theory. These changes can include systemic changes in the governing coalition of a subsystem, socio-economic changes such as significant financial crises, sudden shifts in public opinion (such as those seen in the last decade on gay rights and marijuana legalization), and finally, decisions in other policy subsystems which have significant impact on the subsystem being analyzed. Rarely, like in punctuated equilibrium theory(Jones &amp; Baumgartner, 2012), these external events can be linked to a shift in the policy environment, most likely by providing a shift in the internal environment of the policy subsystem. An example of this can is seen in the policy environments following both World War I (a move towards US isolationism), WWII (a move towards international organizations to prevent widespread war), and the Great Depression (a move towards a social safety net). Also external to the policy subsystem are the opportunities for long-term coalitions to take advantage of. These opportunities are themselves influenced by the stable factors described earlier, but also directly affect how policy subsystems operate. These factors are related to the political systems in which policies are considered, such as the difference between divided party control of the executive and legislative branches of the US government. These factors will dictate whether, and how much, consensus is needed before a policy can be adopted. In broadly democratic political systems, the amount of consensus is relatively high compared to systems with politics which allow for a single governmental actor to take drastic policy action. The final structure in ACF theory to be considered are the short-term constraints in which policy subsystem actors operate. These constraints are affected by both the opportunities factors and the external events, but the constraints also operate directly upon the policy subsystem as well. For example, in a policy environment where there have recently been significant policy shifts, the coalitions within a policy subsystem are all constrained from further action as lawmakers turn their attention to other policy subsystems. 4.6.3 Conclusion ACF theory is considered to be the creation initially of Paul Sabatier, but upon his passing, the theory has been continuously refined and adapted to the policy realities of the different contexts within which it continues to be applied. ACF has proven remarkably resilient, as it maintains the flexibility of the policy process approaches that preceded it, while recognizing the feedback loops (Pierson, 2000; Soss &amp; Schram, 2007) which recognize and incorporate the influence of stability, shocks, constraints and opportunities in the policy environment, and political systems. A drawback of ACF theory is that it remains a difficult proposition to translate effectively for non-academic audiences, whereas multiple streams analysis and punctuated equilibrium theory both benefit from the ability for non-academic audiences to easily construct metaphors which illuminate policy problems. Relatedly, the majority of ACF applications are one-off studies by scholars who use the framework a single time on a single case of interest, often in the environmental policy area (Pierce et al., 2017). ACF scholarship would benefit from a sustained empirical study by scholars over multiple cases, and a broadening of the policy areas investigated. 4.7 Policy Process in Comparative Context 4.7.1 Why Comparative? While most of the policy process theories originated within the United States context, there is broad agreement that good policy study (emphasis in original) both is and should be comparative in application (Wilder, 2017, p. S47). There are a number of reasons why comparative applications of theory are broadly supported in social science research generally, and political science and public policy research specifically. Research methods texts justify comparative research in many ways (Halperin &amp; Heath, 2016; Singleton Jr &amp; Straits, 2018). Often the most important reason to engage research comparatively is as an exercise in theory testing. Comparative methods allow the researcher to test the extent a theory built upon cases in one context to be tested for generalizability in cases from a differing context. In policy studies, this point has interesting implications. First, as noted in an article (Cairney &amp; Jones, 2016) tracing the claimed impact of the multiple streams approach (Kingdon, 1995), the comparative context allows researchers to identify both universal and territorial contributions in a theory. When a theory is successful, as the authors argue multiple streams analysis (MSA) has been, it has universal aspects that apply without respect to culture or country. For example, MSAs focus on bounded rationality applies to humans, regardless of their cultural or national origins. This universality allows for MSA to be transported easily, and likely contributes to how widely it has been applied. At the same time, a good theory has territorial aspects which allow the theory to apply in specific contexts, such as authors who use MSA concepts to describe policymaking differences between types of national governments, or regional similarities in responses to policy problems. A second implication is increasingly seen in policy studies, and more broadly in public administration scholarship. Because the vast majority of public policy theory has been developed in the United States, and the remainder in predominantly Western nations, it is often an untested assumption that the theory will apply in very different cultures. An example of this is in applying the theory of emotional labor, which was first explicated by Hochschild (1983), an American scholar. The theory was then tested, refined, and built in the same US context, with some Europeans applications as the theory was broadened to the public sector (Guy, Newman, &amp; Mastracci, 2014). Still, until very recently the theory was not well tested in collectivist cultural contexts (Hofstede, Hofstede, &amp; Minkov, 2010). Testing the invariance of measurement across multiple Asian countries finds that while broadly applicable, the emotional labor model needs to be more carefully investigated in those contexts (Mastracci &amp; Adams, 2018). 4.7.2 The Comparative Turn &amp; Recent Examples The comparative turn in policy studies is well documented by Wilder (2017), who sees the domination by American political scientists as fomenting a reaction from non-US scholars in the form of network theories of the policy process (p. S50). Three of the four main policy theories  advocacy coalition framework, punctuated equilibrium theory, and multiple streams analysis  were developed to explain political behavior in the American institutional environment (p. S51). The other leading theory, Institutional Analysis and Development (IAD), developed by Elinor Ostrom (1990), has a metatheoretical orientation which helped transcend the constraints of the particular American political environment. Still, given the origins of the main policy process theories and frameworks, the majority of work in those theories tended to result in findings which were salient only in that same, or very similar, political context. The recognition of an American-centric bias in policy scholarship has led to a comparative turn in policy studies (Schlager &amp; Weible, 2013), and the literature in comparative public policy is voluminous and growing (Wilder, 2017, p. S56). This recognition has led to a sea change in the discipline, (Wilder, p. S59), as new theoretical work has generated approaches which find synergy between the positivist, post-positivist, and constructivist ontologies. Approaches such as the narrative policy framework (NPF) and social construction of target populations (SCTP) have moved beyond critiques of previous discourse analyses as unscientific by producing well-specified models with falsifiable hypotheses (DeLeon, 2005; Epstein, Farina, &amp; Heidt, 2014; Jones &amp; McBeth, 2010; Pierce et al., 2014). This has led to a resurgence of policy scholars willing to take ideas and discourse seriously (Schmidt, 2008, p. 304). This essay is too short to consider anything beyond a few examples of recent comparative work. An example of an applied comparative study is Fifer and Orrs (2013) study of the Yellowstone fires of 1988. The authors investigate how fire policy in both the United States and Canada differed, and attribute the differences to how the problem of wildland fires are defined in the two countries. Commonly understood as the first step in linear policy models, defining the problem is key to shaping which policy responses will even be considered in policy debates. In the US context, political forces interfered with science-based policymaking by defining wildland fire as a destructive force without ecological purpose (Fifer &amp; Orr, 2013, p. 651). However, in Canada, the fires were defined as a natural ecological phenomenon which, if interfered with through more logging and prescribed fires (as in the US), would result in even more negative outcomes. The findings from Fifer and Orr demonstrate the power of discourse, and more broadly, how comparative institutional differences lead to divergent policy interventions. A further example of public policy theory being applied comparatively is recent work by Jennifer Hadden (2018), who wants to know how advocacy coalitions make tactical choices. Hadden uses evidence from climate advocacy organizations in both the United States and Europe to build upon existing coalition theory. Using qualitative data drawn from interviews with environmental advocacy organizations, Hadden finds new variables for advocacy coalition scholars to include in future quantitative work. In this way, she demonstrates the value of both comparative policy work, and along the way makes a convincing case for the use of a plurality of methods in policy work generally. For instance, Hadden finds that the tactical choices of peers influence how actors make their own tactical choices. This suggests advocacy coalition studies should find ways to operationalize peer choices and their influence, a suggestion which hearkens back to policy network studies which were the first significant European response to the American policy study hegemony (Wilder, 2017). 4.8 Comparing and Combining Policy Theories The study of public policy proceeds under a relatively constrained number of accepted theoretical approaches. As of yet there is no single public policy theory, framework, or approach which is adequate to explaining all policy process (Cairney &amp; Heikkila, 2014), nor is a grand unifying theory of public policy likely given the complex human factors which are ever-present. This front half of this essay will highlight a set of criteria on which to attempt to compare policy theories, which otherwise are often difficult to compare given their varying focuses, definitions, and methods. The second half of the essay will discuss three approaches to using different theories  for synthesis, for comparison, and for competition. 4.8.1 Comparing Theories Cairney and Heikkila (2014, p. 363) aim to bring rigor to the process of comparing public policy theories. The authors are not seeking to identify the best theory. Rather, they are interested in identifying their key concepts, when and how each is particularly useful, and the extent to which the insights of different theories can be combined (Cairney &amp; Heikkila, 2014, p. 363). Perhaps most useful of these three goals is the effort to identify when and how the different theoretical approaches are most useful for researchers. While there are relatively few approaches, even the eight identified in the third edition of Sabatier and Weibles Theories of the Policy Process (2014) can be overwhelming. Each of the theories are complex and many scholars only use one approach for one or two studies, so learning to differentiate the approaches and identify which is most appropriate for a given subject is valuable. Even choosing which criterion to judge policy process theories can be difficult, given the very different concepts which each is most interested in explaining. For instance, where the punctuated equilibrium (PE) approach (Baumgartner et al., 2009; Jones &amp; Mortensen, 2018)is most interested in identifying when and why a theory changes (or remains the same), the social construction of target populations (SCTP) approach (Schneider &amp; Ingram, 1993)is focused on how different populations affected by a given policy are viewed by policy makers end up over- or under-advantaged. This lack of consistent focus and terminology is a major complication to any comparison attempt. Cairney and Heikkila (2014, fig. 10.1) choose to use five criterion in their comparison of the elements of each theory: (1) scope and levels of analysis; (2) shared vocabulary and defined concepts; (3) assumptions; (4) model of the individual; and (5) relationships among key concepts. Using these elements allows a researcher to identify the most promising theoretical approach for a given study subject. For example, a researcher whos research question is related to attention and framing might find that PE theory most appropriate, with its model of the individual more focused on individuals attention than other approaches. Alternatively, a research question which is more explicitly interested in values, emotion, and heuristics could use the five criterion to investigate and find that SCTP theory is more appropriate given its model of the individual. However, while selection of an appropriate model is a necessary first step for policy scholars, there is also the pretty standard advice (Sabatier, 1999, p. 330) that scholars combine, compare, and contrast their primary theoretical focus with multiple theories. This advice is convered in more detail in the next section. 4.8.2 Combining Theory There are three main reasons to engage with multiple policy process theories in the study of a subject of interest (Cairney, 2013). First is the goal of synthesis, in which the insights from separate theories are combined into a more explanatory theory. A second goal is to complement a primary analysis with insights from another approach, in order to shore up areas in which the primary approach is not as able to offer understanding. The third primary motivation for using multiple theories is to introduce contradictory explanations in policy studies. This last may also be understood as an attempt to falsify the claims, particularly the causal claims, offered by the primary theoretical approach. The goal of synthesis is difficult to attain in policy process studies, for the reasons articulated in the first section of the essay. Most of the policy process approaches are ridden with incomparable concepts, scopes, models of human cognition, or even broad goals of what is important to explain (Cairney &amp; Heikkila, 2014). Peter John(2003, 2013) identifies five aspects of policymaking that interact in complex ways to make processes within it difficult to study: the role of institutions in structuring behavior; policy subsystems; external factors; the choices of actors in policymaking; and beliefs of actors which guide their choices. Synthesis is possible in the policy process context, John argues, because the mainline theories attempt to address these five areas, but none is adequate on its own to do so. However, one critique of the synthetic approach is that although the varying theories often use similar phrases, people may attach different meanings to key terms (Cairney, 2013, p. 7). The second common goal in combining policy theory is the complementary approach. This approach is less concerned with providing alternatives for hypothesis testing, and more interested in bringing different lenses to an empirical case. In doing so, the hope is that the researcher can broaden how a case is understood by showing how competing theories explain what has occurred. The complementary approach leverages the differences that are a weakness in the synthetic approach, because the differing worldviews can produce different answers to the same question and prompt us to seek evidence that we would not otherwise uncover (Cairney, 2013, p. 8). However, in practice the complementary goal can be quite difficult for two reasons. First, due to the varying concepts in the different approaches, constructing an adequate research design is difficult. Related to that difficulty, the second obstacle is that many studies which purport to use a complementary approach do not actually engage the theories at a deep level. Instead, they use a more manageable, and superficial, proxy for theoretical comparison (Cairney, 2013, p. 9). When this occurs, the lessons drawn from the proxy are less satisfactory. Given the realities of constrained research resources most academics confront, it is simply impractical to expect a full-fledged application of multiple policy process theories, which are often so complex that even engaging in one approach fully is difficult, and many papers only use a subsection of one. The third approach to using multiple policy process theories is a contradictory approach. This approach is closest to what Paul Sabatiers (1999, p. 330) aim in giving pretty standard advice to policy researchers, and reflects his relatively strict interpretation (or post-positivist, depending on the view) of what makes good theory. Namely, by using alternative, competing theories we are able to falsify the claims of theories, and secondarily can make the researcher more aware of the assumptions built into a policy theory. 4.8.3 Conclusion Scholars will generally broadly agree that any of the three aims of using multiple theories in studies is a beneficial goal. Sabatier(1999, pp. 321322) laid out his vision of what makes good policy theory, principles which are widely endorsed by other scholars (King, Keohane, &amp; Verba, 1994). These principles are that: (1) the theory should be coherent so other scholars are able to test any findings; (2) the causal claims, drivers, and processes should be clear; (3) propositions should be falsifiable; (4) the scope of the theory should be relatively broad; (5) the theory should generate non-obvious findings (p. 12) and each assumption should give rise to (at least) several predictions. However, Paul Cairney (2013, pp. 1012) identifies at least five complications to basing scholarship on those principles. First, despite widespread acceptance of the goal of using multiple theories, few researchers actually do so. Second, most of the reason for the support for using multiple theories is because it helps scholars weight claims made from repeated replication studies  but most social research relies on trust, reputation, and peer review rather than intense replication. Third, even when multiple policy theories are engaged, outside of the primary theoretical focus most researchers rely on proxies rather than full engagement with competing or complementary theories. Fourth, the complexity of the policy process is so immense that true falsification may not even be possible. Finally, the fifth obstacle to such pure research is that few social science projects adhere closely to all five goals as described by Sabatier, because social science research is more of a social product of the academic environment than the sterile proclamations issued by academia on what constitutes good research. 4.9 Five Policy Theories There are a lot of potential generic policy framework questions, but as a very broad example consider the following three questions that might be answered with the following short essay: A number of frameworks have been used to analyze the process and outcomes of American public policy. Among these frameworks are elitism, pluralism, neopluralism, incrementalism, feminism, subgovernments, policy process models, issue networks, advocacy coalitions, and others. Identify two frameworks that you regard as especially useful for the study of public policy. For each, explain how the framework approaches the study of public policy and evaluate its strengths and weaknesses as tool for understanding the process and substance of public policy. Scholars make use of frameworks, theories, and models in their attempts to explain the politics of policy-making processes and the collective authoritative public choices that come from them. Distinguish among these three approaches to empirical inquiry, and discuss how they are interrelated, if at all; then describe the extent to which researchers have improved our understanding by applying them to specific substantive areas of public policy. Imagine that you have a representative sample of Americans captive for a single lecture on public policy. What are they least likely to know about public policy making and implementation? What would be most important to communicate to them? Choose two different policy areas in your answer and support your decisions about what to emphasize with references to the public policy literature. The following bits got used a lot in both my American and Public Administration exams. In fact, they may have been the most useful pre-writing I ended up doing. One lesson: concentrate on covering different theories in some depth. They are easy to drop into a variety of contexts. That is, after all, one of the goals of a good theory. 4.9.1 Five Policy Theories Compared Ideally, policy process theories help make sense of what appears from the outside to be an inexplicably complex process. Theory helps us identify when policy change occurs, or when the status quo prevails. It identifies factors which propel a policy proposal forward or cause it to stall. A mature theory can help citizens, practitioners, and scholars understand how to use those factors to participate in the policy process themselves, and advocate for their desired policy outcomes (Stone, 2002). Policy studies are essential to political science because they are intimately related to politics  or as Lowi (1972) described, the way in which we find (p. 299) policy conditions underlying our political patterns and how (p. 209) policies determine politics. This essay will cover five main theoretic approaches to public policy and is structured to move somewhat temporally as well. It begins with the oldest and still most commonly understood policy process theory, the linear policy process. Following the rejection of the assumptions of the linear process (Cohen, March, &amp; Olsen, 1972) came punctuated equilibrium (PE) theory, which still retained some linear elements but moved away from the incrementalist predictions of the linear theory. The third theory, multiple streams analysis (MSA) helped explain the significant policy shifts in punctuated equilibrium theory but added theoretical flexibility which gave it greater explanatory power for understanding why some policies are adopted, while others lay fallow. While MSA has proven popular for its parsimony and flexibility, some scholars have long complained it lacks the ability to explain process in the many different contexts in which policy is found. The fourth theory, advocacy coalition framework (ACF), takes many concepts from the MSA framework, but trades parsimony for greater explanatory power. Finally, the essay concludes with a synopsis of social construction of target populations (SCTP) theory. SCTP theory doesnt attempt to explain everything in the policy process but instead deconstructs the language and assumptions of policy actors which then are used to justify actions which have inequitable consequences for different populations affected by the policy. 4.9.2 The Linear Policy Process The development of non-linear policy process theory is a relatively recent development, and the linear process model remains the most common way of thinking about how policy is developed outside policy studies. The linear policy process is the natural outgrowth of applying the most simplistic rational choice assumptions to policy. In policy studies, the theories that come after the linear process, and its assumptions, are reacting to it. Linear policy process theory makes assumptions about the people involved in the process which are rooted in rational choice assumptions. It sees people as self-interested beings who have ordered preferences (preferring one option over another), and that those preferences are stable. It assumes that the individual has no mental, emotional, or cognitive deficiencies which would hamper their ability to make choices in their own best interest. It assumes that the individual is capable of knowing all information related to the choice before them, and thus is able to make a reasoned decision about the which option to select, with the predicted choice being the one which maximizes the individuals benefit while minimizing the cost. The most common linear model holds that there are a series of steps to the policy process. First, a problem is recognized; (2) actors work to define the problem carefully, and in particular the root cause of the problem; (3) a number of policy options which would address the problem are conceived; (4) the options are evaluated for costs, benefits, and likelihood of success, and the best option is adopted; (5) the chosen policy is implemented; (6) following implementation, the policy is occasionally evaluated for success or failure, and modified accordingly. The linear process was never useful as a predictive model of policymaking, and the Garbage Can Model of policy (Cohen et al., 1972) takes the opposite assumptions, and successfully challenged rational choice as an appropriate set of assumptions for policy theorists. The Garbage Can model explains the policy process as inherently chaotic and unpredictable, a mix of problems, ideas, technology, and solutions, all flowing around in an amorphous soup, from which a policy eventually congeals when the right components interact with one another. While Garbage Can modeling has not proven useful as a theoretical framework in the long-run, it is important for the theories it inspired, particularly multiple streams analysis (Kingdon, 1995; Zahariadis, 2014) and the advocacy coalition framework (Sabatier &amp; Weible, 2007). 4.9.3 Punctuated Equilibrium Punctuated equilibrium (PE) (Baumgartner &amp; Jones, 2009; True, Jones, &amp; Baumgartner, 1999) is a policy theory which borrows from biological science to describe long periods of policy status quo, suddenly interrupted by significant shifts in the policy landscape. Baumgartner and Jones recognized that the slow incremental policy changes predicted by the base linear policy model were not reflected in the empirical policy evidence. Rather than slow, steady policy progress, they saw long periods of policy stability which were then suddenly disrupted by sharp changes in short periods of instability. This, to the authors, seemed to reflect the sudden evolutionary adaptations seen in the biological sciences, as species maintain long periods of stability, with sudden natural adaptations (Gersick, 1991; Gould &amp; Eldredge, 1977). Though more useful than its simplistic predecessor, PE is still at its root a theory of linear change, though with generally more relaxed assumptions about the rational nature of the individuals involved. For instance, PE assumes that people are boundedly rational (Simon, 1976) rather than perfectly so. Similarly, PE recognizes that policymakers have limited attention capacity, and cannot know everything about a policy issue. Another critical concept in PE is that of framing (Zaller, 1991; 1992), which groups use to define how a policy problem is understood, in order to better position their preferred policy solution. Similar to both multiple streams theory and advocacy coalition framework, the PE framework attempts to understand how policy groups operate to bring about policy change. PE uses concepts such as agenda setting, policy monopolies, and venue shopping to explain how these groups overcome the natural tendency towards stability and continuity in the policy environment. With agenda setting, groups make strategic choices about how much attention to bring to their preferred policy solutions. If they worry that attention will risk derailing the policy they will work to minimize attention, while at other times, particularly with lawmakers reluctant to pay attention, the policy groups actively manage attention around a policy problem and solution in order to generate political momentum. Policy monopolies, which are reminiscent of the iron triangles of earlier policy studies (Jordan, 1981) develop in specific policy areas, and like in advocacy coalition framework (Sabatier &amp; Weible, 2014), these monopolies can persist for long periods of time, as they work to continue passing policy which reinforces their access to resources and thus policy influence. The answer to policy groups which are locked out of a policy monopoly is what Baumgartner and Jones (Baumgartner &amp; Jones, 2009) refer to as venue shopping. If a group is locked out of the legislative policy arena, for instance, they may choose to change venues and begin looking for ways to pass their preferred policies at the executive or judicial levels of government. Punctuated equilibrium policy theory was developed in the United States, and it provided a useful explanation of empirical policy changes there. Early use of PE theory (Baumgartner &amp; Jones, 1993; 2010) was used to explain US nuclear policy, which existed mostly out of public sight in the post-war period. Following decades of that stability, where the policy was primarily left to technical experts and legislative subcommittees, anti-nuclear power advocates were successful in challenging the positive image of the nuclear industry, and venue shopped their policy ideas to courts and the public. The existing policy monopoly was broken, and heavy regulation of the nuclear industry effectively halted the expansion that had been seen in the post-WWII period. The US government is structured in a divided power arrangement, which tended to reinforce status quo arrangements, and was seen as responsible for the periods of policy stability. However, the PE theory has been usefully applied in non-US contexts as well. A comparative study of policy regimes in the US, Denmark, and Belgium (Baumgartner et al., 2009, p. 615) using data from dozens of processes across three nations and covering hundreds of thousands of observations found the same non-normal distribution of policy inputs and effects. This study provides strong evidence that it is not necessarily the US constitutional system which is providing friction in policy development and thus favoring status quo. While all three countries in the study are democracies, there are enough structural differences to suggest that a General Punctuation Hypothesis can be applied in comparative contexts. Punctuated equilibrium theory is robust and takes its place, alongside multiple streams analysis and advocacy coalition framework, as one of the most cited and useful modern theories of the policy process. It provides a framework that allows even non-scholars to immediately connect with the relatively simple idea  things tend to stay the same, until they do not. At the same time, it has enough complexity and flexibility to be adopted in varied political contexts. 4.9.4 Multiple Streams Analysis The appeal of the linear policy process theory has been its simplistic, straight path construction of policy development. However, scholars have long recognized that the linear process is far more normative than descriptive. John Kingdon attempted to lay out a more realistic, descriptive model (Kingdon, 1995), in what is known as Multiple Streams Analysis (MSA). While on the surface MSA has similarities to punctuated equilibrium theory (Baumgartner &amp; Jones, 2009), it does differ in its departure from the linear process assumptions which punctuated equilibrium held. MSA takes the path between the utter chaos of the garbage can and the too-linear punctuated equilibrium frameworks, and in doing so presents a more compelling theoretical structure than either. MSA recognizes that policy is complex, like the social problems it attempts to address. Ambiguity is at the heart of why policy is so difficult to study (Zahariadis, 2014), because policy actors can never really know the root cause of a social problem, and even problem definition  the start of the linear process model  is ultimately a contestable, political step. Rather than assume policy actors are purely rational beings, MSA holds that humans are boundedly rational (Simon, 1976), and so operate with limited information capacity, selective attention, and imperfect cognition. Further, there are significant time constraints which limit the ability of policy makers to ever know enough, let alone know all the facts that perfect decision making would require. In the end, MSA seeks to answer the question: In a universe of nearly limitless policy problems and solutions, how do the relatively few new policies rise above the rest? MSA is one of the most cited academic theories of the policy process and key influence on the study of public policy (Cairney &amp; Jones, 2016, p. 1) with over 12,000 citations as of 2015. The appeal of Kingdons framework lies in its flexibility. MSA posits three streams in the policy process  the problem, political, and policy streams. How these three streams come together, or fail to, is a useful structure for thinking about why certain policies are implemented, while other, similarly good policies, fail. Understanding the three streams is key to understanding MSA. While the streams are discussed in a certain order here (problem/political/policy), in practice the analysis is much more about how the streams interact than about their temporal order. In the problem stream, attention is paid to how attention is gathered around a policy problem. Attention in this frame can be mean many things, none of which are necessarily objective indicators. Attention might be statistical information which point to a problem, or in some cases a crisis gathers immediate and widespread attention to a problem. Problems exist whether or not attention is being paid to them, and MSA recognizes that policy makers are only ever paying attention to a very small number of the universe of problems which they could be minding. The political stream refers to the many people, advocacy groups, and political bodies such as legislatures, interested and involved in policy making. The partisan composition of a US Congress, for example, will have an impact on whether or not a policy solution which is perceived as increasing tax burdens has any chance of being implemented. Similarly, the national mood in the wake of a financial crisis must be considered when considering whether complex regulatory policy might be implemented. The political stream is about the actors who must pay attention to a problem, and possible solutions, before a policy can be implemented. During some time periods, the political stream dictates that some problems in the problem stream wont gather attentions, while ideas from the policy stream wont be considered. In the US context, periods of divided government, when one party controls Congress while the other party controls the presidency, are predicted to have relatively little policy movement. Conversely, periods where one-party controls both the executive and legislative functions are predicted to have a better chance of implementing larger policy changes. The policy stream is described as a policy primeval soup by Kingdon, where potential policy ideas from a variety of policy actors conceive of potential policy ideas in policy communities. At any point in time, the policy stream contains a large number of possible policy solutions, but not all of them are feasible, supported, or available. While a policy idea may originate with a single actor, the ideas change as they are exposed to and considered by other actors in the policy stream. The ideas that eventually become policy are the result of a large number of participants modifying the original idea, and is often a much wider solution than the original, narrower solution. Some of these actors are so-called policy entrepreneurs who recognize an opportunity to insert their own policy solutions into one which is gaining support. Policy entrepreneurs are important to MSA. These are the people and organizations who recognize that the politics and policy streams are often not in sync. A policy entrepreneur waits for, and recognizes, when the two streams offer an opportunity for their preferred policy idea to be implemented. These policy ideas are developed before the actual streams coincide, and the preferred policy is offered as a solution to a problem which has garnered attention. At the same time, these policy entrepreneurs will work to bring the streams together, for example by attempting to bring greater attention to a problem while the politics stream is perceived as favorable to their already developed policy solution. Metaphors to think about the stream process in MSA are numerous (Cairney &amp; Zahariadis, 2016), and that flexibility has been key to its success. Some think of the streams as literal rivers, which once mixed or merged, are difficult to unentangle. Kingdon himself suggests a space launch metaphor in which all factors must be perfect for launch, implying that policy makers will abort a policy before implementation if all the factors in the streams are not ideal. MSA assumes that when the problem, policy, and political streams come together, there is opportunity for policy change, but most of the time the streams are not in synchrony. Policy entrepreneurs are thus critical to policy change, as they work to align timing in the streams to create the window of opportunity for their preferred policy change. They work to gather critical mass attention to a problem, so that a solution is demanded. They work with other policy actors in the policy stream to develop their preferred solution to the identified problem. They work to shift the political landscape so that policy and law makers are persuaded to adopt their solution. In the end, the flexibility of the MSA metaphor, and the relatively low barrier-to-entry for scholars to understand policy through the MSA framework has made it one of the most popular and useful ways to examine policy (Cairney &amp; Jones, 2016). The ease of use of MSA, and the associated limited empirical usefulness, will stand in stark contrast to the advocacy coalition framework (Sabatier &amp; Weible, 2007). 4.9.5 Advocacy Coalition Framework The advocacy coalition framework (ACF) was developed by Paul Sabatier and Hank Jenkins-Smith (Sabatier, 1988; Sabatier &amp; Jenkins-Smith, 1993), and from the beginning has been defined by defining the role of belief systems in the policy process, especially their role in shaping policy-oriented learning. The most complex of the mainline policy theories covered in this essay, ACF attempts to develop a holistic theory of policymaking. Because it is designed to be applicable across a variety of policy contexts, and because it assumes that each policy environment is inherently complex, the ACF framework is itself quite complex. In the ACF framework, policymaking takes place in a complicated environment which contains multiple actors across multiple levels of government (Weible, Sabatier, &amp; McQueen, 2009). Policymakers have very high levels of uncertainty, and their decisions are always made with inherent ambiguity. Policy decisions take years to produce policy outcomes, and those outcomes are difficult to ascertain with any certainty. ACF recognizes that there are also different types of policies at play, with some policies being fairly straightforward, others being very technical and complex and done outside public notice, while some policies are incredibly political, controversial, and evoke national partisan fights. Beliefs are a key concept in ACF, as individuals and coalitions compete in politics to turn their beliefs into implemented policy. In ACF, there are three types of basic beliefs. Core beliefs are those that are so rooted in the individual that they are unlikely to change, or be changed by external events. Core beliefs tend to be so broad that they are unlikely to provide meticulous rules for policy. Conversely, policy core beliefs are more likely to be changeable, and more likely to influence how an individual believes policy should be constructed. The third type, secondary aspect beliefs are far less important to the definition of the individual, and much more likely to shape their views on policy implementation, while being more easily shaped than the other types of belief by learning new information about a policy. Individuals with shared belief systems are likely to be found together in coalitions, which form policy subsystems in ACF analysis. ACF treats policy subsystems as the unit of analysis. These subsystems are comprised of politicians, policy experts, advocates, and professionals. These subsystems are similar to the policy stream in the multiple streams framework (Kingdon, 1995), and in ACF the policy subsystem has within it coalitions of associated members all focused on a specific policy issue. These coalitions are epistemic communities (Haas, 1989)  systems of shared belief and activity  and networks within the subsystem can cooperate or compete to bring their preferred policy solutions to the forefront during policy debates. Strong coalitions often dominate policy issues for long periods of time, and because ACF is concerned with policy cycles, the periods examined often stretch out a decade or more. Law makers, who are constrained in attention and time, often assign responsibility in a policy area to senior public administrators, who in turn rely on the advice and consultation from policy subsystems, who are framed as the experts in the area. Within a policy subsystem, coalitions compete in the policy space. In a simple hypothetical, Coalition A and Coalition B each have a preferred policy solution. Between the two coalitions is are policy brokers who are also part of the policy subsystem, and who work between coalitions and lawmakers. Each coalition has its own policy beliefs and resources to compete with the other with, and policy brokers help structure that competition. Eventually, a decision is taken by the governmental authority with jurisdiction in the policy space at question. The governmental decision has outcomes for new institutional rules (or removal of old rules), new resource allocations, and appointments to new institutional bodies. There are also policy outputs from the policy decision, which in turn lead to policy impacts. The new rules, resources, appointments, outputs, and impacts all exist in a feedback loop which in turn alter the existing coalition arrangements. In extreme cases, a policy coalition may cease to exist as the winning coalition solidifies itself as the dominant voice in the policy subsystem for years to come. More commonly, there is simply a shifting of resources and policy strategy among the advocacy groups which comprise the coalitions, and the game plays on. There are factors in the ACF framework outside of the policy subsystem, all of which have effects on the subsystems. There are relatively stable factors, reminiscent of the forces in punctuated equilibrium theory, which serve to produce a policy environment which favors the status quo against change. These stable parameters include the core and policy core beliefs of the policy actors, social values, the distribution of resources, the social structure in which the subsystems exist, and the core structures of the government (i.e. a constitutional democracy versus a communist state). The common theme of the stable factors is they tend to be exogenous to the subsystem and other influencing factors. These stable factors influence the rest of the framework, but tend not to be influenced themselves. Unlike the relatively stable factors, ACF also recognizes that there are endogenous factors which both significantly alter, and are altered by, the policy environment; these are events which are reminiscent of the shocks in punctuated equilibrium theory. These changes can include systemic changes in the governing coalition of a subsystem, socio-economic changes such as large financial crises, sudden shifts in public opinion (such as those seen in the last decade on gay rights and marijuana legalization), and finally, decisions in other policy subsystems which have large impact on the subsystem being analyzed. Rarely, like in punctuated equilibrium theory, these external events can be linked to a very large shift in the policy environment, most likely by providing a shift in the internal environment of the policy subsystem. An example of this can be seen in the policy environments following both World War I (a move towards US isolationism), WWII (a move towards international organizations to prevent widespread war), and the Great Depression (a move towards a social safety net). Also external to the policy subsystem are the opportunities for long-term coalitions to take advantage of. These opportunities are themselves influenced by the stable factors described earlier, but also directly affect how policy subsystems operate. These factors are related to the political systems in which policies are considered, such as the difference between divided party control of the executive and legislative branches of the US government. These factors will dictate whether, and how much, consensus is needed before a policy can be adopted. In broadly democratic political systems, the amount of consensus is relatively high compared to systems with politics which allow for a single governmental actor to take drastic policy action. The final structure in ACF theory to be considered are the short-term constraints in which policy subsystem actors operate. These constraints are affected by both the opportunities factors and the external events, but the constraints also operate directly upon the policy subsystem as well. For example, in a policy environment where there has recently been significant policy shifts, the coalitions within a policy subsystem are all constrained from further action as law makers turn their attention to other policy subsystems. ACF theory is considered to be the creation initially of Paul Sabatier, but upon his passing the theory has been continuously refined and adapted to the policy realities of the different contexts within which it continues to be applied. ACF has proven remarkably resilient, as it maintains the theoretical flexibility of the theory systems that preceded it, while recognizing the feedback loops (Soss &amp; Schram, 2007) which recognize and incorporate the influence of stability, shocks, constraints and opportunities in the policy environment, and political systems. The drawback of ACF theory is that it remains a difficult proposition to translate effectively for non-academic audiences, whereas multiple streams analysis and punctuated equilibrium theory both benefit from the ability for non-academic audiences to easily construct metaphors which illuminate policy problems. 4.9.6 Social Construction of Target Populations To this point, this essay has concentrated on the large theories and frameworks, which all aim to explain the policy process as a whole. This proves to be a difficult goal for policy theory to meet, given the extreme complexity in policy types, political environments, and even policy problems. However, not all theory must be so comprehensive, and in some ways theories with more restricted aims, like the social construction of target populations (SCTP), are more able to give clear theoretical explanations coupled with the ability to offer predictive and empirical power, because they examine smaller pieces of the larger policy environment. SCTP was first developed by Schneider and Ingram (1993), and defeats another assumption of the linear process, that policy makers, and policy itself, are neutral or unbiased actors. Their argument is not itself post-modern, but builds on post-modernist critiques of language which deconstruct the power relationships inherent in language (Foucault, 1991, 2005; Yanow, 2003). Foucauldian discourse analysis has been effectively used by researchers to understand how different approaches to language contain critical assumptions about how changes in policy relate to broader social change (Sharp &amp; Richardson, 2001, p. 193). The central role of language in policy debates (Schmidt, 2000) reflects how important language is to the human experience more generally: The limits of my language mean the limits of my world, (Wittgenstein, 2013, pt. 5.6). Schneider and Ingram show that elected policy makers adopt value judgements about the social groups which are impacted by policy programs, and that those value judgements have an impact on the policies they create and implement. In this framing of political statements, some politicians will for instance, use language which implies that individuals living in poverty are lazy and have created their own situation, that may justify policies which withhold government benefits from that group. But just as language can justify under benefitting certain social classes, it can also over-benefit others. The same politician may use language which confers noble, worthy qualities on business owners, which would then serve to justify policies which shift resources to that social class. Moreover, this type of construction is not limited only to politicians, and front-line, street-level bureaucrats (Lipsky, 1983). Police officers and teachers have been found to construct their own identities of the citizens they serve, sometimes to the detriment of those citizens (Maynard-Moody, Musheno, &amp; Musheno, 2003). Construction of target populations is not as simple as positive and negative populations though in the SCTP theory, and Schneider and Ingram illustrate this (1993, p. 336) through their use of a two-axis notional figure, where measures of positive and negative constructions are paired with high and low perceived power constructions. Power in this use is the ability of a social group to accept or reject the image painted onto them. This gives a four-category scheme of advantaged (high power/positive), contenders (high power/negative), dependents (low power/positive), and deviants (low power/negative) social groups. These simplistic categorizations of complex populations make it easier for politicians and governments to implement policies which over-benefit the advantaged, while making it extremely difficult for deviant populations to even challenge their disadvantaged status in policy debates. This creates a policy feedback loop, as an advantaged group like homeowners not only are over-benefitted in terms of resources granted by policy, but then are able to reify their position in the social hierarchy, leaving to more opportunity to implement even more policies which will benefit them. This creates asymmetries of participation and power, and those asymmetries are reinforced by the system creating and accepting social constructions of the deserving and undeserving. This flaw in the system has long been recognized in political studies (Schattschneider, 1960; Schlozman, 1984), but SCTP offers a useful empirical starting point for understanding how particular social groups have been affected by policy choices influenced by social construction. One of the most powerful critiques offered by SCTP is showing how these constructed beliefs about social classes not only has immediate effects on resource allocation, but has effects on those social classes long after the policy maker has left office. This phenomenon is known as a feed-forward effect, or in other literatures as path dependence (Pierson, 2000). Path dependence recognizes that the timing of policy choices matters, and policy makers select policies which have self-reinforcing feedback processes (Soss &amp; Schram, 2007). These processes represent the resiliency of institutions which are far longer lived than the policy makers tenure (Sanders, 2006). Path dependency imposes a cost to going back to a previous point, and the longer a policy scheme has lived, the higher the cost. In this way, earlier choices have greater impact than later ones, as the policies themselves shape the institutions which house the policies (Mettler, 2002). SCTP offers a compelling critique of policy studies itself, as it uncovers how the language involved in policy can compel certain beliefs and narratives which can hinder, harm, or help certain classes of individuals (Sharp &amp; Richardson, 2001), even as policy scholars unthinkingly use the same language. Further, SCTP critiques the underlying, formative ideals of early public administration and political science, that of the neutral and unbiased bureaucrat, or public administration scholar. From the founding of the American political system, the ideal of competing factions balancing the power of any one faction (Dahl, 1982; Madison, 1787) has provided powerful argument that the US constitution and division of power among the federal branches would protect minority interests from the powerful machinations of the majority. However, the justifications of the pluralist federalist system was largely imputed by Madison and Hamilton into the Federalist Papers in a post-hoc manner intended to justify ratification of the US Constitution (Peterson, 2012). VO Key (1963) was ahead of his time in noting the effects of sectionalist national politics on state politics and parties, noting that national political tides spill into local politics. Party cleavages at the national level are projected into state elections, with the national party need to retain control used to justify the racist practices of the Southern Democrats of Keys time. This can reduce the incentive for local and state politicians to perform well, as they justify their control  and pardon their own structurally biased practices  in the name of national party priorities. So, rather than the administrative and policy state providing an intricate balancing wheel (Madison, 1787; Rohr, 1986) against the predations of a majority, at least in some cases SCTP theory allows us to see how policy and law makers are able to use the concealed power of language to prolong and protect the interests of the already powerful. One limit of SCTP is that it is less concerned with comprehensive theoretical explanations of policy process, and so in cases where there are not clear-cut social classes at play, SCTP may be less useful. A second limit is that, at least in the original construction of the theory, there is little said about how social classes might contest how theyve been constructed by policy makers and the public. SCTP has little to say about how, or more importantly why, one social group may attempt to help challenge the social construction of a less powerful one. Why for instance, would a feminist group  hypothetically located as a challenger in SCTP  want to help restore the voting rights of an ex-prisoner class? SCTP still has buried assumptions of rational choice, presenting the actions of the powerful as merely, or purely, self-interested. A final limit of early SCTP theory was a lack of direction  what should individuals and advocates do with this knowledge. That critique has been substantially, though not wholly, blunted as more researchers have become interested in critical policy theories, and extended the original insights into examining the ill effects of economic policy concentrated on women and blacks (Andersen, 2001), food justice (Billings &amp; Cabbil, 2011), and Native American school children (Quijada Cerecer, 2013). 4.9.7 Conclusion Good theory is portable  it can be carried across contexts, and when contexts differtheory is required to generalize from one to another (Coppock, 2018, p. 11). Kingdons multiple streams framework allows for the identification of universal concepts (Cairney &amp; Jones, 2016) which can be applied in multiple contexts. However, critics of MSA have pointed out that while MSA has contributed greatly to the theoretical literature, it has had relatively less impact in empirical studies. Kingdon developed MSA in the US context with case studies of policymaking at the federal level, and that has limited application of the framework in the international context. Recent work linking the streams framework of MSA with the stages analysis of the advocacy coalition framework (Howlett, McConnell, &amp; Perl, 2017) shows a path forwards for researchers who want a more robust system for analyzing policy, particularly in the comparative policy literature. Howlett and his colleagues formulate a five-stream framework, adding a program stream and a process stream, all of which proceeds along the traditional linear policy stage path. Though too soon to judge whether such a combined model will prove any more useful in both theoretical and empirical  and it must, given the additional complexity the model has compared to more parsimonious models  there is at least an attempt to synthesize the main policy theories, most of which are at least several decades old. At this time in policy studies, the advocacy coalition framework is still the most flexible and explanatory theory available, and though far from perfect, allows for a broad examination of policy in many contexts. The adaptability of the ACF framework means it can fold in even critical theory insights, which by themselves do not produce a fully satisfactory explanation of how policy is conceived, adopted, and implemented. 4.10 Institutional Analysis and Development Framework Common pool resources are those for which the exclusion of users is difficult (referred to as excludability), and the use of such a resource by one user decreases resource benefits for other users (referred to as subtractability) (Heikkila &amp; Carter, 2017). Some typical common pool resources are fisheries, water systems, wildlife, and forests. Prior to Elinor Ostroms Governing the Commons (Ostrom, 2015), most policy analysis was done using assumptions borrowed from rational choice theories. Ostroms (1999, 2011) Institutional Analysis and Development framework is one approach to the policy process that retains rational economic assumptions about policy choice, while focusing on the institutional environments that allow for management of common pool resources. Unchecked and unexamined, rational choice assumptions can lead to a conclusion that disastrous collective action problems are unavoidable when confronting common pool resources. The rational man, formally modeled as homo economicus, assumes that a person has full information about a problem, well-ordered preferences, and will always act to maximize the net value returned to them among alternatives (Aaron, 1994; Olson, 1965; Ostrom, 2011). This situation results from an inability to effectively manage common pool resources, as actors all rationally act in their own best interest. Where a resource is non-excludable and subtractable, this often leaves the resource degraded for all users. When self-interested actors take what they can without regard to the other actors, degradation such as rain forest depletion and troubling reductions in fisheries can result. The pure rational choice approach to common resource pools can give rise to the tragedy of the commons, (Hardin, 1968). Hardins argument was directed at breeding rights as a common pool resource, with a Malthusian critique that those who overuse breeding rights will drive the human race towards extinction. People who recognize the danger will choose not to have children, while those without a conscience will continue to have larger and larger families, unfairly drawing on the breeding resource. This rational choice conundrum can only be solved, Hardin argues, by government regulation of breeding rights. Ostrom takes on the tragedy of the commons, and the rational choice games which too uncritically give rise to it. The assumptions of rational choice games are too bleak and too uncritical. People often do act cooperatively, and work to govern collective resources. Ostrom developed the Institutional Analysis and Development (IAD framework to give a common scholarly language and approach for researchers interested in studying policy approaches to common resource problems. 4.10.1 Elements What allows some communities to effectively manage their common pool resources? Ostroms IAD offers a set of eight design principles that help analysts parse why some common pool resources (CPR) are effectively managed, while others are not. While Ostrom emphasizes that there are not hard and fast rules which will define success in every CPR context, the design principles provide an adequate starting point for policy analysts. The design principles are (1) CPRs are confined, with users able to define the resource being managed as well as legitimate users of the resource; (2) CPRs have rules which define how much a user can have as well as what a user is expected to contribute; (3) Rules are influenced by the users who are affected by them; (4) CPR are governed by monitors who watch user conduct and the state of the CPR; users are often monitors, or at least in charge of monitoring the monitors, keeping costs low and consequences swift; (5) Consequences for rule breaking can be low or high depending on pattern of conduct and outcomes of the rule-breaking  higher costs equate to higher consequences for the rule breaker; (6) Mutual monitoring means conflict is routine, but resolution normally low cost and rapid; (7) CPR users can self-organize unrestricted by outside impediment; (8) CPRs are often connected across different geographic and political contexts, but in a way that does not undermine individual projects. Communities which are able to structure self-governing of CPRs with the eight design principles are able to overcome the tragedy of the commons, Ostrom argues, because users become mutually committed to avoiding rule breaking, conserving the resource, and managing the long-term resource. However, three major complications can undermine even the best designed plans  trust, rules, and complexity. Trust between users is crucial because it keeps monitoring and rule enforcement low. While simple rules are key to design, there is often a proliferation of rules, rules about rules, and norms. Different types of rules need to be analyzed for costs and benefits, otherwise rules themselves can become a source of strategic conflict between users seeking maximum benefits. Complexity is a related concern, and because CPRs are often complex systems there can be a tendency to develop complex designs. When the design of a CPR management scheme becomes too complex, however, some users can become overwhelmed by the costs of compliance, while other users leverage the complexity to engage in rule sanctioned behavior that would otherwise be considered to be against the spirit of the CPR design scheme. 4.10.2 Applying the IAD Rules and institutions are central to IAD analysis. Institutions are rules, norms, and strategies, or collectively shared prescriptions that guide behavior in any given situation (Watkins &amp; Westphal, 2016, p. S99). Yet, because those rules are composed of words, no ruleset is ever complete, perfectly clear, or free from misunderstanding: Words are always simpler than the phenomenon to which they refer (Ostrom, 2011, p. 19; Wittgenstein, [1921] 2013).The rules surrounding common pool resource management are complex, and the IAD framework attempts to provide a common scholarly language to assist in studying those rules. In service to that common scholarly language Crawford and Ostrom (2005) developed the ADICO syntax to classify institutional rules and norms. ADICO is an acronym: (A) attribute, (D) deontic, (I) aim, (C) condition, and (O) or else. These five types of classifiers can be combined to define three types of institutional statements found in action arenas. Strategies have attributes, aims, and conditions (AIC); norms have attributes, deontics, aims, and conditions (ADIC); and rules have the entire ADICO syntax. The ADICO approach can be used by scholars to properly classify the many institutional rules found in studies of institutional policies. Attributes define which actors a statement applies to; a deontic describes what behavior by actors is permitted, expected, or prohibited; the goals a deontic applies to are the aims; the condition refers to the when and where of an aim; and the or else defines the consequence for failure to comply with the statement. The ADICO syntax is important because it allows scholars to conduct their inquiries and collect data in such a manner that scholars who may have never studied the same context can understand. Doing so adds to the reliability of institutional policy studies, and conveys valid and substantive meaning (Basurto, Kingsley, McQueen, Smith, &amp; Weible, 2010, p. 523). IAD studies use the ADICO syntax to impose order on incredibly complex policy contexts which otherwise appear beyond definition. Basurto and his coauthors (2010) use the ADICO system (Ostrom &amp; Crawford, 2005) in an IAD approach to comparing tow types of policies  United States transportation policy and the U.S. state of Georgias abortion legislation. While the authors intend their use of the ADICO syntax as a proof-of-concept, their descriptive outcomes provide some interesting insights. For example, despite both policies being incredibly dense and complicated, the actual rules of each comprise very little of the whole. The abortion bill contains four rules, and the transportation policy has none. Rules, though, depend on sanctions, which neither policy emphasizes. Rather, the emphasis in both is on norms, which have no sanctions (no or else in the ADICO syntax). While including only four rules, the abortion policy had 110 norms; and with no rules, the transportation policy managed 128 norms. 4.10.3 Conclusion The finding (Basurto et al., 2010) that the number of norms in policy far eclipses actual rules underlines a concept borrowed by theorists in the narrative policy framework world (Jones, 2018; McBeth, Jones, &amp; Shanahan, 2014)  the stories we tell are often more important than the (claimed) objective facts within a policy system. Norms are often just as important as rules, despite the central role of rules in the IAD framework (Watkins &amp; Westphal, 2016, p. S99), as norms are understood as strong motivational and guiding forces of human behavior, and this understanding transcends many academic disciplines. Ostrom (Ostrom, 2000, p. 154) recognized the central role of norms in managing common pool resources, commenting that policy initiatives too concerned with rational rule making may have been misdirected  and perhaps even crowded out the formation of social norms that might have enhanced cooperative behavior that would have helped in policy success. Elinor Ostroms contributions to understanding the policy process is difficult to overstate, a contribution which helped make her the sole woman to be awarded a Nobel Prize in Economics (Nobel Prize, 2009). IAD remains one of the giants of public policy theoretical approaches (Cairney, 2013), and because of its careful construction and application over many decades (Sabatier &amp; Weible, 2014) remains an important tool in the policy analysts kit. 4.11 Ambiguity and Multiple Streams The appeal of the earliest policy process literature, linear policy process theory, was its simplistic, straight path construction of policy development. However, scholars have long recognized that the linear process is far more normative than descriptive. John Kingdon attempted to lay out a more realistic, descriptive model (Kingdon, 1995), in what is known as the Multiple Streams Framework (MSF). While MSF has surface similarities to punctuated equilibrium theory (Baumgartner &amp; Jones, 2010), it differs in its departure from the linear process assumptions which punctuated equilibrium holds. MSF was inspired by, but takes the path between, the utter chaos of the garbage can (Cohen, March, &amp; Olsen, 1972) and the too-linear punctuated equilibrium frameworks (Baumgartner &amp; Jones, 2010), and in doing so presents a more compelling theoretical structure than either. 4.11.1 Complexity, Ambiguity, and Subjectivity MSF recognizes that policy is complex, like the social problems it attempts to address. Ambiguity is at the heart of why the policy process is so difficult to study (Herweg, Zahariadis, &amp; ZohlnhÃ¶fer, 2018; Jones et al., 2016; Zahariadis, 2014), because policy actors can never really know the root cause of a social problem, and even problem definition  the start of the linear process model  is ultimately a contestable, political step. Rather than assume policy actors are purely rational beings, MSF holds that humans are boundedly rational (Simon, 1976), and so operate with limited information capacity, selective and serial attention, and imperfect cognition, negating the existence of a rational solution to a given problem (Herweg et al., 2018, p. 18). Further, there are significant time constraints which limit the ability of policymakers ever to know enough, let alone know all the facts that perfectly sound decision making would require. In the end, MSF seeks to answer the question: In a universe of nearly limitless policy problems and solutions, how do the relatively few new policies rise above the rest? 4.11.2 Problem, Political, and Policy Streams MSF is one of the most cited academic theories of the policy process and key influence on the study of public policy (Cairney &amp; Jones, 2016, p. 1) with over 12,000 citations as of 2015 (Jones et al., 2016, p. 13). The appeal of Kingdons framework lies in its flexibility. MSF posits three streams in the policy process  the problem, political, and policy streams. How these three streams come together, or fail to, is a useful structure for thinking about why certain policies are adopted, while other, similarly good policies, fail to gain support. Understanding the three streams is key to understanding MSF. While the streams are discussed in a particular order here (problem/political/policy), in practice the analysis is much more about how the streams interact, without a temporal order. The streams exist independently of one another, and require exogenous actors (policy entrepreneurs) to recognize that a window exists to bring the three streams together. In the problem stream, attention either gathers or remains diffuse around a policy problem. Problems can be defined as (Herweg et al., 2018, p. 21) sets of circumstances that deviate from policymakers or citizens ideal states. Problems are therefore not objectively perceived, but subjective social constructs which are shaped through interactions between people, experiences, and circumstances. Problems shape people, while simultaneously people shape problems. Those problems that gather attention gain saliency in the policy environment and are more likely to attract competing solutions. Attention in this frame can mean many things, none of which are necessarily objective indicators. Attention might be statistical information that point to a problem, or in some cases a crisis gathers immediate and widespread attention to a set of conditions. In this shapeable context, then, agency becomes an important concept and has been the focus of recent work which attempts to more deeply understand how agency is shaped (Winkel &amp; Leipold, 2016). In the case where a problem has no identifiable policy solution, few policymakers will be motivated to identify a problem as such, because there is little efficiency or effectiveness in merely identifying the unsolvable. Borrowing from Simon (1976), policy actors are boundedly rational sequential processors of problem information, preventing them from taking on all problems. Problems exist whether or not attention is given to them, and MSF recognizes that policymakers are only ever paying attention to a scintilla of the possible problems that they could be minding. The political stream refers to the many people, advocacy groups, and political bodies such as legislatures, interested and involved in policy making. In the US context, periods of divided government, when one party controls Congress while the other party controls the presidency, are predicted to have relatively little policy movement. Conversely, periods where one-party controls both the executive and legislative functions are predicted to have a better chance of implementing more substantial policy changes. The partisan composition of the U.S. Congress, for example, will impact whether or not a policy solution perceived as a tax burden has any chance of being adopted. Similarly, the national mood in the wake of a financial crisis must be considered when considering whether complex regulatory policy might be embraced. The political stream is about the actors who must pay attention to a problem, and possible solutions, before a policy can be selected and adopted. During some periods, the political stream dictates that some currents in the problem stream will gather attention, while ideas from the policy stream will not be considered. To the well-attuned policy entrepreneur, mismatches of this sort signal an opportunity to promote their favored policies. The policy stream is described as a policy primeval soup by Kingdon, where potential policy ideas from a variety of policy actors conceive of potential policy ideas in policy communities. At any point in time, the policy stream contains a large number of possible policy solutions, but not all of them are feasible, supported, or available. While a policy idea may originate with a single actor, the ideas change as they are exposed to and considered by other actors in the policy stream. Ideas that eventually become policy are the result of a large number of participants modifying the original idea and is often a much wider solution than the original, narrower solution. Some of these actors are so-called policy entrepreneurs who recognize an opportunity to insert their preferred policy solutions into one which is gaining support. Policy entrepreneurs are essential to the MSF. These are the people and organizations who recognize that the politics and policy streams are often not in sync. A policy entrepreneur waits for, and recognizes, when the two streams offer an opportunity for their preferred policy idea to be implemented. These policy ideas are developed before the actual streams coincide, and the preferred policy is offered as a solution to a problem that has garnered attention. At the same time, these policy entrepreneurs will work to bring the streams together, for example by attempting to bring greater attention to a problem while the politics stream is perceived as favorable to their already developed policy solution. There are numerous metaphors we can use to think about the stream process in MSF (Cairney &amp; Zahariadis, 2016), and flexibility has been key to this frameworks success (see also: Jones et al., 2016, fig. 1). Some think of the streams as literal rivers, that once mixed or merged, are difficult to unentangle. Kingdon himself suggests a space launch metaphor in which all factors must be perfect for launch, implying that policymakers will abort a policy before implementation if all the factors in the streams are not ideal. MSF assumes that when the problem, policy, and political streams come together, there is an opportunity for policy change, but most of the time the streams do not synchronize. Policy entrepreneurs are thus critical to policy change, as they work to align timing in the streams to create a window of opportunity for their preferred policy change. They work to gather critical mass attention to a problem so that a solution is demanded. They work with other policy actors in the policy stream to develop their preferred solution to the identified problem. They work to shift the political landscape, such that policy and lawmakers are persuaded to adopt their solution. 4.11.3 Conclusion In the end, the flexibility of the MSF metaphor, and the relatively low barrier-to-entry for scholars to understand policy through the MSF framework has made it one of the most popular and useful ways to examine policy (Cairney &amp; Jones, 2016). Though the framework is most often applied in a positivist analytical tradition, recent work combining MSF and discourse analysis demonstrates that a post-positivist perspective holds great potential for enriching the MSF theoretically and strengthening it analytically (Winkel &amp; Leipold, 2016, p. 108). The ease of use of the MSF and its associated limited empirical usefulness stands in contrast to the advocacy coalition framework (Sabatier &amp; Weible, 2007) or the institutional analysis and development framework (Ostrom, 2011), both of which harbor complexity and at least some predictive qualities. 4.12 The Narrative Policy Framework Most of the policy process theories covered by in the Theories of the Policy Process (Sabatier &amp; Weible, 2014) could be considered positivist approaches to questions engaged in policy scholarship. One clear exception is the Social Construction of Target Population (SCTP) theory (Schneider &amp; Ingram, 1993), which takes a critical approach to language used in policy contexts to understand how some social groups are advantaged and others are disadvantaged. An enduring critique of SCTP has been that as a post-positivist approach, it does not offer falsifiable hypotheses. The early 2000s saw purposive effort to develop the Narrative Policy Framework (NPF), which clearly borrows from SCTP the insight that policy debates are socially constructed. Early NPF work beginning in 2000 was originally critiqued by established policy scholars such as Paul Sabatier, who pushed the originators to be clear enough to be wrong (for historical tracing see McBeth, Jones, &amp; Shanahan, 2014; Shanahan, Jones, &amp; McBeth, 2018, p. 332). To that end, inspired by postmodernism and the seemingly contradictory charter of science (Jones, 2018, p. 724), NPF aimed to produce work that could stand up to this Popperian critique (Popper, 2005). By 2010, the was formalized as a structural account of narrative which sought to test the influence of policy narratives on policy processes, designs, and outcomes at three different levels of analysis (McBeth et al., 2014, p. 227). By 2013 the Policy Studies Journal held an NPF focused symposium featuring tests of the framework, and in 2014 the NPF held its place in the third edition of Theories of the Policy Process (McBeth et al., 2014; Sabatier &amp; Weible, 2014). The historical context above is important, and it helps illustrate how the NPF was born from post-positivist instincts but adopted to the positivist, falsifiable demands of the policy process academy. Proponents of NPF argue that the admixture of positivist/post-positivist scholarship renders critical discourse studies and other poststructuralist concepts normally outside the realm of empirical study (Jones &amp; McBeth, 2010, p. 329) into a scientific approach clear enough to be wrong (Shanahan et al., 2018, p. 332). 4.12.1 Elements of the Narrative Policy Framework The NPF was proposed as a quantitative, structuralist, and positivist approach to the study of policy narratives (Jones &amp; McBeth, 2010, p. 330). NPF scholarship borrows from a wide variety of academic fields including discourse analysis, rhetoric, and critical literature studies (McBeth et al., 2014). NPF builds on what it borrowed, overlaying a structuralist framework to narratives in order to give a common theoretical language for policy scholars. The structuralist approach of the NPF defines a narrative as having four core elements  setting, characters, plot, and a moral. A setting is the policy context that a policy problem is situated in, such as the legal and constitutional parameters, geography, scientific evidence, economic conditions, agreed-upon norms, and other features which constitute the policy arena (McBeth et al., 2014, p. 228). NPF requires at least one character (but this is a minimal requirement which is almost always surpassed. The characters in NPF can be victims, heroes, or villains. The plot in policy narratives has a beginning, middle, and end, and serves to connect the characters to each other and to the policy problem. Finally, policy narratives have a plot, which serves to promote a particular policy solution favored by the coalitions promoting the narrative. Evolving from the structuralist definition of narrative described above, the NPF approach makes five assumptions (McBeth et al., 2014; Shanahan et al., 2018). First, important elements of the policy process are socially constructed, a clear lesson drawn from SCTP. Second, those social constructions vary boundedly, not randomly, and have temporal stability. Third, policy narratives have generalizable structural elements, which allow for the social constructions to be measured. Fourth, policy narratives occur at three levels  micro, meso, and macro, corresponding to the individual, group, and cultural and institutional levels. The fifth and final assumption of the NPF approach is that narratives play a central role in how humans communicate and cognate, known as the homo narrans model of the individual (Shanahan et al., 2018, p. 333). From these five assumptions, NPF scholars constructed a long series of propositions and hypotheses for each of the three levels of analysis. McBeth, Jones and Shanahan (McBeth et al., 2014, pp. 234246) describe the set of hypotheses: five at the micro/individual level (table 7.2, p. 234), nine at the meso/group level (table7.2, p. 244), while the macro/institutional hypotheses remain, as yet, unspecified. Given the nascent nature of NPF scholarship, the authors concede that the majority of even the specified hypotheses remain completely untested, and all hypotheses lack broad, consistent testing. Despite its structuralist nature, and the effort to adapt to Sabatiers positivist requirements through the integration of behavioral, evolutionary, cognitive, and neuroscientific theories in understanding the public policy process, (McBeth et al., 2014, p. 256), the NPF still requires a great deal of empirical testing. 4.12.2 Applying the Narrative Policy Framework. The list of assumptions, core aspects, and multiple hypotheses of the NPF can be overwhelming, though Michael Jones (Jones, 2018, p. 726) warns not to be turned off by the seeming complexity, because at base, the NPF is as simple as the differences in two stories. The idea that NPFs complexity could turn away policy process scholars is perhaps overblown, particularly in the face of competing frameworks such as the Advocacy Coalition Framework (Pierce, Peterson, Jones, Garrard, &amp; Vu, 2017; Sabatier &amp; Jenkins-Smith, 1993; Sabatier &amp; Weible, 2007) or Institutional Analysis and Development theory (Ostrom, 2011), both of which offer at least equally complex, if not more, takes on public policy processes. The relative ease of applying the NPF approach to policy questions may help explain why, despite only a few years passing since NPF was formalized, there has already been fairly robust empirical application. Merry (2018) is perhaps the exemplar of baking in the SCTP origins with the quantitative aspirations of NPF with her study of gun control policy in the United States. Merry investigates the gun policy narratives of gun control advocacy coalitions by examining over 58,000 Facebook posts of fifteen different policy groups. Her analysis shows how the racial aspects of gun control are ignored by both coalitions for and against gun control, an interesting finding which NPF is well poised to explain with its hero and villain concepts. Merrys findings suggest that the objective policy realities are distorted by the policy narrative demands. Gottlieb, Bertone Oehninger, and Arnold (2018) use a case study approach to the hydraulic fracking policy debate in New York over a four-year period. The authors findings challenge the existing NPF hypotheses related to the devil shift and angel shift, (Weible, Sabatier, &amp; McQueen, 2009) an important study outcome for NPFs falsifiability. This challenge to a key concept within NPF, a concept which was conceived of by some of the most senior, respected scholars in public policy (Weible et al., 2009), is important. It shows that the NPF scholar community is not wed permanently to its origins, and is willing to move and adapt as needed and as demanded by empirical tests of its predictions. Continuing the trend of combining insights from NPF with better established theories of the public policy process, McBeth and Lybecker (2018) investigate the policy narratives of so called sanctuary cities in the United States. The authors combine NPF insights with elements from Multiple Streams Analysis (Jones et al., 2016; Kingdon, 1995; Zahariadis, 2014) using a mixed-methods case exploration. The findings demonstrate the value of combining elements from the much better studied Multiple Streams Analysis (MSA) into NPF, especially in policy cases where the researcher is interested in agenda setting. The authors also contribute to the ongoing formulation of NPF methodology, critiquing the difficulty of temporal scope. Narratives have internal structure (beginning, middle, and end) but when and how are the narratives themselves born, age, or die? Through their study, McBeth and Lybecker (2018, p. 868) demonstrate it is difficult to determine how long a policy narrative remains powerful and relevant, a methodological limitation of MSA as well in regards to a lack of clarity on how to define a policy window, let alone its beginning, duration, or end point. 4.12.3 Conclusion If a framework is to meet Sabatiers requirement of clear enough to be wrong, then, at least sometimes, its predictions should be wrong. NPF scholars have not flinched from that demand. In particular, Gottlieb, Bertone Oehninger, and Arnolds (2018) study of sanctuary cities undermines the devil/angel shift hypotheses which are key to the original NPF formulation. The fact that the NPF community of scholars is willing to absorb such major reworkings shows its strength and commitment. By taking on the importance of storytelling to the human experience and applying it in a structured, testable manner to the policy process, NPF is a valuable approach for researchers. Like its close cousin ACF, that value is strongest, so far, for case studies within an environmental policy frame, with empirical tests of both approaches mostly taking on environmental policy debates (Jones, 2018; Pierce et al., 2017). That said, NPF has broadened its policy scope with the examples of gun control policy (Merry, 2018) and sanctuary cities (McBeth &amp; Lybecker, 2018) in the latest highlighting of the NPF in Policy Studies Journal, which included works on other policy areas as well (Jones, 2018). With an identifiable Lakotosian scholarly community (Lakatos, 1976), the NPF is well poised to address the critiques and gaps identified already. Key among these will be enhancing the lackluster meta level of policy narratives, which NPF takes as a key component but so far lacks accepted predictions, and thus falsifiability (Peterson, 2018). 4.13 Advancing the Narrative Policy Framework Another NPF essay here, this time expanding the where to go next with the theory. You may have noticed I have quite a few NPF essays, and as it turns out I was able to use much of it in the comprehensive exam. One lesson - if you have a theory you are interested in, try to develop a few different length pieces around it. That gives you a lot of flexibility to make it the focus of an answer, or just a little extra bit of theory when youre really focused elsewhere. 4.13.1 Introduction The Narrative Policy Framework (NPF) is the latest approach in the policy process literature to gain significant adoption by researchers. The NPF was developed as a quantitative, structuralist, and positivist approach to the study of policy narratives (Jones &amp; McBeth, 2010, p. 330). This policy process approach asserts that narratives (or stories) are primary mechanisms by which individuals process complex information and communicate about events and issues (Merry, 2018, p. 749). In other words, the NPF recognizes that the stories people tell, and are told, are critically important to understanding how policy is adopted. NPF scholarship borrows from a wide variety of academic fields including discourse analysis, rhetoric, and critical literature studies (McBeth, Jones, &amp; Shanahan, 2014). NPF builds on what it borrowed, overlaying a structuralist framework to narratives in order to give a common theoretical language for policy scholars. The paper proceeds in three sections. First is an introduction to the NPF through a literature review, including the explicit assumptions of the approach. Complementary discussions around media framing and scope of conflict in the policy process give rise to a set of preliminary hypotheses. Second, the sampling strategy is discussed, with attention to the time frame and source material justifications. Finally, three possible analytic strategies are considered. This section is long, as it traces deep into the theoretical proffer of NPF in order to develop specific analytic tests of implicit assumptions that have not yet been tested. This section offers substantial potential contributions to overall NPF scholarship, as both theory testing and theory building outcomes are possible, or even likely. There are a handful of essential assumptions and research decisions to be made before engaging with the NPF on a research topic, as the approach is not a one-size fits all for projects centered on narratives (Shanahan, Jones, &amp; McBeth, 2018, p. 333). There are several strong assumptions built into NPF which must cohere with the aims of the research question before proceeding. 4.13.2 Narrative Strategies and Hypotheses Stories count, but how do we count stories? The Narrative Policy Framework (NPF) allows the researcher to go beyond evaluating a news article as positive/neutral/negative, a common operationalization in framing studies that can be sensitive to rater bias. An NPF study is interested in how that information is transmitted through narrative, rather than if an opinion is transmitted. Through operationalization of characters, setting, and plot, an NPF study can surface commonalities in narratives even when the authors have opposing views. Stories are either told well, or poorly and investigating the differences in how stories are connected to successful policy initiatives is the goal. The five assumptions of the NPF are worth making explicit (McBeth et al., 2014). First, the approach assumes that the policy reality we perceive is socially constructed, rather than objectively true. This assumption reflects the influence of Schneider and Ingrams (1993) Social Construction of Target Population (SCTP), another policy process approach. Second, NPF scholars recognize that those socially constructed policy realities have meaning which necessarily varies, but in boundedly rational ways. The meaning has stability over time, can be measured, and is not random  an assumption that has yet to be tested, and which I address at some length in the analytic plan section of this paper. The third assumption is that narratives have a general structure which can be identified, such as including characters and plot. The fourth assumption is that narrative has effects at multiple levels (micro, meso, and macro) and that narrative interacts across these levels. The final assumption could be considered a meta-assumption, and is said to be the homo narrans model of the individual. Homo narrans assumes that narratives play an important role in how humans understand the world. In other words, that people prefer to think and speak in story form (Shanahan et al., 2018, p. 333). As noted above, the NPF includes three levels of analysis  the micro, meso, and macro. The micro level is concerned with the effect of narrative strategy on how individuals perceive policy choices (McBeth et al., 2014). The meso level is focused on broader narrative strategy by policy actors, and understanding how those actors build those narratives. This is the level of analysis of the present study. Finally, a macro level of analysis is proposed by the NPF, though at this time no published work operates at this level. The macro level has also been synonymized with meta-narrative, grand narrative, and master narrative (Shanahan et al., 2018, p. 341). The structuralist approach of the NPF attempts to surface the most essential elements of a narrative and make them quantifiable. The structure defines a narrative as having four core form elements  setting, characters, plot, and a moral. A setting is the policy context that a policy problem is situated in, such as the legal and constitutional parameters, geography, scientific evidence, economic conditions, agreed-upon norms, and other features which constitute the policy arena (McBeth et al., 2014, p. 228). NPF requires at least one character, but this is a minimal requirement which is almost always surpassed. The characters in NPF can be victims, heroes, or villains, and importantly for this study, need not necessarily be human characters as non-human characters retain their character status in most NPF applications (Shanahan et al., 2018, p. 335). The plot in policy narratives has a beginning, middle, and end, and serves to connect the characters to both each other and the policy problem. Finally, policy narratives need a moral, which serves to promote a particular policy solution favored by the coalitions promoting the narrative. NPF presumes that these four core elements are generalizable across contexts, and can be operationalized. The coding schema used in content analysis is relatively stable, and a full rendering can be referenced in Shanahan and her co-authors appendix (2018, appendix A, pp. 343344). The coding strategy outlined here closely adopts that schema. The standard narrative elements identified within the NPF scholarly community are listed along with corresponding potential body-worn camera examples in Table 1, located in the appendix to this paper. 4.13.3 Framing Effects in Media The study of framing effects in media has a long research tradition (Goffman, 1974; Iyengar, 1991; Kahneman &amp; Tversky, 1984), and the findings are essential for understanding why media narratives are an appropriate source of data in NPF studies. The choices made in narrative structure by policy actors are communicated through the media, and reflect embedded policy beliefs and strategies that seek to influence readers policy preferences (Shanahan, McBeth, &amp; Hathaway, 2011, p. 378). The linkage between framing and narrative policy analysis is clear, as the importance of story is highlighted in both. However, as Jones (2018) notes in his recent review of NPF studies, more needs to be done to understand how the two intersect. The most common understanding of framing comes from Gamson and Modigliani (1987, 1994), who define frames as the central organizing idea or storyline that provides meaning to an unfolding strip of events, weaving a connection among them. Frames are communicated by many sources, but mass media outlets are key actors in this process (Scheufele, 1999; Zaller, 1992). How members of the public form opinions has been a consistent source of scholarly work from the earliest days of political research. The consensus that emerged is that the ideal of high-quality opinion is stable, consistent, informed, and connected to abstract principles and values (Chong &amp; Druckman, 2007, p. 103). This ideal is rarely found among the general public. Because people are not capable of perfectly locating, absorbing, understanding, or recalling information (Simon, 1972; Zaller, 1992), they rely on information shortcuts in forming opinion, and use frames to develop a particular conceptualization of an issue (Chong &amp; Druckman, 2007, p. 104). An illustrative example of framing effects is found in the policy of providing federal funding for local police departments in the US to purchase body-worn cameras (BWCs). In 2015, as funding implementation decisions were considered, the question of BWCs did break down into a partisan policy question. Elite policy actors from across the political spectrum supported adoption of the cameras. President Obama, a Democrat president, supported BWCs as a solution, and matched his vocal support with millions in federal funding to police agencies to purchase the technology (Office of Public Affairs, 2015). Donald Trump, then a Republican primary contender, supported BWCs and believed they can solve a lot of problems  period (Jacobs, 2015, para. 3). Hillary Clinton, Donald Trumps eventual opponent in the 2016 presidential race, agreed, making federal funding of BWCs a key point of her criminal justice policy platform (Clinton, 2015) which she believed were capable of improving transparency and accountability (Laughland &amp; Gambino, 2015, para. 11). This bipartisan agreement on significant a policy proposal is rare enough, and rarer still in a period of increased partisanship during a presidential campaign. However, this does not mean media framing is not a factor in the BWC policy story. In their analysis of Newsweek stories from 1975 to 2008, Wagner and Gruszcynksi (2016) show that framing tends to affect attitudes towards policy but not partisanship. As such, bipartisan support of BWC policy (in this case federal funding) serves as evidence of a policy topic on which attitudes can be affected, even (or especially) when no partisan differences are detected. Non-competitive environments are where most is known about framing effects, while research into how framing works in competitive elite environments lagged behind (Chong &amp; Druckman, 2007). While this is a deficit in the broader framing literature, it does not impact this study of narrative effects on BWCs policy, which was situated in a non-competitive partisan context. Policy process theories have long been concerned with the role of public opinion on policy formation. The advocacy coalition framework places policy belief as a core component of analysis (Jenkins-Smith, Silva, Gupta, &amp; Ripberger, 2014). Similarly, scholars working in the punctuated equilibrium approach generally follow Kingdons (1995) conceptualization of the medias effect on public opinion through agenda setting. In this view, the effect of the media is most potent at the agenda-setting level, rather than on individual-level policy preference. In other words, media effects are rarely expected to change individual opinion on policy preference. Instead, the media acts to constrain policy choices through agenda-setting effects. In an alternative theory of the policy process, the advocacy coalition framework (ACF) originally conceived of public opinion as an unimportant force within policy subsystems (Sabatier &amp; Jenkins-Smith, 1993), while the opinion of political elites was the center of subsystem power. This early view has evolved; depending on the policy context, public opinion can play a central role as an external shock to coalitions within the subsystem, or even as an internal force (Shanahan et al., 2011). Media reports are among the most common source of narrative data in NPF studies (McBeth et al., 2014; McBeth &amp; Lybecker, 2018). Media accounts, including newspaper articles, often contain embedded policy beliefs and narrative framing strategies, meaning they do not just convey factual information, but instead act as more of a contributor than a conduit in the policy change process (Shanahan, McBeth, Hathaway, &amp; Arnell, 2008, p. 115). Newspaper stories and editorials are a common source of data in NPF studies (McBeth &amp; Lybecker, 2018; Shanahan et al., 2008), and more generally across social science studies interested in media effects (Edy, Althaus, &amp; Phalen, 2005; Lecheler &amp; de Vreese, 2012; Matthes, 2009). 4.13.4 Scope of Conflict NPF proceeds from the assumption that public opinion, at the least, plays a part in policy formation, and that opinion is affected through media framing. The framework differs in focus however, as it seeks to quantify not whether media narrative framing is important, but rather how it is done (McBeth et al., 2014). At the meso-level, a strategic reason that policy actors leverage narrative is to either expand or constrict the scope of the policy conflict. Long understood as a political strategy (Schattschneider, 1960), the concept of scope of conflict is explained in the NPF as a narrative strategy that distributes the costs and benefits of a proposed policy to the array of characters in the policy narrative (Shanahan et al., 2018, p. 337). The dominant group benefiting from the status quo policy environment will generally attempt to limit the scope of conflict, while the policy coalition or actors who perceive themselves as less powerful will attempt to expand the scope of conflict. The winning coalition is generally the one that is most successful in concentrating the costs (typically on the villain) while diffusing the benefits. In Professor Merrys research on narratives in gun control policy advocacy organizations (2018), she notes the link between social construction policy theory (Schneider &amp; Ingram, 1993) and the NPF. Merry predicts that policy advocates will select and construct characters in their narratives in order to influence how a policy issue is framed. In other words, policy actors will use policy narratives to evoke sympathy and might highlight victims who are positively constructed, such as children (Merry, 2018, p. 751). This is another tactic in an overall strategy of conflict expansion, as actors seek to grow their coalition by appealing to compassionate onlookers by highlighting positively constructed victims. A second conflict expansion strategy is when actors seek to translate a public problem into a personal threat (Goss, 2010, p. 107) by increasing the perceived proximity of a problem for the reader. This strategy is intended to bring in support from those who might otherwise feel a policy issue does not affect them. Proximity can be literal, in which the study would expect actors to highlight a problem in the community of the intended audience. It can also be figurative, in which framing choices evoke a feeling of closeness to a problem (Merry, 2018, p. 750). 4.13.5 Analytic Strategies In a recent review of progress in NPF studies, Jones (2018) highlights the relative sameness in NPF research designs. The prevailing NPF analytic method was a mix of descriptive statistics and measures of association, and, of course, plenty of regression analyses (Jones, 2018, p. 734). This analytic monotony is an understandable feature of early NPF work as scholars attempted to build out and justify the framework. Recently, NPF scholars have begun to broaden the analytic scope, with the use of rare event analysis (Kirkpatrick &amp; Stoutenborough, 2018) and causal mediation analysis (Zanocco, Song, &amp; Jones, 2018). Network analysis and in the inclusion of big data have been suggested as potential next steps for researchers looking to expand the analytic toolkit of NPF (Shanahan et al., 2018). For this study, in addition to the orthodox regression analysis, I propose a further way to contribute to the testing of the NPF through the inclusion of structural equation modeling (SEM). While SEM is capable of directly testing the same null hypothesis as logit regression, it can also test hypotheses constructed to test indirect paths of causation. Indirect causation is an especially salient question for NPF, which assumes that narrativity is a dynamic process, but which is generally only tested in a linear regression formulation. Those tests assume a closed causal space and one-to-one interactions on the causal path between independent and dependent variables. For example, perhaps both heroes and villains are important (a hypothesis supported by current NPF theory), but that narrativity increases only when a villain is accompanied by a hero. This logic is an example of a dynamic process not testable with linear regression, but one that is well-fit to the analytic domain of SEM. 4.13.6 Linear Regression Regression is the most common analysis done in NPF studies. The approach is well-fitted to this study for several reasons. For those studies moving beyond the mere description of narrative elements, is it the most common method to establish (arguably) causality. Given its widespread use in the social sciences, regression is an easily interpretable and familiar method. As a first analytic stop, using linear regression has much to recommend it here as well. Given its extensive use in NPF studies, scholars are unlikely to object to its underlying assumptions, usefulness, or explanatory power. In a non-specific example, a regression design would seek to test a model where a dichotomous outcome (conflict expansion=1, conflict containment=0) is explained by some combination of character (villain, victim, hero), setting (nominal), and moral (proPolicy=1, antiPolicy=0) formulation. However, there are a number of limitations to linear regression in an NPF study as well. Linear regression has several strong assumptions which must be met before its output can be relied upon. Among these is an assumption of independence for the explanatory variables. For example (and as discussed in much more detail in the SEM section below), the NPF presumes that the core elements of narrativity can be collected into a narrativity index. If one attempts to model that index with a regression, with the core components as a set of independent variables, then one is assuming that plot, setting, characters, and setting (at least) are completely independent of one another. This is a heroic assumption, and not one we should be willing to move past easily given the dynamic nature of story elements implied by the NPF. Further limitations to consider include the difficulty of interpreting logit coefficients (as would be required in a policy win/loss outcome), and limited interpretability. What does it mean that relative density of characters increases narrativity index exactly (see Shanahan et al., 2018, p. 337)? What would a non-significant result mean? And finally, with regression the core analytic choice of many NPF studies, we should consider that a lack of methodological triangulation to test the theory which undergirds the NPF either explicitly or implicitly has limited the overall reliability of its predictions. 4.13.7 Structural Equation Modeling (SEM) Regression methods are hampered by the inability to easily identify measurement error. This is a salient problem within the social sciences broadly, but specifically for research within the NPF framework, which relies on data collection techniques that are vulnerable to bias. Structural equation modeling (SEM) is a second-generation statistical technique that allows for both identification of measurement error (and therefore, correction), but also takes into account the indirect effects of endogenous variables within the model (Kline, 2015). These analytic benefits make SEM a significant and indispensable tool for empirical researchers (Tarka, 2018, p. 338), and the method is widely applied across scientific disciplines. Taking an SEM analytic approach to an NPF study has several identifiable benefits. First, one assumption of linear regression is that the explanatory variables are independent from one another. Because NPF assumes the narrative elements are not only related, but dynamic, regression is at a basic level an inappropriate test for NPF models. SEM can handle non-independent causal variables, a clear advantage in this case. A second advantage of SEM is related to measurement error. Researcher supplied measurement error is unavoidable in a method such as NPF. This bias is baked into the very assumptions of the approach, especially the homo narrans base of the approach. Stories universally influence how humans (including the researcher subgroup of humans) perceive and understand their world. This influence can lead to inter-coder bias as data collection proceeds. Even an experience, careful researcher coding the narrative content of newspaper stories is likely to (at a minimum and in the best case) supply a bias in how structured narrative content is encoded. Intercoder reliability is not a balm either, and in fact, may exacerbate measurement bias. For example, a graduate student or research assistant can reasonably be assumed to harbor the same rating bias as the principal researcher who trained them. In such a case, high intercoder reliability can be interpreted as, at least in some cases, highly reinforced systemic mismeasurement. While SEM does not magically do away with mismeasurement, but the relaxed assumptions and ability to measure latent error could be useful in the specific case of narrative content. Finally, SEMs use of latent constructs is an ideal modeling technique to test foundational NPF theory. Latent constructs are a way of measuring the unobservable latent character of complex social phenomenon. Any individual question or observable item is subject to bias and mismeasurement, or likely does not capture the full meaning of a social phenomenon. However, through the use of several observable measures, each of which captures an aspect of the overall unobservable latent character of the phenomenon being studied, a researcher can be more assured of the validity of the overall measure. 4.13.8 Applying SEM to the NPF What constitutes a policy narrative? In the specific case of NPF, narrative is the unobservable social phenomenon, and SEM offers a unique contribution to both the overall framework of the NPF approach and the policy process theory environment as well. The framework assumes this unobservable measure narrative is comprised of several underlying, unordered, but observable constructs  the four core form elements of setting, characters, plot, and moral. The elements come together to form a narrativity index. This index is assessed to understand the robustness of any given narrative or set of narratives (Shanahan et al., 2018, p. 337). However, the effect of higher or lower narrativity is yet to be known (p. 137). I suggest an analytic pause before turning to assess the effect of narrativity, and a step back to assess what is even meant by index in this framing. It appears that the implicit assumption is that the elements are not only essential but essential at the same level. The plot, therefore, is just as critical to narrativity as moral, characters, or setting. Perhaps, but this far from settled within the NPF literature, as indicated by the advice that policy narratives may include all or some narrative components (Shanahan et al., 2018, p. 336). The implied index formulation is akin to a stew recipe, where the overall outcome is relatively invariant to the order, amount, or prevalence of ingredients. Scholars generally agree that at a minimum it must have at least one character, and must refer to a public policy, but past this minima, the recipe is a dash of plot, other characters, setting, and moral as needed. Continuing the metaphor (perhaps a bit too far), if NPF is to enhance the replicability and rigor of a narrativity index, then it needs a baking recipe, with more exactitude in types, amounts, and timing of the ingredients. In the grammar of SEM, this narrativity index recipe forms an implied covariance matrix. A diagram of the implied covariance matrix would appear as shown in Figure 1 below. In the diagramming syntax of SEM, an oval shape is a latent construct; rectangles are observed items; and small circles are error terms for observed items . Directional arrows from observed items to latent constructs denote a regression-like relationship. Following model resolution (discussed below), path coefficients would be calculated for the weight of each observed variable on the latent construct. These coefficients can be interpreted much like linear regression coefficients. They can denote a positive or negative relationship, and each path can be significant or non-significant at an alpha level specified by the researcher. In the ideal case, each path in this test would be significant and in a positive direction. 4.13.8.1 Figure 1: Base Implied Covariance Matrix for the Narrativity Index Importantly, Figure 1 should not be construed as representing the only implied covariance matrix implied by the NPF approach. Instead, it is the most likely given the current assumptions and structural considerations of NPF. The NPF is open to alternative definitions operationalizing the structures of a policy narrative (Shanahan et al., 2018, p. 335), and so alternative model specification is possible. However, given that even the base NPF model has not been tested in this way, at this time the four core elements of narrativity are adequately encoded in the first diagram. It is easy to consider and diagram a multiplicity of other models of narrativity which take into account the possibility of indirect relationships as well. For example (Figure 2): What if variance in setting strengthens or weakens the influence of a character type on how robust a narrative is (indirect path A), while simultaneously exerting a direct influence (path B) on narrativity as well? SEM is able to solve these equations simultaneously in the implied open solution space. 4.13.8.2 Figure 2: Hypothetical Indirect Implied Covariance Matrix This paper noted relatively early that NPF explicitly assumes bounded rationality in narratives. This assumption suggests that narrative has stability over time, can be measured, and is not random. Another way of describing that stability of measure is measurement invariance (Nesselroade &amp; Cattell, 2013). A full discussion of measurement invariance is beyond the scope of this paper. However, the key idea is that by modeling datasets from a variety of times, contexts, and sources, we test the underlying model for measurement artifacts. This provides a check that any change we are seeing in the model output is due to actual underlying changes in the data, rather than some other source (Boker &amp; Laurenceau, 2006; Newsom, 2015). Academic psychology pioneered much of the work in longitudinal modeling to detect measurement variance at the inter- and intra-individual level of measurement (Nesselroade &amp; Baltes, 1979). The application of SEM to the problem of measurement variance is considered state-of-the-art methodology (Deboeck, Nicholson, Kouros, Little, &amp; Garber, 2015). Relatively few published articles consider measurement invariance testing directly, beginning around 2011. In the case of testing NPF models of narrativity, SEM techniques can ensure measurement invariance (or diagnose variance) by conducting a series of tests that impose equality constraints to establish parameter stability. If done well, this could result in a genuinely reliable narrativity index which far surpasses the current stew stage of recipe development. Note that Figure 2 above does not require a change in variable or operationalization of the model shown in Figure 1, though a hypothesis reformulation is likely required. SEM is imbued with natural flexibility that allows the researcher to consider a wide variety of narrativity index models. Further, once a likely candidate model is identified, it can be tested across policy contexts. If the model holds, we can begin to isolate the relative weighs of each component and path, allowing for even more theory building. For example, it may be characters (or plot, or setting) to are worth more narrativity. In that case, experimental designs with narratives designed with more or less robustness (macro level) could be tested for their (micro-level) effects on the formation of policy belief in individuals. However, we are now far afield in the what-if scenarios, which all hinge on first establishing configural validity for the basic model illustrated in Figure 1. 4.13.9 Model Testing Progressing from the specification of the implied covariance matrix, SEM then tests the ideal model against the observed data matrix (known as the sample covariance matrix) using maximum likelihood estimation (MLE). This estimation attempts to maximize the likelihood of the observed data given the parameters encoded in the implied model. In other words: Does what we observe in a collection of observed data on the underlying story elements fit well into the unobservable latent construct of narrative? Through the use of omnibus goodness-of-fit statistics, such as RMSEA, CFI, TFI, and more, the researcher can compare how closely the observed data fit the implied model. Guidelines for assessing the fit of an SEM model as specified is relatively straightforward (Hooper, Coughlan, &amp; Mullen, 2008). While model assessment is an active area of debate among scholars , the analysis proposed here can safely be considered among the most well-trodden and least controversial SEM methods (Kline, 2015; Marsh, Morin, Parker, &amp; Kaur, 2014). 4.13.10 Drawing Conclusions (from drawings) Several conclusions might follow the above analysis, which is a type of confirmatory factor analysis (CFA). First, the observed covariance model could obtain very close fit with the implied covariance model. In this case, the structural elements of narrativity would be shown to be just as the NPF has assumed. This outcome is the most likely, given that the structural elements of NPF are the result of careful research which has been developed by talented scholars for many decades. The NPF was, at least in part, developed with the transparent goal of meeting policy process scholar Paul Sabatiers requirement that a theory possess a clear model specification and be clear enough to be wrong (Jones &amp; McBeth, 2010; Sabatier, 1999; Shanahan et al., 2018, p. 332). Having only recently being accepted into an important policy process handbook (Sabatier &amp; Weible, 2014), the approach detailed here offers a real possibility for method triangulation in support of the still-growing NPF. Alternatively, if the two covariance structures are incompatible, essential assumptions of the NPF approach can fairly be said to have been falsified. In that case, assumption three of the approach would require significant interrogation. Assumption three is that narrative has generalizable structural elements, and building on that assumption NPF models the four core elements of plot, setting, characters, and moral as the quantifiable elements. To undermine that construction would be to undermine foundational aspects of the NPF. However, before drawing such a damaging conclusion, the limitations of the analytic tests must be assessed. 4.13.11 Limitations There are three obvious limitations to consider, though these are only three limitations that would have to be considered and are not intended to be an exhaustive list. Applying and testing the NPF is more of an iterative venture, with some ideas developed concurrently and not necessarily bound by unyielding order. In that spirit, the identified limitations at this proposed stage are likely to be joined by others as the research process takes place. In the case of poor model fit, there are several sub-analyses which would be required before drawing firm conclusions. First, the observed data would need to be assessed. Perhaps the specific sample here  a New York Times content analysis of body-worn camera stories over eight months  does not provide an adequate testbed for the NPF model. This weakness is protected against somewhat by the number of NPF studies which have drawn substantive conclusions using newspaper articles. However, because of the reliance in SEM on the observed covariance matrix, if the underlying data is a priori not a good test of the implied covariance matrix, nothing interesting has been learned. If the sample does not provide an adequate corpus for testing, several options are available. A separate narrative source on the same topic, and in the same timeframe, could be obtained. A second limitation might be the implied model. Some authors have opined that perhaps only two elements, a character and a public policy, are needed for a narrative. These character in a narrative is a foundational narrative element that differentiates a narrative from a non-narrative, such as a chronology or a report (Shanahan et al., 2018, p. 336). Perhaps, then, the observed covariance matrix is mis-specified, and the latent narrativity construct should contain only two observed items based on two questions: (1) Does a character exist in the article? And (2), does the article pertain to public policy? In such a case, SEM would not be an appropriate analytic tool, because of the vulnerability of two-item constructs. If this conclusion was supported, it would still be a worthwhile contribution to the field, and would require re-specification of the core narrative elements model of NPF. Related to the above, a third limitation might be a lack of comparison narratives. In their application of NPF to the policy of sanctuary cities, McBeth and Lybecker (2018) select Breitbart News, a more reliably partisan news source, to construct their dataset. The authors then built a companion dataset derived from congressional GOP floor debates. Comparing the two datasets, the study concludes that the narratives used by Breitbart News were able to set the agenda on an important public policy by influencing the policy beliefs of policy elites. 4.13.12 Conclusion Stories count; this is the homo narrans assumption of narrative influence on human activity. The NPF has been successful in providing structure to the assumption such that the relationship between narrative and policy can be assessed. NPF synthesizes the quantitative demands of policy process scholarship with the qualitative instincts of social inquiry interested in meaning-making. To date, the burgeoning NPF evidence base has demonstrated its value to our overall understanding of the policy process. In order to build on the early success of the NPF, I have suggested an analytic expansion is needed to provide clarity and falsification of untested assumptions related to how the approach conceives of a narrativity index. The NPFs front-end of demonstrating that stories count is more well-developed than the analytic back-end of counting stories. This critique is not intended to underplay the contributions of NPF scholars or scholarship. An academic community must find its grounding in description before it can stretch to inference. It is only due to the determination of early NPF researchers that any demand for more theory testing can be made, as has been done here. To its credit, and in contrast to many of the other policy process theories, NPF makes its explicit assumptions clear. Implied, or at least rarely stated assumptions still exist. Perhaps the most untested of the implied assumptions of NPF is that of dynamism. Story elements of plot, characters, setting, and moral are all assumed to interact in some way to produce an index of narrativity (Shanahan et al., 2018, sec. 6.1.4). The same fluidity is presumed for the narrative levels, as micro-, meso-, and macro-level narratives interact with and reshape one another. As demonstrated in the exploration of possible analytic strategies undertaken here, more effort should be given to testing that assumption. The strongest likelihood is that applying new methodology, or as stylistically applied here, an improved method of counting stories, will only serve to solidify the strong assumptions of NPF. Unfortunately, linear regressions are built on strong assumptions which are at odds with the equally strong ones of the NPF. Fortunately, SEM is a well-accepted methodology which can triangulate with the existent research to test and strengthen NPF theory. 4.14 Policy Feedback Theory In its most general definition, policy feedback theory (PFT) captures the idea that new policies create new politics (Moynihan &amp; Soss, 2014, p. 320, quoting from Schattschneider, 1935, p. 288). In turn, the created politics then influence future policy (Moynihan &amp; Soss, 2014; Pierson, 1993). At its best, PFT generates better causal hypotheses in political science (Tilly, 2001) by encouraging political scientists to (Pierson, 2000, p. 264) think more clearly and explicitly about the role of time, and history, in social analysis. 4.14.1 The Policy Feedback Approach The feedback in policy feedback can take many forms. As Fleming (2014) notes, one simple form of policy feedback used by scholars is public opinion. Once a policy is passed into the public sphere, citizens can demonstrate their approval or opposition to the effects (Fleming, 2014, p. 56) of the policy through their votes. Such votes select policymakers who then create more policy, keeping in mind the public opinion of the previous policy outputs. In this way, policy creates politics, politics creates policy, and on ad infinitum. An example of this feedback is how voters personal experience with public health insurance regimes affects their attitudes towards Medicare and the Affordable Care Act in the United States (Lerman &amp; McCabe, 2017). Linking personal experience with previous policy outputs to future attitudes towards a similar policy is a crucial feature of PFT. This link also provides a new way to answer to a critical pillar in American political study, which is interested with understanding how public opinion is formed (Mettler &amp; Soss, 2004; Zaller, 1992). This cyclical repetition is a weakness of PFT, as it implies there is an extensive system from which to draw from. The systemic level of analysis in PFT can present difficulty in choosing which politics and policies to concentrate on. Mettler (2002), for instance, in her study of the effects of the G.I. bill on the political activity and engagement of benefitted veterans, is taking on a feedback loop lasting multiple decades. Such a time lag invites a host of confounding variables which need to be analyzed. In parallel work, Mettler and Welch (2001) analyze some of those potential confounders using a two-stage methodology find similar results (Mettler, 2002, n. 13). So, the long scope is not necessarily a fatal vulnerability but must be dealt with by scholars interested in using PFT. Another form of feedback is between different elements of the policy system, as seen in how advocacy coalition framework (ACF) theorists (Sabatier &amp; Jenkins-Smith, 1993; Sabatier &amp; Weible, 2007) incorporate policy feedback theory. In ACF, coalitions of actors who share policy beliefs compete against other coalitions who favor different policy solutions. Two types of shocks, internal and external, can change coalition positions within the policy subsystem. An internal shock might be coalition members changing their minds when new evidence from a previous policy outcome becomes available. An external shock could be a new policy environment created when a policy is passed, giving the competing coalition a political advantage. Both types of shocks are reliant on policy feedback theory, as policy creates new politics and the coalitions react to them, positioning themselves for the next policy battle. 4.14.2 Policy Feedback Applications As a concept, PFT stands in stark contrast to much of the political science which came before it, which searched for the big causes resulting in big changes and rooted that search in the political process. In contrast, PFT allows scholars the ability to locate large effects in the small causes, or at least a system of smaller causes, giving a more nuanced and detailed historiological analysis to political inquiry. Pierson (2000, p. 215) predicted that if policy feedback theory was found to be appropriate to social research questions, it would shake many subfields of political inquiry. Pierson was right, and scholars have since found a great deal to like in PFT, and the concept has found root as a mechanism within many other policy process theories (Fleming, 2014). Both social construction of target populations theory (Schneider &amp; Ingram, 1993), and advocacy coalition framework (Sabatier &amp; Jenkins-Smith, 1993), for instance, use the concept of policy feedback within their larger theoretical explanations (Cairney &amp; Heikkila, 2014). PFT is also key to the underlying approach of punctuated equilibrium, spurred in part by PFTs assumption that (Pierson, 2000, p. 251) political development is often punctuated by critical moments or junctures that shape the basic contours of social life. An example of applying PFT to the public administration context comes from a study from Wichowsky and Moynihan (2008). A policy is more than the sum of the technical language passed as law, and includes the administrative practices of translation and implementation (Moynihan &amp; Soss, 2014, p. 320). Taken with the policy feedback assumption that policy creates politics then (p.320) implies that administration shapes politics. Policies affect (Wichowsky &amp; Moynihan, 2008, p. 908)political participation, social capital, a sense of civic belonging, and self-worth as a citizen. In other words, the authors are able to extend the policy-politics cycle to a policy-politics-administration-citizen cycle, with all components affecting each other. While early iterations of policy feedback built to the conclusion that citizens create policy through feedback, acting as thermostat (Fleming, 2014, p. 56), Wichowsky and Moynihan show how policies shape citizenship through public administration of those policies. While early presidential scholars tended to focus on the personalities of presidents, Skowroneks (2008) concepts of presidential time and secular time take into account the temporal context that affects the presidency, a critical assumption of path dependence and feedback approaches. Only when the political and secular cycles are serendipitously arranged, concurrent to a president of sufficient skill taking office does presidential power indeed become strong. Where presidential scholars in the behavioralist tradition argued about a presidents character and temperament, and then drew reductionist conclusions about relative strength or weakness (James D. Barber, 1968; James David Barber, 1974), Skowronek provides a more compelling account of a generally weak presidency by incorporating policy feedback and path dependence approaches. Skowroneks focus on context and how the institution of the presidency interacts with time on multiple fronts is more explanatory and ultimately more convincing because of feedback concepts. 4.14.3 Conclusion The behavioralist tradition dominated political science through the 1980s, but functionalist theories did not provide a compelling picture of how policy processes interact with time. Emerging from that period, the notion of path dependence used extensions from economics but departs from the purely rational choice conclusions which dominated political inquiry through the 1980s (Cohen, March, &amp; Olsen, 1972; March &amp; Olsen, 1984). Using path dependence correctly can support claims from the historical institutionalists that the timing of events matters (Pierson, 1993), and offer a better causal explanation than the competing debates about isms which dominated previous political discourse (Tilly, 2001). Policy processes do not end at implementation but continue to have effects on future policy and politics. 4.15 Punctuated Equilibrium Theory Punctuated equilibrium theory (PET) (Baumgartner &amp; Jones, 2009; True, Jones, &amp; Baumgartner, 1999) is a policy process theory that borrows from biological science to describe long periods of policy status quo, suddenly interrupted by significant shifts in the policy landscape. Baumgartner and Jones recognized that the slow incremental policy changes predicted by the base linear policy model were not reflected in empirical policy evidence. Rather than slow, steady policy progress, they saw long periods of policy stability, which were then suddenly disrupted by sharp changes in short periods of instability. To the authors, this cycle seemed to reflect the sudden evolutionary adaptations seen in the biological sciences, as species maintain long periods of stability, with swift natural adjustments (Gersick, 1991; Gould &amp; Eldredge, 1977). 4.15.1 PET: Framework and Considerations Though more useful than its overly simplistic linear model of policy change, PET is still at its root a linear theory, albeit one with generally more relaxed assumptions about the rational nature of the individuals involved. For instance, PET assumes that people are boundedly rational (Simon, 1976) rather than perfectly rational. Similarly, PE recognizes that policymakers are boundedly rational  they have limited attention capacity, and cannot know everything about a policy issue, problem, or solution. Another critical concept in PE is that of framing (Zaller, 1991, 1992), which groups use to define how a policy problem is understood, in order to better position their preferred policy solution for consideration and adoption by lawmakers. Key to PET is understanding how attention is gathered, and by who. Early policy theories assumed electoral processes were the key to policy change, but in the face of policy stability across electoral outcomes, a fresh perspective was needed (Baumgartner &amp; Jones, 2009). Politicians and policymakers are boundedly rational (Simon, 1976), and along with those bounds come restrictions on how much information  attention  those people can give to policy problems. Attention gathers and dissipates without (necessarily) regard to electoral outcomes because policy problems exist before, during, and after elections. Even in policy areas where opposing parties/candidates hold starkly different policy views  a relative rarity itself  the winning candidate does not have the attention or capability to address all policy problems at the same time. Policymaking thus becomes a continual struggle between the forces of balance and equilibrium, dominated by negative feedback processes, and the forces of destabilization and contagion, governed by positive feedback processes (Jones &amp; Baumgartner, 2012, p. 3). Policy information feedback itself is an active area of research, even when it does not use PET overtly as a research framework (Mettler, 2002; Soss &amp; Schram, 2007). Similar to both multiple streams theory and advocacy coalition framework, the PET approach attempts to understand how policy groups operate to bring about policy change. PET uses key concepts such as agenda setting, policy monopolies, and venue shopping to explain how these groups overcome the natural tendency towards stability and continuity in the policy environment. With agenda setting, groups make strategic choices about to bring attention to their preferred policy solutions. If they worry that attention will risk derailing the policy, they will work to minimize attention. At other times, particularly with lawmakers reluctant to pay attention, the policy groups actively manage attention around a policy problem and solution in order to generate political momentum. Policy monopolies, which are reminiscent of the iron triangles of earlier policy studies (Jordan, 1981) develop in certain policy areas, and like in the advocacy coalition framework (Sabatier &amp; Weible, 2014), these monopolies can persist for long periods of time, as they work to maintain policy that reinforces their access to resources and policy influence. The answer for policy groups who find themselves locked out of a policy monopoly is what Baumgartner and Jones (Baumgartner &amp; Jones, 2009) refer to as venue shopping. If a group is locked out of the legislative policy arena, they may choose to change venues and look for ways to pass through their preferred policies at the executive or judicial levels of government. Punctuated equilibrium theory has much in common with another main approach to the policy process, the multiple streams framework (MSF) (Cairney &amp; Jones, 2016; Zahariadis, 2014). Both MSF and PET are heavily cited and relied upon in the policy process literature, and formed the basis for later, more complex approaches such as Sabatier and Jenkins-Smiths (1993; Sabatier &amp; Weible, 2007) advocacy coalition framework (ACF). Both PET and MSF benefit from a simplicity lacking in the later frameworks, and both suffer from that simplicity in the form of relatively little predictive power, though PET advocates rightfully point to a better record on this front than the MSF literature can boast. Both PET and MSF can be usefully applied to different policy contexts, and where one might be less useful, the other often provides a better analytic frame. 4.15.2 Applying PET Across Contexts Punctuated equilibrium policy theory was developed in the United States, and it provided a useful explanation of empirical policy changes there. Early use of PET theory (Baumgartner &amp; Jones, 2009) was used to explain US nuclear policy, which existed primarily out of public sight in the post-war period. Following decades of that stability, where the policy was left mainly to technical experts and legislative subcommittees, anti-nuclear power advocates were successful in challenging the positive image of the nuclear industry, and venue shopped their policy ideas to courts and the public. The existing policy monopoly was broken, and burdensome regulation of the nuclear industry effectively halted the expansion that had been seen in the post-WWII period. Following the early use in the nuclear policy arena, further testing of PET to predict shifts in nuclear budgets has provided further evidence for the predictive ability of PET in budgetary contexts (Hegelich, Fraune, &amp; Knollmann, 2015). The US government is structured in a divided power arrangement, which tended to reinforce status quo arrangements, and was seen as primarily responsible for the periods of policy stability. However, PET theory can be usefully applied in non-US contexts as well. A comparative study of policy regimes in the US, Denmark, and Belgium (Baumgartner et al., 2009) using data from dozens of processes across three nations and covering hundreds of thousands of observations found the same non-normal distribution of policy inputs and effects. This study provides strong evidence that it is not necessarily the US constitutional system which is providing friction in policy development and thus favoring the status quo. While all three countries in the study are democracies, there are enough structural differences to suggest that a General Punctuation Hypothesis can be applied in comparative contexts. Comparative study has also contributed to understanding PET in non-democratic contexts such as the Peoples Republic of China. Chan and Zhao (2016) find that the authoritarian Chinese government alienates opposition views, leading to a lack of information about problems outside the official government view. Without that information, the system is more susceptible to large punctuations, as problems are slow to gather the necessary attention necessary to address them, which undermines their ability and incentive to make frequent adjustments to the status quo (Chan &amp; Zhao, 2016, p. 148). When time authoritarian officials finally realize there is a problem, the nature of authoritarian regimes allows them to undertake radical changes unopposed (Chan &amp; Zhao, 2016, p. 148). This cycle means that over time, authoritarian governments are more susceptible to rapid, overly large shifts of punctuation after periods of stasis which are longer than they would be if there were more information available. 4.15.3 Conclusion Punctuated equilibrium theory is robust and retains its place as one of the most cited and useful modern theories of the policy process. It provides a framework that allows even non-scholars to connect with the relatively simple idea immediately  things tend to stay the same, until they do not. At the same time, it has enough complexity and flexibility to be adopted in varied political contexts. Flexibility and applicability have been key to its success as an approach to policy process studies. There are no final answers available to policy scholars, success in this context centers on the extent to which the idea is fruitful, by which we mean the extent to which it stimulates further research that itself raised more new questions (Jones &amp; Baumgartner, 2012, p. 1). What punctuated equilibrium theory may lack in predictive ability outside constrained systems such as budgeting (Flink, 2017), it makes up by offering a relatively low-barrier for both scholars and practitioners to understand critical aspects of the policy process. The stability brought by a disjointed American constitutional regime tends to support stasis  but in the wake of the rapid dissolution of structural and policy factors which supported that stasis, we occasionally see substantial shifts in the policy environment. 4.16 Social Construction of Target Populations Developed by Anne Schneider and Helen Ingram (1993; 1997), Social Construction of Target Population (SCTP) theory confronts an assumption of the linear process: that policymakers, and policy itself, are neutral or unbiased actors. Their argument is not itself post-modern but builds on post-modernist critiques of language which deconstruct the power relationships inherent in language (Foucault, 1991, 2005). Foucauldian discourse analysis is critical to SCTP (A. Schneider &amp; Sidney, 2009) and has been effectively used by researchers to understand how different approaches to language contain critical assumptions about how changes in policy relate to broader social change (Sharp &amp; Richardson, 2001, p. 193). 4.16.1 The SCTP Approach Schneider and Ingram (1993) show that elected policymakers adopt value judgments about the social groups that are impacted by policy programs and that those value judgments have an impact on the policies they create and implement. In this framing of political statements, some politicians will, for instance, use language which implies that individuals living in poverty are lazy and have created their own situation, arguments which may justify policies that withhold government benefits from that group (Ingram &amp; Smith, 2011). However, just as language can justify under serving certain social classes, it can also over-benefit others. The same politician may use language that confers noble, worthy qualities on business owners, which would then serve to justify policies that shift resources to that social class. Construction of target populations is not as simple as positive and negative populations though in the SCTP theory, and Schneider and Ingram illustrate this (Schneider &amp; Ingram, 1993) through their use of a two-axis notional figure, where measures of positive and negative constructions are paired with high and low perceived power constructions. Power in this use is the ability of a social group to accept or reject the image painted onto them. This conceptualization gives a four-category scheme of advantaged (high power/positive), contenders (high power/negative), dependents (low power/positive), and deviants (low power/negative) social groups. These simplistic categorizations of complex populations make it easier for politicians and governments to implement policies that over-serve the advantaged, while making it extremely difficult for deviant populations to even challenge their disadvantaged status in policy debates. This phenomenon creates a policy feedback loop (Pierson, 2000), as an advantaged group like homeowners not only are over-benefitted regarding resources granted by policy but then can reify their position in the social hierarchy, leading to more opportunity to implement even more policies which will benefit them. This system of self-reinforcing policy benefits is known as the feed forward proposition in SCTP theory (Pierce et al., 2014; A. Schneider &amp; Sidney, 2009) creates asymmetries of participation and power, and those asymmetries are reinforced by the system creating and accepting social constructions of the deserving and undeserving. This flaw in the system has long been recognized in political studies (Schattschneider, 1960; Schlozman, 1984), but SCTP offers a useful empirical starting point for understanding how particular social groups have been affected by policy choices influenced by social construction. One of the most potent critiques offered by SCTP is showing how these constructed beliefs about social classes not only have immediate effects on resource allocation but have effects on those social classes long after the policymaker has left office. This phenomenon is known as a feed-forward effect (A. Schneider &amp; Sidney, 2009), or in other political science literature as path dependence (Pierson, 2000). The feed forward proposition recognizes that the timing of policy choices matters, and policymakers select policies which have self-reinforcing feedback processes (Ingram &amp; Schneider, 2006; Pierce et al., 2014; A. Schneider &amp; Sidney, 2009; Soss &amp; Schram, 2007). These processes represent the resiliency of institutions that are far longer lived than the policy-makers tenure (Sanders, 2006). Path dependency imposes a cost to going back to a previous point, and the longer a policy scheme has lived, the higher the cost. In this way, earlier choices have more significant impact than later ones, as the policies themselves shape the institutions that house the policies (Mettler, 2002). SCTP offers a compelling critique of policy studies itself, as it uncovers how the language involved in policy can compel certain beliefs and narratives which can hinder, harm, or help certain classes of individuals (Sharp &amp; Richardson, 2001), even as policy scholars unthinkingly use the same language. Further, SCTP critiques the underlying, formative ideals of early public administration and political science, that of the neutral and unbiased bureaucrat, or public administration scholar. A considerable advantage to SCTP is that it invites, or even demands, methodological breadth in studying the policy process. In contrast to much of the policy process and design scholarship, which is focused on large quantitative studies, SCTP requires interpretive research methods (A. Schneider &amp; Sidney, 2009, p. 115) that allow the scholar to engage in meaning making (Yanow &amp; Schwartz-Shea, 2006) as they reflect on their research practices, their subjects of study, and the world making, the images of reality, the stereotypes people use to make sense of their reality (A. Schneider &amp; Sidney, 2009, p. 105). 4.16.2 SCTP and U.S. Historical Context From the founding of the American political system, the ideal of competing factions balancing the power of any one faction (Dahl, 1982; Madison, 1787) has provided a powerful argument that the U.S. Constitution and division of power among the federal branches would protect minority interests from the powerful machinations of the majority. However, the justifications of the pluralist federalist system were largely imputed by Madison and Hamilton into the Federalist Papers in a post-hoc manner intended to justify ratification of the U.S. Constitution (Peterson, 2012). V.O. Key (Key, 1963) was ahead of his time in noting the effects of sectionalist national politics on state politics and parties, noting that national political tides spill into local politics. Party cleavages at the national level project into state elections, with the national partys need to retain control used to justify the racist practices of the Southern Democrats of Keys time. This political macro reality can reduce the incentive for local and state politicians to perform well, as they justify their control  and pardon their own structurally biased practices  in the name of national party priorities. Consequently, rather than providing an intricate balancing wheel (Madison, 1787; Rohr, 1986) against the predations of a majority, the administrative and policy state SCTP theory allows us to see how policymakers and lawmakers, at least in some cases, can use the concealed power of language to prolong and protect the interests of the already powerful (Foucault, 1991). 4.16.3 Limits and Directions of SCTP One limit of SCTP is that it is less concerned with comprehensive theoretical explanations of the policy process, and so in cases where there are not clear-cut social classes at play, SCTP may be less robust. A limit of early SCTP theory was a lack of direction and application  what should individuals and advocates do with this knowledge? That critique has been substantially, though not wholly, blunted as more researchers have become interested in critical policy theories, and extended the original insights into examining the adverse effects of economic policy concentrated on women and African Americans (Andersen, 2001), food justice (Billings &amp; Cabbil, 2011), and Native American school children (Quijada Cerecer, 2013). While one of the oldest critiques of SCTP is that it lacked empirical application (Sabatier, 1999), a recent review of SCTP theory (Pierce et al., 2014) has identified 123 application and theory building publications. A second limit is that, at least in the original construction of the theory, little is said about how social classes might contest the ways they were constructed by policymakers and the public. SCTP has little to say about how, or more importantly why, one social group may attempt to help challenge the social construction of a less powerful one. Why for instance, would a feminist group  hypothetically located as a challenger in SCTP  want to help restore the voting rights of the formerly incarcerated? SCTP still has buried assumptions of rational choice, presenting the actions of the powerful as merely, or purely, self-interested. In her study of the gun control policy debates, Merry (2018) posits that argues that one way for the less dominant policy groups (in this case, gun control groups) to gain cohesion and power is through building exactly such cross-cutting alliances. Merry suggests nascent efforts of the groups Cure Violence and Gays Against Guns to highlight the role of race in gun violence (Merry, 2018, p. 764) can draw in the effort and interests of groups not traditionally aligned with gun control, such as Black Lives Matter. Such alignments are difficult though, and carry a risk that if the involved groups do not align their policy narratives, the effort can stymie momentum and give their opponents dominance in the policy area (Merry, 2018, p. 764). A final related critique of SCTP is the lack of explanation for how various socially constructed groups move from one categorization to another (DeLeon, 2005). SCTP recognizes that such moves take place, but understanding the underlying mechanisms by which such change takes place is an ongoing challenge for SCTP researchers (Pierce et al., 2014). 4.17 Political Participation 1 In response to: The ability of citizens to participate in politics and to influence government action is often considered to be one of the defining characteristics of democracy. Based on the research you have read, what do we know about who participates in politics, how they participate, and to what effect? 4.17.1 Who Participates? A core belief of democratic theory is that in order to function properly, a democracy must have citizens able and willing to participate, and that their participation must have the ability to influence the public policy decisions taken by the government. Political participation is at the heart of democracy, (Verba, Schlozman, &amp; Brady, 1995, p. 1), and only through participation can democratic citizens seek to control who will hold public office and to influence what the government does. However, citizens participate in unequal and varied ways, and their participation doesnt always equate to policy outcomes. In three parts, this essay will offer a brief overview of some of the important literature which informs our academic understanding of political participation. In the first section, the question of who participates? will be reviewed, with a focus on the unequal ways in which differing parts of the American electorate participate politically. Following that a review of the differing methods of participation are covered. Finally, the connection between political participation and government action is considered. 4.17.2 Unequal Participation While Americans generally endorse the normative democratic belief that everyone should have a voice in politics, the reality is that there are distinct patterns of participation, patterns which serve to distort that normative ideal (Bartels, 2016). The most important pattern throughout studies of participation is that socio-economic status matters a great deal, and that citizens with education and money participate; the poor and uneducated do not. As a consequence, the interests of the affluent are well represented in government, and those of the less advantaged are not (Flanigan, Zingale, Theiss-Moore, &amp; Wagner, 2014, p. 60). Perhaps the most influential scholar of political participation is Sidney Verba, and his work alongside Norman Nie (1972) in Participation in America has shaped how participation is studied and understood. Verbas work centered socio-economic status (SES) at the center of participation studies. The SES model of participation posits that a persons income, education, and class status affect their likelihood of (Verba and Nie, 1972, p. 2) acts that aim at influencing the government, either by affecting the choice of government personnel or by affecting the choices made by government personnel. SES remains the most accepted, central, explanatory factor in political participation. In Pathways to Participation, Beck and Jennings (1982) examine the formations of political participation from a sociological standpoint, using panel data from the second iteration of the survey used by Jennings in earlier work (Jennings and Niemi, 1968). The authors seek to differentiate between types of participation, such as activities, and to show that voting is just one of those methods. They structure four path models, testing effects of parental SES, parental political participation, high school activity, and parental civic orientations, and find each model performs well. Still, their findings show that SES and education continue to have the largest effect. They are successful in finding that education level has a larger effect than income, but the two are highly correlated and work slightly differently in how they affect participation. For the most part, the authors use clear theoretical framing and empirical evidence, with the exception of their finding that high school activity participation has a positive effect on civic orientation. Its not clear that activities lead to civic orientation as they claim, and a reverse causal relationship is just as conceivable. Even with that critique, and despite their theoretical stance, Beck and Jennings findings serve to further reinforcing just how important SES is in the participation literature. With SES so clearly in the foreground of the participation literature, some scholars soon turned their attention to the affect of race, which is correlated with SES, on political participation. Race matters broadly for participation. Non-white people, especially black and Latino populations, have less political information. One of the most interesting and replicated findings to come out of Participation in America (Verba &amp; Nie, 1972) is that once SES is controlled for statistically, black Americans are more likely to participate than white Americans. Verba and Nie theorized this was due to a race consciousness in black Americans, and found support during interviews where they found that black respondents who mentioned race were more likely to participate than those who didnt. For African-Americans in particular, race matters in participation, but in voting specifically, this difference is less clear. Once you control for SES, race matters less, but in the full range of political participation, race matters a lot. Most scholarship shows that blacks participate less than whites, and Hispanics less than blacks, though in recent years, black and whites have relatively similar rates of political participation once SES is accounted for. Bobo and Gilliam (1990) test the race consciousness theory with a hypothesis that black citizens living in areas with black mayors are more likely to participate. While their findings support the hypothesis, their assertion of causal direction is problematic, as it appears just as likely that it is the political participation of black citizens which leads to black political leadership in the community. Further, Bobo and Gilliams theory implies a robust time effect, but their reliance on cross-sectional 1987 survey data is unsuitable to test that theory. Differences in how men and women participate politically is a continuously salient question for scholars. Stanley Verba has, of course, investigated, this time with co-authors Nancy Burns and Kay Schlozman in The Public Consequences of Private Inequality: Family Life and Citizen Participation (Burns, Schlozman, and Verba, 1997). While the researchers began with a theoretical disposition which assumed women participate less than their male partners, their findings did not fully reflect those assumptions. Using a national telephone survey, the research team narrowed down to a sample (n=609) which contained both married and unmarried individuals. Married couples were both interviewed by phone separately. While the researchers expected the household roles of women to suppress their political participation, the research found instead that it is mens household roles which affect male participation. Men with more free time and control of financial resources tended to equate to greater political participation, while womens participation was boosted when both partners held beliefs of gender equality. The latest wrinkle in modern studies of political participation is the growing scholarship on the network and social effects which affect participation. Gerber, Green, and Larimer (2008) offer an excellent example of this research in their piece Social pressure and voter turnout: Evidence from a large-scale field experiment in which they used a large, sophisticated experimental design to test the effect of social surveillance on voter turnout. The authors sent single postcard sized mailers with one of four simple messages, using a stair-step approach of increasing social surveillance pressure  civic duty (voting is your duty as a citizen, least pressure), the Hawthorne effect (researchers are watching), the self message (showing the recipients voting record), and the neighbors message (most pressure, showing their neighbors voting record). While the magnitude of effect for the messages was relatively small, only a couple percentage points increase to turnout, the finding that every increased level of social pressure had a corresponding statistically significant amount of increased turnout was clearly an advance in participation scholarship. This research has been replicated since (Sinclair, 2012), although with most researchers finding lower magnitude of effect, and remains a touchstone of modern work in participation. Sinclair (2012) extends the work of Gerber, Green, and Larimer (2008) by testing how social pressure affects a variety of participation modes  voting, political canvassing, affiliate with political parties, and political donating. The findings of Gerber, Green, and Larimer (2008), and Sinclair (2012), do not fully depart from the SES model, which remains the dominant theoretical model for understanding political participation. But their work does expand theoretical structure of the field in ways that are appropriately reflective of the modern context in which participation is taking place. 4.17.3 Modes of Political Participation The most visible and common act of political participation is voting. Americans love the idea of voting, but in practice fall short of the ideal of one vote for every voice. The most basic measure of voting is turnout, measured as the percentage of eligible voters who actually cast a vote in an election. Studies of voter turnout form one of the largest subsets of American behavior literature, and confront the most basic discrepancy in American democracy (Powell, 1986): In a country that holds the citizen vote in such high regard, why do so relatively few Americans regularly vote? In the international comparative context, American turnout rates are low, as other industrialized democracies have consistently had higher rates. Generally, American presidential elections hover around the 50% turnout rate, though in recent elections that number has begun to reach back towards 60%. Still, this modern rate appears to be low even compared historically, as turnout between 1860 and 1900 was between 70% and 80% (Gans and Mulling, 2011). Most scholars accept the beginning premise that voting turnout has significantly declined, and their research reflects that broad research question. And while that research orientation is broadly true for the literature, its worth noting that some scholars claim methodological problems with how turnout has been calculated are responsible for creating the false impression of declining turnout (McDonald and Popkin, 2001). Measurement debates aside, studies of how Americans participate politically represent a very large literature. Power (1986) does a good job explaining the institutionalist concerns, and finds that restrictive voter registration laws and declining party affiliation caused a decline in voter turnout beginning in the 1960s. Registration laws have liberalized since Powells work, without the hoped-for return to earlier turnout levels, casting some doubt on that portion of his findings. Still, party identification continues to be a robust variable in voting choice models, particularly the historically dominant Michigan model established with the publication of The American Voter (Campbell, Converse, Miller, &amp; Stokes, 1960). Abramson and Aldrich (1982) also identify weakening party affiliations among voters, as well as declining beliefs in external political efficacy, as correlated with the decline in turnout. They show that party affiliation matters, with strongly affiliated partisans voting at a higher rate than those without strong party affiliation. This helps explain the historical trend of a decline as well, as in the past the U.S. populace has had very high partisan affiliation among voters, and so the empirical decline in party affiliation makes sense theoretically as well. Many modern scholars see the sharp decline in turnout in the post-1964 era as rebounding to some degree, with some attributing these trends to inter-generational changes related to broad value changes across countries as overall standards of living have increased (Inglehart, 1971; 2018). Theories of socialization in voting behavior as discussed earlier, such as those used by Beck and Jennings (1982) have tended to be less popular in the recent literature, but Eric Plutzer (2002) revitalized the basic theories, using the third iteration of the data used earlier by Beck and Jennings (1982) and Jennings and Niemi (1968). Plutzer brings sophisticated methodology to propose a new model of voting which takes into account the path dependence of voting, as he finds that once a citizen begins voting, they tend to vote in subsequent elections. Again, SES and education levels dominate the other variables in predicting whether someone will participate through voting, but Plutzers findings are compelling and offer an advancement of the basic turnout model. The most obvious and common way to participate politically is by voting in elections, but other methods exist as well. Citizens express their opinions in political discussions, shaping and being shaped by other participants. They donate to political parties and individual politicians with whom they agree. They become political activists, join social groups, and canvass their neighborhoods in support of political candidates. Alexis De Tocqueville (1835) famously commented on the willingness of Americans to associate themselves in voluntary organizations. While this willingness continues to be a mainstay of American political participation, scholars such as Robert Putnam (2000) have grown concerned that declines in participation in voluntary associations has led to a decay of social capital, a change that threatens the stability of American political life. However, other work finds that while some forms of associational participation have declined, it has been replaced with increased participation through other modes such as political donations and directly contacting elected officials (Verba, Schlozman, &amp; Brady, 1995). Familiar scholar voices return to the discussion of differing participation among Americans in Citizen Activity: Who Participates? (Verba, Schlozman, Brady, &amp; Nie, 1993). The authors are responding to other scholars findings that voters and non-voters are similar demographically. Using a dataset designed to oversample political activists, the paper seeks to find if activists and non-activists are also demographically similar. They find that the two groups have similar beliefs, but differ in how they participate, and that the differences matter. Activists tend to have higher SES, and far fewer activists come from the lowest SES groups. However, those activists who do come from lower SES backgrounds are more effective in communicating their personal stories of human need to politicians whom they contact. This finding has been widely cited in participation literature due to the basic finding that SES affects how someone participates through political communication. 4.17.4 The Electoral Connection and Democratic Effects In Public Opinion and American Democracy, V.O. Key (1961, p. 7) emphasizes the important link between political participation and the ability to influence government action, insisting that Unless mass views have some place in the shaping of policy, all the talk about democracy is nonsense. To that end, scholars have gone to great effort in attempting to locate the effect of public participation and opinion on public policy. David Mayhew (1974) produced one of the most enduring theories in the field in his book The Electoral Connection, where he lays out a stark case that only re-election matters to members of Congress (and to some extent, other elected officials). Given that claim, which is still firmly attended to by most, the voting publics opinions on policy ought to matter a great deal, and their political participation taken to express those opinions as well. Larry Bartels focuses a great deal of attention on the ability of the public to influence public policy in chapter eight of his book Unequal Democracy: The Political Economy of the New Gilded Age (2016). Bartels basic thesis is that economic inequality is growing, and that growth has political, not just economic effects. In chapter eight he presents his findings that economic inequality leads to a lack of representation of the views of low income Americans, and that senators attach little or no weight to the preferences of low-income constituents and that the political views of the poorest third of Americans receive little or no weight in the policy making process (Bartels, 2016, p. 259). One might be tempted to simply connect this lack of representativeness back to the discussion of SES earlier: if poorer people vote less, isnt it sensical that elected politicians would tend to represent the views of poor people less? Bartels shows, however, that the magnitude in turnout differences between rich and poor groups are too small to correlate well with how senators vote against the policy preferences of the poor. In the end, he finds that while affluent Americans can influence the policy process through both direct and indirect processes, poorer Americans are really left only with indirect methods, such as when less-affluent Americans vote as a group in such a way that close elections are decided by those votes. For democratic theorists, there is a normative connection between the two  public opinion ought to affect policy if in fact the polity has control of government. Reflecting that ideal, scholars have attempted to connect Americans political participation to the policy outcomes of their government, with mixed success. For many years the literature failed to establish correlation, let alone causation, between public opinion and public policy. But beginning in the late 1980s and 1990s, two primary types of research in this area were established (Monroe, 1998)  studies of congruency and those of consistency. The classic congruency study is Effects of Public Opinion on Policy (Page &amp; Shapiro, 1983), which uses survey data collected over multiple decades. The authors use similarly worded questions from across the time periods, and then attempt to correlate policy shifts from before the first time period a question was asked, and after the next time it was asked. Page and Shapiro are able to establish that when a shift in public opinion is detected (they look for shifts larger than 6% in aggregate opinion), there is a correlative policy switch approximately two-thirds of the time. This is a higher percentage than most expected, as most previous research had failed to find any connection between public opinion and public policy. However, given the lack of causal connection the authors were necessarily reserved in their claims. While Page and Shapiro represent the congruency approach, Monroe (1998) places himself in the consistency camp of researchers, which compares how the distribution of policy outcomes with the distribution of public opinion. Monroe compares two time periods, 1960-1979 and 1980-1993, and finds that in the later period public policys consistency with public opinion had dropped from 63% to just 55%. Monroe attributes this relatively low consistency to institutional reasons connected to the inherent bias against change in the American political system. Monroe goes further than Page and Shapiro (1983) by further stratifying his samples of opinion and policy into substantive policy area, allowing him to detect that, for example, in foreign policy, there is nearly 100% consistency between public opinion and policy change. Like Shapiro and Page, though, Monroes methods limit him to correlation claims rather than causal ones, and in the case of foreign policy, the nearly 100% correlation leads one to believe that at least a significant portion of the consistency is due to policy affecting public opinion, rather than the opposite. While the research considered here has so far been concerned with national-level issues, Erickson, Wright, and McIver (1989) offered an interesting variation, locating the discussion in state-level research. The most important finding to come out of this work is that state electoral forces are the most important factor in the correlation  or lack of it  between public opinion and public policy. Using complex path models, they demonstrate that ideological variation between states makes comparisons very difficult - i.e. a Democrat from Alabama is probably more conservative than most New York Republicans. State policy outcomes do represent state opinion preferences, but party control of a state legislature is not a good predictor of state policy, as the party activists and the centrist voter tend to be pulling politicians in different directions than the national party. 4.17.5 Conclusion When observing American political participation, demographics matter. Wealth, income, class, and education measures continue to provide the greatest explanatory power for researchers interested in questions of who participates? E.E. Schattschneider famously made reference to the political bias for the wealthy in The Semisovereign People (1960), writing The flaw in the pluralist heaven is that the heavenly chorus sings with a strong upper-class accent. Socioeconomic status continues to be the most powerful explanatory factor for determining who participates, how they participate, and whether their participation is able to substantively influence political and policy decisions in their favor. Americans do participate differentially in politics, in voting as well as other modes, and that participation appears to have differing effects on politicians and the public policy they implement. 4.18 Political Participation 2 American political scientists have been addressing questions of political participation since the beginning of the field. Estimates of voting participation, which is the most commonly studied mode of participation, show that between 1860 and 1900, national voter turnout was between 70% and 80% (Gans &amp; Mulling, 2011). In the modern era however, turnout has sharply declined (Abramson &amp; Aldrich, 1982), particularly after the 1960 election cycle, and turnout levels of approximately 50% in most presidential elections are the new normal. Sidney Verba is perhaps the most influential scholar in the participation literature, as he centered SES measures in the calculus of participation. The predominant modern model of political participation is the socio-economic status (SES) model, which posits that a persons income, education, and class status affect their likelihood of acts that aim at influencing the government, either by affecting the choice of government personnel or by affecting the choices made by government personnel (Verba &amp; Nie, 1972, p. 2). SES remains the most accepted, central, explanatory factor in political participation. Socioeconomic measures remain central to understanding American political participation, but the research remains robust as scholars continue to seek a more complete model, expand what participation means, and make use of increasingly sophisticated research methods. Covering the whole of participation literature is an impossible task in any writing length short of a book, and so this essay will proceed in three main sections. First, a brief introduction to the literature looking at participation broadly, with a focus on the influential work asking questions about who participates, and the correlates associated with participation. The second section turns to the specific question of voting turnout, and presents five competing explanatory theories of institutions, attitudes, habits, pressure, and conformity. 4.18.1 Who Participates and Why? Beck and Jennings (1982) provide an overview of the essential concerns of those political participation scholars. The authors use the second iteration of the data set used by Jennings in his earlier sociological work (Jennings &amp; Niemi, 1968), with the continuing research forming panel data for the researchers to use. The authors attempt to rehabilitate (or perhaps simply extend the end-of-life of) political socialization in the face of growing theoretical reliance on rational choice explanations that were becoming popular (Aldrich, 1976). While not successful in that goal, they do nicely lay out the sequential argument, testing four separate path models, and then combining those into a final model. They give credence to the rising acceptance of the SES model of participation (Verba &amp; Nie, 1972), including early work showing that economic adversity such as unemployment and poverty work to suppress political participation and turnout (Rosenstone, 1982). In addition to those effects in adulthood, Beck and Jennings (1982) find evidence that pre-adult forces also affect participation. They single out parental socioeconomic status, participation, and civic orientation, as well as youth school activity, as having statistically significant effects. Still, the traditional components of SES  education levels and income  have larger effects. Beck and Jennings weakest causal claim is related to the youth activity levels, as it is just as likely that young adults already interested in political participation are more likely to have more activity engagement, thus undermining the causal path suggested by the authors. Finally, the representativeness of the sample must be questioned, as the dataset does not include those young adults who have dropped out of high school. As high school completion is already highly correlated with socioeconomic factors (Mare, 1980; Toutkoushian &amp; Curtis, 2005), it is likely that Beck and Jennings models would show even stronger SES effects if the sample were truly representative. Narratives are an increasingly salient area of policy study (Epstein, Farina, &amp; Heidt, 2014; McBeth, Jones, &amp; Shanahan, 2014) and build upon early work on how personal narratives and participation intersect. Recall that Stanley Verba helped shaped the field of political participation research, and in Citizen Activity: Who Participates? he and his co-authors (Verba, Schlozman, Brady, &amp; Nie, 1993) narrow in on political activism as a specific, non-voting form of political participation. While voting turnout is relatively low historically and comparatively, becoming an activist is even rarer. The authors are addressing earlier findings which showed that both voters and non-voters as groups are similar demographically and ask: Ddoes the same apply to activists and non-activists? To answer the question, they use national survey data designed to oversample political activists (ANES). They report that while the two groups have similar beliefs, there are SES differences within activists and non-activists, and further, that the differences matter. Activists with lower SES backgrounds tend to use more compelling, humanistic stories based in their own experience when they are speaking to policy and law makers. But because of their disadvantaged SES backgrounds, there are relatively fewer activists within that SES group. This finding has been replicated and widely cited due to the core finding that SES status affects the messages that someone communicates politically, which is a distinction worth noting. Reflective of the impact of Verbas work, Lawrence Bobo and Franklin Gilliam (1990) test one of the most influential findings from Participation in America (Verba &amp; Nie, 1972): that once socioeconomic controls are introduced, black Americans actually participate politically at a greater rate than their white counterparts. Verba famously theorized that this was due to a group consciousness, which was supported by findings from interviews that black respondents who talked about race more often were also more likely to politically participate. Bobo and Gilliam (1990) are motivated by that theory, and test their hypothesis that black citizens living in areas with black mayors are more likely to participate. They find empirical support for their hypothesis, but ultimately their findings are significantly undercut by both causality problems as well as a mismatch between theory and method. Causally, it is not clear that it is black political leadership that is causing increased black political participation  and in fact the reverse is quite more likely to be true, as the black political leadership must be campaigned for and voted for, and those actions are very likely to be undertaken by black supporters who are already participating politically. Further problematic is that the authors theory implies a durable time effect  that with black political leadership in place, black participation ought to increase over the term of that leadership. However, the authors use only cross-sectional data from a 1987 General Social Survey (GSS) dataset (National Opinion Research Center, 1941). This limitation is quite likely tied to limits on the dataset itself, as the 1987 GSS intentionally oversampled black respondents. Regardless of reason, however, the causal and methodological problems limit the confidence we can have in the findings. Stanley Verba and Kay Schlozman return as co-authors in The Public Consequences of Private Inequality: Family Life and Citizen Participation (Burns, Schlozman, &amp; Verba, 1997), reporting on a survey study of married couples and political participation. The authors begin their study with the accepted theory of the time that because women are oppressed within the family structure, it is likely their political participation is lowered. Despite this theoretical orientation, and to their credit as academics, they report findings not fully in-line with their prior expectations. The study started with examining a large national telephone survey, and then narrowed the scope to identifying a randomized sample (n=609, married n=380). Researchers then interviewed the smaller sample in detail by telephone regarding their household roles and political participation. Rather than finding that household roles suppress women, the authors contribution is that roles affect men. Specifically, free time and control of household resources matter for men, while womens political participation is enhanced by beliefs in gender equality, both their own and their partners. 4.18.2 Turnout: Institutions, Attitudes, Habit, Pressure, or Conformity? While voter turnout  the proportion of citizen who do vote, compared to the population that are eligible to vote  is covered briefly by some of the authors covered in the first section of this essay, there is value in covering the different theoretical orientations that have developed around this most visible, and most heavily researched, aspect of political participation. Rational choice theories gradually replaced the sociological explanations for political behavior broadly beginning in the 1980s. The earliest rational choice and turnout work (Riker &amp; Ordeshook, 1968) constructed a model in which the choice to vote was equal to the benefits times the costs, plus a duty measure, minus the costs of voting. Turnout was fit more specifically into rational choice theory over the next few decades, with mixed results (Aldrich, 1993). Overall the rational choice orientation has not proven well-suited to explaining why people choose to vote, or not (A. Blais, 2000), though there are some research agendas still focused on exploiting the theory in experimental conditions (Duffy &amp; Tavits, 2008), or to explore informal social networks (Abrams, Iversen, &amp; Soskice, 2011). As noted in the beginning, most scholars accept the beginning premise that voting turnout has significantly declined, and their research reflects that broad research question. And while that research orientation is broadly true for the literature, it is important to note some scholars claim there are methodological problems with how turnout has been calculated that are responsible for creating the illusion of declining turnout (McDonald &amp; Popkin, 2001). Once the calculation problem is corrected, the true historical turnout pattern is fairly stable, with a surge of voting in the 1950s. What factors led to this surge, they claim, should be the focus of turnout-related research. An example of such focus is research that shows lower participation in Canadian elections is due to life-cycle and generational effects, as post-baby boomers are less likely to turnout (A. E. G. Blais, Nevitte, &amp; Nadeau, 2004). The turnout measurement debate continues and researchers continue to propose more rigorous and accurate turnout metrics (Stockemer, 2017a), but there is still no single accepted model of turnout regardless of measurement preference. This remains one of the largest research literatures in political behavior, if not the largest, as comparative research continues to grow as well. Meta-analysis of the turnout literature finds that even the most accepted model of turnout may not be correct, and that turnout might be more complex than the current theory suggests and is rather more context dependent (Stockemer, 2017b, p. 698). In particular, comparative studies suggest that increased turnout is expected when there are 1). compulsory voting laws, 2). in small nations, 3). when an election is perceived to be important. Regional attachment and autonomy can increase the perceived importance of elections, leading to higher turnout (Henderson &amp; McEwen, 2010). Perceptions are also important as they relate to how people perceive the integrity of elections, as they are less likely to vote when there are doubts about the fairness of the process (Birch, 2010). So, what are the common theories of turnout? This essay covers five: theories of institutions, attitudes, habits, pressure, and conformity. Powell (1986) structures the major institutionalist concerns, many of which are still within the scope of modern scholarship. Powell lays out one of the fundamental questions of turnout: Why does the American populace, which has the political attitudes and educational levels that are associated with higher turnout, lag behind other institutionalized democracies in voting turnout? In this study two primary institutional factors are linked to turnout  voter registration laws and the U.S. party system. Overly onerous registration laws depress turnout by 14%, while a party system without clear class affiliations (such as those found in the UK and other European countries) depresses it by another 13%. With the benefit of retrospect, Powells findings on registration laws are not appear as robust as he hoped, as the US registration laws have largely liberalized since his research, without the hoped for significant increase in turnout. However, his party-linked findings are still useful in examining the US system. From a broad perspective, both registration laws and party linkages are of continuing concern in turnout research. Abramson and Aldrich (1982) examine the effect of political attitudes, specifically attitudes towards political parties, on turnout. Like Powell (1986), these authors were interested in what had caused the precipitous decline in voting turnout after the 1960 election. They identify weakening party affiliations among voters, as well as declining beliefs in external political efficacy as correlated with the decline in turnout. Political efficacy belief is when a person believes that government will be responsive to their political participation. This contributes to the theoretical link between declines in political efficacy belief and reduced turnout  if a voter does not think their political activity will result in government action to address that activity, they are less likely to engage in the activity in the first place. This is related to other research linking perceptions of unfair electoral practices and lower turnout (Birch, 2010). Abramson and Aldrich are able to show that party affiliation matters, with strongly affiliated partisans more likely to vote than those without strong party links. Historically the U.S. populace has had very high partisan affiliation among voters, and so the empirical decline in party affiliation matches the theoretical predictions as well. Following the research of Abramson and Aldrich(1982) and Powell (1986), scholars have been able to identify some of the reasons behind the central puzzle of declining turnout post-1960. A generational effect may be responsible (Inglehart, 1971, 2018). The WWII post-war generation had unusually high beliefs in good civic values, while the generation that followed did not share in those same beliefs, leading to a decline in turnout. Similar to generational effects, further research has located the inertial effects of voting  that is, people who vote tend to continue to vote, while non-voters tend to continue to abstain. Eric Plutzer (2002) suggests a developmental theory of turnout. He applies modern, sophisticated methodology to relatively old data, using the third wave of the Student-Parent Socialization Study (Jennings &amp; Niemi, 1968). Plutzers research is the rare resurfacing of socialization theory, while using individual-level time-series analysis to identify the factors behind an individuals decision to vote. Plutzer offers a new framework of voting habit, which includes a starting level (probability a person will vote in first eligible election) and measures of inertia (person continues voting). He identifies factors which influence both starting level and inertia. When first eligible to vote, parental SES and political resources largely define the probability of voting, and continues to be influential in subsequent elections, though that influence declines as the individual voters accomplishments increase. While Plutzers findings are not necessarily surprising, by identifying voting and not voting as habits he contributes compelling findings and theory that advance the overall model of turnout. 4.18.3 Turnout, Social Pressure, and Field Experiments One growing trend in turnout research is that of social pressure, and there has been robust field experiment work in this area, which will be the focus in this section of the essay. The foundational research in this line of research was a large-scale randomized field experiment that showed nonpartisan phone calls were ineffective at increasing turnout, while canvassing and direct mailers had small positive effects (A. S. Gerber &amp; Green, 2000). The original results were replicated in part soon after (Green, Gerber, &amp; Nickerson, 2001), with an experiment in six cities showing that door-to-door canvassing resulted in an approximately 7% increase in turnout. Nickerson (2007) rehabilitats phone-calls a few years later by showing that they can increase turnout, but only when the quality is high, and in separate work (D. W. Nickerson, 2007) demonstrates that nonpartisan emails had no significant effect, though other research shows emails can be effective (Malhotra, Michelson, &amp; Valenzuela, 2012). The formative research is from some of the same authors (A. S. Gerber, Green, &amp; Larimer, 2008). Using a sophisticated, large field experiment design, the authors sent single postcard sized mailers with one of four simple messages, using a stair-step approach of increasing social surveillance pressure: 1). civic duty (voting is your duty as a citizen, least pressure), 2). the Hawthorne effect (researchers are watching), 3). the self message (showing the recipients voting record), and 4). the neighbors message (most pressure, showing their neighbors voting record). While the magnitude of effect for the messages was relatively small, only a couple percentage points increase to turnout, the finding that every increased level of social pressure had a corresponding statistically significant amount of increased turnout was astounding. In the same year that Gerber, Green, and Larimer (2008) firmly established the effect of social pressure on turnout, Nickerson (2008) uses similar methods to demonstrate the strong effect of spillover. That is, around 60% of the effect of canvassing directly on one member of a household is passed on to other members of the household. The spillover effect (Nickerson, 2008) has arguably become more important as time has increased research into the social effects of interventions on turnout (Sinclair, 2012). Gerber, Green, and Larimers social pressure research has since been replicated and strengthened as researchers advance the fields understanding of social network effects, with small but statistically significant effects from social pressure found across political participation contexts, including voting, political donations, candidate selection, and party identification (Sinclair, 2012). This moves the field beyond even pressure and begins to show how individuals conform to their social network. As shown by Sinclair (2012), individuals conform to their geographic and social network pressures in party identification. For example, Republican individuals who have close friends who are Democrats do not necessarily change party identification, but they do begin to retreat from public declarations of party affiliation. Similarly, small subsets of individuals who identify as having conservative beliefs vote for Democrats in presidential elections, and the same phenomenon occurs with liberals voting for Republican candidates. Sinclair shows that the strongest predictor of this cross-ideological voting is that the individual lives in an area with strong partisan leanings opposite their ideological beliefs. Social media is playing a larger role in turnout research. The largest election day study (Bond et al., 2012) of approximately 61 million Facebook users showed that simple I Voted messages combined with faces of their friends induced hundreds of thousands of users to vote. Teresi and Michelson (2015) show that Facebook mobilization efforts are successful in increasing turnout among college students, even with motivation from online friends who are not well known. Finally, the social pressure from shaming and praising Facebook friends for not voting or voting can significantly increase turnout (Haenschen, 2016). There is much more to explore before the full scope of social effects on political participation is understood, but the beginnings of this area of research is very promising. There is growing evidence that the treatment effect of social pressure on turnout is heterogenous (Arceneaux &amp; Nickerson, 2009; Coppock &amp; Green, 2016), and that social pressure mobilization efforts are primarily having an effect on people who are already likely to vote, whereas there is little effect on l0w-propensity voters (Enos, Fowler, &amp; Vavreck, 2014). Meta-analysis of research on social pressure and voter turnout has shown that the average treatment effect for all modes of contact increases when there is a personal element to the outreach, while those lacking the social pressure component generally have no effect (Green, McGrath, &amp; Aronow, 2013). Nickerson has continued to contribute in this area, with his recent demonstration that canvassing for voter registration has an indirect but significant positive effect on turnout (D. W. Nickerson, 2015). 4.18.4 Conclusion This essay has progressed from the broadest conceptions of participation, narrowed to turnout as one aspect of participation, and then narrowed further to look at one theory of turnout. The selection of social network effects on participation as the most focused aspect of the participation literature was not accidental, but intended to reflect the intensity of research in that area going forward (Cox, 2015; Gerber &amp; Green, 2017). It is not surprising that in a world ever-more increasingly connected through virtual social networks that academic research would tend to grant greater resources to exploring the impact of our social selves on traditional political science questions. There is growing acceptance that social environment determines individuals political choices and participation, (Sinclair, 2012, p. 153), and while there is not yet a widely accepted explanatory model of participation, it seems clear that at least marginal increases to the canonical SES model can be found in exploring our social selves rather than simply describing our demographic traits. 4.19 The Weak American Presidency An enduring debate within American political science is whether the office of the presidency is fundamentally strong, or weak. In this paper I will argue that the presidency is indeed an institutionally weak office: It was created constitutionally weak, operates largely constrained, and even in those moments where a truly strong President appears, it is due to cyclical circumstances largely outside of their control (Skowronek, 1993). Many theorists have lined up on the strong side of the debate, but in the end they focus to much on small slices of what presidents do (such as executive orders) and mistake the actions of a few skilled presidents who had the fortune to take the office in a fortuitous time as representative of an office which has the vast majority of the time operated in a context where it was constitutionally and politically constrained. 4.19.1 Presidents are strong The American political system is based on the sharing of power between the executive, legislative, and judicial branches. In the pluralist tradition, the president is strong by virtue of being an equally balanced member of the American governmental triumvirate. In Federalist #51, James Madison (1787) lays out a theory of early pluralism, famously writing, Ambition must be made to counteract ambition. In constructing the office of the presidency, the founders sold the idea that the executive branch, would be just as strong as the other two branches. In creating three separate, independent, and conflictual branches of government, Madison argues, the country would avoid the tyrannies of both the majority and the despot. Pluralism dominated early American political science, yielding only slowly and never fully, and pluralist assumptions can still be found being usefully applied, albeit it in a substantially altered manner, such as in Neustadts (1991) work on presidential bargaining. Prior to the rise of new institutionalism (March &amp; Olsen, 1983), political science primarily saw the presidency through contextual, utilitarian, reductionist, functionalist, and instrumentalist theories. Politics broadly, and the presidency specifically, were separate from larger society, and susceptible to exogenous events, primarily reactive. Political scientists searched for behavioral and economic theories to explain politics, which they believed could be understood as individuals acting out of self-interest. Most damningly these theories saw the American political system functionally, misappropriating evolutionary theory (1983, p. 735) to see history as an efficient mechanism for reaching uniquely appropriate equilibria. Early presidential political scholarship did not focus on the institutional factors of the office, and academic renderings of a weak or strong presidential office were rendered through psycho-biographical scholarship. In this tradition are authors like James Barber (2017) and Fred Greenstein (1994). These authors essentially argue that good presidents are inherently strong, brilliant men, and bad presidents are inherently weak men. Barber in particular argues that presidents fall into a two-by-two matrix: active positives, active negative, passive positives, and passive negatives. This tradition eventually provides unsatisfactory answers, due to the post-hoc nature of the examination. Critics rightly point out that Barber does not leave room for agency on the part of presidents, as essentially how they will act as presidents is pre-determined from an early age. Further, Barbers methodology leads to surprising category assignments for some presidents, such as asserting that President Clinton was an active positive when his presidential performance would lead most to believe he was an active negative, at least under Barbers assignations. William Howell and David Lewis (2002) write within the tradition of scholars who see the presidency as strong, particularly within a context of a weak (and weakening over time) Congress. They see presidents strength in unilaterally creating agencies outside of Congress control (and often against their wishes), which in turn expands presidential power. The measure of congressional weakness continues to have significant and positive effects on the number of executive-created agencies each year. When Congress is weak, presidents create more agencies by executive action, and through path dependence (Pierson, 2000) those agencies accrue further power to the president. Andrew Rudalevige joins the chorus of early 2000s scholarship which saw a resurgent presidency, strong and growing stronger. The presidency (in this case President George W. Bush) was increasingly free to take unilateral action, particularly in foreign affairs. Democratic accountability weakened in a post 9/11 America, with increasing governmental secrecy and a Congress unwilling to confront the president, and Congress members were increasingly dependent on the executive branch for information, weakening the separation of powers. Slightly preceding Rudalevige but with findings that support his belief in a strong, expanding executive branch, Howell and Lewis (2002) test whether federal agencies created via the executive branch are less vulnerable to congressional oversight, and find that they are. The ability to act unilaterally to create administrative agencies stands out as one of the most important characteristics of the modern presidency, (p. 1113), they write, and indicates a strong presidency in the face of a Congress burdened by institutional factors which makes is weak in relation. Bolton and Thrower (2015) pick up on Rudaleviges assertion that increasing use of the executive order to bypass Congress is an example of a strengthening presidency and decide to test it. They test two related hypotheses, (1) that prior to the 1940s when Congress had low legislative capacity, Presidents issued more executive orders, and (2) that post-1940s, as Congress had increased capacity, Presidents issued fewer executive orders. Bolton and Throwers analysis finds that indeed, presidents used the executive order less in the post-war period, casting some doubt on Rudaleviges theory of an expansive and strong presidency. In hindsight, Rudaleviges conviction in a renascent imperial presidency may have been overly dependent on a single war-time president, George W. Bush. Further, as Bolton and Thrower admit in their conclusion (2015, p. 661), conceptualizing a presidents power as being strongly related to the number of executive orders issued is problematic, as these are by no means the only way Presidents exercise unilateral power. Memoranda, proclamations, signing statements, national security directives, and regulations all serve as vehicles for presidents to potentially circumvent the legislative process. One could easily add more that Presidents do without Congressional approval. Presidents give speeches, conduct foreign travel and relations, conduct limited (many would argue the modifier here) military actions, direct covert intelligence activities, and on and on. Obsessing over the number of executive orders to prove the presidency is a fundamentally strong institution misses the forest for the trees. 4.19.2 Presidents are weak James March and Johan Olsen set the stage for moving beyond the dominant political theory of the time, pluralism, in American political scholarship with the publication of (1983) The new institutionalism: Organizational factors in political life. March and Olsens insights allowed for presidential scholarship to advance beyond the personal, biographical, and daddy issues of authors like Barber and Greenstein. Instead of biographies of elites, the new institutionalism insisted that (1983, p. 747), The organization of political life makes a difference. Institutions, including the presidency, were endogenous, with their own history, culture, and practices which affected it. The state is not only affected by society, but society is also affected by the state; leaders do not simply affect followers, but are affected by followers as well. Richard Neustadt (1991) adopts the new institutionalist perspectives in his presidential scholarship. The power of the presidency is relatively weak, Neustadt believes, and therefore presidential power is dependent on individual skill of presidents interacting with context. How presidents behave is dictated by the weakness of the office, so president cant rely on the power of the office, and has to rely on persuasion, negotiation, bargaining. The presidents resources include bargaining powers that come from the position, professional reputation, and public prestige. The presidents (p. 150) power is a product of his vantage points in government, together with his reputation in the Washington community and his prestige outside. Neustadt believes that professional reputation is the most important of these. Neustadt (1991) uses pluralism as a vehicle for his argument that presidents must bargain both externally and internally in order to wield the relatively weak power of the office. Presidents bargain internally with competing factions of his own executive branch. Heads of federal executive agencies, cabinet secretaries, and bureaucrats all have competing interests. The most important factor of these in Neustadts view is a presidents reputation inside Washington D.C. Neustadts work has proven to be a long lasting and powerful theory of presidential scholarship, as modern examples continue to be seen in President Obamas use of the executive order to bypass Congress in the Deffered Action for Childhood Arrivals (DACA) and President Trumps Congress-bypassing travel ban on immigrants from specific countries. Kernell (2007) agrees with Neustadts general premise that the institution of the presidency is weak, but challenges Neustadts pluralist, bargaining argument and instead makes the case that a presidents public prestige is more important to their power than their reputation in Washington, D.C. Neustadt was right about the presidents and Washington, D.C. of his own time, argues Kernell, but since that time presidents are increasingly taking their policy messages to the wider public, bypassing Congress. The modern Washington, D.C. looks very different than the city of the past, and has transformed into an individual pluralism. This is due to the sheer number of interest groups, legislative members and their staff, and executive agencies a president would be forced to bargain with. Skowronek (1993) agrees with Kernell narrowly here, in that he believes we are currently in a Plebiscitary Era with increasingly candidate-centered presidential campaigns, and greater reliance by presidents on direct appeals to the electorate. The presidency is an institutionally weak office, and so the president uses his plebiscitary power to appeal to the public, which can then influence members of Congress to give the president what he wants. Other scholars have answered Kernell by asking for examples where this has occurred and was successful. While presidents have been more public in their appeals, finding times where a preferred presidential policy was implemented through strategies of public appeals, skipping the legislative bargaining piece, has proven difficult. Canes-Wrone (2001) answer Kernells critics who question whether the plebiscitary power of the president are effective. The authors make rational-choice assumptions about presidents, namely that presidents go public with an issue only when the public already supports the presidents view. If presidents go public when the public is not already supportive, the president risks alienating the legislative branch by raising the issues salience without the broader support necessary for passage. Canes-Wrones compare appropriations data and televised speeches by the president, and find general support for their hypotheses. Going public in Canes- Wrones analysis does help presidents overcome the weakness of the office to get what they want. Stephen Skowronek (1993) offers a different take on the presidency, one that is context dependent, and in the end the most convincing. Presidents are not individually great, or weak, or competent, or incompetent, but instead are in most ways defined by the presidential cycle they find themselves in. Skowronek classifies presidents in two dimensions. He asks if the current political regime is strong, or weak, and then asks is the president affiliated or opposed to that regime? These two dimensions give rise to four types of presidents: reconstructive, articulative, pre-emptive, and disjunctive. Presidents of reconstruction are what history remembers as strong presidents, such as Thomas Jefferson, Andrew Jackson, Abraham Lincoln, Franklin D. Roosevelt, and Ronald Reagan. The weakest presidents are those that precede political presidential reconstruction, such as Jimmy Carter, Herbert Hoover, and I would argue our current president Donald Trump (a president affiliated with a weak or weakening political regime). In addition to regime affiliation and strength assessments, Skowronek adds a related distinction between presidential power and presidential authority. Presidential power remains fairly constant over time, fundamentally weak but probably growing slightly over time. The authority of the president on the other hand depends on where in political time the president takes office. Reconstructive presidents have the most authority, while disjunctive presidents have the least. Skowronek more closely aligns with theorists who see the institutional powers of the presidency as weak, and presidents themselves are more likely to be prisoners to their own place in political and secular time than they are to be fully-realized agents of a powerful office. In addition to the political cycles (called political time), Skowronek theorizes there are also eras of presidential time (secular time). American history has had four eras, with the current era beginning in 1972 (the Plebiscitary Era). Over time, these eras have gradually become ever-more institutionally thick and resistant to change. Skowronek and Neustadt provide the most compelling theoretical and empirical arguments of the presidential scholars, and seem to at least agree that modern presidents are operating in a different era of presidential politics compared with presidents of the past, although the two come to different conclusions. Where Neustadt divides between modern and pre-modern presidents, Skowronek would say there have been four presidential eras, and we are in the Plebscitary Era. Further Skowronek provides a compelling theory in showing the rise of the modern administrative state (Howell and Lewis, 2002) has brought with it an accretion of the political interests of those administrative agencies to the presidential status quo. Ultimately Neustadts conclusion that pre-modern presidents were clerks of the executive branch is less convincing and too simplistic compared to Skowroneks. The modern president is both impeded by the thickening administrative barnacles on the ship of state, but also has the advantage of the weight of the administrative state added to his office when he is able turn it in the right direction. Only when the context of political and secular cycles are serendipitously arranged at the same time a president of sufficient skill takes office does presidential power truly become strong. In those presidencies of reconstruction, the existing political regime dies giving birth to the next regime. Skowrowneks theoretical and empirical rendering of a fundamentally weak office which is at specific, very limited times filled by a skilled president is the most convincing. By removing the focus on the individual and concentrating his attention on the institutional factors of the office, he allows for a historical, analytical approach to the presidential scholarship which does not easily bog down in distance-psychodiagnosis or partisanship. 4.19.3 Conclusion The presidency is an inherently weak institutional power. The mere fact that history has given us scattered, strong and successful presidents is not enough to counteract the institutional context which defines a weak presidency. The presidency is weak, but of course not powerless, allowing for skilled presidents in the right historical moment to rise above a constrained office and appear enormously strong. However, the strength of these outliers is remembered so well in large part due to the vast number of presidents who are largely feckless and prisoners of their own place in time. The primary constraints on the office of the presidency are constitutionally designed. While Madison (1787), writing under the pseudonym Publius, claims that the three branches of government are equally balanced, it is important to remember Madison was primarily writing in order to promote ratification of a Constitution. The balancing of the constitutional powers was important to both a public tired of kings and an aristocracy terrified of popular rule. The Federalist Papers can be thought of a partly propaganda, intended to sell the Constitution, and so it made sense to sell the normative view of how pluralism would prevent an imperialist president or mob rule, revolution, and guillotines. Yet while in #51 Madison sells a vision of equally balanced powers, Alexander Hamilton undermines the image of an equally strong presidency in Federalist 69, titled The Real Character of the Executive. Hamilton (also working under the pseudonym Publius) appears to be working to address the primary fear of the anti-federalists, who worried a president was just another name for a King, which they were devoted to preventing. The presidents authority, Hamilton wrote (1788), would amount to nothing more than the supreme command and direction of the military and naval forces, as first general and admiral of the confederacy. Pluralist beliefs of how things should work should not be confused with how they do work. The constitutional constraints on the presidency give really only one true strong power, that of the presidential veto, and even that can be and has been overridden with a super-majority of Congress. The president can propose a budget, but cannot pass one. He can ask for a declaration of war, bargain for preferred policy, appeal to the public, and yet in the end he must go to the legislature to take action. Those who argue that the president can use executive orders or limited military action to bypass Congress are right insofar as those powers exist, but wrong in translating those limited activities into an institutionally powerful office. In any case, as shown by Bolton and Thrower (2015), use of the executive order has in fact decreased in the post-war period. Even in cases where there seem to be examples of a strong presidency willing to use executive orders, as in the case of Presidents Obama and Trump, their use is more accurately seen as a symptom of a weak office, too unskilled to wield their own bargaining and plebiscitary powers to leverage Congress into their preferred action. An institutionally weak presidency is good news in an America dominated by partisan swings in the Presidency. Despite the incautious rhetoric of President Trump, and the utterly predictable reactions of horror from many, the institutional limits on the presidency have for the most part prevented President Trump from taking unilateral action. At every step he is confronted by an institutionally thick (Skowrownek, 1993) American government which prevents him from taking unilateral action, resulting in impasse. As much as the public hates impasse on their preferred policies, they should simultaneously recognize that the slow, grinding nature of the American political system also protects them against the fever dreams of would-be kings. 4.20 Trump as Skowroneks Disjunctive President? In The Politics Presidents Make, Stephen Skowronek (1993) lays out the historical institutionalism case for understanding how and why US presidents are successful in remaking the American political order  or not. Skowronek sees the history of American presidents playing out in cycles comprised of four types of politics: the politics of reconstruction, articulation, pre-emption, and disjunction. Although Skowronek makes room in his theory for hard cases, in general if his theory holds then one ought to be able to predict the broad strokes of a presidency. This paper will not engage Skowroneks theory critically in the sense of attempting to challenge his theory. Rather, I will take the theory on its own best ground, granting its assumptions and conclusions, and attempt to follow the implications of Skowronekian thought through to its bitter, Trumpian ends. In some future history, President Trump should fit into one of Skowroneks categories, and in this paper, I will make the case that he will be seen as a disjunctive president. President Trump does not cleanly fit into either the categories of articulative or pre-emptive, and so the only alternative within Skowroneks formulation would be President Trump as a reconstructive president. I grant at the outset that either are possible, and good arguments can be reasonably made for either. However, the weight of evidence seems to tilt towards Trump as disjunctive; therefore, I will also address why he is likely not a reconstructive president. 4.20.1 Skowroneks Historical Cycle Where other presidential scholars tend to attribute success and failure to the personality characteristics and decisions of presidents (Neustadt, 1991) or their personal communication styles and talents (Kernell, 2007), Skowronek insists that presidents must be seen in relation to those who came before them, and to the politics of the time. Presidents exist both in time and act over time. Skowroneks presidential cycle always begins with a reconstruction, followed by a period where presidents of articulation and pre-emption exchange through time, before finally a president of disjunction takes office. The politics of disjunction proves the established order no longer has the answers to the questions faced by the nation, and is soon followed by the next president of reconstruction. Importantly, disjunction is not describing a situation where one major party or the other no longer has the answers  but the system itself, comprised of both parties, no longer does. When just one party (or president) is seen as failing, this is a sign of either a pre-emptive president or one of articulation  either attempting to reinvigorate the politics of the previous reconstructive president (articulation) or attempting to provide answers the politics of the reconstructive president could not (pre-emption). 4.20.2 Skowroneks Modern Cycle Skowronek places President Reagan at the beginning of the modern political cycle, as a president of reconstruction. Successive Presidents Bush (41, articulation), Clinton (pre-emptive, and Bush (43, articulation) traded offices between the poles. When President Obama took office in 2008, much was hoped for and predicted for his forthcoming transformational presidency. President Obamas election, though doubtlessly inspirational for much of the world, did not translate to a repudiation of the established political order. Pragmatic problem solving, innovation within the boundaries set by the conservative regime ordered by President Reagan better characterize President Obamas two terms than does reconstruction of the American political reality. In any case, President Obamas failure to secure the presidency for his named successor, a hallmark of reconstructive presidents, should permanently secure his place as a pre-emptive president  at least under Skowronekian law. 4.20.3 Trumps Disjunction Skowronek defines the politics of disjunction as those periods of time where the established political order is no longer capable of effectively addressing the nations problems. A time of disjunctive politics is required for there to be a time of reconstructive politics. The disjunctive period serves as proof to the voting public that the established political order is no longer a viable order  and the transformative period that follows requires that there be no viable alternative available to the established order. Some might be tempted to see Trump as a reconstructive president. I think this is a mistaken impression which is heavily influenced by what Trump (as both candidate and president) says rather than what he does. Trump at times speaks as if he were a reconstructionist president intent on remaking the system in a new image. Drain the swamp, his oft-heard quote and tweet, is intended to capture that timeless American hobby of disapproving of the intrigue of Washington D.C., or as James Madison (1787) wrote in Federalist 10: Men of factious tempers, of local prejudices, or of sinister designs, may, by intrigue, by corruption, or by other means, first obtain the suffrages, and then betray the interests, of the people. Yet, while Trump has rhetorically railed against the Washington D.C. political environment, there is little to suggest he has taken action to support that rhetoric. Whereas candidate Trump routinely invoked Goldman Sachs as a bogeyman (Coppins, 2018), President Trump appointed a Goldman Sachs alum, Gary Cohn, as director of the National Economic Council. Candidate Trump campaigned on a promise to seek legislation placing a five-year lobbying ban on former Congress members and staff; President Trump hasnt sought any such legislation. And while candidate Trump promised to limit the influence of lobbyists, press reports show that twenty former lobbyists work in President Trumps executive office, and forty-nine former lobbyists now work for the agencies they previously lobbied (Freidersdorf, 2017). A longer list of how candidate Trumps rhetoric conflicts with President Trumps actions could be compiled, but is outside the scope and length of this paper. In any case, most if not all presidents could likely be accused of the same campaign versus administration conflicts. The value in examining these conflicts here is not simply to report that politicians campaign ambitions are not carried into administrative action, but to examine why President Trump is not building a politics of reconstruction. Trump often has the rhetoric of reconstruction politics, but his actions betray disjunctive hints. Skowronek (p. 38) adds this regarding reconstructionist presidents: Reconstructing political order is a process that joins party building to an assault on the residual institutional infrastructure of the old order. As I show above, President Trumps actions have not assaulted the established political order, despite his rhetoric claiming otherwise. His reliance on Wall Street veterans to head economic councils, for instance, seems to preclude a Jacksonian reconstruction of the national banking system. Far from transformative or reconstructive, President Trumps actions, and the response of both the Republican and Democrat national parties, point towards a time of disjunctive politics. Disjunctive politics are those times Skowronek defines as when the established orders instinct to protect the status quo politics of the time, becomes at these moments a threat to the vitality, if not survival, of the nation, and leadership collapses upon a dismal choice (emphasis added, p. 39). In Skowroneks formulation, while the office of the president is a battering ram (p. 28) in politics, only those presidents best situated in political time have been able to use that power. Skowroneks political time refers to both the national political institutional environment prevailing at the time a president governs (weak or strong), and the presidents relationship to that environment (affiliated or non-affiliated). The politics of disjunction require a weak national political regime and an affiliated president; and so, the next section attempts to narrow those questions directly. 4.20.4 Weak or Strong; Affiliated or Unaffiliated? The national regime established by the last transformative president, Ronald Reagan, is that of conservatism. The conservative regime is weak following the successive presidential tennis match seen in Bush/Clinton/Bush/Obama. All either failed to show the established regime was bankrupt of answers (pre-emptive cycles of Clinton and Obama) or attempted to re-establish the Reagan golden era (articulative cycles of both Bush presidents). President Obamas failure to appoint a (winning) successor in Hilary Clinton only cemented his status as the latest pre-emptive president. The conservative regime is over forty-years-old now, and does not appear to be answering the questions faced by a United States of America of 2018  a world vastly different than the one in which the conservative regime was borne. While a resurgent Russian bloc under Vladimir Putin may remind some of President Reagans political time, in fact he presided over the end of the USSR as a world power, not its birth. Trade, communications, technology, work force compositions  the list of the macro conditions which have changed both worldwide and nationally does not need full elucidation here for the point to hold. The conservative regime, accepted by both the Republicans and Democrats in the absence of a viable alternative, continues to hold together but not through its untapped potential for new answers. As Skowronek notes (p. 31), while the executive branch has vastly expanded in power, so too have the institutions and interests surrounding it as well. This makes even a weak constitutional regime difficult to reconstruct, as the institutional thickening makes the plans of even those presidents with the most compelling warrants for independent action difficult to achieve in the face of the equally thickened defenses of competing factions. So, if Reagans conservative regime is weak (though institutionally thick), then in Skowroneks theory, President Trump could be either a reconstructive, if unaffiliated, or disjunctive, if affiliated with the conservative regime. This is not a question of President Trumps ideological conservative bona fides, which have always been doubtful to many, given he travelled in liberal Democrat circles for most of his adult life. The question of his affiliation to the conservative regime asks a different question: Does he act in ways that would tend to support, or overthrow, Reagans conservative regime? Both candidate and President Trump have argued that the modern regime is weak, though he would not say the conservative regime is weak. But that is, in fact, what he is implying when attacking the so-called deep state of the modern regime, as the modern American state has grown to the breadth and depth it is within the agar laid down by President Reagan. However, while Trump has argued, though not acted, against the modern political regime, he has absolutely affiliated himself with its founder. President Trumps oval office is decorated with a large portrait of President Reagan, and he has affirmatively affiliated himself with the reconstructionist as both a candidate and a president. Candidate Trump has offered similarities including that both he and President Reagan are former Democrats (Richardson, 2015). President Trump, following the publication of a book critical of his presidency, tweeted that Ronald Reagan had the same problem and handled it well. So will I! (Schwab, 2018). 4.20.5 Conclusion Some may counter that appeals to Reaganesque stature is simply a hallmark of Republican candidates seeking to establish themselves with conservative voters, and thus is a cynical political stance, not one truly held. This may be true, but in any case, ignores that every president since Reagan has also claimed to have affiliation with him. Candidate Obama in 2008 made the comparison himself (Murray, 2008): I dont want to present myself as some sort of singular figureI think Ronald Reagan changed the trajectory of America in a way that Richard Nixon did not and in a way that Bill Clinton did not. He put us on a fundamentally different path because the country was ready for it. As a Democrat candidate still engaged in a primary fight, Obama was not campaigning for conservative values. But Obama was a political actor in a still resilient political environment shaped by Reagan, and so while he opposed the political order, he was not able to cast aside the vision of leadership offered by Reagan, and still very much desired by the American electorate. Orthogonally, President Trump, though faced with a much weaker political regime following President Obamas tenure, affiliates with the regime. No candidate  other than a reconstructive one  can afford to cast aside that vision of leadership. 4.21 Public Opinion: Media Sources &amp; Public Policy Impacts How public opinion is formed, and its effects on public policy, has been an integral facet of American political since the 1940s, beginning with the famous Columbia school of American political behavioral scholarship. These studies pioneered survey research in America, and eventually produced two influential books  The Peoples Choice: How the Voter Makes Up His Mind in a Presidential Campaign (Lazarsfeld, Berelson, &amp; Gaudet, 1948), and Voting: A Study of Opinion Formation in a Presidential Campaign (Berelson, Lazarsfeld, &amp; McPhee, 1954). These two works were the first of the Columbia school of American political though, forerunners of a disillusioned view of the American electorate as irrational and not up to the task of running a democracy (Bartels, 2008), and have guided political research in public opinion for decades after (Bartels, 2010; Delli Carpini &amp; Keeter, 1996; Zaller, 1992). The Columbia study proved the value of survey-based research, and soon after scholars at the University of Michigan began their own pioneering work. The national survey work in Michigan began in 1948, and was repeated every four years after, eventually producing one of the longest-running research projects in the history of academic social science (Bartels, 2010). The research produced what eventually became known as the Michigan Model and after the first decade of work resulted in the The American Voter (Campbell, Converse, Miller, &amp; Stokes, 1960). The book is the signature work of the Michigan Model, and has remained a hallmark American political study. The books classification of party identification and candidate attractiveness as primary motivations of the American voter have remained important through today. While the Colombia School and the Michigan Model proved remarkably influential, it should not be surprising that their findings were not as consistently accurate as perhaps their methods were. The remainder of this essay will address later work in two specific areas. First, whether mass media affects public opinion, and to what extent, and second, how public opinion might affect public policy. 4.21.1 Media Effects Like its methodological influence, the Columbia studys findings that mass media had little effect on public opinion persisted for decades. The Colombia study used long-term panel studies to establish that even in the face of substantial mass media input, public opinion appeared to be remarkably stable, leading researchers to conclude there was no effect at all (Klapper, 1960), let alone the large effects predicted for mass media. The no effects finding was accepted in the field for decades, and not until the late 1960s and 1970s did researchers began accepting there were probably small effects from media on public opinion, particularly with the agenda-setting function of the media (McCombs, 2004; McCombs &amp; Shaw, 1972). Despite these early entries, the same period still saw strong arguments from some scholars that the growth of media did not mean there was a growth in media effects (Sears &amp; Whitney, 1973). Though these arguments predate Zallers (1992) Receive-Accept-Sample model of public opinion, they were important for their theorizing of selective exposure and perception, parts of theories of motivated reasoning that are central to understanding the effect of media on public opinion (Bolsen, Druckman, &amp; Cook, 2014). Selective exposure effects were likely to cause the public to not consume information that conflicted with prior belief, and selective perception effects would result in the public dismissing conflicting information even if exposed. This effect is a strong feature in recent research into the increasingly partisan and polarized American electorate (Iyengar, Lelkes, Levendusky, Malhotra, &amp; Westwood, 2019). For example, a positive frame in media can cause the public to dismiss negative information (Druckman &amp; Bolsen, 2011), though members of the public with strong prior beliefs appear less susceptible to media framing effects (Lecheler &amp; de Vreese, 2012, 2018; Lecheler, de Vreese, &amp; Slothuus, 2009). As rational-choice theories in political science more broadly began to gain adoption (Aldrich, 1976), the question of media effects was still outstanding, as it did not appear that there was a rational connection between media consumption and public opinion. Into that frame, Page and Shapiro (1987) offered new methodology and direction for researchers with their research presented in What Moves Public Opinion. The authors improved methodology in the field by pairing specific survey questions asked at different points, and selecting the questions where there was a significant (&gt; 6%) difference overall public opinion. Instead of simply measuring self-reported media consumption, they looked at media stories which occurred between the two points in survey questions. They also coded the media for the source quoted in the media, and how prominent the story was by looking at how early in the news broadcast the story was featured. Page and Shapiro (1987) argue that media does have an effect on public opinion, but that the information must be received, understood, relevant, credible, and at odds with their previously held beliefs. While their findings were somewhat limited by a small sample of approximately 80 cases, the paper was significant for finally locating substantial media effects on public opinion, after four-decades of researchers failing to do so. The findings are difficult to assign causation to given the nature of the survey research, and the authors stretch too far in drawing some causal relationships where they are not present, such as finding that news commentators drive public opinion, when it seems more likely the news commentators are following broad public opinion changes. Page and Shapiro followed up their 1987 work with a more full rational choice accounting of public opinion (1992). Using data that speaks to a wide range of policy domains, the authors hold a focus on aggregate public opinion, which appears to be rationally connected to important events. On the whole, public opinion is stable and the change that does occur is generally rational, even when the individuals in the system do not necessarily appear to be so. More so than any other piece, Experimental Demonstrations of the Not-So-Minimal Consequences of Television News Programs (Iyengar, Peters, &amp; Kinder, 1982) revitalized academic interest in media effects on public opinion. Using relatively complex experimental methods, the authors exposed their treatment group to doctored news broadcasts which changed the topics covered, and how early they were broadcast in the segment, when compared to the control group. Experimental methods were not well accepted at the time in political science, a fact well documented by the amount of time the authors spend justifying their methodological choices. The experiment was successful in showing strong agenda setting effects in the media  or the ability for stories earlier in the broadcast to convince viewers of the importance of those stories. The further finding that viewers who were less sophisticated in their political knowledge were more susceptible to the agenda setting effect was to be important to later researchers examining differences in how opinion shifts in the public. The findings were not perfect however, and in particular their argument for media priming the audience, or how the media might alter the standards by which people evaluate government was not as convincing in the long run, and the logic was substantially improved on later by Zaller (1992) with his receive  accept  sample model, particularly in how people process conflicting messages in the media. Iyengar continued to make important strides in this theme of research (Iyengar, 1990, 1991; Iyengar &amp; Kinder, 1987) for several years, generally finding that the media (particularly television media) has agenda setting and priming capacities. Later work (Baum, 2002) builds on these findings, and demonstrates that consumption of soft news and entertainment television manages to transmit political information - but typically of foreign crises, and not the less dramatic national politics. This suggests that barriers to political information for low-engaged citizens may be falling in an era where infotainment is increasing. Soft news and entertainment transmits some information about high profile events, particularly international/security information, to the low-information, low-engagement voters that have concerned some scholars for decades (Converse, 1964; Delli Carpini &amp; Keeter, 1996), and is further evidence that there are alternate methods and heuristics that the public is able to use to come to opinion sets that closely match those of more highly engaged political consumers (Lupia, 1994). Though unable to overcome the identification problem, Page and Shapiro (1987) were important for providing a basis to understand that the media interacts with other political actors to influence public option. They presented at least some evidence that presidents are able to harness the media to persuade the public, at least when presidential job approval ratings are high. Later scholars suggested that the presidential ability to move public opinion was curtailed by the rise of cable television news (Baum &amp; Kernell, 1999), but on balance the research showed that the effects were more complicated. While the president has been a reliable source of cueing public opinion (Mondak, 1993), news media can direct public evaluation of presidents when the news source is trusted (Miller &amp; Krosnick, 2000). With the theory that media has more than negligible effects on public opinion well established by the 1990s, researchers began to investigate how the tone of media messages might affect public opinion (Ansolabehere, Iyengar, Simon, &amp; Valentino, 1994). This work heeds the call of earlier research (Iyengar et al., 1982) for methodological pluralism. First in the experimental stage, they showed that a treatment group exposed to negative political advertising were less likely to intend to vote. In the second phase of their research, they took that model and texted it against voting and political advertising data from the 1992 senate elections. The experimental results were validated empirically, with the second phase finding that turnout in senate races with more negative political ads was by approximately the same amount (~4%) as the intent to vote in the experimental phase participants. In using field data to validate their experimental findings, the researchers were successful in making a convincing argument that voter demobilization is due to general cynicism - as campaigns become more negative and cynical, so does the electorate. That finding has proved controversial, however, as replicating the findings has had only mixed success, with the result that while it is probably true that negative campaigning can depress voter turnout, the amount of depression is likely not as large as the original findings suggest. Barabas and Jerit (2009) show how far the literature has changed from the days of the no effect findings of the Columbia study. The study uses sophisticated Bayesian analysis to estimate effects of the media on public opinion, but more importantly what political information is transmitted to the public through media. The authors add to the media has effects literature, with additional findings related to how the media can transmit political information to voters. What would seem to be the most obvious determinant of media effects-the volume of coverage-is not the only or even the most important predictor of knowledge. The breadth of coverage and the prominence of a story are equally powerful predictors of knowledge and are more important than demographic characteristics or indicators of socioeconomic status. These findings continue to be impactful, though with more time to study these effects, they appear to be weaker than the authors determine here. Another line in the literature of media and public opinion seeks to understand the medias role in the polarization of the public. Before reviewing the contesting claims, however, it should be noted that whether there is polarization at the mass public level is a still contested question. Polarization among elites and highly partisan members of the public is a well demonstrated phenomenon in modern American politics (Poole &amp; Rosenthal, 1984). However, other scholars argue forcefully that polarization at the elite level is not new and has had a consistent presence in American politics (Lee, 2009; Nivola &amp; Brady, 2008), and that it is the relative balance of power in the two parties that is responsible for how the institution of Congress acts, not ideology or polarization (Lee, 2016). The focus on income inequality and its link to political outcomes has a strong research tradition (Bartels, 2010; Schattschneider, 1960). McCarty, Poole, and Rosenthal (2006) extends earlier work by some of the same authors (Poole &amp; Rosenthal, 1984) by causally linking increasing income inequality and immigration to increasing polarization. Still, some of the most recent review of the scholarship finds that mass polarization is occurring, and that it is affecting how Americans behave in non-political realms (Iyengar et al., 2019). So, setting aside the question of whether polarization is a widely observed public phenomenon, assuming it exists, is the media responsible for it? With the existence and extent of mass polarization still contested, it is not surprising that the mechanism explaining the proposed relationship would be controversial as well. The early entry in this area of research was not on polarization exactly, but on the broader social division that could be exacerbated by narrowcast media (Mendelson &amp; Nadeau, 1996), which was just beginning to emerge in the forms we recognize to day as overtly partisan media outlets such as Fox and MSNBC in cable news, as well as the many forms of small media firms that take partisan sides. Hacker and Pierson (2005) note that overall mass partisanship had not changed much, although conservative policy had moved far more right than the median conservative voter or lawmaker. Most American are politically moderate, even on highly salient political issues such as abortion, gun control, and gay marriage (Fiorina, 2017), and the conception of America as highly polarized is primarily driven by media reinforcing messages of the political elite. This may show the primary effect of media on polarization is still limited to political elites (Prior, 2013), who tend to be more ideological than the typical voter from the same partisan family. In any case, the evidence that the media is responsible for what some see as a dangerously increasing polarization in the public (Iyengar et al., 2019) is quite thin, and measurement issues continue to hold back our understanding of the relationship, should it exist. The most likely explanation for the correlation between increased partisan media is that technology made it easy to enter small, discrete media formats in order to monetize the strong partisans already in existence who were generally unhappy with the more moderate news media that dominated in the 1970s. Selective exposure then occurs, as strong partisans increasingly turned to media channels and sites that were congruous with their pre-existing beliefs. In other words, if anything, media followed partisan members of the public, not the other way around, and at this point (Prior, 2013, p. 119), Research to date does not offer compelling evidence that partisan media have made Americans more partisan. 4.21.2 Public Opinion and Public Policy Whereas the scholarship discussed in the previous section was concerned with the effects on public opinion, the following section is primarily focused on the connection between public opinion and public policy. For many democratic theorists, there is a normative connection between the two  public opinion ought to affect policy if in fact the polity has control of government . Like the connection between mass media and public opinion, for many years the literature failed to establish correlation, let alone causation, between public opinion and public policy. In the late 1980s and 1990s, two primary types of research in this area were established (Monroe, 1998)  studies of congruency and those of consistency. In the congruency camp, the classic study comes from Benjamin Page and Robert Shapiro (1983). Using trimmed survey data culled from multiple decades, the authors used similar methodology to their research on media and opinion (1987), looking for similarly worded public survey questions on policy, and then correlating policy shifts from before the first survey and after the second survey. In this way they showed that indeed, in the aggregate at least, there were relatively higher correlations (around 64%) than existing theory would expect between the public opinion and public policy shifts. The authors were appropriately reserved in their own judgement, given the lack of any causal connection. Further, in approximately one-quarter to one-third of the cases, public policy shifted in a direction opposite the public opinion direction, leaving a great deal still to be explained. In contrast to the congruency approach of Page and Shapiro (1983), research by Alan D. Monroe (1998) highlights the consistency research in public opinions connection to public policy. For Monroe, consistency research compares the distribution of public opinion with the policy outcome, and compares two periods, 1960-1979 and 1980-1993, and finds that in the later period public policys consistency with public opinion had dropped from 63% to just 55%. He attributes this relatively low number to the inherent bias against change in the complex American political system. Monroe added further to this literature by examining consistency not just in the aggregate, but also stratified by substantive policy area. This allowed him to show very interesting results, such as his report that in foreign policy, there is 100% consistency between opinion and policy in the latter period studied. Again, like Page and Shapiro, Monroe is not able to establish a complete causal connection, and given the nature of the research problem, modern research has still failed to convincingly do so. The study of state electoral politics in order to better understand how public policy forms is a central lesson throughout political science (Key, 1949, 1963). Eriksons early work (1976) evaluates data from the 1930s and showed that public opinion and state policy were strongly correlated on death penalty and child labor law issues of the day. Erikson, Wright, and McIver (1989) expand that early work with an interesting variation on research into public opinion and public policy, locating the discussion in state-level research. Their basic finding is that state electoral politics is the most important factor in correlation between state opinion and state policy. The authors propose a new model of electoral representation, in which centrist parties are rewarded. The authors are rehabilitating and improving on Downs (1957) original argument that political parties will eventually migrate to the center of public opinion. But Downs original model was too simple, and the actual electoral politics make the path between public opinion and policy outcomes more complex. Erickson, Wright, and McIver demonstrate this with their own complex path model. They demonstrate that ideological variation between states makes comparisons very difficult - i.e. a Mississippi Democrat is probably more conservative than a New York Republican. State policy outcomes do represent state opinion preferences, but party control of a state legislature is not a good predictor of state policy, as the party activists and the centrist voter tend to be pulling politicians in different directions than the national party. This connection is an electoral one (Mayhew, 1974), as voters reward legislative control by selecting party control based on ideological position, leading politicians to pay close attention to shifts in public opinion (Erikson, McIver, &amp; Wright, 1993). Showing there is still considerable research and debate in the public opinion and public policy field, Jason Barabas (2004) uses Bayesian theories of information updating to propose a model where citizens who deliberate revise their prior beliefs, particularly when they encounter consensual messages. This work builds upon the receive-accept-sample model (Zaller, 1992), but uses thoroughly different methodology to do so, and attempts to answer some of the outstanding questions in the literature. One finding in the deliberation literature is that on the individual level, people do have opinion shifts following deliberation, and deliberation increases knowledge and alters opinions, but it does so selectively based on the quality and diversity of the messages as well as the willingness of participants to keep an open mind. Barabas (2004) findings are in line with earlier meta-analysis that shows media messaging is translated into measurable learning, influences attitudes, and shapes behavior in the public (Emmers-Sommer &amp; Allen, 1999). It is further supported in more recent research (Coppock, 2016) that finds that persuasive political messages elicit small, homogenous changes in beliefs. But in the aggregate, as Barabas (2004) shows, there is not much change, and even the individual shifts tend to be short-term. Short-term is still contested and relatively poorly defined, as experimental work Coppock (2016) shows that the changes persist for at least some period that could conceivably effect policy. Despite Barabas careful methodology and analysis, in the end his findings run into the same problems as previous deliberation research. 4.21.3 Conclusion The consistency in public opinion with public policy matches long-standing findings from participation research (Nie, Verba, &amp; Petrocik, 1976; Verba &amp; Nie, 1972) that American voters hold consistent attitudes, understand and identify with the ideological frameworks in operation nationally, and vote according to those ideological preferences. In other words, there is a consistent thread connecting how the public votes, how they understand public policy, and how they affect that policy through political participation. At the aggregate level, public opinion is stable, and when shifts do occur they are met by lawmaker response through legislation that matches the new public policy preference (Page &amp; Shapiro, 1983; Shapiro, 2011). This connecting thread is a public policy variant of the electoral connection (Mayhew, 1974). The causal pathway is not always clear however, as the concept of low-information rationality shows voters also rely on framing messages from politicians (Popkin, 1991) and other sources (Lupia, 1994) as heuristics for forming their own opinion (Lupia, McCubbins, &amp; Popkin, 2000). The study of public opinion and its hypothesized effect on public policy continues to be a substantial research topic in American political behavior. On the whole, there is enough evidence to believe that there is indeed a connection between public opinion and the formation of public policy. However, future research is still left with huge questions, including the primary one, which is investigating the causal connection. While Mayhews (1974) electoral connection can be relied on to a certain point, it is not clear past election how exactly policy shifts in response to changes in public opinion. Even more strikingly, in an America where so much policy work is done outside any direct electoral connection  in courts, administrative organizations, and in public-private and public-non-profit contexts  there is even less obvious causal link to explain policy shifts. 4.22 Voting and Elections The ability of citizens to influence, or even control, their form of government is at the heart of democratic theory, and explaining how people decide who, or what choices, to vote for forms perhaps the largest body of research literature in the American behavior field. Because the body of work is so large, this essay cannot hope to cover it in detail. Instead, it will proceed in three sections. First, the three largest academic traditions which have shaped the field will be briefly considered. Second, the role of partisan identification in vote choice will be reviewed through three important works. Finally, the role of political campaigns and theories of decision making in vote choice are reviewed through a brief examination of Lau and Redlawsks (2006) novel experimental approach to correct and incorrect voting. 4.22.1 Traditions of Vote Choice Scholarship Three broad traditions have emerged out of political scholarship to explain how voters choose in elections  the Columbia school, the Michigan model, and rational choice. All three theories of voter choice offer competing explanations, and to a great degree have shaped how scholars approach vote choice research questions. 4.22.1.1 The Columbia School The Columbia school studies were based in sociological traditions. Research coming out of this school predated the ability to conduct large telephonic or web-based data collection. Instead, researchers delved deeply into the community in which voters lived. Not surprisingly, then, researchers found that voting is a group act  that is, it was formed and influenced by the social groups in which people lived. Columbia school studies tended to be long-term longitudinal studies over the space of a single election, based in very specific geographic locations. The studies tended to discount the role of media, election campaigns, or other correlates which occurred outside the very concrete, observable social groups to which their subjects belonged. The explanations fit well within the design constraints these researchers operated within, but tended to be myopic and non-representative, as the findings didnt travel well to other locales, or to the nation as a whole. 4.22.1.2 The Michigan Model The sociological approach of the Columbia school was to be quickly supplanted by the social-psychological approach of what came to be known as the Michigan model. This literature was begun by a group of political scientists and one social psychologist (Campbell, Converse, Miller, &amp; Stokes, 1960). These scholars centered their research quite differently compared to their Columbia school colleagues. Whereas a Columbia school researcher might ask which groups do you belong to? Michigan research was more interested in which groups do you think you belong to? This slightly different formulation was forced somewhat by choice of method, and allowed for very different answers, and different models. Michigan model research was based on large telephonic survey methods, so researchers could not directly observe the local social groups a respondent might participate in, and so had to rely on which groups a respondent reported they belonged to. The community context that was so important to the Columbia school was stripped away, and group identity emerged instead of group membership. The Michigan model benefitted from the very large samples they were able to produce, and their findings tended to be more nationally and regionally representative than the smaller Columbia studies. While the Michigan model covers decades of work, the basic model which came out of The American Voter (Campbell, Converse, Miller, &amp; Stokes, 1960) can be summarized as three main components which have a direct effect on voter choice. The single largest factor is partisan identification, defined as which political party a voter says they more closely identify with. The next largest component of vote choice is candidate image, or how favorably or unfavorably a voter considers a political candidate. The third, and much smaller facet of vote choice is a voters reported position on the issues which are in play during the election. The Michigan model was not a complete break from the Columbia scholarship, and the move from sociology to social-psychology is better thought of a refinement than a reinvention. For example, while Columbia scholars never directly named partisan identification they talked about various aspects of it. Still, if forced to choose, the Michigan model has proven the more lasting tradition and the dominant model of vote choice. Even today political scientists still measure partisan identification and candidate image variables in the same ways that Michigan scholars were over fifty years ago. The Michigan studies of national voting behavior have continued uninterrupted and are now known as the American National Election Study (ANES), which continues to be an important source of data for modern vote choice scholars. While dominant, the Michigan model is not without critics. The largest critique is the models treatment of issues, which end up as a distant third in importance compared to partisan identification and candidate image. In fact, issues dont matter much at all, but this has been critiqued because of the way Michigan researchers conceptualized what an issue voter is. Their method was overly rigorous, as it required a respondent to know where the political parties stood on an issue, where the respondent themselves stood, and had to be able to accurately differentiate these stances across a wide variety of issues. The issues themselves were selected by researchers, which led to a secondary critique that the Michigan model lacks any measurement of issue salience  what is important to the voters themselves as they consider their vote? Later scholarship has shown that once people are asked about the issues that are important to them, the issue of issues in voting looks very different. Single issue voters can be identified, and for these voters, issue stance is the most important determinant of vote choice, which is a finding the Michigan model overlooked due to their research design. Still, most research has consistently found that the typical American voter is not an issue voter, lending further credence to the Michigan model as a whole. 4.22.1.3 Rational Voter Choice Models While rational choice theory was adopted throughout other areas of political behavior study, it wasnt initially a popular theoretical structure to explain voter choice. Initially, the conclusion of many attempts to explain voting behavior such as turnout with rational choice (Aldrich, 1993) led to the unhelpful conclusion that voting wasnt in the voters interest. Morris Fiorina (1978) caused some controversy when he claimed he could use rational choice methods to predict voter choice just as well as the Michigan model. Fiorinas essential claim was that when faced with a choice in an election, the voter essentially asks who will benefit me the most, and was forming that belief based on which candidate or party had most benefitted them in the recent past. Critics pointed out that what Fiorina had done was essentially take partisan identification  the taproot of Michigan model theory  and renamed it in a rational choice friendly way. In the end, rational choice still struggles to explain vote choice in a compelling way, due to its roots as an economic model. Attempting to explain voting in utils is always going to be at a disadvantage in explaining behavior with social and psychological roots. 4.22.2 Partisanship and Vote Choice The 1979 article A Dynamic Simultaneous Equation Model of Electoral Choice by Gregory Markus and Phillip Converse is an excellent example of how the Michigan model conceives of vote choice. The authors lay out a very complex series of regressions (a path model) among the most typical correlates, including the big three of partisan identification, candidate image, and issues. The study uses panel ANES data from the 1972 to 1976 presidential election, and results of the model claim to be able to correctly predict 90% of the vote choice by respondents. The authors are responding to other critics, including Fiorina (1978) who claim that a respondents vote in the previous election is enough to predict a large proportion of votes in the current election. Markus and Phillip (1979) include the respondents previous election vote into their model and show that it isnt as predictive as the other scholars believe. Voters occasionally switch party in their votes, but a Democrat voting for Regan in 1984 is (usually) still a Democrat in 1988. In addition to the normal focus on partisan identification as the predominant causal mechanism for vote choice, Mark and Phillips model also concentrates heavily on candidate image and does a better job than previous Michigan model work with issue saliency. While a good example of the Michigan model, this paper has been criticized later for the relatively small sample (n=884), but this is primarily an artifact of the panel data used by the authors. Further critiqued is the authors choice of regression modeling, as they use ordinary least squares (OLS) regressions to model a dichotomous vote outcome. This choice was popular though for some time, and even replicating the study with the more appropriate probit or logistic regressions would be unlikely to change the direction of effect between independent and dependent variables. Another preeminent American political scholar is Larry Bartels (2000), and in Partisanship and Voting Behavior, 1952-1996 he analyzes partisan voting in American elections. Bartels uses probit regressions of ANES data to address what some scholars believed was a trend in Americans voting less frequently on a partisan basis. 1972 proved to be a low-point in partisan voting, as popular Republican President Nixon handily won re-election in a country that was still safely Democrat. Bartels finds that strong party identifiers decreased for a short period between 1964 to 1976 but rebounded strongly since then. Partisan identifiers decreased as a proportion of Americans overall since 1964, but have increased as a proportion of voting Americans, and Bartels shows that partisanship among the voting public is at a level similar to those found in the immediate post-war period. Bartels contributes as well with his discussion on how to measure partisan identification, and points out that while a sizeable percentage of respondents will answer questions about their partisan leaning, many will not answer corresponding ideological questions. This may be at least partly due to the trend in ANES data noted in other work (Sinclair, 2012, p. 78), which finds that 11 percent of self-identified liberals voted for the Republican presidential candidate, and 29 percent of self-identified conservatives votes for the Democratic presidential candidate. While the data Bartels uses is mostly focused on presidential elections, he finds similar increases in party-basis voting in Congressional races as well. Bartels theorizes that the increases in partisanship-based voting (77% higher in 1996 than in 1972, and up to 20% higher than in the post-war period) is due to increasing differentiation between the political parties, particularly as the Democratic partys dominance in the southern United States degraded. Bartels is successful in rehabilitating partisanship, as he shows that once models correctly take into account who is voting, not just who is eligible to vote, party identification remains a primary motivator of vote choice. The early Columbia studies found that election campaigns dont matter much at all, while later scholarship has found that negative campaign messages can depress voter turnout (Ansolabehere, Iyengar, Simon, &amp; Valentino, 1994), that direct mailers from campaigns could theoretically increase turnout (Gerber, Green, and Larimer, 2008), and that door-to-door canvassing by campaign workers from the local community could increase it even more (Sinclair, 2012). But one ongoing and current debate in vote choice studies is what effect, if any, election campaigns have on the choice a voter makes once they actually turnout. Hillygus and Jackman (2003) address this question in Voter Decision Making in Election 2000: Campaign Effects, Partisan Activation, and the Clinton Legacy. Partisanship tends to matter a great deal at election time, but typically has less salience during non-election years. Hillygus and Jackman try to measure how election campaign events such as party conventions and political debates affect how voters feel about candidates George Bush and Al Gore in the 2000 presidential campaign. This study contributes usefully in its method. The authors piggyback on a private marketing survey which samples web-based respondents multiple times per day. This allows the authors to conduct a time-series study of candidate image throughout the campaign, measuring aggregate differences before and after the campaign events they are interested in. The study finds, for instance, that Al Gore won the conventions and George Bush won the debates. While this is useful, in the end this study ends up reinforcing earlier findings that election campaigns just dont seem to make a big difference. Voters make up their minds about candidates very early, and while there are small aggregate shifts throughout the campaign, in the end partisan identification and candidate views dont change substantially. 4.22.3 Campaigns, Information, and Vote Choice In their book How Voters Decide: Information Processing during Election Campaigns, Richard Lau and David Redlawsk (2006) usefully provide an overview of the predominant models of voter choice, and then compare those models using novel experimental treatments to see how voters process information as they make election vote choices. In addition to the rational choice model, the authors compare Herbert Simons model of bounded rationality and satisficing; a cognitive consistency model loosely based on the sociological Columbia model, although the theorists never directly use that phrase; and finally, a heuristics short-cuts model. The Columbia model has enough overlap with the Michigan model that some comparison can be made in the results presented by the authors. Lau and Redlawsk want to test the four models of vote choice, using a unique definition of correct voting tested with experimental methods. For the authors, a correct vote is one in which the study subject votes for a hypothetical candidate in a time-constrained environment with too much information (modeling a campaign where voters are inundated with election information), and then votes again for that candidate later, in a non-time bounded environment, where the subject can study a candidate at great length. In those cases where a study subject switches their vote in the second vote, they are considered to have cast an incorrect vote in the first vote. In this study, up to 30% of voters cast incorrect votes. The experiments findings reveal that rational choice decision models dont appear to help the voters in decision making. The psychological strategies, Simons satisficing and the heuristics or shortcut model, improve voter decision making  that is, improve correct voting, while the sociological model is only useful in the most simplistic scenarios, which are unlikely to be found in national elections. In elections with more than one candidate, which are presumed to be more complex, the effect of partisan identification becomes even more important as a shortcut, lending credence to the earliest Michigan model findings. Lau and Redlawsks work is not without limitations. Their findings are subject to the usual limits of experimental research design, in that it is not clear to what degree their findings are portable to the real world of political campaigns and voter decisions among candidates. However, the strength of their experimental methods allows scholars to make useful distinctions between the different models, which often have overlapping theoretical edges. Lau and Redlawsk are able to claim strong causal links, make useful distinctions between the models, and reject at least one in rational choice. While no single model dominates vote choice, the experimental results are most clear in rejecting the rational choice model as useful in explaining vote choice, and voters are likely using some combination of the other three, with psychological aspects playing a dominant role. 4.22.4 Conclusion How a citizen decides who to vote for at election time remains a stubborn question. There are now decades of evidence that partisan identification plays a central role in vote choice, and the Michigan model remains the best theoretical structure to understand it. It is somewhat surprising just how robust the Michigan model has proved, given its relatively advanced age. Advancing experimental techniques, such as those used by Lau and Redlawsk (2006), point the way towards more refined theoretical sensitivity which may help with greater understanding of vote choice, and the psychological aspects of decision making offer promising future refinement as well. Given the ever-escalating political stakes, and the saliency of partisanship even in off-election years, the subfield of vote choice is likely to remain a core research agenda within American political studies. 4.23 What do Americans Know about Politics? In response to: Do average Americans really know enough about politics to participate effectively in the process of democratic decision making? A not unreasonable assumption about democratic governments is that citizens need to be sufficiently informed about political institutions, important political actors, and the substance of public policy to be able to understand and evaluate both their own interests as well as the interests of others. Based on the research that you have read about what Americans know about politics and how citizens make political decisions, how would you evaluate whether most Americans are sufficiently informed about politics to participate effective? Questions about how citizens develop their basic political beliefs, perceive political issues, and participate in the political process are at the heart of the study of American political behavior. In the democratic ideal, the citizen is a well-informed participant in the political realm, able to effectively consider a wide-range of information about a wide-range of topics and distill that information into a well-reasoned act of political participation. However, this normative ideal is loaded with assumptions that are worth testing empirically. This essay will consider a wide range of political science literature which examines the components of the ideal political citizen. Broadly, it will consider whether most Americans are sufficiently well-informed about politics in order to participate effectively. The essay will progress in three broad parts, first examining how Americans learn about politics, and continuing then to discuss what Americans know about politics, and finally, whether Americans know enough about politics to perform meaningfully in political processes. 4.23.1 How Americans Learn Political Information Prior to developing a political opinion, value, or belief, at least some information must be gathered by the individual. The earliest political science inquiries into how Americans learn about politics were developed in the sociological tradition in the years after World War II. Scholars were focused on trying to understand what had made America and Great Britain different from the Axis power countries. How had Americans and the British managed to resist totalitarian and fascist takeovers of their governments, while Germans and Italians had not? For political scientists of that era, the obvious answer was that there must be something about how America and Great Britain were raising their children that imbued them with a natural political resistance to despots. Political researchers, borrowing from sociological theory popular at the time, attempted to test that theory. Two of the earliest examples of the socialization approach to political knowledge are Fred Greensteins (1960) The Benevolent Leader along with Transmission of Political Values from Parent to Child, by Kent Jennings and Richard Niemi (1968). Still researching in the era before broad national telephone surveys were a realistic data gathering method, Greenstein directly interviewed school-age children, and found they have more positive views of politicians, what Greenstein described as unqualified sympathy, than their parents did. Though still cited in modern work, Greensteins early attempt to locate political information as springing directly from parental political views was not very successful. Kent and Jennings (1968) were more successful in showing that at least some political knowledge in children was correlated with parental political belief, but really only in terms of partisan identification. These early sociological attempts, while influential, were not convincing on the whole, as there was a clear gap between theoretical expectations and empirical evidence: children did not simply adopt their parents political views. In addition to these empirical problems, the theory of socialization had a substantial problem in that it expects that by adulthood our preferences (in this case political preferences) are fixed. This expectation was undermined however, with increasing evidence that people maintained a life-long openness, and socialization continued throughout adulthood, as individuals continued to try to fit-in with their work, neighborhood, and other social environments. Into the empirical and theoretical gap left by the sociological scholars, the growing popularity of theories of rational choice were being used profitably across much of political science, but did not prove as useful in studies of the formation of political knowledge. While socialization would for the most part fade as a favored theory of political knowledge, there are occasional attempts to resurrect at least pieces of it. Sears and Valentino (1997) use elements of socialization to examine how exogenous political events such as presidential campaigns help form persistent political attitudes. This type of socialization is taking place outside the family, and comports more easily with other scholarship (Inglehart, 1971) which finds generational shifts in political beliefs and values. Inglehart and Abramson (1994) provide more evidence of this type of generation shift having a formative impact on political knowledge, which still has a socialization root. The authors find there is a cohort effect within generations which is affected by the environmental conditions the cohort experienced as children, and that as a society becomes more prosperous, and thus less likely to be worried about base survival needs, their political views as adults will tend to be post-materialist. While not technically a socialization theory, but uses theories of the socialization of information profitably in a political context, in that they allow for a theory of political knowledge that allows for events outside of the immediate choices in front of a person, as expected by rational choice theory. A common, and contemporaneously relevant, explanation for how people learn about political information is that they do so from what they are exposed to by varying media sources. The earliest models of political knowledge from the Columbia school studies discounted the effect of mass media on political knowledge. However, by the late 1980s and early 1990s scholars were successful in locating at least modest effects of media on the political beliefs of Americans. By this time, rational choice theory was increasingly adopted by political scientists, but with relatively less success in the specific question of political knowledge formation. Page, Shapiro, and Dempsey (1987) examine a small sample (n = 80) of pairs of public opinion polls over time and compare them to the media coverage of issues covered in those polls. They find that the views of political elites, (such as experts, popular presidents, media commentators), transmitted through mass media, can affect public opinion. While influential, this study is hampered by the small sample and relatively short time-frames used by the authors. One of the most comprehensive models comes from John Zaller (1992) in his book The Nature and Origins of Mass Opinion. Zaller gives an excellent frame for understanding the effects of media on not only what Americans know about politics, but how that knowledge is learned. Zallers model of how political opinions are formed starts with receiving information, which is often from political elites through mass media. People must then decide to accept or reject that information, and the final step before forming a political opinion is then to sample from the most recent information that person is aware of. This final sampling step is often a decision by the person made by reflecting on the information learned from mass media sources. This is a dynamic process, and recency matters a great deal. Zallers insights and modeling have had a broad, long-lasting impact on how we understand the formation of political knowledge, belief, and values. 4.23.2 What Americans Know About Political Information Quite separate from the question of how we learn political information is the question of what Americans know about politics. In this area normative democracy theorists will not find much peace of mind. Some of the original research in this area from Converse (1962) showed that Americans frequently have little political information with which to base their partisan identification, and lack coherence when asked open-ended political questions (Converse, 1964). In What Americans Know about Politics and Why it Matters, Michael X. Delli Carpini and Scott Keeter (1996) follow Converse, and carefully and thoroughly undermine the idea that the average American knows much at all about politics. The crux of the book is that the distribution of political knowledge is very uneven. Americans from higher socio-economic backgrounds, older Americans, white and male Americans, in part or in sum, all have a fairly good basis of political information. However, if Americans who are young, from the inner city, black, or female, tend to fare worse in tests of political knowledge. These differences matter not only for knowledge, but for rates of participation, and even the effectiveness of that participation. One area where the authors have been critiqued is that they do not distinguish what types of knowledge might be more useful for different demographic groups. For instance, while a white, middle aged male might have his political needs served by certain information (the type the authors test for), a young black woman may have very different political information needs. Delli Carpini and Keeter do an excellent job documenting their research process, and the methods used to come to their conclusions. While their argument stretches in some areas (see Baum, 2002, below), overall they make a good case for why we should be concerned about what Americans know about politics. One example of how John Zallers (1992) work has influenced later research is Matthew Baums (2002) Sex, Lies, and War: How Soft News Brings Foreign Policy to the Inattentive Public, which helps explain how the media affects what Americans know about politics. Baum shows that soft infotainment shows, which regularly cover the big political foreign crises of the day, help shape Americans views of foreign policy. This helps explain one of the counter-intuitive findings from Delli Carpini and Keeter (1996) that Americans possess more information about foreign policy than domestic policy. 4.23.3 Political Knowledge and Meaningful Participation Do Americans have enough factual information to be able to participate meaningfully in their American democracy? The findings of Delli Carpini and Keeter (1996) along with others would argue that Americans do not have the political knowledge to participate fully. Because political information is distributed unevenly across demographic groups, groups with less access to political information participate less, and when they do participate, they are less likely to attain the political results they seek. This is reminiscent of the findings of Larry Bartels in his book Unequal Democracy (2016), which shows that while lower-income Americans tend to vote at similar rates as higher income Americans, their vote counts for less because it is given less preference by politicians. The finding that socio-economic status influences the impact of political participation is found across modes of participation, as shown in Citizen Activity: Who Participates? (Verba, Schlozman, Brady, &amp; Nie, 1993), which found that lower income Americans were less likely to become political activists, and even when they did they used different (although sometimes more effective) communication methods than did activists with more financial resources. However, some scholars would disagree with the stark findings of the scholarship above. Lupia (1994) argues that voters dont need to be fully informed encyclopedias in order to vote, and that less-informed voters use information shortcuts to vote in ways very similar to their better-informed counterparts. Lupia uses empirical evidence from a California initiative on insurance reform, a topic that most typical voters will have very little information about. Low-information voters participate meaningfully by relying to cues from third-parties such as advocacy groups and political parties to form their political opinion, which is then translated into voting that is not dissimilar to those who spend much more time delving deeply into political issues. However, this kind of partisan motivated reasoning has been found by other scholars to reduce the quality of political opinions (Bolsen, Druckman, &amp; Cook, 2014), and to be more shaped by the power of prior belief than the accuracy of new information (Taber &amp; Lodge, 2006). Americans must make political decisions in a complex, fluid environment, and much of the scholarship which finds lackluster participation and lower political efficacy is based in a somewhat elitist rational choice belief that correct participation or incorrect voting exists in the first place. Lau and Redlawsk (2006) undermine this assumption in How voters decide: Information Processing in Election Campaigns. The authors use clever experimental methods to test four models of how voters process information and make voting decisions. They have subjects make voting decisions on hypothetical candidates in a time-pressured environment, and then in the second phase allow those same respondents to collect information for as long as they need before making a voting decision. Subjects who change their vote between the first and second phases are considered to have made an incorrect vote in the first phase, while those whose vote is consistent between phases made correct votes. They find that in up to three-quarters of the time, their subjects were able to make correct votes despite not knowing enough. The methods used by Lau and Redlawsk are subject to critiques that their experiments are artificial environments, and so dont necessarily tell us exactly how voters make decisions in real elections. However, the value of these experimental findings is that they closely mimic the frantic, bounded rationality (Simon 1972; 2000) and heuristic shortcuts (Lodge &amp; Hamill, 1986; Taber &amp; Lodge, 2006) real Americans in the real world must contend with when making political decisions. In many ways Lau and Redlawsks findings are supportive of Lupia (1994) and others who reject the belief that democracy can only function properly when Americans are participating with rational, well-informed political knowledge. ### Conclusion Americans are remarkable political creatures. They form political knowledge along socioeconomic cleavages, vote at low rates and participate in declining numbers in other participation modes, possess little accurate political information, and their political participation tends to have little impact. Yet, their political behavior is redeemed when the context of that political behavior is more fully considered. It is a privilege to have the time, resources, and desire to fully pursue political information, and that privilege is extended to relatively few in American society. Still, despite the privations of political knowledge, expertise, and participation, most Americans manage to get it right most of the time  they operate in political spheres remarkably well in the face of factors which in a more rational approach should convince them to not participate at all. That is not to attempt to dispose of the normative democratic ideal, but perhaps to soften the approach of its most ardent believers. We should still heed the warnings of scholars such as Bartels (2016), who rightly worry that growing economic inequality threatens democracy. While not yet a thousand-year proven success, the American democratic experiment has so far succeeded despite the flaws of its citizens political knowledge. Short of the ideal lies a political persistence in the American citizen which manages to know enough, participate enough, and succeed politically enough. 4.24 What is Political Science For? Those who have handled sciences have been either men of experiment or men of dogmas. But the bee takes a middle course: it gathers its material from the flowers of the garden and of the field, but transforms and digests it by a power of its own. Sir Francis Bacon, The New Organon, 1620 4.24.1 Assessing the Discipline &amp; Profession of Political Science The authors in this reading selection seem to agree that political science scholarship is unbalanced on the whole, though the measures differ for each. All seek to redraw the contours of the scholarship landscape, and in doing so believe political science scholarship will better serve the public, and democratic ideals. Though their prescriptions (where existent) differ, the authors desire a more impactful political science scholarship  through methodological diversity, an embracing of teaching responsibilities, or new paths to addressing free-access goods. In looking backwards to identify gaps, and attempting to describe a path forward, all four authors ignore the paradigmatic shift coming to all social sciences through the development of deep-learning neural networks and artificial intelligence. In a future where a century of empirical data is reworked in relative moments by machine learning capable of descriptive inference at a resolution unobtainable by a human mind  what is a political scientist? 4.24.2 Conversations The four authors all trace selected histories of the political science field, and describe dialogic forms they believe are unbalanced. Robert Putnam (2003) seeks to hold quantitative methods in high esteem while raising the qualitative ones alongside. Robert Keohane (2008) argues for a value-laden political science, and a recommitment from scholars to teaching undergraduate and graduate students. Finally, Jane Mansbridge (2014) seeks to turn a field too focused on preventing tyranny towards discovering better paths towards legitimate coercion in order to find solutions for the free-access problems facing humanity. In a way, Rogers Smith (2015) goes further than the others and sees a political science too enamored of science, producing research without impact, and failing to serve democracy or the public. Smith sees political scientists serving the goal of intellectual rigor at the expense of what is supposed to be an equally important goal  serving democracy. In chasing quantitative methods and rational choice theory, he argues, we have neglected important political questions not amenable to such methods (Smith, 2015, p. 368). Smith continues his analysis by equating this neglect with a failure to enhance democracy, and linking both to low public confidence in political science research. How then have the other sciences had success in both? Smith doesnt appear to contemplate other social science scholarship which, while often being rigorously quantitative, still surfaces in every news cycle with findings that appear to interest the general public (assuming the preferences of the news directors who continue to select such stories are an appropriate proxy for public interest). Smith complains the sentinel works by Elinor Ostrom (1990) and Robert Putnam (2001), the two most influential political scholars in recent decades, tend to celebrate many traditional American values and institutions, to express concern about loss of older civic virtues, and most importantly, to favor decentralized, civil society solutions to common problems  not big government, certainly not any radical egalitarian reform agendas (Smith 2015, p. 369). This is a strange complaint, as Smith later essentially acknowledges the American public is correct in dismissing the research arm of political science, given the limited public impact of most late twentieth-century and twenty-first century American political science scholarship (Smith, 2015, p. 374). Its not clear which Smith wants more: public impact or radical reform agendas? The two are unlikely to be found in the same book on the same bestseller list. Rogers Smith does not offer prescriptions alongside his diagnosis  the disease is too far along for remission: The trends I have sketched, he writes, are largely not reversible, nor would many types of reversal be desirable. Putman (2003) does not appear concerned about appealing to one partisan enclave or another. Rather, he sees a professional responsibility to engage with our fellow citizens in deliberation about their political concerns, broadly defined. Like Smith, Keohane sees a need for a recommitment to teaching of students, which will in turn strengthen the research goals of the field and its scholars. Keohane (2009, p. 363) sees most value in teaching students to question the taken-for-granted, to ask simple questions and on the critical imagination, conceptual boldness, and intellectual rigor of successive cohorts of newly trained scientists. Big Data, Big Problems Reviewing an entire field and categorizing it along two-dimensional scales  tyranny or legitimate coercion? Teaching or research? Quantitative or qualitative? Rigor or applicability?  is at once too broad a demand and too simple a remedy. All of them are right, and none of the authors are wrong- at least not for a retrospective look at political science scholarship. Their collected decades of thinking about political science scholarship has taken place in a context where the giants who came before, and their contributions, are intensely valued. Yet, of the four authors here, perhaps only Keohane appears comfortable with the knowledge that what comes next  artificial intelligence  could render what came before as interesting historical context. In a recent research note, Kriegeskorte (2015, p. 2) reviews how quickly advances in neural networks are approaching human-level performance in brain and vision tasks: Now deep neural networks provide a framework for engaging complex cognitive tasks and predicting both brain and behavioural responses. Kriegeskorte continues (2015, p.1): With human-level performance no longer out of reach, we are entering an exciting new era, in which we will be able to build biologically faithful feedforward and recurrent computational models of how biological brains perform high-level feats of intelligence. While other fields are excitedly moving forward with incorporating machine learning into their scholarship, what of political science? While not comprehensive, a simple Google Scholar query for political science and neural network and political science and artificial intelligence had no relevant results. Gary King is clear in his assessment (Lohr, 2012, p. 1): Its a revolution. Were really just getting underway. But the march of quantification, made possible by enormous new sources of data, will sweep through academia, business, and government. As political science scholars are well aware, revolutions tend to have some bloodletting, at least metaphorically, and our field, concerned with both government and academia, should not consider itself safe from such a revolution. Within the next several decades, deep learning neural networks and artificial intelligence will begin to replace two of the four pillars of what Keohane (2008) identifies as the core functions of political science: descriptive inference and causal inference. Retooling political science through old ontological debates will not answer the question faced by political scientists in the coming years: what are we for? To reframe Smith (2015, pp. 366-367): perhaps political science is not so exceptional. Political science is not alone in facing profound change in how scholarship will be done. Already, health care is reckoning with a future in which expert systems and deep-learning neural networks will soon outperform classical diagnosis in terms of recall and prediction. Does the field of political science fancy itself so different in scope and complexity that it can escape what other human-centered fields have already begun to cede core functions to? No matter ones preferred -tatives or -isms, it seems an unlikely outcome. In recent years Russian President Vladimir Putin predicted (emphasis supplied) artificial intelligence is the future, not only for Russia, but for all humankindIt comes with colossal opportunities, but also threats that are difficult to predict. Whoever becomes the leader in this sphere will become the ruler of the world (Hern, 2017). In the same week, and in response to Putin, technological wunderkind Elon Musk predicted the next world war will be started by competing artificial intelligence networks controlled by states (Hern, 2017). One would be hard pressed to understate the salience for political science or the threat to democratic values presented by a government (whether autocratic, tyrannical, or democratic) ceding strategic and tactical control of their military to an artificial intelligence. International power, regime studies, war theory, genocide, administrative evil, and ethics  nothing is off limits. Jane Mansbridge (2014), in attempting to locate paths to legitimate coercion, may be most well positioned to contribute to a future political science in an era where political actors have been replaced by political artificialities unconnected to human experience. Political science, with its history of studying human conflict writ large, can help guide the ethical considerations and responses of inhuman, or at least non-human, politics of the future. Sarah Jordan (2014, p. 375), writing in Public Integrity, predicted The future of public administration lies in its ethical knowledge work and expertise. Sounding similarly alarmed, Donald Menzel, (2015, p. 363) noted that the ethical implications of government use of information technology  which is the basest level of technological complications on the horizon  is one sketchily researched area deserving more scholarship (Menzel, p. 363). If machinated intelligence comes to dominate descriptive and causal inference, as appears likely, what political scientists should get better at is the puzzling (Keohane, 2008, p. 360)  observing what does not fit with theory - and conceptualizing, particularly as it relates to translating scholarly arcana to ordinary usage. We must become better data scientists and qualitative researchers and puzzlers and conceptualizers  all at once. Alongside those, society will be in need of intense scholarly focus on instilling our ethical knowledge work into the machine learning, neural networks, and artificial intelligences that are the future of both governance, and the study of governance. In her address to the Southern Political Association, Mary Guy (2003, p. 651) stated: The field is served best when we remain self-consciously aware of the implications of our models and the information they produce. Two decades hence, the best human political scientists will be those that who are able to be aware of the human and ethical implications of models and information produced by inhuman minds. The big question, as seen by Sara Jordan (2014, p. 276): How ought government protect the public against the use of their data but also protect the public through the use of their data? The field of political science should be prepared to begin answering that question  that is what we will be for. 4.25 Partisan Hearts &amp; Minds: Political Parties and the Social Identities of Voters In Partisan Hearts and Minds (Green, Palmquist, &amp; Schickler, 2002) partisanship is defined as a type of social identification: a psychological process of self-categorization and group evaluation (p. 13). People identify as a Democrat or a Republican in the same way they identify as belonging to a religious denomination or ethnic group. Instead of the warmth indicators used by many partisanship researchers in surveys, Green, Palmquist and Schickler argue that people ask themselves two questions: What kinds of social groups come to mind as I think about Democrats, Republicans, and Independents? What assemblage of groups (if any) best describe me? (2002, p. 8). This a rejection of the rational choice version of partisanship which dominated the academic view of partisanship at the time (Green &amp; Shapiro, 1996). How a person answers this question to themselves produces a very stable partisanship. The authors see partisanship as a relatively non-dynamic phenomenon. That is, rather than elections producing a great deal of party choice change among voters, most people already have a partisan identification (at least to themselves) and that identification is rather unlikely to change in the short-term span of an election cycle. Elections are more of a cause for cheerleading ones own team, and less a competition between two (or more) choices of individual politicians: Elections are also forums for intergroup competition. Individuals who identify with these groups are drawn into this competition. Their interest and level of emotional engagement increase as they embrace the team as their own. Although not irresistible, the desire to see ones team prevail powerfully influences the probability of casting a vote for the candidate of ones party (Green et al., 2002, p. 202). This willingness to see past rivaling individual politicians and engage with politics as social identification is why partisanship matters  it matters because it affects electoral politics. The authors seek to provide empirical support for their theory not just in American politics through the case of the 2000 presidential election, but in comparative international contexts as well, with evidence from the United Kingdom, Canada, and Germany. This is an important claim from the authors, who position their theory of partisanship not as an American phenomenon, but a human one. 4.25.1 Methodological Contribution The book makes a clear methodological contribution as well, despite containing relatively sparse statistical analysis than other texts in the genre. Because of their underlying critique that party identification has been poorly measured in much of the partisanship research, the authors present and defend a way of accounting for measurement error (p. 231-234). Once models of partisanship allow for measurement error, the authors argue, party identification is revealed as a very stable pattern over multiple decades. While in this work they use mean-corrected panel analysis, this is just one example of how to correct for measurement error. Psychologists have long recognized that measurement error interferes with causal inference (Baltes &amp; Nesselroade, 1979). Green, Palmquist, and Schickler make good use of this insight to address pooled measurement error, which still remains relatively unaddressed in much of political science research. The next steps needed can already be seen in modern techniques and rapid development still taking place in developmental psychology (Deboeck, Nicholson, Kouros, Little, &amp; Garber, 2015), which uses derivatives of both inter- and intra-measurement error. Political science has not yet developed even the tools to collect the tools needed to build datasets capable of being tested in this way. Once (if) they are, however, further insights into the stability of partisanship over time, and its vulnerability to political events including elections, could be gleaned. As it is, the authors make a good case for including measurement error in partisanship studies, and more broadly political science. 4.26 Southern politics in state and nation  VO Key VO Keys Southern Politics in State and Nation (1949) is a central text in American political studies, and the remains the single most important work in understanding the role of the South in American politics (Bateman, Katznelson, &amp; Lapinski, 2015, p. 154). VO Keys central insight that drives the analysis in the rest of the book is captured in his concept of black belts. These are the areas within Southern states with much higher proportions of black Americans. The dominance of black belt whites explains a tremendous amount of Southern politics, particularly the dominance of the Democratic party, which in many places effectively established one-party rule. Whites in the black belts have been the predominant shapers of politics in the South since even before the Civil War. Black belt whites successfully pushed for secession, despite opposition from many of the whites in non-black belt areas. West Virginia split from Virginia over this dispute. Though the secession of the South was defeated, the political power of whites in the black belt soon reasserted itself. In the 1890s a series of uprisings re-entrenched Southern political power in the hands of black belt whites. To varying degrees, black belt whites sought to establish one-party rule in order to prevent partisan competition for the black vote and to present unified political resistance to attempts from the Federal government to remove the white supremacist policies of the South. Key argues that in those southern states where there is more partisan competition, such as Florida, North Carolina, Texas, and Tennessee, the competition is a direct result of having fewer and smaller black belts. Where multiple factions exist, due to small black belts, more progressive politics emerge. As a result of greater electoral competition, rare Republican victories at the state level occasionally emerged. The increased partisan threat served to keep Democrats more organized and cohesive. Party discipline was needed to win elections, and the party was motivated to work for redistributive policies that benefitted more than just black belt whites. However, the cases of partisan competition are relatively limited in the South. In most states, one-party domination by Democrats was the rule. More than any other, Arkansas was the example of a pure one-party state, though the same general pattern could be found in most of the South. Extreme political conformity meant that no consistent factions arose, as political hopefuls were basing success on friends and neighbors in the areas they were lived. This reified the power of black belt whites, who in turn were motivated to rule through non-redistributive policy. After all, if winning elections means keeping your (white) neighbors happy, and politicians are at least strongly motivated to win re-election (Mayhew, 1974), then making sure those neighbors are well taken care of by the party machine is a rational strategy. Keys study of the South generated broader implications for political study of states and parties. His genius was in deriving more general political hypotheses from close study of Southern state cases. The primary insight is that the closer a state comes to pure one-party rule, the more multi-factionalism will result within those parties. In states with more (though not equal) partisan competition, both parties will become more cohesive. This begs the question: What is the difference between party and faction? Key sees the differences as a continuum, from the most extreme one-party rule in Arkansas and South Carolina to states where the minority Republicans came close to establishing two-party rule, most identifiably in North Carolina. Key identifies at least five differential effects  things parties do that factions do not. First and primarily, when there is a unified and persistent minority party, the majority party rules more responsibly, redistributes benefits to compete for votes among blacks and minority party members, and is more disciplined. Fractured factional leaders do not do this. Second, parties can organize voters, and sustain those coalitions of voters around shared interests, whereas factions are too locally focused on merging interests with other outside factions. Thus, factional politicians end up having to rebuild any coalition around a new identity each election cycle, without continuity of effort or dedication. The third effect is that states with more than single-party rule, the minority party can sustain their opposition, whereas factional opposition cannot. Fourth, the sustained nature of parties means that leaders are vetted and experienced over time, whereas in factions, charisma becomes more critical as they attempt to build coalitions each cycle quickly. Fifth, corruption, nepotism, and political favoritism are more endemic to factional rule in one-party states because factional politicians must use whatever means are available (Key, 1949, p. 305) as they attempt to bribe friends and neighbors to stay loyal. In a cohesive party, leaders are still likely to rewards friends with a place in the unified party government, but again this a done in a more distributed manner. Also, because there is a unified opposition party with at least some governmental levers to pull, the risk of discovery of criminal behavior in the majority party serves to keep corruption relatively lower. The differences between parties and factions show how complex results can spring from the relatively simple difference that parties have internal cohesion and discipline, while factions do not. With some limited exceptions, the South was a political body comprised of factions. Democrat rule was the rule. Whereas Key generally expects national politics to seep into local politics, if not dominate them, the South remained politically isolated from the nation. The Souths atomized factionalism meant the governments were generally unable to provide the political leadership necessary to cope well with the governmental problems of the South (Key, 1949, p. 310). The South was primarily organized politically around the interests of black belt whites, who were primarily interested in preserving their power at the expense of the blacks who far outnumbered them. This was a political division that did not hold at the federal level and reinforced the political isolation of the South, which remained insular and overly focused on localism and racist traditions. 4.27 More? Stay tuned! "],["pa-real.html", "Chapter 5 Public Adminstration Real Exam 5.1 Required Question: 5.2 Optional Question 1: 5.3 Optional Question 2:", " Chapter 5 Public Adminstration Real Exam This chapter provides an example of a full written comprehensive exam. In this common format, there is a required question that every student must answer, which generally is intended as a broad field literature review. In this exam, that question asks students to review the major schools of thought and theories associated with the classical school of public administration. Following the required question, five optional questions are provided to the student, who must select two to answer. Generally, these are a little shorter in length compared to the required question, but that is not always true. In the examples provided, I selected a fairly lengthy exam, hoping to provide you with more material to think about and synthesize with your own work as you prepare for exams. 5.1 Required Question: What is the classical theory in public administration? Who are the classical theorists and what are some of their arguments? What led to the rise of other theories/schools such as human behavior and contingency? Describe the theorists and ideas associated with the various schools. What are the strengths and weaknesses of each approach? 5.1.1 Public Administration: Classical Roots &amp; New Branches As a discipline, public administration is a study in unresolved and unresolvable tensions. The term public administration itself is difficult to define perfectly: Is it the professional practice of running public and non-profit services, or the academic study of that work that seeks to (Marini, 2000, p. 3) understand, develop, criticize, and improve that professional practice as well as train individuals for that professional practice? Does running a government differ from running a business? How intertwined are politics and administration? How intertwined should they be? As we confront the problematic tradeoffs in public policy, should we pay more attention to facts or values? This essay will review the traditions of primarily academic public administration, though its practitioners make appearances as well  like attempts to divide politics from public administration, attempting to describe American public administration through only its theorists is a doomed effort. The essay proceeds as follows. In the first section, I review the co-founding of America with the first examples of public administration norms in the acts of George Washington and the administrative structures of Alexander Hamilton. In the second section, the essay recounts the foundation of classic public administration through the works of its first theorists. In the third section, the essay covers the behavioralist and contingency movements in public administration. The fourth section details how the scholars thought about the public/private dichotomy in administration, and following that looks at the famous debate between Herbert Simon and Dwight Waldo. In the fifth section, the schools of New Public Administration, New Public Management, and New Public Governance are compared, before the essay closes with a short conclusion. 5.1.2 The Founding The dilemmas and tensions that the field of public administration is concerned with today are to a great degree the same that have been of concern from the moment of the nations founding. The Constitution set forth the framework that the nations Founders believed gave the nation a coherent way of addressing those dilemmas, but did not include detailed instructions on how to implement that framework (Rohr, 1986). In the centennial year of the Constitution, Woodrow Wilson, often acknowledged as the first scholar of public administration, would highlight the challenge (Wilson, 1887): It is getting to be harder to run a constitution than to frame one. The constitution was framed, but it was left to early efforts by George Washington and Alexander Hamilton to sketch out the institutional foundations that were necessary to run a constitution. Washington and Hamilton provided the most impactful early examples of how to administer a new nation: A system that holds service to the public as its first principle, and a blended economic, commercial, and military union that could prevail in the storm of state-based interests that would confront the nation. George Washington was Americas first president, and thus, the nations first executive administrator. Without binding precedent to guide him, Washingtons actions would themselves become the guide for all that followed. Key among his challenges was the creation of the tools to run the constitution, a challenge that for many public administration scholars remains the highest calling for the field. Washington was well aware that as the first president, his actions would reverberate throughout the nations future history. As such, he believed the foundation of his actions needed to be firmly set in principle. As he wrote to James Madison (quoted in Cook &amp; Klay, 2015, p. 76), As the first of everything, in our situation, will serve to establish a Precedent, it is devoutly wished on my part, that these precedents be fixed on true principles. Among his first actions was establishing a public administration, and the true principle Washington tied it to was the public wishes and affection. In other words, public administration should rest upon service to the public will. In his 1791 address to Congress, Washington tied the establishment of the direction of the nations public administration directly to the public will (Cook &amp; Klay, 2015, p. 77): It is desirable on all occasions, to unite with a steady and firm adherence to constitutional and necessary Act of Government, the fullest evidence of a disposition, as far as may be practicable, to consult the wishes of every part of the community, and to lay the foundations of the public administration in the affection of the people. The rough sketch of how to establish a public administration may have been penciled in by George Washington, but it was the hand of Alexander Hamilton that inked in depth and detail. Like Washington, Hamilton was a hero of the Revolutionary War, and he would establish and administer the signal public agencies of the first decades of the new republic (Green, 2019). Much of Hamiltons approach to public administration is not found in the Constitution he helped create, but in the Federalist papers (Hamilton, Madison, &amp; Jay, 2009) that defended the Constitution to a nation distrustful of a new Federal nation. Hamilton was responsible for authoring approximately 50 of the Federalist Papers, and he saw that the government could not solely be about checking power among the three branches, it would also have to enable action. Hamiltons concept of partial agency meant that powers should be blended among the executive, legislative, and judicial branches, such that the three institutions would collaborate to address the problems of the nation. His Federalist co-conspirator James Madison was a patrician elite who was focused on keeping the federated states civil, especially in regards to interstate trade. However, it was Hamilton who saw that the federal government should seek that civility explicitly through the development of a complex economic union. To accomplish that vision, Hamilton spent a great deal of his time enhancing executive power. Hamilton saw that the young nations survival would require an intricate bonding of the commercial and military functions of the state. Critical to that bonding was a strong defensive military capability, and as Secretary of the Treasury, Hamilton oversaw many of the first efforts in that domain. Green gives a sense of Hamiltons influence and scope as he shaped American defensive capabilities in a variety of administrative contexts (Green, 2019, p. 156): he attended to the organization and management of the Department of War, and through his management of the Customs Service and a fledgling Coast Guard, he oversaw the protection of harbors from French privateering as the French Revolution ensued. He also equipped militias and helped Washington lead in the successful effort to quell the Whiskey Rebellion in western Pennsylvania in 1794. When war loomed with France in the late 1790s, he returned to the military as a major general, second-in-command to General Washington, serving also as inspector general of the Provisional Army until 1800. He laid extensive plans and lobbied hard for the establishment of the navy, for the outfitting of a small standing army, and for professional military academies in which to train military leaders and subordinate officers in matters ranging from broad military policy to the technology of warfare. As he discusses in Federalist essays 23-29 (Hamilton et al., 2009), Hamilton believed a permanent military establishment would eventually become necessary to secure the republic. However, distrust of centralized federal power among Anti-Federalists was strong and able to prevent the establishment of a fulltime federal military until after the Civil War. We should not underestimate Hamiltons impact on public administration based on whether an institution was or was not established, because it is his vision that so strongly permeates how we think about public administration even today. The controversies Hamilton confronted were often left unresolved, and persist today. Hamilton was born a member of the lower socioeconomic class, and knew what it meant to be treated as a second-class citizen. Hamilton even suggested that indigenous and Black Americans should be treated as citizens (though he famously did not include women in his progressive vision). Even today America has not resolved its racial or gender inequality (Riccucci &amp; Ryzin, 2017), but in Hamiltons day, that idea was genuinely radical. Hamilton sought social revolution through commercial and economic revolution. His successes come to us today as unresolved questions on public versus business administration. Perhaps the most lasting unresolved controversy is Hamiltons view that there was no politics and policy dichotomy: Administration and policy merged seamlessly in his mind, each conditioning the other (Green, 2019). The founding of the American nation and construction of its initial administrative scaffolding were successful in setting the stage for a constitutional public administration, though the imprinting of the separation of powers in the constitutional arrangement would never disappear from the countrys administrative structures (Kettl, 2015; Rosenbloom, 2016). A system of addressing the controversies resulted in regularized processes of administrative law. The Constitutions framers created a certain ambivalence in the status and direction of American public administration (OToole, 1987). The Constitution embedded the concept of separation of powers the American consciousness, and so it should be no surprise that as the administrative state was founded, there were efforts to instill a similar balance by dividing politics and policy. The Pendleton Act, also known as the Civil Service Act of 1883, is an example of attempts to divide politics from administration (Theriault, 2003). The act aimed to insulate the bureaucracy from political influence, and even more obviously represented an effort to enact the dichotomy (OToole, 1987). Before Wilson introduced his own dichotomy to public administration, there were efforts to legislatively do the same to the practice of administration, such as the Budget and Accounting Act of 1821 - probably the greatest landmark of our administrative history except for the Constitution itself (Emmerich, 1971). Similarly, the Hatch Act of 1939 legislated the dichotomy even further by prohibiting federal employees (and some state and local by 1940 amendment) from participating in most partisan political activities. 5.1.3 Classic Public Administration The first century of the young nation established a public administration apparatus, but it took that century before any scholarly attempt to study it began. Woodrow Wilson was the first to do so in 1887. Though much later he would become president himself, at the time he was interested in government and how to best understand how a government should organize its efforts. In his article Study of Administration (Wilson, 1887), he argued that the complexity of government meant that the best was to study it was from two perspectives: the politics found in the legislative function, and the public administration found in the executive functions of government. This gave birth to a politics and policy dichotomy that would dominate our academic understanding of public administration until late in the 20th century (Goodnow, 2017). Though Wilson acknowledged that the two areas of government were intertwined, his on the dichotomy was an academic convenience to simplify the study of it. Wilson argued that the politics of governing could best be understood when it was intentionally isolated from the administration of political decisions. In this early Wilsonian view, decisions about who gets what, when, and how (Lasswell, 1936) are best understood by studying the political and legislative (who gets what, when), separate from the executive actions to complete politics decisions (how). Wilson sought to scientifically uncover the principles that would enable public officials to run the Constitution, by establishing the study of public administration as a field of study separate from politics. Classic public administration scholarship was dominated by systematized and hierarchical theorizing, exemplified in Frederick Taylors (1914) scientific management, and Luther Gulicks (1937) acronym POSDCORB: (planning, organizing, staffing, directing, coordinating, reporting, and budgeting). Neither theory is useless or unused, even today. Taylor was an engineer interested in applying the scientific method towards management, and finding the single best way to organize human effort. He saw scientific management as putting greater demands on management and easing the work of the worker. Taylor advocated a scientific approach, to move the knowledge contained in the workmans heads onto paper where it could be studied, best practices extracted, and then propagated to other systems. In his view, this would lead to minimal conflict between workmen and management. The embrace of Taylorism and scientific management was inexorably linked to an abstraction of the laborer, a view that has been called the productivism of late 19th and early 20th-century management (Rabinbach, 1992). Productivism was a view of human labor as (Scott, 1999, p. 98) a mechanical system which could be decomposed into energy transfers, motion, and the physics of work. In America, Taylor is responsible for establishing the technocratic framework in which to measure and administer that mechanical system (Maier, 1970). Taylorism was not a political system, or even a democratic one, but instead played to the high modernist, utopian visions (Scott, 1999) in America and beyond (Rabinbach, 1992, p. 272): Taylorism and technocracy were the watchwords of a three-pronged idealism: the elimination of economic and social crisis, the expansion of productivity through science, and the reenchantment of technology. The vision of society in which social conflict was eliminated in favor of technological and scientific imperatives could embrace liberal, socialist, authoritarian, and even communist and fascist solutions. Productivism, in short, was politically promiscuous. The United States entered World War I under the presidential leadership of Woodrow Wilson, who is also often recognized as the first formal scholar of public administration (Wilson, 1887). The bureau men of public administration embraced Progressive era ideals that were born in rejection of the atrocities of World War I, and further, an optimism that industry and science that would lead the country to a new golden administrative age (Stivers, 1995, 2002). Progressive reformers were informed by the pragmatists of an earlier decade, such as John Dewey, who was distrustful of the absolute reason imposed by the Hegelian ideal of the state (Dewey, 1915), and especially its institutional form found in the Prussian and Germanic military states. As Spicer (2005) notes, there is a clear link between the Prussian military state and foundational public administrative thought  what Spicer deems the purposive state: a nation that turns its power, resources, and citizens towards certain ends, as opposed to the state as a civil association. Spicer succeeds in showing the influence of Prussian and German thinking on modern American administration through their influence on Woodrow Wilson and others. Dewey was wary of the militarism that he saw in Wilson and others, particularly a warlike mentality and nationalism he felt was ultimately destructive to his normative view of what the American state could be, arguing that (Dewey, 1915, p. 118) philosophical justification of war follows inevitably from a philosophy of history composed in nationalistic terms. History is the movement, the march of God on earth through time. . . . War is the signally visible occurrence of such a flight of the divine spirit in its onward movement. The idea that friendly intercourse among all the peoples of the earth is a legitimate aim of the human effort is the basic contradiction of such a philosophy. Though Wilson expressed disquiet about Prussian state theory almost thirty years earlier (W. Wilson, 1887), he believed Americans could safeguard against the excesses, that we could borrow effective methods of sharpening a knife without engaging in the same murderous ends. Though foundational, Wilsons propensity to engage in self-evident truths would be replaced by public administration scholars wary of easy answers based on clever metaphors (Simon, 1946). The promise of technological solutions was attractive to Progressives as they sought to alleviate class struggle and suffering. The classical public administration born in the pragmatic and Progressive early 20th century was one that embraced scientism. This embrace had the unintended effect of silencing the essential voices of women in early public administration (Feldheim, 2003; Follett, 2016) who ran the settlement houses of the period. Science was understood to be a masculine pursuit, while the human-centered approaches of the settlement women were left behind by Progressive men who tired of being slandered as long-haired men in emasculated service of short-haired women (Stivers, 2002). Gulick attempted to move beyond Taylors scientific management, with an effort to more logically divide work. Gulick proposed there are limits to division of work, and that proper coordination among the divisions of labor are necessary: If a subdivision is necessary, so is coordination of that work. Gulick was an early positivist who believed empirical research would be necessary to understand a range of questions, including the proper span of control, or how many laborers a manager could be expected to manage well. He did not approve of multiple commands, but instead urged unity of command. Finally, he was not a technocrat and did not trust experts to stay within their own field: experts on tap, not on top. In his view, the study of organizations must be approached from both bottom-up and top-down perspectives. Gulick combined his insights into a theory of the proper executive: A chief executives job is PODSCORB planning, organizing, staffing, directing, coordinating, reporting, budgeting. 5.1.4 Behavioralism and Beyond The end of World War II brought about the end of orthodox (or classical) public administration, and the beginning of behavioral, empirical public administration (Marini, 2000). The behavioralist bent was not unique to public administration scholarship, and was sweeping across the social sciences broadly. In public administration, behavioralism was simultaneously taking place alongside a new humanistic, values-oriented approach. This section will explore the most visible debate between those two views later in recounting the Simon/Waldo debates (Simon, Drucker, &amp; Waldo, 1952). First, however, I trace how the bureaucratic approach was converted to an organizational one. The post-WWII period brought new energy to the study of public administration and efforts to diversify its theoretical and empirical study. Gulicks (1937) bureaucratic approach covered earlier is still alive and well in the practice of public administration, even as its academic study leaves the acronym behind as too simplistic. Even in Gulicks day, other scholars thought his prescription was unrealistic and too unfocused on the people that make organizations work. Charles Barnard (1938) recognized the importance of individuals and that organizations cannot be well understood without also understanding people. While Gulick focused on the formal lines of command, familiar to us today as organization charts, Barnard highlighted the importance of informal organizations. Informal organizations are based on personal rather than joint purposes, and promote uniform states of mind by crystallizing mores and customs. Barnard set out several ways informal and formal organizations are interdependent: Informal organizations give rise to formal organizations; formal organizations are necessary to any large informal organization; formal organizations make explicit the states of mind developed within the informal organizations; formal organizations in turn also create new informal organizations. Finally, informal organizations are necessary to formal organizations as a means of communication, cohesion, and of protecting the integrity of the individual. A sociologist at Columbia University, Robert Merton (1939) stressed how the study of bureaucracy misses the importance of personalities within the bureaucratic structure. Merton saw how bureaucracies infuse the employees with certain rules in order to maximize efficiency, but these rules become the end, instead of a means to the end. Merton saw this tendency in organizations that were soon run over with bureaucratic hurdles (red tape) that hindered efficiency and effectiveness. Merton called on other social scientists to begin studying public administration. Many soon did, and relied on Maslows hierarchy of needs as a basis for understanding human motivation in organizations. Also at Columbia University, Maslow (1943) described a basic structure of human needs, arranged in a hierarchy: Basic needs, safety needs, love needs, and self-actualization. Though not substantiated empirically, Maslows hierarchy proved crucial to the beginnings of motivational and human-focused theories in the study of administration. The human focus for some public administration scholars can be seen in MacGregor (1960) and his Theory X and Theory Y approach to motivating employees. Most theories of public administration were based on expectations that employees would shirk their responsibilities and therefore needed close supervision and clear punishments to keep them in line. MacGregor saw that another approach, based on Maslows hierarchy of needs (Maslow, 1943), was better suited to the evolving workplace. In this Theory Y, MacGregor advocated that the individual worker is creative and driven, and a good manager encourages employees to problem-solve on their own, gives them the tools to do so, and then gets out of the way. Theory Y is management by objectives rather than the carrot and stick management of Theory X. MacGregor saw this as a necessary adjustment to an evolving workforce that expected more out of work than mindless micromanagement: This is a process primarily of creating opportunities, releasing potential, removing obstacles, encouraging growth, providing guidance. In MacGregors view, this was not leadership for public managers, but management for both public and private agencies. By the end of the 1960s, it was clear that the classic model of ideal bureaucracy (Weber, 1947) was no longer serving public organizations well. Unstable political and strategic environments meant that the nature of public organizations had to be more flexible than the strict hierarchical models of the classical theories permitted (D. Katz &amp; Kahn, 1978). James Thompson (1967) theorized on how modern organizations could adapt, with a theory of contingency. Similar to the impact that Lipsky (1983) would have with his street-level bureaucrats, Thompson was influential in raising the profile of middle management in particular. Managers in public organizations must emphasize change, adaptation, and evolutionadopt an open-systems perspectiveanticipate trends, scan for threats, span boundaries, enact changesand expand the organizations domain (Morgan, Green, Shinn, &amp; Robinson, 2013, p. 184; Thompson, 1967). Thompsons model was not restricted to, or even primarily focused on, just public organizations. His work enveloped both private and private spheres, and as was common at the time, did not necessarily differentiate between the two. 5.1.5 Divorcing Public from Private, Proverbs from Positivism The application of business principles to public administration practice was a taken-for-granted good in public administration , and even today there are consistent efforts to imbue government with the magical efficiency of public markets. One early effort to separate public and private management, and to more closely intertwine democracy and public administration, was made in the book Government is Different (Appleby, 1945). Three aspects differentiate running a government versus a business. First, the government has a vastly expanded scope and impact. Second, the government is publicly accountable to everyone, not just a small pool of shareh0lders. Third, the political character of public administration means that the government must take into account the will and wishes of the people, a factor that recounts Washingtons founding principle of public administration. Appleby saw that government, in its people, attitude, and function, is different from any other activity, including business. He was especially critical of those who would come from the business world and expect governing to be a good fit for them: Only a politician can be president. Government is different because government is politics, and while businesses are able to select their market carefully, government has no clearly delineated border: Statecraft - government - is different than all other professions because it is broader than anything else in the field of action. As late as 1955, with the publication of the first public administration textbook, business and public administration were still seen as somewhat synonymous, and the textbook called for a public administration that is more than the time-honored approach of muddling through (White, 1955). Public administration was seen as the great problem of government, and like the original call for more exacting study (Wilson, 1887), White (1955) suggested that American democracy could learn better administration techniques from the autocrats in Europe. There was a growing focus on the longest-lived organizations, churches and universities (Downs, 1967), and Europe was home to the oldest of both (at least to the Western-centric scholars of public administration at the time). Even as Downs theorized the lifecycle of bureaus resulted in highly conservative institutions, however, the landscape of American public administration was shifting. Civil service unions were gaining power as their membership grew massively at both the federal and state level (Mosher, 1968). Bureaucrats were no longer the heroes of the progressive era and a new, negative connotation was taking hold. The unending cycle of reform in American public administration (Kaufman, 1969) was due to the uniqueness of the American experience, especially the constitutional nature of power separation that led to a succession of shifts in focus on three core values: representativeness, politically neutral competence, and executive leadership. Kaufman argued from a pluralist perspective and saw that none of the three was ever truly absent from the American consciousness, but the focus changed. And as the focus changed, pressure from groups interested in the other two brought pressure and calls for more reform. Kaufman saw the calls for decentralization of government power in his time as the result of racial and youth power groups who felt underrepresented in the current regime. The constant reform was not a negative, however, as Kaufman wrote that wheels turning on their own axes still advance. The dangers of too much political control of the bureaucracy became clear in the wake of the Watergate era. In Moshers (1974) view, Watergate was an aberration, and extension, and a culmination of events that had their root in a lack of bureaucratic independence. The overwhelming drive to re-elect Nixon subsumed all other ethical and legal considerations for many in the administrative agencies. There was a purge of top-level officials following Nixons first term, where anyone deemed too hesitant or lacking pure loyalty was removed. The Watergate climate was the result of too close a relationship between the political and administrative spheres, with the political side pressuring the administrative side to take action designed solely to enlarge presidential power. 5.1.5.1 Simon and Waldo Debates The most critical inflection point in the modern study of public administration came from Herbert Simon. Simon was an organizational theorist who urged scholars to think carefully about what a methodology of public administration should be (Simon, 1946): How do we acquire scientific or empirical knowledge about public organizations? Webers (1946, 2015) ideal bureaucracy does not exist in the real world, so how can we compare and contrast the types of bureaucracy in a scientific sense? Herberts wide-ranging critique of the study of administration was born from the positivist and post-positivist debates (Popper, 1959) that sought to replace the verifiability claims of empiricists with a demand for falsifiability. Herbert likened what came before to proverbs, not scienceArmchair philosophizing about administrationhas gone about as far as it can profitably go in this particular direction. Herbert provided the push to turn the study of public administration towards post-positivist science. Dwight Waldo disagreed with Simons positivist prescription for the direction of public administration scholarship going forward, and the two engaged in an exchange of ideas in the pages of the American Journal of Political Science. The Simon-Waldo debate was structured on two differing philosophical perspectives that continue to define the study of public administration today (Harmon, 1989). The debate was quite ugly, and a full understanding of the importance of the debate only became clearer with the passage of time, and as Herberts unique genius became even more noticed with the awarding of the Nobel Prize in Economics in 1978 (March, 1978). However, two decades earlier the first punch in the defining debate in public administration scholarship began with the fortieth footnote in Waldos essay Development of Theory of Democratic Administration. Waldo maintains that to follow arguments for efficiency in administration to their logical ends is to engage in nihilism, and then while he emphasizes the need for democratic values in making administrative decisions, he manages to slight Simons accomplishments as being unscientific (Waldo, 1952, p. 97): In this contention, the present weight of authority is against me. But I believe that there is no realm of factual decisions from which values are excluded. To decide is to choose between alternatives; to choose between alternatives is to introduce values. Herbert Simon has patently made outstanding contributions to administrative study. These contributions have been made, however, when he has worked free of the methodology he has asserted. Until this point, Waldo and Simon had been complimentary of one another, and both attacked the naÃ¯ve scientism that had dominated the study of administration to that point. However, beginning with Waldos salvo, it was clear that two competing visions had emerged. On the one hand, Simon drew analytic distinctions between facts and values, and then another distinction between administration and policy. On the opposing hand, Waldo insisted that administration and policy were both impossible to separate from normative values (Harmon, 1989, p. 440): Waldos project was, after all, to warn of the limits of science in human  and, in particular, administrative affairs, while Simons was to inform us of its power. Where Herbert sought efficiency, Waldo asked efficiency for whom? Many a barrel of ink has been spilled evaluating the Simon/Waldo debates, and it is outside the scope of this essay to cover the differences in full, nor is it particularly helpful to understand either Simon or Waldos philosophical orientation to public administration through a handful of their papers in the early 1950s. Some of the draw of this debate is no more than the dramatic counter-punching and name-calling that took place. For instance, consider this exchange opened by Simon in his first reply to Waldo, (Simon et al., 1952, p. 495): Quite apart from whether Mr. Waldos premises are right or wrong, I do not see how we can progress in political philosophy if we continue to think and write in the loose, literary, metaphorical style that he and most other political theorists adopt. The standard of unrigor that is tolerated in political theory would not receive a passing grade in the elementary course in logic, Aristothelian or symbolic. Waldo does not back down from his literary, metaphorical style in responding (Waldo, 1952, p. 501): Professor Simon charges me with profaning the sacred places of Logical Positivism, and I am afraid I have. I use this figure of speech because Professor Simon seems to be that rare individual in our secular age, a man of deep faith. His convictions are monolithic and massive. His toleration of heresy and sin is nil. The Road to Salvation is straight, narrow, one-way, and privately-owned. We must humbly confess our sins, accept the Word, be washed pure in the Blood of Carnap and Ayer. Then, he says, we will no longer be enemies. I do not mean to suggest the two did not engage with the substantive issues that had brought them to loggerheads in the first place. However, the visceral, pointed debates were more fun to read because of the high personal stakes each was willing to bring to bear in defense of their philosophical orientations. This was not a removed, dry, and academic debate most were used to in the low-stakes philosophical battles waged in the pages of American Journal of Political Science. A stylistic dichotomy has persisted in how we think about the Simon/Waldo debate, however, and that differing view is that Simon has come to represent the unrepentant logical positivist, while Waldo plays the foil as the artistic, normative, and value-concerned philosopher. Neither caricature is accurate, but both are helpful in understanding the mens influence on the ensuing development of public administration scholarship into a post-normal field of inquiry (Riccucci, 2010). 5.1.6 The New Public (Administration, Management, Governance) The logical positivism of Simon and the values orientation of Waldo have been replicated in contemporary conflicts between the two main theoretical orientations of scholars: New Public Management (NPM) and New Public Governance (NPG). Simons scientific, efficiency-centered outlook underpinned the rise of NPM to a dominant approach by the 1980s, while Waldos vision is seen in NPG, which makes value conflicts a legitimate function of administrative work Morgan &amp; Shinn, 2014, p. 9). The politics-administration dichotomy is sometimes seen as a quaint or naÃ¯ve view of the shape of bureaucracy by scholars, but the normative value of a neutral bureaucrat still has a powerful hold on Americans view of the bureaucracy. The traditional views of public administration put forth before the 1970s elevated increased efficiency, economy, and coordination as its primary goals. In his essay Towards a New Public Administration, Frederickson (1971) added social equity (defined as activities designed to enhance the political power and economic well-being of disadvantaged minorities) to the mix. Frederickson was providing an overview of the 1968 Minnowbrook Conference, a gathering of public administration scholars in which Dwight Waldo played an important role. Minnowbrook attendees sought to define the normative orientation for public administration scholarship by focusing on equity (Frederickson, 1971): Simply put, new Public administration seeks to change those policies and structures that systematically inhibit social equity. In a departure from the logical positivism of Simon, New Public Administration did not elevate neutrality as a value: public administrators should be committed to both good management and social equity as values. The New Public Administration (NPA) framework would return with a fuller theory of public administration eventually in New Public Governance (Morgan &amp; Cook, 2015; Osborne, 2006), but at the time its most apparent contribution was to add equity to the traditional formula of efficiency, effective, and economic management of public agencies. Between Minnowbrooks innovation and its eventual translation to the New Public Governance (NPG) came an intervening acronymic regime of public administration: New Public Management (NPM) (Hood, 1991). Though acronymically similar to New Public Administration, its goals and emphases are quite different. NPM attempted re-inject the responsive, customer-centric management perspective found in business management into public administration (Mastracci &amp; Guy, 2019). To do so, NPM applied business management techniques such as a focus on customer satisfaction, performance measurement, and competition into the public sector. The approach first emerged in New Zealand but soon found eager practitioners in the United Kingdom and the United States (Hood, 1991; Mastracci, Adams, &amp; Kang, 2019). The values of NPM are rooted in principles of economic markets, and those values mean that decisions are often made with market interests (Stone, 2002), such as cost minimization, profit maximization, and return-on-investment. Though the critiques of the approach are manifest and will become evident momentarily, NPM was successful in some areas. The focus on measures of efficiency and effectiveness gave public managers and street-level employees (Lipsky, 1983) the capacity to use their expertise to diagnose and correct operational problems (Ammons &amp; Rivenbark, 2008). NPM also emphasized performance management, and the resulting visibility of performance data broadly increased interest in systems of accountability in government (Barzelay, 1992, 2005; Pandey &amp; Moynihan, 2006; Wholey &amp; Hatry, 1992), as well as the role of selection and motivation of public employees to improve organizational performance (Moynihan &amp; Pandey, 2007). Finally, the emphasis on systems of performance management expanded the array of values that were considered important in public administration to include cost, efficiency, outputs, outcomes, impacts, satisfaction, responsiveness, and quality of life (Morgan &amp; Shinn, 2015). Though NPM saw some successes, it cannot overcome two fundamental problems. First is that there is no common denominator that can be applied in a cross-cultural context, and so there is no common basis for comparison (Dickson, BeShears, &amp; Gupta, 2004; Haller, Jowell, &amp; Smith, 2009; Mastracci &amp; Adams, 2019). Relatedly, even the modest expansion of values that can be measured pales in comparison to the values available and vital to the study of public administration: fairness, equity, protection of rights, and transparency play important roles in determining the legitimacy of political institutions, processes, and outcomes (Morgan &amp; Shinn, 2015, p. 4). The second shortcoming of NPM is its over-reliance on models of business administration to structure the governance of public institutions. Consider just the American example of public administration, with overlapping spheres of authority and influence at the federal level, to say nothing of the balkanized state and local government, reliance on non-profit entities, and contractual relationships between public and private sectors (Morgan, Green, Shinn, &amp; Robinson, 2013, pp. 115118). These critical flaws in classic administration were not overcome by NPM, which in turn led to the founding of NPG. As the failures of NPM became apparent, scholars noted a new approach was needed, one that acknowledges the existence and likely persistence of third-party government and that brings the new tools of public action that are now in widespread use to the center of public and professional attention (Elliott &amp; Salamon, 2002, p. 8). From that call was born NPG, which begins with acknowledging the pluralist nature of the state (Dahl, 1982), and sees that to manage such a state demands acknowledging the co-production of values among the participants in that state. Co-production, in turn, leads to value conflicts, and it is the role of public administration to manage those value conflicts (Stone, 2002). The second main advantage of NPG over NPM is in the formers focus on an engaged citizenry, enabling the efficiency found in co-production. NPG moves well beyond the limited, dichotomous view of public versus private sectors in the classical public administration to a networked, holistic concept of public and private and non-profit (Pestoff, Brandsen, &amp; Verschuere, 2013). This integrates the polycentric theories of the Ostroms work (E. Ostrom, 1982; 2011; V. Ostrom, 1987). The polycentric concept was originated in studies that looked at conflicting studies of municipal police departments (Parks et al., 1981), which could not parse why small city police departments had fewer costs, while they enjoyed more trust and satisfaction from the residents they served when compared to large police agencies. The orthodox theory at the time predicted that the efficiencies of large metropolitan police agencies should improve trust and satisfaction among residents. The answer to the seeming contradiction was found in what was deemed co-production of public safety (Parks &amp; Ostrom, 1999). In smaller jurisdictions, residents knew their public safety officials and felt safe reporting suspicious activity and crimes to a degree that residents of large metropolitan areas did not. The close relationship between public and private actors co-produced public safety, and accordingly the costs of public safety were less in smaller jurisdictions. This model of co-production was soon modeled in areas of local governance other than public safety (McGinnis &amp; Ostrom, 2012). Though there were substantial issues with study operationalization and measurement know even at the time (Pachon &amp; Lovrich, 1977), the establishment of co-production as a legitimate theoretical construct in public administration is still important today. Co-production is a core value of NPG, and means that successful public managers are able to interact with a public that is citizen, customer, and partner (Thomas, 2013). 5.1.7 Conclusion Looking back on the first century-and-a-half of the formal study of American public administration, one can quickly see how the field has consistently been drawn to consistent dichotomies. Wilson (1887) saw it as a division between policy and politics. Simon and Waldo drew distinctions between science and values (Harmon, 1989). New Public Management sought the adoption of private market theories into the management of the public weal. New Public Governance pivoted from the business management model of governing and reinvigorated public management with a call to blend public, private, and non-profit. The seduction of epistemic communities continues to drive much of current scholarship as well, as sub-communities of the public administration field hew close to their preferred traditions and methods of uncovering T/truth (Riccucci, 2010). These divisions can undermine how the field advances, as academic sectarianism produces less understanding rather than moreEpistemologically, we should recognize there are multiple valid and perhaps even complimentary paths to understanding (Lake, 2011, p. 465). Riccucci (2010) suggests the answer to dogmatism lies in recognizing that the applied nature of public administration means it operates outside the paradigmatic strictures of Kuhn (1970, 1974): maintaining some semblance of methodological pragmatism, matching method to research question, and triangulating on answers with multiple methods. 5.2 Optional Question 1: Critics argue that the public policy field has made little theoretical progress, finding itself mired in description and journalistic analysis. Critique this assessment, evaluating the extent to which the major theoretical approaches to the study of public policy meet the standards for theory. Identify competing theoretical frameworks and their chief proponents, discuss their contributions and limitations, and suggest what is needed for them to make the transition from framework to theory. 5.2.1 Policy Theories are Scientific Theories In the early 2000s a new policy theory entered the scholarship  the Narrative Policy Framework (NPF), which centered the power of policy stories to shape policy outcomes. In response, Paul Sabatier, a leading policy theorist, pushed the originators to be clear enough to be wrong (Shanahan, Jones, &amp; McBeth, 2018, p. 332). To that end and inspired by postmodernism and the seemingly contradictory charter of science (Jones, 2018, p. 724), NPF aimed to produce work that could stand up to this Popperian critique (Popper, 1959). By 2010, the NPF was formalized as a structural account of narrative which sought to test the influence of policy narratives on policy processes, designs, and outcomes at three different levels of analysis (McBeth et al., 2014, p. 227). By 2013 the Policy Studies Journal held an NPF focused symposium featuring tests of the framework, and in 2014 the NPF held its place in the third edition of an influential textbook, Theories of the Policy Process (McBeth et al., 2014; Sabatier &amp; Weible, 2014). To complete the story arc, in 2019 the academic journal Policy Studies named a leading NPF theorist, Michael Jones, to the editor-in-chief position. The historical context above is important in that it helps illustrate how the NPF was born from post-positivist instincts but adopted to the positivist, falsifiable demands of the policy process academy. Proponents of NPF argue that the admixture of positivist/post-positivist scholarship renders critical discourse studies and other poststructuralist concepts normally outside the realm of empirical study (Jones &amp; McBeth, 2010, p. 329) into a scientific approach clear enough to be wrong (Shanahan et al., 2018, p. 332). The early critique of unscientific is not unique to the NPF. A common critique of, and within, policy theories is that they are not really scientific enough, more akin to journalism than social science. This historical tendency has led to a sensitivity within the policy process research world, and as a result, the field demands much of itself and potential new theoretical frameworks. This essay will defend the scientific credentials of the public policy theory scholarship, by focusing on the underlying theoretical frameworks that motivate the vast majority of research in the area. This essay will cover five main theoretic approaches to public policy and is structured to move somewhat temporally as well. It begins with a quick acknowledgment of the theory of the linear policy process. Following the rejection of the assumptions of the linear process (Cohen, March, &amp; Olsen, 1972) came punctuated equilibrium (PE) theory, which still retained some linear elements but moved away from the incrementalist predictions of the linear theory. The third theory, multiple streams analysis (MSA) helped explain the significant policy shifts in punctuated equilibrium theory but added theoretical flexibility, which gave it greater explanatory power for understanding why some policies are adopted, while others lay fallow. While MSA has proven popular for its parsimony and flexibility, some scholars have long complained it lacks the ability to explain policy process in the many different contexts in which policy is found. The fourth theory, advocacy coalition framework (ACF), takes many concepts from the MSA framework but trades parsimony for greater explanatory power. The final section of the essay closes with a synopsis of social construction of target populations (SCTP) theory. SCTP does not attempt to explain everything in the policy process but instead deconstructs the language (Wittgenstein, 2013) and assumptions of policy actors, which then are used to justify actions that have inequitable consequences for different populations affected by the policy. In closing, the essay points to the importance of scientific theory in policy studies, and to the importance of the scientists in the area to remain pragmatic and flexible to the constantly shifting policies they aim to study. 5.2.2 The Linear Policy Process The development of non-linear policy process theory is a relatively recent development, and the linear process model remains the most common way of thinking about how policy is developed outside policy studies. The linear policy process is the natural outgrowth of applying the most simplistic rational choice assumptions to policy. In policy studies, the theories that come after the linear process, and its assumptions, are often reacting to it. Linear policy process theory makes assumptions that are rooted in rational choice assumptions. People are self-interested beings who have ordered preferences (preferring one option over another), and those preferences are stable. The individual has no mental, emotional, or cognitive deficiencies, which would hamper their ability to make choices in their own best interest. It assumes that the individual is capable of knowing all information related to the choice before them, and thus is able to make a reasoned decision about which option to select, with the predicted choice being the one which maximizes the individuals benefit while minimizing the cost. These assumptions have been set aside as unrealistic models of human behavior in modern political and policy scholarship (Green &amp; Shapiro, 1996; Jones, 2002) The linear process was never useful as a predictive model of policymaking. The Garbage Can Model of policy (Cohen et al., 1972) takes the opposite assumptions and successfully challenged rational choice as an appropriate set of assumptions for policy theorists. The Garbage Can model explains the policy process as inherently chaotic and unpredictable, a mix of problems, ideas, technology, and solutions, all flowing around in an amorphous soup, from which a policy eventually congeals when the right components interact with one another. While Garbage Can modeling has not proven useful as a theoretical framework in the long-run, it is influential for the theories it inspired, particularly multiple streams analysis (Kingdon, 1995; Zahariadis, 2014) and the advocacy coalition framework (Sabatier &amp; Weible, 2007). 5.2.3 Punctuated Equilibrium Punctuated equilibrium (PE) (Baumgartner &amp; Jones, 2009; True, Jones, &amp; Baumgartner, 1999) is a policy theory which borrows from biological science to describe long periods of policy status quo, suddenly interrupted by significant shifts in the policy landscape. Baumgartner and Jones recognized that the slow incremental policy changes predicted by the base linear policy model were not reflected in the empirical policy evidence. Rather than slow, steady policy progress, they saw long periods of policy stability, which were then suddenly disrupted by sharp changes in short periods of instability. This, to the authors, seemed to reflect the sudden evolutionary adaptations seen in the biological sciences, as species maintain long periods of stability, with sudden natural adaptations (Gersick, 1991; Gould &amp; Eldredge, 1977). Though more useful than its simplistic predecessor, PE is still at its root a theory of linear change, though with generally more relaxed assumptions about the rational nature of the individuals involved. For instance, PE assumes that people are boundedly rational (Simon, 1976) rather than perfectly so. Similarly, PE recognizes that policymakers have limited attention capacity, and cannot know everything about a policy issue. Another critical concept in PE is that of framing (Chong &amp; Druckman, 2007; Zaller, 1991, 1992), which groups use to define how a policy problem is understood, in order to better position their preferred policy solution. Similar to both multiple streams theory and advocacy coalition framework (covered later), the PE framework attempts to understand how policy groups operate to bring about policy change. PE uses concepts such as agenda-setting, policy monopolies, and venue shopping to explain how these groups overcome the natural tendency towards stability and continuity in the policy environment. With agenda setting, groups make strategic choices about how much attention to bring to their preferred policy solutions. If they worry that attention will risk derailing the policy they will work to minimize attention, while at other times, mainly with lawmakers reluctant to pay attention, the policy groups actively manage attention around a policy problem and solution in order to generate political momentum. Policy monopolies, which are reminiscent of the iron triangles of earlier policy studies (Jordan, 1981) develop in specific policy areas, and like in the advocacy coalition framework (Sabatier &amp; Weible, 2014), these monopolies can persist for long periods of time, as they work to continue passing policy which reinforces their access to resources and thus policy influence. The answer to policy groups that are locked out of a policy monopoly is what Baumgartner and Jones (2009) refer to as venue shopping. If a group is locked out of the legislative policy arena, for instance, they may choose to change venues and begin looking for ways to pass their preferred policies at the executive or judicial levels of government. Punctuated equilibrium policy theory was developed in the United States, and it provided a useful explanation of empirical policy changes there. Early use of PE theory (Baumgartner &amp; Jones, 1993; 2010) was used to explain US nuclear policy, which existed mostly out of public sight in the post-war period. Following decades of that stability, where the policy was primarily left to technical experts and legislative subcommittees, anti-nuclear power advocates were successful in challenging the positive image of the nuclear industry, and venue shopped their policy ideas to courts and the public. The existing policy monopoly was broken, and heavy regulation of the nuclear industry effectively halted the expansion that had been seen in the post-WWII period. The US government is structured in a divided power arrangement, which tended to reinforce status quo arrangements, and was seen as responsible for the periods of policy stability. However, the PE theory has been usefully applied in non-US contexts as well. A comparative study of policy regimes in the US, Denmark, and Belgium (Baumgartner et al., 2009, p. 615) using data from dozens of processes across three nations and covering hundreds of thousands of observations found the same non-normal distribution of policy inputs and effects. This study provides strong evidence that it is not necessarily the US constitutional system that is providing friction in policy development and thus favoring the status quo. While all three countries in the study are democracies, there are enough structural differences to suggest that a General Punctuation Hypothesis can be applied in comparative contexts. Punctuated equilibrium theory is robust and takes its place alongside multiple streams analysis and advocacy coalition framework as one of the most cited (Baumgartner et al., 2009) and useful modern theories of the policy process. It provides a framework that allows even non-scholars to connect with a relatively simple idea immediately  things tend to stay the same until they do not. At the same time, it has enough complexity and flexibility to be adopted in varied political contexts. 5.2.4 Multiple Streams Analysis The appeal of the linear policy process theory was its one-dimensional, straight path construction of policy development. However, scholars have long recognized that the linear process is far more normative than descriptive. John Kingdon attempted to lay out a more realistic, descriptive model (Kingdon, 1995), in what is known as Multiple Streams Analysis (MSA). On the surface, MSA has similarities to punctuated equilibrium theory (Baumgartner &amp; Jones, 2009), but it does differ in its departure from the linear process assumptions that punctuated equilibrium held. MSA takes the path between the utter chaos of the garbage can and the too-linear punctuated equilibrium frameworks, and in doing so presents a more compelling theoretical structure than either. MSA recognizes that policy is complicated, like the social problems it attempts to address. Ambiguity is at the heart of why policy is so difficult to study (Zahariadis, 2014), because policy actors can never really know the root cause of a social problem, and even problem definition  the start of the linear process model  is ultimately a contestable, political step (Schneider &amp; Ingram, 1993). Rather than assume policy actors are purely rational beings, MSA holds that humans are boundedly rational (Simon, 1976), and as such, operate with limited information capacity, selective attention, and imperfect cognition. Further, there are significant time constraints that limit the ability of policymakers ever to know enough, let alone grok all the facts that perfect decision making would require. In the end, MSA seeks to answer the question: In a universe of nearly limitless policy problems and solutions, how do the relatively few new policies rise above the rest? MSA is one of the most cited academic theories of the policy process and key influence on the study of public policy (Cairney &amp; Jones, 2016, p. 1) with over 12,000 citations as of 2015. The appeal of Kingdons framework lies in its flexibility. MSA posits three streams in the policy process  the problem, political, and policy streams. How these three streams come together (or fail to) is a useful metaphor for thinking about why specific policies are implemented, while other, similarly good policies, fail. Understanding the three streams is key to understanding MSA. While the streams are discussed in a certain order here (problem/political/policy), in practice, the analysis is much more about how the streams interact than about their temporal order. In the problem stream, attention is paid to how attention is gathered around a policy problem. Attention in this frame can be mean many things, none of which are necessarily objective indicators. Attention might be statistical information that points to a problem, or in some cases, a crisis gathers immediate and widespread attention to a problem. Problems exist whether or not attention is being paid to them, and MSA recognizes that policymakers are only ever paying attention to a tiny subset within the universe of problems that they could be minding. The political stream refers to the many people, advocacy groups, and political bodies who are interested and involved in policymaking. The partisan composition of a US Congress, for example, will have an impact on whether or not a policy solution that is perceived as increasing tax burdens has any chance of being implemented. Similarly, the national mood in the wake of a financial crisis must be considered when considering whether complex regulatory policy might be implemented. The political stream is about the actors who must pay attention to a problem, and possible solutions, before a policy can be implemented. During some time periods, the political stream dictates that some problems in the problem stream will not gather attention, while ideas from the policy stream will not be considered. In the US context, periods of divided government, when one party controls Congress while the other party controls the presidency, are predicted to have relatively little policy movement, though recent scholarship convincingly disputes this prediction (Lee, 2009, 2016). Conversely, periods where one-party controls both the executive and legislative functions are predicted to have a better chance of implementing larger policy changes. The policy stream is described as a policy primeval soup by Kingdon, where potential policy ideas from a variety of policy actors conceive of potential policy ideas in policy communities. At any point in time, the policy stream contains a large number of possible policy solutions, but not all of them are feasible, supported, or available. While a policy idea may originate with a single actor, the ideas change as they are exposed to and considered by other actors in the policy stream. The ideas that eventually become policy are the result of a large number of participants modifying the original idea, and is often a much broader solution than the original, narrower solution. Some of these actors are so-called policy entrepreneurs who recognize an opportunity to insert their own policy solutions into one which is gaining support. Policy entrepreneurs are essential to MSA. These are the people and organizations that recognize when the politics and policy streams are not in sync. A policy entrepreneur waits for and recognizes when the two streams offer an opportunity for their preferred policy idea to be implemented. These policy ideas are developed before the actual streams coincide, and the preferred policy is offered as a solution to a problem that has garnered attention. At the same time, these policy entrepreneurs will work to bring the streams together, for example, by attempting to bring more attention to a problem while the politics stream is perceived as favorable to their already developed policy solution. Metaphors to think about the stream process in MSA are numerous (Cairney &amp; Zahariadis, 2016), and that flexibility has been key to its success. Some think of the streams as literal rivers, which, once mixed or merged, are challenging to unentangle. Kingdon suggests a space launch metaphor in which all factors must be perfect for launch, implying that policy makers will abort a policy before implementation if all the factors in the streams are not ideal. MSA assumes that when the problem, policy, and political streams come together, there is an opportunity for policy change, but most of the time the streams are not synchronous. Policy entrepreneurs are thus critical to policy change, as they work to align timing in the streams to create the window of opportunity for their preferred policy change. They work to gather critical mass attention to a problem, so that a solution is demanded. They work with other policy actors in the policy stream to develop their preferred solution to the identified problem. They work to shift the political landscape, so that policy and lawmakers are persuaded to adopt their solution. In the end, the flexibility of the MSA metaphor, and the relatively low barrier-to-entry for scholars to understand policy through the MSA framework has made it one of the most popular and useful ways to examine policy (Cairney &amp; Jones, 2016). The ease of use of MSA and the associated limited empirical usefulness will stand in stark contrast to the advocacy coalition framework (Sabatier &amp; Weible, 2007). 5.2.5 Advocacy Coalition Framework The advocacy coalition framework (ACF) was developed by Paul Sabatier and Hank Jenkins-Smith (Sabatier, 1988; Sabatier &amp; Jenkins-Smith, 1993), and from the beginning has been defined by defining the role of belief systems in the policy process, especially their role in shaping policy-oriented learning. The most complex of the mainline policy theories covered in this essay, ACF attempts to develop a holistic theory of policymaking. Because it is designed to be applicable across a variety of policy contexts, and because it assumes that each policy environment is inherently complex, the ACF framework is itself quite involved. In the ACF framework, policymaking takes place in a complicated environment that contains multiple actors across multiple levels of government (Weible, Sabatier, &amp; McQueen, 2009). Policymakers have very high levels of uncertainty, and their decisions are always made with inherent ambiguity. Policy decisions take years to produce policy outcomes, and those outcomes are difficult to ascertain with any certainty. ACF recognizes that there are also different types of policies at play, with some policies being fairly straightforward, others being very technical and complex and done outside public notice, while some policies are incredibly political, controversial, and evoke national partisan fights. Beliefs are a key concept in ACF, as individuals and coalitions compete in politics to turn their beliefs into implemented policy. In ACF, there are three types of fundamental beliefs. Core beliefs are those that are so rooted in the individual that they are unlikely to change or be changed by external events. Core beliefs tend to be so broad that they are unlikely to provide meticulous rules for policy. Conversely, policy core beliefs are more likely to be changeable, and more likely to influence how an individual believes policy should be constructed. The third type, secondary aspect beliefs are far less important to the definition of the individual and much more likely to shape their views on policy implementation. They are also more easily shaped than the other types of belief through learning new information about a policy. Individuals with shared belief systems are likely to be found together in coalitions, which form policy subsystems in ACF analysis. ACF treats policy subsystems as the unit of analysis. These subsystems are comprised of politicians, policy experts, advocates, and professionals. These subsystems are similar to the policy stream in the multiple streams framework (Kingdon, 1995), and in ACF, the policy subsystem contains coalitions of associated members all focused on a specific policy issue. These coalitions are epistemic communities (Haas, 1989)  systems of shared belief and activity  and networks within the subsystem can cooperate or compete to bring their preferred policy solutions to the forefront during policy debates. Strong coalitions often dominate policy issues for long periods of time, and because ACF is concerned with policy cycles, the periods examined often stretch out a decade or more. Lawmakers, who are constrained in attention and time, often assign responsibility in a policy area to senior public administrators, who, in turn, rely on the advice and consultation from policy subsystems that are framed as experts in the area. Within a policy subsystem, coalitions compete in the policy space. In a simple hypothetical, Coalition A and Coalition B each have a preferred policy solution. Between the two coalitions is are policy brokers who are also part of the policy subsystem and who work between coalitions and lawmakers. Each coalition has its own policy beliefs and resources to compete against the other, and policy brokers help structure that competition. Eventually, a decision is taken by the governmental authority with jurisdiction in the policy space at question. The governmental decision has outcomes for new institutional rules (or removal of old rules), new resource allocations, and appointments to new institutional bodies. There are also policy outputs from the policy decision, which in turn lead to policy impacts. The new rules, resources, appointments, outputs, and impacts all exist in a feedback loop, which in turn alters the existing coalition arrangements. In extreme cases, a policy coalition may cease to exist as the winning coalition solidifies itself as the dominant voice in the policy subsystem for years to come. More commonly, there is simply a shifting of resources and policy strategy among the advocacy groups that comprise the coalitions, and the game plays on. There are factors in the ACF framework outside of the policy subsystem, all of which have effects on the subsystems. There are relatively stable factors, reminiscent of the forces in punctuated equilibrium theory, which serve to produce a policy environment which favors the status quo against change. These stable parameters include the core and policy core beliefs of the policy actors, social values, the distribution of resources, the social structure in which the subsystems exist, and the core structures of the government (i.e. a constitutional democracy versus a communist state). The common theme of the stable factors is they tend to be exogenous to the subsystem and other influencing factors. These stable factors influence the rest of the framework but tend not to be influenced themselves. Unlike the relatively stable factors, ACF also recognizes that there are endogenous factors that both significantly alter and are altered by the policy environment; these are events that are reminiscent of the shocks in punctuated equilibrium theory. These changes can include systemic changes in the governing coalition of a subsystem, socio-economic changes such as significant financial crises, sudden shifts in public opinion (such as those seen in the last decade on gay rights and marijuana legalization), and finally, decisions in other policy subsystems that substantially impact on the subsystem being analyzed. Rarely, like in punctuated equilibrium theory, these external events can be linked to a huge shift in the policy environment, most likely by providing a shift in the internal environment of the policy subsystem. An example of this can be seen in the policy environments following both World War I (a move towards US isolationism), WWII (a move towards international organizations to prevent widespread war), and the Great Depression (a move towards a social safety net). Also external to the policy subsystem are the opportunities for long-term coalitions to take advantage of. These opportunities are themselves influenced by the stable factors described earlier, but also directly affect how policy subsystems operate. These factors are related to the political systems in which policies are considered, such as the difference between divided party control of the executive and legislative branches of the US government. These factors will dictate whether, and how much, consensus is needed before a policy can be adopted. In broadly democratic political systems, the amount of consensus is relatively high compared to systems with politics that allow for a single governmental actor to take drastic policy action. The final structure in ACF theory to be considered are the short-term constraints in which policy subsystem actors operate. These constraints are affected by both the opportunities factors and the external events, but the constraints also operate directly upon the policy subsystem as well. For example, in a policy environment where there has recently been significant policy shifts, the coalitions within a policy subsystem are all constrained from further action as law makers turn their attention to other policy subsystems. ACF theory is considered to be the creation initially of Paul Sabatier, but upon his passing, the theory has been continuously refined and adapted to the policy realities of the different contexts within which it continues to be applied. ACF has proven resilient, as it maintains the theoretical flexibility of the theory systems that preceded it while recognizing the feedback loops (Soss &amp; Schram, 2007) that incorporate the influence of stability, shocks, constraints, and opportunities in the policy and political systems. The drawback of ACF theory is that it remains a difficult proposition to translate effectively for non-academic audiences, whereas multiple streams analysis and punctuated equilibrium theory both benefit from the ability to construct easily understood metaphors around policy problems and proposals. Recent work linking the streams framework of MSA with the stages analysis of the advocacy coalition framework (Howlett, McConnell, &amp; Perl, 2017) shows a path forward for researchers who want a more robust system for analyzing policy, particularly in the comparative policy literature. Howlett and his colleagues formulate a five-stream framework, adding a program stream and a process stream, all of which proceed together along the traditional linear policy stage path. Though too soon to judge whether such a combined model will prove any more useful in both theoretical and empirical contexts  and it must, given the additional complexity the model has compared to more parsimonious models  there is at least an attempt to synthesize the main policy theories, most of which are at least several decades old. 5.2.6 Social Construction of Target Populations To this point, this essay has concentrated on the most extensive theories and frameworks, which all aim to explain the policy process as a whole. This proves to be a challenging goal for policy theory to meet, given the extreme complexity in policy types, political environments, and policy problems. However, not all theory must be so comprehensive, and in some ways theories with more restricted aims, like the social construction of target populations (SCTP), are more able to give clear theoretical explanations because they examine smaller pieces of the broader policy environment. SCTP was first developed by Schneider and Ingram (1993) and defeats another assumption of the linear process  that policymakers, or policy itself, are neutral or unbiased actors. Their argument is not itself post-modern but builds on post-modernist critiques of language, which deconstruct the power relationships inherent in language (Foucault, 1991, 2005; Yanow, 2003). Foucauldian discourse analysis has been effectively used by researchers to understand how different approaches to language contain critical assumptions about how changes in policy relate to broader social change (Sharp &amp; Richardson, 2001, p. 193). The central role of language in policy debates (Schmidt, 2000) reflects how important language is to the human experience more generally: The limits of my language mean the limits of my world, (Wittgenstein, 2013, pt. 5.6) Schneider and Ingram show that elected policymakers adopt value judgments about the social groups which are impacted by policy programs and that those value judgments have an impact on the policies they create and implement. In this framing of political statements, some politicians will, for instance, use language that implies individuals living in poverty are lazy and have created their own bad situation. This framing can justify policies that withhold government benefits from the targeted group. But just as language can justify under-benefitting certain social classes, it can also over-benefit others. The same politician may use language which confers noble, worthy qualities on business owners, which would then serve to justify policies that shift resources to that social class. Moreover, this type of construction is not limited only to politicians, and front-line, street-level bureaucrats (Lipsky, 1983). Police officers and teachers have been found to construct their own identities of the citizens they serve, sometimes to the detriment of those citizens (Maynard-Moody, Musheno, &amp; Musheno, 2003) Construction of target populations is not as simple as positive and negative populations, however, and Schneider and Ingram illustrate this point (1993, p. 336) through their use of a two-axis notional figure, where measures of positive and negative constructions are paired with high and low perceived power constructions. Power in this use is the ability of a social group to accept or reject the image painted onto them. This gives a four-category scheme of advantaged (high power/positive), contenders (high power/negative), dependents (low power/positive), and deviants (low power/negative) social groups. These simplistic categorizations of complex populations make it easier to see how politicians and governments implement policies that over-benefit the advantaged while making it extremely difficult for deviant populations to even challenge their disadvantaged status in policy debates. This creates a policy feedback loop (Larsen, 2018; Pierson, 2000), as an advantaged group like homeowners not only are over-benefitted in terms of resources granted by policy, but then are able to reify their position in the social hierarchy, leading to more opportunity to implement even more policies that will benefit them. This creates asymmetries of participation and power, and those asymmetries are reinforced by the system creating and accepting social constructions of the deserving and undeserving. This flaw in the system has long been recognized in political studies (Schattschneider, 1960; Schlozman, 1984; Stone, 2002), but SCTP offers a useful empirical starting point for understanding how particular social groups have been affected by policy choices influenced by social construction. One of the most potent critiques offered by SCTP is showing how these constructed beliefs about social classes not only have immediate effects on resource allocation but have effects on those social classes long after the policymaker has left office. This phenomenon is known as a feed-forward effect, or in other literature as path dependence (Pierson, 2000). Path dependence recognizes that the timing of policy choices matters, and policymakers select policies that have self-reinforcing feedback processes (Soss &amp; Schram, 2007). These processes represent the resiliency of institutions that are far longer-lived than the policymakers tenure (Sanders, 2006). Path dependency imposes a cost on going back to a previous point. The longer a policy scheme has lived, the higher the cost. In this way, earlier choices have a more significant impact than later ones, as the policies themselves shape the institutions that house the policies (Mettler, 2002). SCTP offers a compelling critique of policy studies itself, as it uncovers how the language involved in policy can compel certain beliefs and narratives that hinder, harm, or help certain classes of individuals (Sharp &amp; Richardson, 2001), even as policy scholars unthinkingly use the same language. Further, SCTP critiques the underlying, formative ideals of early public administration and political science, that of the neutral and unbiased bureaucrat, or public administration scholar. From the founding of the American political system, the ideal of competing factions balancing the power of any one faction (Dahl, 1982; Madison, 1787) has provided a compelling argument that the US constitution and division of power among the federal branches would protect minority interests from the powerful machinations of the majority. However, the justifications of the pluralist federalist system were largely imputed by Madison and Hamilton into the Federalist Papers in a post-hoc manner intended to justify the ratification of the US Constitution (Peterson, 2012). So, rather than the administrative and policy state providing an intricate balancing wheel (Madison, 1787; Rohr, 1986) against the predations of a majority, at least in some cases SCTP theory allows us to see how policy and lawmakers are able to use the concealed power of language to prolong and protect the interests of the already powerful. One limit of SCTP is that it is less concerned with comprehensive theoretical explanations of the policy process, and so in cases where there are not clear-cut social classes at play, SCTP may be less useful. A second limit is that, at least in the original construction of the theory, there is little said about how social classes might contest how theyve been constructed by policy makers and the public. SCTP has little to say about how, or more importantly why, one social group may attempt to help challenge the social construction of a less powerful one. Why, for instance, would a feminist group  hypothetically located as a challenger in SCTP  want to help restore the voting rights of an ex-prisoner class? SCTP still has buried assumptions of rational choice, presenting the actions of the powerful as merely, or purely, self-interested. A final limit of early SCTP theory was a lack of direction  what should individuals and advocates do with this knowledge. That critique has been substantially, though not wholly, blunted as more researchers have become interested in critical policy theories ( Jones &amp; McBeth, 2010; McBeth, Jones, &amp; Shanahan, 2014). Recent work has extended the original insights of SCTP by examining the ill effects of economic policy concentrated on women and blacks (Andersen, 2001), food justice (Billings &amp; Cabbil, 2011), and Native American school children (Quijada Cerecer, 2013). 5.2.7 Conclusion Policy studies are clearly much more than mere journalism. To engage properly with policy studies requires a canvassing of many complex policy process theories, and understanding both what they are capable of answering as well as what research questions they are not well equipped to address. This essay has covered only five of the theories available, with an eye towards selecting those that have survived at least several decades of empirical testing. There are more approaches available, and more continue to be added even as the most established theories continue to be honed in the pages of academic journals every month. Good theory is portable  it can be carried across contexts, and when contexts differtheory is required to generalize from one to another (Coppock, 2018, p. 11). Kingdons (1995) multiple streams framework allows for the identification of universal concepts (Cairney &amp; Jones, 2016) that can be applied in multiple contexts. Presently, the advocacy coalition framework is still the most flexible and explanatory theory available, and though far from perfect, allows for a broad examination of policy in many contexts. The adaptability of the ACF framework means it can fold in even critical theory insights, which by themselves do not produce an entirely satisfactory explanation of how policy is conceived, adopted, and implemented. This essay has strived to make clear that attempts to delegitimize policy studies as journalistic, unscientific, or unfalsifiable are misguided. The policy theory landscape is vast, active, and offers a compelling host of approaches to studying policy problems, proposals, and outcomes. There is no single best theory, though every scholar is likely to be drawn to one or two that fit their skills and interests. More important is to remain methodologically and theoretically pragmatic rather than programmatic (Riccucci, 2010). As policy itself evolves, so must the tools that we bring to the study of it. An excellent example of such reactivity is the Narrative Policy Framework (Jones, 2018), which moves from the axiomatic  stories count in the policy process  to the scientific  how do we count stories in the policy process? But NPF is not the end of policy history, and the policy process theories covered in this final essay are all representative of active scientific communities that investigate public policy. The best evidence that policy theories are scientific is the willingness of the scholars within it to continue to look for better scientific methods to improve our understanding of the many facets of public policy. 5.3 Optional Question 2: How would you characterize the state of research in public administration as it has progressed thus far? In what areas has research made the most progress, and in what areas is progress still at the fledgling stage? What are the major questions that should occupy public administration and management researchers over the next 20 years? Why? 5.3.1 Ethical Street Bureaucrats and Amoral Artificial Intelligences: Research Past and Future in Public Administration This essay will begin with a review of two areas that public administration scholarship has made significant progress and one large subject area that is in need of focused and sustained scholarship. First, the elevation of the street-level bureaucrat (Lipsky, 1983), and the ethical dilemmas found in public service (OLeary, 2013), are briefly reviewed. In the second section, the essay develops an argument for the need for sustained public administration scholarship to address threats to democratic governance from developments in big data and machine learning algorithms. 5.3.2 Street-Level Bureaucracy Public administration is distinct from mere public policy; as Woodrow Wilson(1887) noted, Administration isgovernment in action. However, action does not come from policy prescription, and even the best policy ideas will founder on the shoals of bad implementation (Pressman &amp; Wildavsky, 1984). Governance comes alive in the hands of the public servants who work at the closest level to the people that policy intends to serve. These public servants are whom Lipksy (1983) deemed street-level bureaucrats. Lipsky defines these critical employees as Public service workers who interact directly with citizens in the course of their jobs, and who have substantial discretion in the execution of their work. Lipskys theory is critical to the idea of government in action and inaction, especially as it relates to mid-level managers. As these managers move towards greater responsibility in their respective agencies, there is also a danger their collective attention will necessarily turn towards broad policy and idea formation. However, as Lipsky makes clear, by re-focusing on street-level bureaucrats, public administration practitioners enhance service to the poorest citizens, and also through better budgetary management. Lipskys theory brought a renewed focus on how to implement the equity goals of the New Public Administration formulated at the Minnowbrook gathering (Frederickson, 1971) because he saw how the influence of street-level discretion grew stronger as the public client grew poorer. The managerial focus on efficiency has historically resulted in social inequity among minority groups. To do otherwise disproportionately affects the poor negatively. The poor are forced to seek those benefits from the government, which they are unable to afford in the private sector, and as the provider of last resort, the government will be judged by its ability to serve that population. Prior to Lipskys most famous work, H. George Frederickson (1971) was calling for scholars to add social equity to the primary values of effectiveness, efficiency, and economy in public administration. Frederickson argues that social inequity constitutes a fundamental, if long-range, threat to the viability of this or any political system and concludes, [I]t appears that new Public Administration is an alignment with good, or possibly God. One synthesis of Lipsky and Frederickson is seeing the discretionary powers of street-level bureaucrats as increasing social equity. After all, as Lipsky (1983) writes, The poorer people are, the greater the influence street-level bureaucrats tend to have over them. Yet that optimistic view must be tempered with the reality that discretion is not always a balm for inequity. Because street-level bureaucrats are tasked with impactful discretionary decisions with little direct supervision, they are invisible to managers and thus tricky to correct. Furthermore, policies themselves, which guide administrative discretion, are often intentionally constructed to imbue public services with inequity towards unfavored groups (Schneider &amp; Ingram, 1993). Police work entails a tension between the exercise of discretion by officers on the street and the control of that discretion by police organizations (Engel &amp; Worden, 2003, p. 131). Maynard-Moody and Musheno (2012a) are especially leery of police officers discretion, arguing it is within this discretionary power that social inequity is allowed to propagate: Racial disparities, then, occur in investigatory stops in which law enforcement personnel are granted substantial legal autonomy and are least subject to administrative oversight. As noted in other works (Epp, Maynard-Moody, &amp; Haider-Markel, 2014; Maynard-Moody &amp; Musheno, 2012b), the impacts of officer discretion are nuanced. While individual officer behavior is better explained by agency policy and legalistic guidance than by individual attitude and bias (Correll, Hudson, Guillermo, &amp; Ma, 2014; Nix, Campbell, Byers, &amp; Alpert, 2017), the policies themselves can perpetuate inequity, and the juridical bounds may grant so much latitude that they take on the nature of a farce (Maynard-Moody &amp; Musheno, 2012b, p. S18). These discretionary concerns are present even today. Some scholars suspect that officers will subvert the intended benefit of BWCs through their control of the cameras activation, specifically (Kerrison, Cobbina, &amp; Bender, 2018, p. 281) their ability to turn [the BWC] off or position a partner to block the view finder frame. Others worry that officers with cynical attitudes towards BWCs because of perceptions that camera footage will be used against them, or negatively impact their professional practices and discretion (Katz, Choate, Ready, &amp; NuÃ±o, 2014) may opt to activate the cameras less (Newell &amp; Greidanus, 2018, p. 4): officer perceptions and interpretations of the technology may impact how they use it. However, along with my co-authors, in my analysis of what factors are associated with officers activating their body-worn cameras, I find that job function, not attitudinal or demographic factors, explain most of the variation in activations (Adams, Mastracci, Mourtgos, nd). This finding seems to bolster the view of officers using their discretion wisely and as principled agents (Dilulio Jr, 1994). Despite the possible adverse outcomes, some discretion is necessary at both the institutional and street level of public administration (Huber &amp; Shipan, 2002; Maynard-Moody &amp; Musheno, 2000). Because it is inevitable and essential, discretion is a critical area of study for public administration. If it were not for Lipskys contribution, we would still focus our research attention at the policymaker, rather than widening our scope to include the street-level bureaucrats who actually implement policy every day. 5.3.3 Ethics in Public Administration Another area that public administration scholarship has been successful in is in elevating the role of ethics in governance, and reviews of the overall health of this area of research points to a healthy, robust enterprise (Menzel, 2015, p. 343). Ethics are important at the elite and elected level of governance, but importantly for an applied field like public administration, there are ethical decisions implicated in the everyday working lives of street-level bureaucrats as well (Balfour, Adams, &amp; Adams, 2014; Finer, 1941; Friedrich, 1940; Lipsky, 1983; Maynard-Moody et al., 2003; OLeary, 2013; Thompson, 1985). The ethics literature is well-developed, and it is outside the length requirements of this section to cover all the significant works. Instead, I will focus primarily on the work of Rosemary OLeary in her book The Ethics of Dissent (2013). OLearys work has much to say in our modern era, particularly with the impending impeachment of President Donald Trump following the whistleblower report of an executive branch employee. It is tempting to imagine a government bureaucracy in which all decisions are just ones, the policies equitable ones, and the outcomes merely a matter of fiat. Unfortunately, such a paradise does not exist. Our government is, crucially, of the people, and George Washington set the goals of public administration firmly on the will of the people (Cook &amp; Klay, 2015, p. 77). By virtue of being populated by the people, in all their flaws, our government is necessarily going to make flawed decisions, implement flawed policies, and have outcomes that range between problematic and disastrous. In this reality, the expectation that all public servants must always follow all orders is dangerous and conflicts with the very ideals of our American experience. An ethical path in a public administration career is possible, but involves struggling with questions of neutrality and structure (Thompson, 1985). Neutrality is the idea that a bureaucrat must be neutral and simply adopt the behavior expected by his organization  in sum, to obey. The ethic of structure is the idea that only the organization is responsible for bad behavior, not the individuals. Thompson (1985) urges us to reject both ethics of neutrality and structure if we are to have administrative ethics. The rejection of structure is inherent in Lipskys (1983) street-level bureaucracy, which takes the responsibility and impact of the individual public servant seriously. The ethic of neutrality is more effectively undermined by examining the most commonly understood institutional case where a duty to obey is paramount  the military. 5.3.3.1 To Obey or Not Obey The idea that the military is full of robotic yes sirs is to misunderstand the military and institutions organized along pseudo-militaristic lines such as policing and firefighting (Caldero, Dailey, &amp; Withrow, 2018; Cowper, 2000). A famous American general of the 20th century, George S. Patten, famously said, If everybody is thinking alike, then somebody isnt thinking. The military thrives on the creativity of its members at every rank. In combat, under fire, facing imminent death  perhaps this is the time for unthinking response to orders. Yet even then, the military recognizes there are higher oaths and responsibilities every soldier has, which supersede the need to follow orders. The Uniform Code of Military Justice (UCMJ, 1956), while making it clear that a service member must follow all legal orders (Articles 90 and 92), also is equally clear that service members have a duty to not follow obviously illegal orders (Reeves &amp; Wallace, 2016): Still, the UCMJ articles make clear that obedience is only required for lawful orders. Patently or manifestly illegal orders impose no duty of obedience on the service member and instead mandate disobedience. In fact, a service member who obeys an illegal order is individually culpable for the crime and cannot later assert following orders as a defense. In fact, this mandate to disobey illegal orders is the result of, and in response to, far too many atrocities committed by those who were just following orders. Both American and international courts have consistently found that there are human rights that are so protected, that to violate them in the pursuit of obedience simply cannot be allowed (Balfour et al., 2014). The My Lai Massacre, the genocides of WWII, and the Abu Ghraib atrocities all have the same lesson: The presumption of obedience, such as that found in articles 90 and 92, cannot be used to justify torture, commit war crimes, or participate in other unconscionable activities. These are examples of the manifestly illegal orders contemplated within the UCMJ. And though there are no guarantees against administrative evil (Balfour et al., 2014), the ability of the military to recognize when discretion is available to even soldiers in combat shows that an administrative ethic is possible. As seen, the implied ethic of unfailingly loyal obedience to orders is not even a truth in the most militaristic of settings  the military itself. It follows, then, that to apply that ethic in less structured environments is inappropriate as well. What then is the value of dissent in the American public service? Rosemary OLeary (2013) covers this question with great depth. OLeary is not pollyannish regarding dissent  she is not arguing it is always appropriate, or even reasonable, and provides plenty of support for the idea that there is a potential dark side of guerilla government (2013, p. 126). However, it is in her willingness to accept the middle ground that she is so convincing (p. 118): Just as it is difficult to argue that there is not a need for obedience by employees, it is difficult to argue overall that acting on ones strongly held personal and spiritual beliefs in certain contexts is improper. Most would agree that a public employee is not compelled by duty to obey obviously illegal orders. OLeary is comfortable in exploring the marginal cases where answers are not so clear, and concludes (p. 110) that not all guerilla government is created equal  some dissenters are a canary in the coalmine while others are simply delusional single-issue fanatics. OLeary is comfortable in not finding some final, clear answer. She notes that most cases are not so easy to judge (p. 110) and that the tensions inherent in guerilla government will never be resolved (p. 117). Her doubts are more convincing than the surety of those who suspect a robotic response by public employees. Government needs to be efficient and therefore exerts hierarchical control over employees in order to ensure that efficiency. However, hierarchal control inevitably clashes with the federalist priority on local autonomy (Elazar, 1984; Madison, 1787). As illustrated in the Nevada Four case (OLeary, 2013, pp. 2741), sprawling federal agencies must rely on employees who are local, and some of those front-line employees will eventually begin to prioritize what they see as crucial over dictates from their bureaucratic superiors in faraway offices, who may have never even been to the areas they are attempting to wrest control over. While OLeary does not argue all dissent is right, nor can dissent be so easily dismissed as inherently flawed, or that it does not hold an important place in public governance (Brewer &amp; Selden, 1998). Dissent is itself an American ideal (OLeary, 2010; Ragosta, 2010; Sunstein, 2003). John Steinbeck (1952) captures this feature of Americana well: And this I believe: that the free, exploring mind of the individual human is the most valuable thing in the world. And this I would fight for: the freedom of the mind to take any direction it wishes, undirected. And this I must fight against: any idea, religion, or government which limits or destroys the individual. This is what I am and what I am about. So long as there is an American government that employs Americans, there will be a need to find ways to include the street-level dissenter in public service. 5.3.4 Big Public Data One of the subjects that public administration scholars will be critical to is the effect of big data, machine learning, and artificial intelligence in public governance, though the field has been relatively slow to react to developments in this area. The voice represented by our scholarship is necessary to surface the realities confronted by the practitioners confronted with overseeing the intersection of the public sector and big data, machine learning, and other technologies. There is no doubt that scholarship needs to be multidisciplinary  international power, regime studies, war theory, genocide, administrative evil, and ethics; every field of scholarship will be impacted. These imaginative visions begin with the adoption of big data technology and machine learning at the municipal level  an adoption that is already occurring (Coglianese &amp; Lehr, 2016, 2018). Machine learning and big data are already used in criminal sentencing, policing strategies, and identification of lethality in domestic violence (Adams, 2019; Ferguson, 2017), among others, all of which fit squarely within traditional domains of public administration scholarship. Public administration offers the natural voice to help guide the ethical considerations and responses to the inhuman, or at least non-human, politics of the future (Agarwal, 2018; Battaglio &amp; Hall, 2018). Sara Jordan frames the public-sector impact implicit in a shift towards big data (2014, p. 276): How ought government protect the public against the use of their data but also protect the public through the use of their data? If public administration scholars do not direct their energy and interests towards investing the human mind into questions of how big data, machine learning, and artificial intelligence interact with governing, it risks becoming outmoded and irrelevant. Public administration is well situated to offer solutions to these questions due to its strengths in multiple methodological and ontological approaches in the field (Riccucci, 2010). In a recent review of literature investigating big data and the public sector, Cecilia Fredriksson and her coauthors reveal the complexity and importance of big data, and the critical importance of scholarship (2017, p. 47): Governments are central to both creating and managing knowledge. Gary King, director of the Institute for Quantitative Social Science at Harvard University, is clear in his assessment of the changes that big data and artificial intelligence promise (Lohr, 2012, p. 1): Its a revolution. Were really just getting underway. But the march of quantification, made possible by enormous new sources of data, will sweep through academia, business, and government. And as political scientists have noted, revolutions tend to have some bloodletting, at least metaphorically, as scientific revolutions look a lot like political revolutions (Farr, 1995). Public administration, concerned with both government and governance, theory, and practice, should not consider itself safe from the big data revolution; no matter ones preferred isms (Lake, 2011), it seems an unlikely outcome. Recall, however, Kings assertion of the underlying questions being quantitative ones. Even allowing for rhetorical excess, as large as his claims are, they are not encompassing enough. It is a mistake to see big data, which is essentially a descriptor of quantitative information, as having only quantitative implications. Recent advances have made the sophisticated quantitative analysis of even very large text corpora a manageable task (Mourtgos &amp; Adams, 2019b; Roberts, Stewart, &amp; Tingley, 2014). 5.3.4.1 Algorithmic Impacts on Democratic Ideals: The GPT-2 Natural Language Model One example of our algorithmic future, and of the need for public adminstration scholarship, can be found in the most recent advances in machine learning predictive text algorithms. The most advanced of these publicly known is the GPT-2 model. Simultaneously released as a blog post on the OpenAI site (Radford, Wu, Clark, et al., 2019), the scholarly article (Radford, Wu, Child, et al., 2019) announcing the development of the GPT-2 natural language prediction model will be seen as a turning point in political speech. The GPT-2 model, and the paper announcing it are bound to be turning points in politics, broadly drawn, and more specifically, the political and policy implications of artificial intelligence methods. The authors directly address the political and policy implications of their own technology, stating that along with synthetic audio and so-called deep fake videos, technologies are reducing the cost of generating fake content and waging disinformation campaignspoliticians may want to consider introducing penalties for the misuse of such systems. The authors address their concerns about the potential misuse of such systems by publicly releasing truncated models with a staged strategy. Though the full model has 1.5B (billion) parameters, the authors decided to first release only the 114M (million) parameter model in February 2019; a 344M model in May 2019; and a 774M model in late August 2019. Reviewing the technical accomplishments of the GPT-2 language transformer is beyond the scope of this essay. However, it should suffice to note that the algorithm surpasses previous attempts in language prediction models, and in some cases approaches human-level capabilities. The model was trained on over 8 million English-language webpages, with the goal of simply predicting the next word in a sentence. A simple goal, but the output of the algorithm is convincing enough that 83% found it indistinguishable from New York Times articles (Kreps &amp; McCain, 2019). Scare tactics around technological innovation are nothing new. It is easy enough to claim an algorithm is dangerous to the polity - what does it look like in practice, and why would it be dangerous to democratic structures? Consider the following fake essay introduction I generated for the purpose of demonstrating the capability of the GPT-2 774M model. Bolded text is the input I used as a seed (I used the introductory sentence to the required question in this submission, page 1), and what the algorithm generated follows in standard text: As a discipline, public administration is a study in unresolved, and unresolvable, tensions. The state of the discipline is in its infancy, but its problems are not yet settled . Some aspects of the discipline have been better understood in the past twenty years than in previous decades. What has emerged is a discipline whose underlying contradictions and tensions are as difficult to resolve as the historical struggles over their solution. This is a discipline in which the basic structures of state power are, and remain, fundamentally ill-defined and ill-regulated. The most recent major challenges to the discipline may be found in China, India, and the United States. These include the expansion of governmental power over private sector actors, the emergence of an increasingly fragmented political economy in many countries, the spread of political and economic elites, and the transformation of the traditional political class into political and economic elites. The above text selection was generated today, October 15, 2019, in approximately two minutes at 10:13 a.m. It is not perfect in terms of proving a causal argument, but it is certainly passable in conveying a believable argument, particularly to a non-academic audience. The exact same fake-text generative power is available to anyone who desires it  whether it is undergraduate students eager to avoid working on an essay or contentious state-actors who wish to undermine democracy with fake-news. There is no scalar limit to the process, and it is as easy to generate 200 fake-news stories to post to Facebook as it is to generate one. To be clear, I am not arguing that the GPT-2 paper is significant because it is the final word in this type of technology. In fact, the ability to generate large amounts of misinformation that is for all intents and purposes indistinguishable from authentic news will only become easier. Importantly, the example above was generated with a version of GPT-2 that is only approximately half as powerful as the full 1.5B parameter model. This is not the end of fake news and disinformation for political purposes, but the beginning. Russian President Vladimir Putin recently predicted that (Polyakova, 2018, para. 1) artificial intelligence is the future, not only for Russia, but for all humankindIt comes with colossal opportunities, but also threats that are difficult to predict. Whoever becomes the leader in this sphere will become the ruler of the world. The American electorate (or at least some substantial portion of it) was misled by foreign powers, including Russian-based organizations, in the 2016 presidential election by the intentional use of memes (Permanent Select Committee on Intelligence, 2019). How will the American polity react to conceivable disinformation generated like the above? If public administration is ultimately concerned with the governance of competing values in a democracy, how should we study the potential undermining of that democracy in the face of withering, algorithmically generated, fake news? Despite the intent of the GPT-2 team to stage releases of the model so that the unintended effects could be judged, such a strategy inherently relies on the belief that either; 1) no one else can do the same work, or 2) those who are capable of re-creating the technology would also restrain themselves. Both premises are doubtful, as shown by the full release of OpenGPT-2 by two graduate students at Brown University (Gokaslan &amp; Cohen, 2019) in a post titled OpenGPT-2: We Replicated GPT-2 Because You Can Too the same week the OpenAI authors released the watered-down model. Moreover, in their release of the 774M model, the OpenAI authors note that they have spoken to five groups that had already replicated GPT-2. These are only the groups willing to publicly admit they are developing the capability - what of the Internet Research Agency (IRA), a front for Russian intelligence agencies intent on destabilizing American elections (Permanent Select Committee on Intelligence, 2019)? With an ever more networked citizenry comes increased risk that those networks can be turned against democratic ideals  ideals that are at the heart of public administration (Waldo, 1952, 2017). A metaphor can be drawn to other historically recent revolutions. If a scholar were to posit that neither the industrial nor internet revolutions were particularly impactful to how public administration is performed and studied, would any reader take them seriously? The industrial revolution, with massive gains to efficiency, was not limited to only affecting industry  political, governance, and ethical implications followed. Even the very recent internet revolution, just a few decades old, has wrought social changes in the rise of populism (Bimber, 1998; Chadwick &amp; Howard, 2009), among many other consequences to governing. While a comprehensive review of the changes to polities brought by the industrial and internet revolutions is outside the scope of this paper, it is also unnecessary, if one accepts the simple premise that a similarly situated revolution is underway in the move towards big data, machine learning, and artificial intelligence. These shifts, in turn, bring swings in political priorities, in class struggles, and in institutions. It is this insight that underlines the need for public administration scholarship to bring its varied methodological tools to bear on the issues, to buffer democratic ideals, and to seek every opportunity to engage with other disciplines. The questions about big data stretch beyond mere quantification, and Sarah Jordan (2014, p. 375) sees the value of public administrations methodological plurality: The future of public administration lies in its ethical knowledge work and expertise. The ethical implications of government use of information technology are one sketchily researched area deserving more scholarship (Menzel, 2015, p. 363). Some work is beginning to appear, with research papers and publications in legal journals beginning to address the role of machine learning in administrative agencies (Coglianese &amp; Lehr, 2016), questions about algorithmic ethics and fairness (Ferguson, 2017; Friedler et al., 2019; Joseph, Kearns, Morgenstern, &amp; Roth, 2016), and emerging legal definitions of personhood among artificial entities (Karanasiou &amp; Pinotsis, 2017). However, these questions, which are necessarily multi-disciplinary, and despite having the potential for grave impact on the public sector (Battaglio &amp; Hall, 2018; Fredriksson et al., 2017), so far lack the input from public administration scholars that would leverage the strength of our focus on merging the theoretical insights of political science with the realities of practice (Guy, 2003). Within the next several decades, deep learning neural networks and artificial intelligence will begin to replace two of the four pillars of what Keohane (2009) identifies as the core functions of political science: descriptive inference and causal inference. Retooling public administration through old ontological debates will not answer the question faced by political scientists in the coming years: what are we for? To reframe Rogers Smith (2015, pp. 366367): perhaps public administration is not so exceptional and is not alone in facing profound change in how scholarship will be done. Does public administration see itself so fundamentally different in scope and complexity that it can escape what other human-centered fields have already begun to cede core functions to? If machinated intelligence comes to dominate descriptive and causal inference, what public administration scholars should get better at is puzzling (Keohane, 2009, p. 360)  observing what does not fit with theory  and conceptualizing, particularly as it relates to translating scholarly arcana to ordinary usage. We must become better data scientists and qualitative researchers and puzzlers and conceptualizers  all at once. Alongside those, society will be in need of intense scholarly focus on instilling our ethical knowledge work into the machine learning, neural networks, and artificial intelligences that are the future of both governance, and the study of governance. 5.3.5 Reflexivity There is no theorist more clever than the scholar claiming to have no theory write the authors of a primer on theories of public administration (Frederickson, Smith, Larimer, &amp; Licari, 2018, p. 3). Though they were gently chiding James Wilsons proclamation (1989, pp. xixii) that any grand organizational theories would be merely partial, place- and time-bound insights, I heed their advice. At this time, I am a scholar in the post-normal mode (Riccucci, 2010), who is primarily interested in the experiences of street-level bureaucrats (Lipsky, 1983). Though I am a methodological pragmatist who is open to many ways of answering research questions, I instinctively reach for post-positivist, testable, falsifiable, and empirical answers in my scholarship. I am a public administration scholar because the field is multi-disciplinary and multi-methodological, as am I. Attempts to constrain the research questions and methods germane to the field are pointless because public administration practices are as old as civilization itself, even if the field of study that constitutes public administration is still young (Frederickson et al., 2018). To borrow an excellent turn-of-phrase , I work in the prose of Herbert Simon, but read and dream in the poetry of Waldo. Herbert Simon, because I value the clarity that constrained and falsifiable hypotheses bring to value-laden policy discussions and the satisfaction of working within sophisticated statistical frameworks. Dwight Waldo  because the most interesting questions I explore are value-laden: how workplace surveillance on wellbeing and street-level discretion (Adams &amp; Mastracci, 2017, 2019b, 2019a); the effect of street-level prosecutorial discretion on general criminal deterrence (Mourtgos &amp; Adams, 2019a); the alienation wrought by detaching emotional expression and public service (Mastracci &amp; Adams, 2018); the importance of listening to the voices of public servants rather than imposing our own scholarly suppositions (Mourtgos &amp; Adams, 2019b); and the difficulty of squaring public and legal opinion regarding police use-of-force as the values of the two (Stone, 2002) rapidly diverge (Mourtgos &amp; Adams, forthcoming). I cannot bring to bear the post-positivist methodological weapons of Simon without first looking for research targets through the eyes of Waldo and Lipsky. 5.3.6 Conclusion Though he is the godfather of the science of artificial intelligence, Herbert Simon was not robotic. At least by the end of his life, Simon writes (Simon, 2019) both about the beautiful and true  the wonderful and the comprehensible  merging humanity and science. While early Simon works emphasized the quantitative and measurable, he grew to see the ontological divisions as somewhat of an artificial distinction. He was right, and with the benefit of hindsight, we can see that both he and Waldo fought against what can be seen now as a naÃ¯ve scientism. Bounded rationality was not a line drawn in concrete, beyond which stood the permanently incomprehensible, but one drawn in sand, pushed backward by the winds of science over time. The movement towards (even bigger) big data, more sophisticated and predictive machine learning algorithms, and general artificial intelligence will continue to push back that line. No perfect rationality may be possible, but the unbounded parcels shrink every day. Some of what is revealed by those winds of progress are terrifying and potentially destructive, while some are illuminating and progress the country forward. In modern co-produced models of governance, public administration scholarship must be tightly focused on helping distinguish between the two. The changes to the public sector brought about by the artificial intelligence revolution will be vast and complex. That complexity, Simons work urges us to understand, is not the same as inexplicable: Wonderful, he writes in the opening of one of his final works, but not incomprehensible (Simon, 2019, p. 1). Simon may seem an unrepentant positivist for some in public administration who embrace more qualitative methods, or at least a post-normal methodologic pluralism (Riccucci, 2010). But that represents an unfair, limited view of Simons work, who, after all, published for forty-nine years after his 1952 debate with Dwight Waldo in the pages of American Political Science Review (Simon et al., 1952). A more expansive and forgiving view of Simon can be found in Rortys assessment (1982, p. xvi): It is important to realize that the empirical philosophers  the positivists  were still doing Philosophy. In her address to the Southern Political Association, Mary Guy (2003, p. 651) states: The field is served best when we remain self-consciously aware of the implications of our models and the information they produce. This highlighting of the importance of the subjective experience is a timely reminder for the role of future public administration scholars, tasked with approaching a world of governance rapidly changed through greater and greater reliance on big data, machine learning, expert systems, and artificial intelligence. Herbert Simon saw intuition as a hidden thinking process; but in a hypothetical world where a machine intelligence achieved true, human or greater level intelligence, our ability to understand the subjective experience of that intelligence is not guaranteed. The human subjective experience represents the cash value of human ethics, of human inquiry, and of human philosophy. John Adams is still correct: Two decades hence, the best of public administration scholars will be those who remain aware of the human and ethical implications of models and information produced by inhuman (or at least not human) minds. The field of public administration should be prepared to begin this undertaking today  for that is what we will be for tomorrow. "],["ap-real.html", "Chapter 6 American Politics: Real Exams &amp; Answers 6.1 Required Question: 6.2 Optional Question 1 6.3 Optional Question 2", " Chapter 6 American Politics: Real Exams &amp; Answers This chapter is constructed around PA themed questions. The questions you encounter will by nature not be exactly the same as these, or other previous comprehensive exams, even within your own program. There is always at least a little variability. Therefore, I suggest students construct a variety of written answers that are built around themes. These themes are common to the study of public adminsitration, and generally will hold across academic contexts. Like the public adminstration exam, this American Politics exam was structured with a single required question, and two optional questions. The required question is a good lesson in one of the follys of pre-writing, or at least of thinking youve pre-written enough. The question was new, meaning it hadnt ever been asked of students before. I loved it though, it was intentionally written to allow students to connect their own research agendas to the larger field of American politics. This is a critical skill for junior scholars to learn, because eventually you will have to take your own research and try to get it published in a journal. At that time, you will need to clearly communicate why your research belongs in this particular journal, in this particular subfield! This chapter and its answers will probably be more useful once youve perused the themes in the American Politics Pre-writes section. 6.1 Required Question: Every year, a great deal of scholarly research is published in the field of American politics. Based on your knowledge of the field, what topic in the study of American politics do you regard as being important and yet understudied? To respond to this question, identify at least one topic in American politics that you believe deserves more scholarly attention. Explain what research scholars have done that is related to this topic and why more research ought to be done on this topic. Also, explain what theories or approaches would be the most helpful in developing an explanation of this topic as well as what research strategies would be best suited to helping scholars learn more about this topic. Finally, explain how more research on this topic would help to better inform our understanding of American politics in general. 6.1.1 Policy &amp; Evidence Disconnects: The Case of Body-Worn Cameras through the Narrative Policy Framework The linkage between policy and evidence is not well understood in American politics. Why is it that some policy proposals with substantial scientific consensus are ignored or met with strong opposition? Alternatively (and more in line with the substantive concern for this essay): How do some policies with little to no evidence, or evidence contradictory to the aims of the policy, pass into law with little opposition? These mirrored questions are essential to the study of American politics because they impinge on so many of the most salient public policy questions of the day, including climate change, health care, and criminal justice. There are many traditional ways to begin answering this question. A likely candidate is that Americans are only boundedly rational (Jones, 2002; Daniel Kahneman, 2003; Shannon, McGee, &amp; Jones, 2019; Simon, 1972), and not able to effectively perceive, process, and take action on complicated policy problems. Perhaps Americans simply do not have enough political knowledge to participate effectively in public policy (Campbell, Converse, Miller, &amp; Stokes, 1960; Delli Carpini &amp; Keeter, 1996). Alternatively, maybe there are structural and wealth inequalities that skew the possibility of policy change (Bartels, 2010). It could be that collective action problems are challenging to address with traditional state institutions (Ostrom, 1990). Or are we wrong to even conceive of a state that takes on these problems, and wary about technocratic state planning (Scott, 1999), we require an administrative retreat to a night watchman conception of our nations administration (Nozick, 1974)? Political science offers a wide range of possibilities, and the previously recounted candidate answers are easily identified due to the vast amount of political research already complete, often in the very policy areas already identified  climate, health, and crime are perennial favorite targets to aim our political theory big guns at. Yet, in the end, a substantial body of literature does not bring generous answers. This essay will not solve the question in full, but in the best scientific tradition will engage with a small but substantive policy area through a modern theoretical framework, the Narrative Policy Framework (NPF), while simultaneously suggesting methodological improvements to that framework. In the end, the essay intends to draw broader lessons about the seeming disconnect of policy and evidence from the exercise by adding in the value of narrative. 6.1.1.1 The Topic at Hand  Body-Worn Cameras It is on a question of criminal justice that this essay takes as its substantive focus, specifically the rapid adoption of body-worn cameras (BWCs) by American police beginning in 2014. The technology was implemented despite little evidence to support the promised benefits to reductions in use-of-force and increased community support. Moreover, widespread use of the cameras has persisted even as evidence mounts that those benefits are mostly not being attained. This seeming contradiction between policy adoption and policy evidence speaks to the more significant questions posed in the opening paragraph: Why were proponents of BWCs successful despite a lack of policy evidence? What causes BWC policies to persist even when the bulk of scientific evidence suggests they have not had statistically significant or consistent effects on most measures of officer and citizen behavior or citizens views of police (Lum, Stoltz, Koper, &amp; Scherer, 2019, p. 93)? The answer, I suspect, is in the power of narrative. The American tale of body-worn cameras begins with an incident for which there was no video. In August 2014, Michael Brown was killed by Ferguson police officer Darren Wilson. In the immediate aftermath of the shooting, witness accounts of the incident were broadcast widely. Horrific stories recounted Michael Brown being shot on his knees, or with his hands in the air, or both, and being allowed to bleed to death in the street for hours, the incident quickly picked up national urgency. Ultimately these stories were found untruthful, but the belief that Michael Brown was the victim of racist police brutality soon turned to rage as Ferguson and nearby St. Louis were the site of widespread rioting and protest. Responding to the crisis, President Obama announced the formation of the Presidents Taskforce on 21st Century Policing. The final report of the taskforce (Office of COPS, 2015) called for the adoption of body-worn cameras by policing agencies, and in response President Obama announced federal funding of up to $75 million dollars to assist agencies in purchasing the camera hardware (Edwards, 2015). Importantly, the implementation recommendations and federal funding were well in advance of the empirical evidence to support them. At the time of implementation, there was just one small empirical study, first available in December 2014 (Ariel, Farrar, &amp; Sutherland, 2015). Rapid adoption followed President Obamas promised funding, and while estimates are difficult, BWC use at least doubled between 2015 and 2018 (Christodoulou, Paterson, &amp; Kemp, 2019; Lum et al., 2019). A recent review of BWC research concludes that despite high hopes for benefits to transparency and process, over 80 empirical studies show BWCs have not had statistically significant or consistent effects on most measures of officer and citizen behavior or citizens views of police (Lum et al., 2019, p. 93). This lack of consistent effects, especially on the hoped-for reduction in police use-of-force, begs the question of how such a national policy came to be. If it was not the evidence-based practice (Lum &amp; Koper, 2017; Sherman, 2015) called for by most scholars interested in policing, what motivated the relatively quick policy process that led to such rapid integration of new technology into American policing? The essay proceeds in five sections, describing a research study that might help us understand how narrative fueled the successful policy implementation of BWCs through federal funding. First is an introduction to the NPF, including the explicit assumptions of the approach. Complementary discussions around media framing and scope of conflict in the policy process give rise to a set of preliminary hypotheses. Second, a sampling strategy is discussed, with attention to the time frame and source material justifications. In the third section, three possible analytic strategies are considered. This section is long, as it traces deep into the theoretical proffer of NPF in order to develop specific analytic tests of implicit assumptions that have not yet been tested. This section offers substantial potential contributions to overall NPF scholarship, as both theory testing and theory building outcomes are possible, or even likely. Finally, a short conclusion considers the development arc of the overall proposal and draws out possible contributions to the broader political science and policy questions that motivate the essay. 6.1.2 The Narrative Policy Framework  Stories Count in Policy The Narrative Policy Framework (NPF) is the latest approach in the policy process literature to gain significant adoption by researchers. The NPF was developed as a quantitative, structuralist, and positivist approach to the study of policy narratives (Jones &amp; McBeth, 2010, p. 330). This policy process approach asserts that narratives (or stories) are primary mechanisms by which individuals process complex information and communicate about events and issues (Merry, 2018, p. 749). In other words, the NPF recognizes that the stories people tell, and are told, are critically important to understanding how policy is adopted. NPF scholarship borrows from a wide variety of academic fields including discourse analysis, rhetoric, and critical literature studies (McBeth, Jones, &amp; Shanahan, 2014). NPF builds on what it borrowed, overlaying a structuralist framework to narratives in order to give a common theoretical language for policy scholars. There are a handful of essential assumptions and research decisions to be made before engaging with the NPF on a research topic, as the approach is not a one-size fits all for projects centered on narratives (Shanahan, Jones, &amp; McBeth, 2018, p. 333). There are several strong assumptions built into NPF that must cohere with the aims of the research question before proceeding. The research proposed here meets those assumption, a discussion held for the next section. As full data collection has not yet been undertaken, the focus will be on developing a full research design guided by a research question: How were media narratives deployed in the body-worn camera debates, and to what effect? 6.1.2.1 Narrative Strategies and Hypotheses Stories count, but how do we count stories? The Narrative Policy Framework (NPF) allows the researcher to go beyond evaluating a news article sentiment, a common operationalization in framing studies that can be sensitive to rater bias. For example, for this proposed study, it is less crucial (though non-trivial) to determine whether a document is for or against BWCs. An NPF study is interested in how that information is transmitted through narrative, rather than if an opinion is transmitted. Through operationalization of characters, setting, and plot, an NPF study can surface commonalities in narratives even when the authors have opposing views. Stories are either told well or poorly, and investigating the differences in how stories connect to policy is the goal. The five assumptions of the NPF are worth making explicit (McBeth et al., 2014). First, the approach assumes that the policy reality we perceive is socially constructed, rather than objectively true. This assumption reflects the influence of Schneider and Ingrams (1993) Social Construction of Target Population (SCTP). Second, NPF scholars recognize that socially constructed policy realities have meaning that necessarily varies, but in boundedly rational ways. Narrative meaning has stability over time, can be measured, and is not random  an assumption that has yet to be tested, and which I address at some length in the analytic plan section of this paper. The third assumption is that narratives have a general structure that can be identified, such as including characters and plot. The fourth assumption is that narrative has effects at multiple levels (micro, meso, and macro) and that narrative interacts across these levels. The final homo narrans model of the individual can be considered a meta-assumption. Homo narrans assumes that narratives play an important role in how humans understand the world. In other words: people prefer to think and speak in story form (Shanahan et al., 2018, p. 333). As noted above, the NPF includes three levels of analysis  the micro, meso, and macro. The micro level is concerned with the effect of narrative strategy on how individuals perceive policy choices (McBeth et al., 2014). The meso level is focused on broader narrative strategy by policy actors, and understanding how those actors build those narratives. This is the level of analysis of the present study. Finally, a macro level of analysis is proposed by the NPF, though at this time no published work operates at this level. The macro level has also been synonymized with meta-narrative, grand narrative, and master narrative (Shanahan et al., 2018, p. 341). A structuralist approach attempts to surface the essential elements of a narrative and make them quantifiable. The structure defines a narrative as having four core elements  setting, characters, plot, and a moral. A setting is the policy context that a policy problem is situated in: the legal and constitutional parameters, geography, scientific evidence, economic conditions, agreed-upon norms, and other features that constitute the policy arena (McBeth et al., 2014, p. 228). NPF requires at least one character, but this is a minimum requirement and is almost always surpassed. The characters in NPF can be victims, heroes, or villains, and importantly for this study, need not necessarily be human characters as non-human characters retain their character status in most NPF applications (Shanahan et al., 2018, p. 335). The plot in policy narratives has a beginning, middle, and end, and serves to connect the characters to both each other and the policy problem. Finally, policy narratives need a moral, which serves to promote a particular policy solution favored by the coalitions promoting the narrative. 6.1.2.2 Framing Effects in Media The study of framing effects in media has a long research tradition, and the findings are essential for understanding why media narratives are an appropriate source of data in NPF studies. The choices made in narrative structure by policy actors are communicated through the media, and reflect embedded policy beliefs and strategies that seek to influence readers policy preferences (Shanahan, McBeth, &amp; Hathaway, 2011, p. 378). The linkage between framing and narrative policy analysis is the importance of story in both. However, more needs to be done to understand how the two frameworks intersect (Jones, 2018). The most common understanding of framing comes from Gamson and Modigliani (1987, 1994), who define frames as the central organizing idea or storyline that provides meaning to an unfolding strip of events, weaving a connection among them. Frames are communicated by many sources, but mass media is a key actor in this process (Scheufele, 1999; Zaller, 1992). How members of the public form opinions has been a consistent source of scholarly work from the earliest days of political research. The consensus emerged that the ideal of high-quality opinion is stable, consistent, informed, and connected to abstract principles and values (Chong &amp; Druckman, 2007c, p. 103). This ideal is rarely found among the general public. Because people are not capable of perfectly locating, absorbing, understanding, or recalling information (Simon, 1972; Zaller, 1992), they rely on information shortcuts in forming opinions. They use frames to develop a particular conceptualization of an issue (Chong &amp; Druckman, 2007c, p. 104). In 2015, as funding implementation decisions were considered, the question of BWCs did not break down into a partisan policy question. Elite policy actors from across the political spectrum supported adoption of the cameras. President Obama, a Democrat president, supported BWCs and matched his vocal support with millions in federal funding to police agencies to purchase the technology (Office of Public Affairs, 2015). Donald Trump, then a Republican primary contender, supported BWCs and believed they can solve a lot of problems  period (Jacobs, 2015, para. 3). Hillary Clinton, Donald Trumps eventual opponent in the 2016 presidential race, agreed, making federal funding of BWCs a key point of her criminal justice policy platform (Clinton, 2015), and she stated BWCs were capable of improving transparency and accountability (Laughland &amp; Gambino, 2015, para. 11). Bipartisan agreement on a significant policy proposal is rare enough and rarer still in a period of increased partisanship during a presidential campaign. However, this does not mean media framing is not a factor in the BWC policy story. In their analysis of Newsweek stories from 1975 to 2008, Wagner and Gruszcynksi (2016) show that framing tends to affect attitudes towards policy but not partisanship. As such, bipartisan support of widespread use of BWCs serves as evidence of a policy topic on which attitudes can be affected, even when no partisan differences are implicated. Non-competitive environments are the area where most is known about framing effects, while research into how framing works in competitive elite environments lags behind (Chong &amp; Druckman, 2007). While this is a deficit in the broader framing literature, it does not impact this study of narrative effects on BWCs policy, which was situated in a non-competitive, non-partisan context. Policy process theories have long been concerned with the role of public opinion on policy formation. The advocacy coalition framework places policy belief as a core component of analysis (Jenkins-Smith, Silva, Gupta, &amp; Ripberger, 2014). Similarly, scholars working in the punctuated equilibrium approach generally follow Kingdons (1995) conceptualization of the medias effect on public opinion through agenda setting. In this view, the effect of the media is most potent at the agenda-setting level, rather than on individual-level policy preference. In other words, media effects are rarely expected to change individual opinion on policy preference. Instead, the media acts to constrain policy choices through agenda-setting effects. In an alternative theory of the policy process, the advocacy coalition framework (ACF) originally conceived of public opinion as an unimportant force within policy subsystems (Sabatier &amp; Jenkins-Smith, 1993), while the opinion of political elites was the center of subsystem power. This early view has evolved. Depending on the policy context, public opinion can play a central role as an external shock to coalitions within the subsystem, or even as an internal force (Shanahan et al., 2011). 6.1.2.3 Scope of Conflict NPF proceeds from the assumption that public opinion, at the least, plays a part in policy formation, and that opinion is affected through media framing. The framework differs in focus however, as it seeks to quantify not whether media narrative framing is important, but rather how it is done (McBeth et al., 2014). At the meso-level, a strategic reason that policy actors leverage narrative is to either expand or constrict the scope of the policy conflict (Olson, 1965). Long understood as a political strategy (Schattschneider, 1960), in NPF the scope of conflict is conceptually understood as a narrative strategy that distributes the costs and benefits of a proposed policy to the array of characters in the policy narrative (Shanahan et al., 2018, p. 337). The dominant group benefiting from the status quo policy environment will generally attempt to limit the scope of conflict, while the policy coalition or actors who perceive themselves as less powerful will attempt to expand the scope of conflict. The winning coalition is generally the one that is most successful in concentrating the costs (typically on the villain) while diffusing the benefits. In Professor Merrys research on narratives in gun control policy advocacy organizations (2018), she notes the link between social construction policy theory (Schneider &amp; Ingram, 1993) and the NPF. Merry predicts that policy advocates will select and construct characters in their narratives in order to influence how a policy issue is framed. In other words, policy actors will use policy narratives to evoke sympathy and might highlight victims who are positively constructed, such as children (Merry, 2018, p. 751). This is another tactic in an overall strategy of conflict expansion, as actors seek to grow their coalition by appealing to compassionate onlookers by highlighting positively constructed victims. A second conflict expansion strategy is when actors seek to translate a public problem into a personal threat (Goss, 2010, p. 107) by increasing the perceived proximity of a problem for the reader. This strategy is intended to bring in support from those who might otherwise feel a policy issue does not affect them. Proximity can be literal, in which the study would expect actors to highlight a problem in the community of the intended audience. It can also be figurative, in which framing choices evoke a feeling of closeness to a problem (Merry, 2018, p. 750). In the context of BWCs, we might expect to see that a pro-BWC coalition would seek to expand the scope of conflict. By constructing narratives that provide diffuse benefits beyond the specific victims, and simultaneously concentrate costs on the villain, a pro-BWC actor would theoretically have a better chance at winning the policy fight. In opposition, an anti-BWC actor is predicted to construct a narrative which concentrates (or even eliminates) the benefits of a policy change on a limited number of victims, while simultaneously telling a story that shows how the costs will diffuse broadly. These conflict expansion expectations give rise to a set of related hypotheses regarding how BWC policy actors will communicate narratives around the technology: Hypothesis 1A: Policy actors engaging in conflict expansion will focus on positively constructed characters such as children, and/or downplay negatively constructed victims and criminals. Hypothesis 1B: Policy actors engaging in conflict containment will downplay positively constructed characters such as children and/or focus on negatively constructed characters such as criminals. Hypothesis 2A: Policy actors engaging in conflict expansion will focus on characters with high perceived proximity and similarity to the intended audience. Hypothesis 2B: Policy actors engaging in conflict containment will focus on characters with low perceived proximity and similarity to the intended audience. 6.1.3 Sampling Strategy Researchers using the NPF are urged to be transparent regarding how you choose to bracket the time-span of your narrative data collection (Shanahan et al., 2018, p. 341). Narrative analysis is time-consuming, and often the volume of information to be coded is such that a random sample may be more feasible (Shanahan et al., 2018, p. 339). This proposal constrains the amount of information by reducing the time frame of interest, and by examining only articles from the New York Times newspaper. The justification for the decision is based on a review of BWC stories and by a review of general public attention to the issue. The process by which I came to justify this sampling decision is worth describing in more detail. 6.1.3.1 Narrative Source &amp; Time Frame Justification Media reports are among the most common source of narrative data in NPF studies (McBeth et al., 2014; McBeth &amp; Lybecker, 2018). Media accounts, including newspaper articles, often contain embedded policy beliefs and narrative framing strategies, meaning they do not just convey factual information, but instead act as more of a contributor than a conduit in the policy change process (Shanahan, McBeth, Hathaway, &amp; Arnell, 2008, p. 115). Newspaper stories and editorials are a common source of data in NPF studies (McBeth &amp; Lybecker, 2018; Shanahan et al., 2008), and more generally across social science studies interested in media effects (Edy, Althaus, &amp; Phalen, 2005; Lecheler &amp; de Vreese, 2012; Matthes, 2009). In an initial review of BWC news articles, I identify two important dates. First is the fatal shooting of Michael Brown by police in Ferguson, Missouri on August 9, 2014. This was one of the watershed moments in American policing (Lum et al., 2019, p. 2) because it was in the aftermath of this event that President Obama and other influential policy actors began to speculate that if there had been footage of the incident, perhaps the civil unrest which followed could have been avoided. In response to widespread concern, President Obama announced the creation of the Presidents Taskforce on 21st Century Policing (Presidents Task Force, 2015). The second critical date happened in May 2015, when President Obama announced that the US Justice Department would begin making up to $75 million in federal funding available for local police departments to purchase BWCs (Funk, 2016). This announcement was in conjunction with the publication of the task force findings (Presidents Task Force, 2015). President Obama stated BWCs would enhance the trust between communities and police (Funk, 2016, para. 28). By September, the funding program had already distributed nearly $20 million to police departments (Office of Public Affairs, 2015), and a survey of police chiefs and sheriffs the same year showed that up to 96% planned to implement BWCs within a year (Lafayette Group, 2015). Exact adoption statistics are not available, but scholars believe that has at least doubled since 2013 (Lum et al., 2019). Following another NPF study using newspaper articles (McBeth &amp; Lybecker, 2018), I use Google Trends to map general public interest in body-worn video and identify general interest spikes. Google Trend data measure individual searches of specific words or phrases. This measure correlates well with more traditional measures of public attention, such as the use of New York Times story counts (Ripberger, 2011). The Google Trend search was specified to only capture news interest as opposed to general or picture searches. This search strategy allows the study to target general public interest in news about body cameras, rather than web searchers merely interested in what a body camera is or looks like. The Google Trend search results are reported in two figures, and both provide focal information for this research. Figure I: General News Interest in Body Worn Video 2014  2015 Before August 2014, search interest was never higher than a 7 in Google Trend index. However, as shown in Figure 1 (above), in August 2014 (the month Michael Brown was shot and killed by police) the search interest index measure rises rapidly. The index peaks at a 100 measure in December 2014, when President Obama announced he would seek federal funding for body cameras. The President confirmed the funding, as well as the results of the Presidents Taskforce on 21st Century Policing (which highlighted BWCs) on May 1, 2018, and the chart shows heightened public interest in body camera news in the months before his announcement. Thus, the data shown in the figures support the time frame selected as well as the use of newspaper articles for the study. Figure 2: General News Interest in Body Worn Video by State, from 8/1/2014  5/1/2015 Figure 2 (above) shows Google Trend information by state for the period between August 2014 and May 2015. The mean index score across states is 53.5, indicating broad national interest in body-worn video. Further, the interest is relatively well dispersed, though some outlier states are present. This information supports the selection of a nationally important paper such as the New York Times. Not all newspaper content is appropriate for narrative analysis, however, so it is critically important to apply NPFs definition of a policy narrative to these texts to determine inclusion and exclusion in your sample (Shanahan et al., 2018, p. 341). An initial Google search of the New York Times, a national paper of record in the United States, reveals that 47 articles during the specified period of August 1, 2014, to May 30, 2015, are related to body cameras. As an initial corpus, this is manageable enough to examine all articles returned in the search, rather than sample from them. 6.1.4 Analytic Strategies: Stews, Baking, and Structural Equation Models In a recent review of progress in NPF studies, Jones (2018) highlights the relative sameness in NPF research designs. The standard NPF analytic method is a mix of descriptive statistics and measures of association, and, of course, plenty of regression analyses (Jones, 2018, p. 734). This analytic monotony is a reasonable early feature as scholars attempted to build out the framework. Recently, NPF scholars have begun to broaden the analytic scope, with the use of rare event analysis (Kirkpatrick &amp; Stoutenborough, 2018) and causal mediation analysis (Zanocco, Song, &amp; Jones, 2018). Network analysis and in the inclusion of big data have been suggested as potential next steps for researchers looking to expand the analytic toolkit of NPF (Shanahan et al., 2018). For this study, and with the goal of expanding the useability of NPF for the study of American political science, I propose a further way to contribute to the testing of the NPF through the inclusion of structural equation modeling (SEM). While SEM is capable of directly testing the same null hypothesis as logit regression, it can also test hypotheses constructed to test indirect paths of causation. Indirect causation is an especially salient question for NPF, which assumes that narrativity is a dynamic process, but which is generally only tested in a linear regression formulation. Those tests assume a closed causal space and one-to-one interactions on the causal path between independent and dependent variables. For example, perhaps both heroes and villains are important (a hypothesis supported by current NPF theory), but that narrativity increases only when a villain is accompanied by a hero. This logic is an example of a dynamic process that is well-fit to SEM. 6.1.4.1 Structural Equation Modeling (SEM) Regression methods are hampered by the inability to easily identify measurement error. This is a salient problem within the social sciences broadly, but specifically for research within the NPF framework, which relies on data collection techniques that are vulnerable to bias. Structural equation modeling (SEM) is a second-generation statistical technique that allows for both identification of measurement error (and therefore, correction), but also takes into account the indirect effects of endogenous variables within the model (Kline, 2015). These analytic benefits make SEM a significant and indispensable tool for empirical researchers (Tarka, 2018, p. 338), and the method is widely applied across scientific disciplines. Taking an SEM analytic approach to an NPF study has several identifiable benefits. First, one assumption of linear regression is that the explanatory variables are independent from one another. Because NPF assumes the narrative elements are not only related but dynamic, regression is, at a basic level, an inappropriate test for NPF models. SEM can handle non-independent causal variables, a clear advantage in this case. The second advantage of SEM is related to measurement error. Researcher supplied measurement error is unavoidable in a method such as NPF. This bias is baked into the very assumptions of the approach, especially the homo narrans base of the approach. Stories universally influence how humans (including the researcher subgroup of humans) perceive and understand their world. This influence can lead to inter-coder bias as data collection proceeds. Even an experienced, careful researcher coding the narrative content of newspaper stories is likely to (at a minimum and in the best case) supply a bias in how structured narrative content is encoded. Intercoder reliability is no balm either and may actually exacerbate measurement bias. For example, a graduate student or research assistant can reasonably be assumed to harbor the same rating bias as the principal researcher who trained them. In such a case, high intercoder reliability can be interpreted as highly reinforced systemic mismeasurement. While SEM does not magically do away with mismeasurement, the relaxed assumptions and ability to measure latent error could be useful in the specific case of narrative content. Finally, SEMs use of latent constructs is an ideal modeling technique to test foundational NPF theory. Latent constructs are a way of measuring the unobservable latent character of complex social phenomenon. Any particular question or observable item is subject to bias and mismeasurement, and does not capture the full meaning of a social phenomenon. However, through the use of several observable measures, each of which captures an aspect of the overall unobservable latent character of the phenomenon being studied, a researcher can be more assured of the validity of the overall measure. 6.1.4.2 Applying SEM to the NPF What constitutes a policy narrative? In the specific case of NPF, narrative is the unobservable social phenomenon, and SEM offers a unique contribution to both the overall framework of the NPF approach and the policy process theory environment as well. The framework assumes this unobserved narrative is comprised of several underlying, unordered, but observable constructs  the four core form elements of setting, characters, plot, and moral. The elements come together to form a narrativity index. The index is assessed to understand the robustness of any given narrative or set of narratives (Shanahan et al., 2018, p. 337). Importantly, the effect of higher or lower narrativity is yet to be known (p. 137). I suggest an analytic pause before turning to assess the effect of narrativity, and a step back to assess what is even meant by index in this context. The implicit assumption is those narrative elements are not only essential, but essential at the same level. The plot, therefore, is just as critical to narrativity as moral, characters, or setting. Perhaps, but this far from settled within the NPF literature, as indicated by the advice that policy narratives may include all or some narrative components (Shanahan et al., 2018, p. 336). The implied index formulation is akin to a stew recipe, where the overall outcome is relatively invariant to the order, amount, or prevalence of ingredients. Scholars generally agree that at a minimum it must have at least one character and refer to public policy, but past this minima, the recipe is a dash of plot, a dollop of other characters, the juice of a setting, and a smidgen of moral as needed. Continuing the metaphor (perhaps a bit too far): if NPF is to enhance the replicability and rigor of a narrativity index, then it needs a baking recipe, with more exactitude in types, amounts, and timing of the ingredients. In the grammar of SEM, this narrativity index recipe forms an implied covariance matrix. A diagram of the implied covariance matrix would appear as shown in Figure 1 below. In the diagramming syntax of SEM, an oval shape is a latent construct, rectangles are observed items, and small circles are error terms for observed items . Directional arrows from observed items to latent constructs denote a regression-like relationship. Following model resolution (discussed below), path coefficients would be calculated for the weight of each observed variable on the latent construct. These coefficients can be interpreted much like linear regression coefficients. They can denote a positive or negative relationship, and each path can be significant or non-significant at an alpha level specified by the researcher. In the ideal case, each path in this test would be significant and in a positive direction. Figure 3: Base Implied Covariance Matrix for the Narrativity Index Importantly, Figure 3 should not be construed as representing the only implied covariance matrix implied by the NPF approach. However, it is the most likely ideal type, given the current assumptions and structural considerations of NPF. The NPF is open to alternative definitions operationalizing the structures of a policy narrative (Shanahan et al., 2018, p. 335), and so alternative model specification is possible. However, given that even the base NPF model has not been tested in this way, at this time the four core elements of narrativity are adequately encoded in the first diagram. It is straightforward to consider and diagram a multiplicity of other models of narrativity which take into account the possibility of indirect relationships. For example (Figure 2): What if variance in setting strengthens or weakens the influence of a character type on how robust a narrative is (indirect path A), while simultaneously exerting a direct influence (path B) on narrativity as well? SEM is able to solve these equations simultaneously in the implied open solution space. Figure 4: Hypothetical Indirect Implied Covariance Matrix Recall that the NPF explicitly assumes bounded rationality in narratives. This assumption suggests that narrative has stability over time, can be measured, and is not random. Another way of describing that stability of measure is measurement invariance (Nesselroade &amp; Cattell, 2013). A full discussion of measurement invariance is beyond the scope of this paper. However, the key idea is that by modeling datasets from a variety of times, contexts, and sources, we test the underlying model for measurement artifacts. This provides a check that any change we are seeing in the model output is due to actual underlying changes in the data, rather than some other source (Boker &amp; Laurenceau, 2006; Newsom, 2015). Academic psychology pioneered much of the work in longitudinal modeling to detect measurement variance at the inter- and intra-individual level of measurement (Nesselroade &amp; Baltes, 1979). The application of SEM to the problem of measurement variance is considered state-of-the-art methodology (Deboeck, Nicholson, Kouros, Little, &amp; Garber, 2015). Relatively few published articles consider measurement invariance testing directly, beginning around 2011. In the case of testing NPF models of narrativity, SEM techniques can ensure measurement invariance (or diagnose variance) by conducting a series of tests that impose equality constraints to establish parameter stability. If done well, this could result in a genuinely reliable narrativity index which far surpasses the current stew stage of recipe development. Note that Figure 4 above does not require a change in variable or operationalization of the model shown in Figure 1, though a hypothesis reformulation is likely required. SEM is imbued with natural flexibility that allows the researcher to consider a wide variety of narrativity index models. Further, once a likely candidate model is identified, it can be tested across policy contexts. If the model holds, we can begin to isolate the relative weighs of each component and path, allowing for even more theory building. For example, it may be characters (or plot, or setting) are worth more narrativity. In that case, experimental designs with narratives designed with more or less robustness (macro level) could be tested for their (micro-level) effects on the formation of policy belief in individuals. However, this is now far afield in the what-if scenarios, which all hinge on first establishing configural validity for the basic model illustrated in Figure 1. 6.1.4.3 Drawing Conclusions (from drawings) Several conclusions might follow the above analysis, which is a type of confirmatory factor analysis (CFA). First, the observed covariance model could obtain close fit with the implied covariance model. In this case, the structural elements of narrativity would be shown to be in accordance with NPF assumptions. This outcome is the most likely, given that the structural elements of NPF are the result of careful research which has been developed by talented scholars for many decades. The NPF was, at least in part, developed with the transparent goal of meeting policy process scholar Paul Sabatiers requirement that a theory possess a clear model specification and be clear enough to be wrong (Jones &amp; McBeth, 2010; Sabatier, 1999; Shanahan et al., 2018, p. 332). Having only recently being accepted into a prominent policy process handbook (Sabatier &amp; Weible, 2014), the approach detailed here offers a real possibility for method triangulation in support of the still-growing NPF. Alternatively, if the two covariance structures are incompatible, essential assumptions of the NPF approach can fairly be said to have been falsified. In that case, assumption three of the approach would require significant interrogation. Assumption three is that narrative has generalizable structural elements, and building on that assumption NPF models the four core elements of plot, setting, characters, and moral as the quantifiable elements. To undermine that construction would be to undermine foundational aspects of the NPF. However, before drawing such a damaging conclusion, the limitations of the analytic tests should be assessed. For the purposes of this essay, I avoid a full limitations discussion reluctantly, but note that poor model fit, weakness in the implied model, and a lack of narrative comparisons all pose threats to potential findings in the proposed research. These are only three limitations that would have to be considered and are not intended to be an exhaustive list. Applying and testing the NPF is more of an iterative venture, with some ideas developed concurrently and not necessarily bound by unyielding order (Shanahan et al., 2018, p. 333). In that spirit, the identified limitations at this proposed stage are likely to be joined by others as the research process takes place. 6.1.5 Conclusion  Counting Stories in Policy This essay has structured a research approach to understand better the narrative content of stories that lead to policy implementation. In the abstract, this improvement could lead to better construction of stories in other policy arenas. The empirical evidence was unimportant to the politics of passing BWC policy, and appears unimportant to the persistence of the policy. To state it as such is not to stand in judgment, but as an observation of the human realities surrounding policy. It may be that in other policy arenas, there are similar pathways to implementing policies that have otherwise remained stuck. Policies aimed at combatting climate change might benefit from better narrative, so might health care, drug policy, or criminal justice proposals  the possible policy list is long. Political scholars with decades of domain expertise are often unable to explain why their exquisite empirical models are not met with policy success. The NPF is one promising avenue to connecting research to policy outcomes. Applying new methodology, or as stylistically applied here, an improved method of counting stories, will solidify the usefulness of NPF, which in turn will help illuminate the motivating questions of how evidence and policy formation interact. Body-worn cameras are just one small example of a policy that was successfully implemented despite evidence, and persists in the face of contradictory evidence. The narrative of abhorrent police brutality matters a great deal to how we construct public policy around policing and use-of-force. To its credit, and in contrast to many of the other policy process theories, NPF makes its explicit assumptions clear. Implied, or at least rarely stated assumptions still exist. Perhaps the most untested of the implied assumptions of NPF is that of dynamism. Story elements of plot, characters, setting, and moral are all assumed to interact in some way to produce an index of narrativity (Shanahan et al., 2018, sec. 6.1.4). The same fluidity is presumed for the narrative levels, as micro-, mes0-, and macro-level narratives interact with and reshape one another. As demonstrated in the exploration of possible analytic strategies undertaken here, more effort should be given to testing that assumption. Stories count; this is the homo narrans assumption of narrative influence on human activity. The NPF has been successful in providing structure to the assumption such that the relationship between narrative and policy can be assessed. NPF synthesizes the quantitative demands of policy process scholarship with the qualitative instincts of social inquiry interested in meaning-making. To date, the burgeoning NPF evidence base has demonstrated its value to our overall understanding of the policy process. In order to build on the early success of the NPF, I have suggested an analytic expansion is needed to provide clarity and falsification of untested assumptions related to how the approach conceives of a narrativity index. The NPFs front-end of demonstrating that stories count is more well-developed than the analytic back-end of counting stories. This critique is not intended to underplay the contributions of NPF scholars or scholarship. Theory ought to be grounded in description before it stretches to inference. It is only due to the determination of early NPF researchers that any demand for more theory testing can be made, as has been done here. 6.2 Optional Question 1 One prerequisite of a functioning democracy would seem to be that average citizens know enough about their own policy preferences and the political system to participate in politics in a meaningful fashion. Yet, many studies of American citizens cast doubts about how much Americans know about politics or even how firmly they hold their own opinions. Based on the scholarly research, what would you conclude about how well the average American is able to participate effectively in our political system? 6.2.1 Americans Know Enough: Political Knowledge, its Origins and Outcomes Questions about how citizens develop their basic political beliefs, perceive political issues, and participate in the political process are at the heart of the study of American political behavior. In the democratic ideal, the citizen is a well-informed participant in the political realm, able to effectively consider a wide-range of information about a wide-range of topics and distill that information into a well-reasoned act of political participation. However, this normative ideal is loaded with assumptions that are worth testing empirically. In Public Opinion and American Democracy, V.O. Key emphasizes the important link between political participation and the ability to influence government action, insisting that Unless mass views have some place in the shaping of policy, all the talk about democracy is nonsense (Key, 1961, p. 7). But how does the average citizen form the views necessary to shape their democracy? Do they know enough to shape it effectively? This essay reviews how scholars have attempted to address questions about what Americans know about politics and their ability to participate effectively as political citizens. It begins with the first sociological approaches to political learning, follows through to the theories of political cognition which gained supremacy following the theoretical and empirical failures of the sociological approach, and moves to a review of Zallers (1992) model of political belief formation and Delli Carpini and Keeters (1996) examination of the stratification of political information in the American public. Following that review of the most established findings on political citizenship, I review recent lines of scholarship that have begun to call into question a long held belief in American behavioral research, that Americans are generally ideologically innocent (Converse, 1964), which set an early scholarly expectation that Americans do not know enough to manage their democracy well. Finally, while the essay mainly draws from the behavioral approach to American politics, in the closing section the connection from behavior to institutional scholarship is made clear with examples from presidential (Skowronek, 1997) and legislative (Lee, 2009) studies. In closing, I conclude that Americans know enough, and that our democratic experiment has certainly survived generations who knew less. 6.2.2 Learning Politics: The Socialization Approach Following the second world war, political scientists were attempting to understand why America and Great Britain were different than the Germany. How did the German people allow their country to be taken over politically by the Nazi party? The obvious answer for many was that there was something different about the American family, and that children were socialized by the family to value democracy. Political scientists, borrowing from theories of sociology, set out to try and test this theory. Fred Greensteins (1960) study The Benevolent Leader: Childrens Images of Political Authority, and Jennings and Niemis (1968) Transmission of Political Values from Parent to Child, typify what is now known as the socialization approach to political behavior. One positive aspect to the socialization approach is that it provides very predictions - your political attitudes should follow how you are socialized - first by parents, and then by friends, so by the time you reach adulthood, we would expect that political grounding will determine your own views. The socialization of political behavior was the primary theoretical framework for much of the scholarly work in the 1960s, but soon ran into both empirical and theoretical problems. Empirically, data became much harder to generate. Whereas Greenstein (1960) was able to simply begin interviewing elementary school aged children, in the era of Institutional Review Boards, the ethical implications of that type of research render it fairly impossible. Moreover, it soon became clear the evidence did not support the theoretical predictions. Jennings and Niemi (1968) in particular exposed the gap between theory and empirics: children did not simply adopt their parents political views. In addition to these empirical problems, the theory of socialization had a substantial challenge in that it expects that by adulthood our preferences (in this case political preferences) are fixed. This expectation was undermined however, with increasing evidence that people maintained a life-long openness, and socialization continued throughout adulthood, as individuals continued to try to fit-in with their work, neighborhood, and other social environments. By the 1970s, theories of socialization were still a going concern. But by the 1980s political scientists were looking back on the behavioralist approaches and finding them lacking. A new theoretical lens, rational choice, was beginning its dominance in political science (Aldrich, 1976; Downs, 1957). Downs (1957) sets out the basic rational choice model and uses it to try and understand voter turnout, arguing that because each individual vote has so little value, it is rational for voters to have little political knowledge, and to not seek out more. The theory of rational choice was soon exposed as having its own theoretical end-point problems (Green &amp; Shapiro, 1996; Waldo, 2017)  namely the expectation that rational people will not vote, which faced considerable empirical challenges. Still, rational choice variants such as prospect theory (Kahneman &amp; Tversky, 1984; Kahneman, 2003) continued to be a dominant theoretical lens for political scientists interested in political behavior (Hammond &amp; Bonneau, 2009; Shepsle, 2006; Herbert A. Simon, 1990). While socialization would never again gain favor as a pure theoretical approach to political behavior, it never completely disappeared either. Sears and Valentino (1997) use elements of socialization to examine a much narrower question then either Greenstein (1960) or Jennings and Niemi (1968). Sears and Valentino (1997) use the context of a presidential election and find that adolescents are socialized, but by exogenous events rather than the family. Empirically this makes sense, as generational shifts in political thinking can be seen in the aftermath of large exogenous events, such as the Great Depression impacting the life-long economic views toward thrift for those who lived through it, or how the terror of 9/11 shifted the political views on patriotism and war for that generation. Ronald Inglehart and Paul Abramson (1994) provide more evidence for this generational effect on political beliefs, using Ingleharts theory of post-materialism (Inglehart, 1990; Inglehart &amp; Norris, 2017). Using a vast amount of survey data from across Europe and the United States, the pair makes a grand generational argument that there is a cohort effect within generations that is affected by the environmental conditions the cohort experienced as children. In Ingleharts theory, as a society becomes more prosperous, and thus less likely to be worried about base survival needs, their political views as adults will tend towards post-materialism. This is not quite a socialization theory, but is useful because it shows how socialization information can be used profitably in the context of political science. Ingleharts theory also tends to undermine the purely rational choice approach to political behavior, as it suggests that individuals choices are determined by events outside of an immediate response to a given situation. Ingleharts theory and evidence point to the importance of understanding political culture, insofar as it impacts political belief formation. 6.2.3 Political Cognition Whereas political socialization asked how people formed their beliefs as they approached adulthood, the question of how Americans think about politics was still left unanswered. This became the central question motivating the scholars studying political cognition. In this field, the field of political science has been closely following the ideas best set out by Converse (1964). This theoretical line operates from a base assumption that voters have clear ideological positions (Downs, 1957), but update the earlier theories to better understand how voters make decisions on candidates and political issues. These theorists believed that for the vast majority of issues, voters can use ideology and partisan identification (Green, Palmquist, &amp; Schickler, 2002) as a shortcut to determine their views fairly quickly even when they are not in possession of deep political knowledge themselves (Lupia, 1994). Converse undermines that assumption, and studies how Americans use and conceive of ideology. Overall, he concludes citizens do not clearly grasp ideology, nor do they use it effectively to form preferences. Instead, Converse argues that while elites have something resembling a consistent ideology, most Americans inconsistent, a feature of the electorate he famously called an ideological innocence. With Converse finding that most Americans dont have ideological principles from which their political beliefs follow, where those beliefs originate? This is where other political scientists pick up the argument. Feldman (1988), for example, tests an alternate theory that in the absence of ideology, people use value systems to form beliefs. Again though, the empirical evidence did not support the value theory. Lodge and Hamill (1986) provide the model that in many ways supplanted the sociological tradition. They borrow heavily from theories in psychology (Kahneman &amp; Tversky, 1984) and make the basic assumption that people are cognitive misers who operate in a very complex political environment with too much information to process fully, and so they want to make decisions as simply and easily as possible. Lodge and Hamill theorize that people use partisan schemas to handle most political decisions, with these schemas making complex political information easier to process, a form of heuristic thinking. The problem for these schemas becomes confirmation bias, as people tend then to dismiss information that does not fit easily with their already held notions, while simultaneously adopting information that confirms those same notions. A second outcome of this theory is the problem of heuristic processing, which occurs as people make errors and begin to fill in information that was never actually there. These problems leave the possibility of belief change somewhat unexplainable, short of massive exogenous shocks to the schema through overwhelming new information. Recent advances in measurement and a Bayesian view of belief updating suggest that the threats of backlash to non-conforming information is overblown, and that when confronted with politically persuasive messages, the receivers of that information update their views in the direction of the persuasion. In other words, information designed to persuade can and does change minds and those changes are positive, small, homogenous, and durable (A. E. Coppock, 2016, p. x). However, partisan schema theories continue to be explored in the literature, and Lodge and Hamills contribution has been long lasting. Their work also shows the beginning of a shift in methodology in political science, as they use experimental research methods, as opposed to the pure survey research that had dominated the field to that point. Arthur Lupia uses his (1994) Shortcuts versus Encyclopedias: Information and Voting Behavior in California Insurance Reform Elections to address some of the problems with partisan schema theories. Lupia demonstrates that low information voters dont have to be perfectly informed information depositories (encyclopedias) in order to mimic the political decisions of their better-informed counterparts. Instead, the low-information voters use information shortcuts, such as third-party endorsements of political positions and candidates, to form their opinions. This allows them to mimic the votes of the better-informed voters. Notions of information processing and heuristics has become a well-established theory in American political behavior. It probably provides a more realistic reflection of how Americans actually behave and operate in a complex political environment. Some problems remain, however, including problems of bias confirmation. Taber and Lodge (2006) address this problem with their model of motivated skepticism that helps explain when and why citizens are biased-information processors. Using a Bayesian-inspired information processing frame, they find evidence that those citizens who are the most politically sophisticated and with the strongest levels of prior belief are most subject to errors induced by confirmation and disconfirmation bias. The authors key argument is that most people are simply unaware of the strength of their own prior beliefs, and that these priors dictate to a large degree how citizens process information. Bolsen, Druckman, and Cook (2014) add to this literature, by examining the motivation process in how people form their political opinions. Their finding is that people are indeed biased processors of information, particularly in the context of in-party and out-party endorsements. The authors predict their finding will be troubling to people who worry that partisan motivated reasoning leads to lower quality opinions due to dogmatism and inflexibility. 6.2.4 Understanding Mass Opinion In some ways, John Zaller can be seen as modernizing and updating the The American Voter (Campbell et al., 1960). Zallers (1992) book The Nature and Origins of Mass Opinion stands a classic in the field, and is centrally concerned with examining how citizens use mass media information to form political preferences. Zaller gives a good frame for understanding mass political opinion, and on balance the evidence that followed him tends to support his theory. Zaller provides theoretical grounding that allows for competing considerations to be held by a person at any given time as they confront political choices. He shows that elites do provide information that voters use to construct their own opinions, but that this process is mediated. Voters have a political awareness which filters elite (here, mass media) information in terms of issue salience and consistency. In other words, argues Zaller, voters do not have any single, true, political preference. Rather, voters have multiple political considerations, which he structures in his Receive-Accept-Sample model of voter preference. Voters must first receive information, that is they must be made aware of it. Next, the voter must accept (or reject) that information based on its consistency with their prior beliefs. Finally, the voter samples from the most recent information theyve been made aware of, with the information nearest in time given highest preference. Zaller uses his model to show that for the most part Americans use of elite cues in the form of political discourse, which they are exposed to by mass media, to form their own political opinions (Prior, 2013). Like Converse, Zaller disabuses political science of the belief that Americans possess consistent political ideology that forms the basis for their political beliefs. But Zaller permanently improved the model by, first, allowing for more sophisticated understanding of what elements the public does use to form political opinions; and second, by illustrating the primary cue for formation of political beliefs originates with exposure to elite discourse on political matters through the mass media. Finally, one of the lasting impacts of Zallers work has to raise fundamental questions about what political scientists are really measuring when they survey peoples attitudes (Prior, 2009). Given the importance of recency considerations for voter behavior (Panagopoulos, 2011), we should question the validity of opinion survey measures, as recent political events stand a good chance of having skewed respondents reported beliefs and opinions. Zallers model gives a good explanation for why people are not consistent in reported opinions over time. Political opinion formation is a dynamic process, and exposure and recency matter. Zallers book was impactful upon its release, and has continued to shape the study of American political behavior since. One example of how Zaller has influenced later research is Matthew Baums (2002) Sex, Lies, and War: How Soft News Brings Foreign Policy to the Inattentive Public, which helps explain how the media affects what Americans know about politics. Baum shows that soft infotainment shows, which regularly cover the big political foreign crises of the day, help shape Americans views of foreign policy. This helps explain one of the counter-intuitive findings from Delli Carpini and Keeter (1996) that Americans possess more information about foreign policy than domestic policy. 6.2.5 Political Knowledge and Citizen Competence Also updating the early Michigan studies (Campbell et al., 1960; Converse, 1964) is What Americans Know about Politics and Why it Matters (Delli Carpini &amp; Keeter, 1996). The primary question confronted here is whether Americans have enough factual information to be able to participate meaningfully in the American democracy. The authors take a view contrary to the political cognition literature, in that they make a strong normative argument that heuristics are not good enough, and that voters need a strong background in meaningful facts in order to properly participate in a democracy. The main point of the book is that the distribution of meaningful political information is uneven, particularly along dimensions of race and socio-economic status (SES). They find that if a voter is a middle-aged or older white male from the upper half of the SES distribution, that person stands a fairly good chance of having the appropriate basis of political information to participate politically. However, if the voter is, for example, a black woman living in the inner-city and from the lower SES distribution, the likelihood is that she does not possess enough relevant political information to be able to participate politically. Delli Carpini and Keeter make a strong argument that there are institutional hurdles that are skewing political participation. Their normative statement is that if we are to thrive in a democracy, we must begin to address the structural elements which produce unequal distributions of political information. They do an excellent job of documenting the process by which they came to their conclusions, and make a convincing argument for why we should be concerned about what people know. However, some scholars would disagree with the stark findings of the scholarship above. Lupia (1994) argues that voters do not need to be fully informed encyclopedias in order to vote, and that less-informed voters use information shortcuts to vote in ways very similar to their better-informed counterparts. Lupia uses empirical evidence from a California initiative on insurance reform, a topic that most typical voters will have very little information about. Low-information voters participate meaningfully by relying to cues from third-parties such as advocacy groups and political parties to form their political opinion, which is then translated into voting that is not dissimilar to those who spend much more time delving deeply into political issues. However, this kind of partisan motivated reasoning has been found by other scholars to reduce the quality of political opinions (Bolsen et al., 2014), and to be more shaped by the power of prior belief than the accuracy of new information (Taber &amp; Lodge, 2006). Americans must make political decisions in a complex, fluid environment, and much of the scholarship which finds lackluster participation and lower political efficacy is based in a somewhat elitist rational choice belief that correct participation or incorrect voting exists in the first place. Lau and Redlawsk (2006) undermine this assumption. The authors use experimental methods to test four models of how voters process information and make voting decisions. Subjects make voting decisions on hypothetical candidates in a time-pressured environment, and then in the second phase allow those same respondents to collect information for as long as they need before making a voting decision. Subjects who change their vote between the first and second phases are considered to have made an incorrect vote in the first phase, while those whose vote is consistent between phases made correct votes. They find that in up to three-quarters of the time, their subjects were able to make correct votes despite not knowing enough, supporting the typical arguments made by Lupia (1994). The methods used by Lau and Redlawsk are subject to critiques that their experiments are artificial environments, and so dont necessarily tell us exactly how voters make decisions in real elections. However, the value of these experimental findings is that they closely mimic the frantic, bounded rationality (Simon 1972; 2000) and heuristic shortcuts (Lodge &amp; Hamill, 1986; Taber &amp; Lodge, 2006) that real Americans in the real world must contend with when making political decisions. In many ways Lau and Redlawsks findings are supportive of Lupia (1994) and others who reject the belief that democracy can only function properly when Americans are participating with rational, well-informed political knowledge. 6.2.6 The Electoral Connection and Democratic Effects Political science scholars have gone to great effort in attempting to locate the effect of public participation and opinion on politics and policy (Verba &amp; Nie, 1972). David Mayhew (1974) produced one of the most enduring theories in the field in his book The Electoral Connection, where he lays out a stark case that only re-election matters to members of Congress (and to some extent, other elected officials). Given that claim, which is still firmly attended to by most, the voting publics opinions on policy ought to matter a great deal, and their political participation taken to express those opinions as well. Larry Bartels focuses a great deal of attention on the (in)ability of the public to influence public policy, and the intersections of that inability with inequality, in chapter eight of his book Unequal Democracy: The Political Economy of the New Gilded Age (Bartels, 2010). Bartels basic thesis is that economic inequality is growing, and that growth has political, not just economic effects. In chapter eight he presents his findings that economic inequality leads to a lack of representation of the views of low income Americans, and that senators attach little or no weight to the preferences of low-income constituents and that the political views of the poorest third of Americans receive little or no weight in the policy making process (Bartels, 2010, p. 259). One might be tempted to simply connect this lack of representativeness back to early findings that lower socio-economic status leads to lower participation (Verba &amp; Nie, 1972; Wolfinger &amp; Rosenstone, 1980): if poorer people vote less, does it not follow that elected politicians would tend to represent the views of poor people less? Bartels shows, however, that the magnitude in turnout differences between rich and poor groups are too small to correlate well with how senators vote against the policy preferences of the poor. In the end, he finds that while affluent Americans can influence the policy process through both direct and indirect processes, poorer Americans are really left only with indirect methods, such as when less-affluent Americans vote as a group in such a way that close elections are decided by those votes. In other words, it is what they earn, not what they know, that upsets the policy electoral connection. For democratic theorists, there is a normative connection between the two  public opinion ought to affect policy if in fact the polity has control of government (Dahl, 1961). Reflecting that ideal, scholars have attempted to connect Americans political participation to the policy outcomes of their government, with mixed success. For many years the literature failed to establish correlation, let alone causation, between public opinion and public policy. But beginning in the late 1980s and 1990s, two primary types of research in this area were established (Monroe, 1998)  studies of congruency and those of consistency. The classic congruency study uses survey data collected over multiple decades (Page &amp; Shapiro, 1983). The authors use similarly worded questions from across the time periods, and then attempt to correlate policy shifts from before the first time period a question was asked, and after the next time it was asked. Page and Shapiro are able to establish that when a shift in public opinion is detected (they look for shifts larger than 6% in aggregate opinion), there is a correlative policy switch approximately two-thirds of the time. This is a higher percentage than most expected, as most previous research had failed to find any connection between public opinion and public policy. However, given the lack of causal connection the authors were necessarily reserved in their claims. While Page and Shapiro represent the congruency approach, Monroe (1998) places himself in the consistency camp of researchers, which compares how the distribution of policy outcomes with the distribution of public opinion. Monroe compares two time periods, 1960-1979 and 1980-1993, and finds that in the later period public policys consistency with public opinion had dropped from 63% to just 55%. Monroe attributes this relatively low consistency to institutional reasons connected to the inherent bias against change in the American political system. Monroe goes further than Page and Shapiro (1983) by further stratifying his samples of opinion and policy into substantive policy area. This allows Monroe to detect that, for example, in foreign policy, there is nearly 100% consistency between public opinion and policy change. Like Shapiro and Page, though, Monroes methods limit him to correlation claims rather than causal ones. In the case of foreign policy, the nearly 100% correlation leads one to believe that at least a significant portion of the consistency is due to policy affecting public opinion, rather than the opposite. While the majority of research considered here has so far been concerned with national-level issues, Erikson, Wright, and McIver (1989) (1989) offered an interesting variation, locating the discussion in state-level research. The most important finding to come out of this work is that state electoral forces are the most important factor in the correlation  or lack of it  between public opinion and public policy. Using complex path models, they demonstrate that ideological variation between states makes comparisons very difficult - i.e. a Democrat from Alabama is probably more conservative than most New York Republicans. State policy outcomes do represent state opinion preferences, but party control of a state legislature is not a good predictor of state policy, as the party activists and the centrist voter tend to be pulling politicians in different directions than the national party. 6.2.7 Relating Changing American Behavior to Institutions Recall that the most important early studies of American political behavior came out of the University of Michigan election studies beginning in 1956 (Campbell et al., 1960), and that work continues to motivate and inform a great deal of political research. Much of how we still conceive of political behavior is influenced by those initial studies (Lewis-Beck, Jacoby, Norpoth, &amp; Weisberg, 2008). One of the main findings on public ideological alignment is that Americans generally do not understand the ideological differences that are important to political elites (Converse, 1964). The publics inattention is very high even in moments of great political conflict, their opinions are inconsistent, and do not cohere ideologically. On the whole, Converse concluded that Americans are ideologically innocent. However, recent research suggests that the ideological innocence is transforming as more Americans become ideologically sorted, with opinion surveys finding that non-elites are more ideologically aligned and constrained (coherent). Baldassari and Gelman (2008) use National Election Study (NES) data from 1974 to 2004 and find that the correlation between issue attitudes and party identification had grown significantly. In other words, we learn a lot about a voters stance on policy issues such as abortion, gay marriage, and social welfare programs simply by knowing whether they identify as a Democrat or a Republican. But was the finding by Baldassari and Gelman (2008) just a short-term trend? Recent evidence suggests a longer-term trend is in play, as shown by Martin Wattenberg (2019) in his conference paper at the 2019 American Political Science Associations national conference. Wattenberg finds that the positive correlation trend has only increased in the decade since Baldassari and Gelman investigated it. The percentage of Americans (Wattenberg, 2019, p. 1)with well-developed belief systems based on a clear understanding of public policy choices has increased substantially even since 2000, and this increase accounts for virtually all of the increase in respondents whose partisanship matches their ideology. Wattenberg traces the start of this increasing ideological coherence to the presidential campaigns of Ronald Reagan, whose presidency was the first (at least in the American National Election Survey era) to (2019, p. 8) promote a clear agenda that represented a major shift in the course of public policy issues such as tax and social welfare reductions alongside increased military funding. Two other research trends support Wattenbergs belief that we are in an unusual moment in American political behavior, though both supports come from the American political institutionalist camp in presidential and senatorial studies. First is presidential scholarship that shows political paradigms tend to dictate presidential leadership and success, rather than innate political skill (Skowronek, 1997, 2008). In Skowroneks telling, we are still in the Reagan era because presidential candidates still hew closely to the policy issue patterns developed by Reagan. For example, both of our most recent presidents overtly compared themselves to Reagan during their campaigns. For example, Senator Obama in 2008 made the comparison himself during the campaign (Murray, 2008, para. 3): I dont want to present myself as some sort of singular figureI think Ronald Reagan changed the trajectory of America in a way that Richard Nixon did not and in a way that Bill Clinton did not. He put us on a fundamentally different path because the country was ready for it. As a Democrat candidate still engaged in a primary fight, Obama was not campaigning for conservative values. But Obama was a political actor in a still resilient political environment shaped by Reagan, and so while he opposed the political order, he was not able to cast aside the vision of leadership offered by Reagan. The Reagan paradigm is what Skowrownek (2008) would call institutionally thick, and sets the terms of engagement for candidates from both parties, and Wattenberg is likely right to frame the increasingly ideological public as beginning with President Reagan. Further evidence for the findings of Wattenberg (2019) and Baldassari and Gelman (2008) comes from Frances Lee (2009, 2016) in her studies of elite polarization among politicians. Lee notes that we are living in a period of intense electoral competition that skews what is normally expected in terms of ideological polarization. Most of American political history was dominated by one party or the other, and only in the modern era is the partisan competition so balanced that the party in power must be constantly attending to the next election. Tied closely the electoral connection (Mayhew, 1974) but leveraged at the institutional level, Lee sees ideological polarization at the elite level is really partisan competition for power, rather than policy positions. This helps explain why issues can flip between parties in a relatively short period of time, such as Democrats moving from dismissing candidate Mitt Romney for his hawkish views on Russia in 2012 (Oppel, 2012) to embracing the view that Russia presents a credible threat to American democracy. On the same issue, traditionally hawkish, anti-Russian Republicans have seemed to lack urgency (Senate Democrats, 2019) to confront Russian threats (Sanger &amp; Edmondson, 2019). The issue realignment at the institutional level is a rational response for politicians who increasingly operate in a nationalized political environment. To return to political behavior, those institutional demands must be met by a coinciding increase in ideological coherence in the populace, a trend that appears supported by the evidence reviewed earlier (Baldassarri &amp; Gelman, 2008; Wattenberg, 2019). Which came first is unclear, but a least one line of research indicates that the issue and partisan polarization is more akin to a social identity than mere policy differences. In Partisan Hearts and Minds (Green et al., 2002, p. 13) partisanship is defined as a type of social identification: a psychological process of self-categorization and group evaluation. People identify as a Democrat or a Republican in the same way they identify as belonging to a religious denomination or ethnic group. Instead of the warmth indicators used by many partisanship researchers in surveys, the authors argue that people ask themselves two questions: What kinds of social groups come to mind as I think about Democrats, Republicans, and Independents? What assemblage of groups (if any) best describe me? (Green et al., 2002, p. 8). How a person answers these questions to themselves produces a stable partisanship. The authors see partisanship as a relatively non-dynamic phenomenon. That is, rather than elections producing a great deal of party choice change among voters, most people already have a partisan identification (at least to themselves) and that identification is rather unlikely to change in the short-term span of an election cycle. Elections are more of a cause for cheerleading ones own team, and less a competition between two (or more) choices of individual politicians: Elections are also forums for intergroup competition. Individuals who identify with these groups are drawn into this competition. Their interest and level of emotional engagement increase as they embrace the team as their own. Although not irresistible, the desire to see ones team prevail powerfully influences the probability of casting a vote for the candidate of ones party (Green et al., 2002, p. 202). A willingness to see past rivaling individual politicians and engage with politics as social identification is why partisanship matters  it matters because it affects electoral politics. The authors seek to provide empirical support for their theory not just in American politics through the case of the 2000 presidential election, but in comparative international contexts as well, with evidence from the United Kingdom, Canada, and Germany. This is an important claim from the authors, who position their theory of partisanship not as an American phenomenon, but a human one. The increasing salience of partisanship as a heuristic device for deciding policy stands goes beyond the political. While partisanship is traditionally seen in issue-based terms, there is evidence that partisanship has affective impacts as well (Iyengar, Lelkes, Levendusky, Malhotra, &amp; Westwood, 2019, p. 129): Ordinary Americans increasingly dislike and distrust those from the other party and this animus is leading Democrats and Republicans both say that the other partys members are hypocritical, selfish, and closed-minded, and they are unwilling to socialize across party lines. 6.2.8 Conclusion The evidence available suggests that the democratic theorists have been mistaken to assume that the average voter is in possession of highly structured, sophisticated ideological frameworks with which to navigate their duties as a citizen. Instead, voters live in a highly complex political world, and tend to only pay attention when they are provided with highly relevant, current information that has direct impact on their world. Zaller (1992) and Delli Carpini and Keeter (1996) continue to provide relevant theoretical lenses with which to examine the American voter and how they construct a political worldview. Modernization has vastly increased the amount of information available but it is unclear whether that information is salient enough for the average voter in order to constitute valuable information. Given the evidence that most voters continue to operate as politically naÃ¯ve, if not outright ignorant, one must begin to question the normative assumption that a well-informed public is necessary for a democracy to survive. If it ever was necessary, when was it present? I suspect it never has been. However, early evidence is emerging that political knowledge is increasing, at least among some issue domains and partisan axes. While some scholars worry that the American voters lack of basic political information threatens democracy, other have held that people do not necessarily need to be in complete command of political knowledge in order to operate effectively as a voter (Shannon et al., 2019) because they use informational shortcuts (Lupia, 1994). Perhaps, given the centuries of relative democratic stability in the American context, it is time to give serious consideration to the idea that in fact the democratic experiment does not require a sophisticated electorate. While a democracy may be improved by one, there seems to be enough evidence at this point to at least conclude that the necessity of politically sophisticated and knowledgeable publics is not a prima facie requirement. 6.3 Optional Question 2 The academic study of public policy making is essentially bereft of theory, resembling journalism far more than science. Based on your knowledge of the study of American public policy, do you agree or disagree with this assessment? Provide evidence in support of the position that you take. 6.3.1 Policy Theories are Scientific Theories In the early 2000s a new policy theory entered the scholarship  the Narrative Policy Framework (NPF), which centered the power of policy stories to shape policy outcomes. In response, Paul Sabatier, a leading policy theorist, pushed the originators to be clear enough to be wrong (for historical tracing see McBeth, Jones, &amp; Shanahan, 2014; Shanahan, Jones, &amp; McBeth, 2018, p. 332). To that end and inspired by postmodernism and the seemingly contradictory charter of science (Jones, 2018, p. 724), NPF aimed to produce work that could stand up to this Popperian critique (Popper, 2005). By 2010, the NPF was formalized as a structural account of narrative which sought to test the influence of policy narratives on policy processes, designs, and outcomes at three different levels of analysis (McBeth et al., 2014, p. 227). By 2013 the Policy Studies Journal held an NPF focused symposium featuring tests of the framework, and in 2014 the NPF held its place in the third edition of Theories of the Policy Process (McBeth et al., 2014; Sabatier &amp; Weible, 2014). To complete the story arc, in 2019 the academic journal Policy Studies named a leading NPF theorist, Michael Jones, to the editor-in-chief position. The historical context above is important in that it helps illustrate how the NPF was born from post-positivist instincts but adopted to the positivist, falsifiable demands of the policy process academy. Proponents of NPF argue that the admixture of positivist/post-positivist scholarship renders critical discourse studies and other poststructuralist concepts normally outside the realm of empirical study (Jones &amp; McBeth, 2010, p. 329) into a scientific approach clear enough to be wrong (Shanahan et al., 2018, p. 332). The early critique of unscientific is not unique to the NPF. A common critique of, and within, policy theories is that they are not really scientific enough, more akin to journalism than social science. This historical tendency has led to a sensitivity within the policy process research world, and as a result the field demands much of itself and potential new theoretical frameworks. This essay will defend the scientific credentials of the public policy theory scholarship, by focusing on the underlying theoretical frameworks that motivate the vast majority of research in the area. This essay will cover five main theoretic approaches to public policy, and is structured to move somewhat temporally as well. It begins with quick acknowledgment of the theory of the linear policy process. Following the rejection of the assumptions of the linear process (Cohen, March, &amp; Olsen, 1972) came punctuated equilibrium (PE) theory, which still retained some linear elements but moved away from the incrementalist predictions of the linear theory. The third theory, multiple streams analysis (MSA) helped explain the significant policy shifts in punctuated equilibrium theory but added theoretical flexibility which gave it greater explanatory power for understanding why some policies are adopted, while others lay fallow. While MSA has proven popular for its parsimony and flexibility, some scholars have long complained it lacks the ability to explain process in the many different contexts in which policy is found. The fourth theory, advocacy coalition framework (ACF), takes many concepts from the MSA framework, but trades parsimony for greater explanatory power. The final section of the essay closes with a synopsis of social construction of target populations (SCTP) theory. SCTP theory does not attempt to explain everything in the policy process but instead deconstructs the language (Wittgenstein, 2013) and assumptions of policy actors which then are used to justify actions that have inequitable consequences for different populations affected by the policy. To close, the essay points to the importance of scientific theory in policy studies, and to the importance of the scientists in the area to remain pragmatic and flexible to the constantly shifting policies they aim to study. 6.3.2 The Linear Policy Process The development of non-linear policy process theory is a relatively recent development, and the linear process model remains the most common way of thinking about how policy is developed outside policy studies. The linear policy process is the natural outgrowth of applying the most simplistic rational choice assumptions to policy. In policy studies, the theories that come after the linear process, and its assumptions, are often reacting to it. Linear policy process theory makes assumptions that are rooted in rational choice assumptions. People are self-interested beings who have ordered preferences (preferring one option over another), and those preferences are stable. The individual has no mental, emotional, or cognitive deficiencies which would hamper their ability to make choices in their own best interest. It assumes that the individual is capable of knowing all information related to the choice before them, and thus is able to make a reasoned decision about the which option to select, with the predicted choice being the one which maximizes the individuals benefit while minimizing the cost. These assumptions have been set aside as unrealistic models of human behavior in modern political and policy scholarship (Green &amp; Shapiro, 1996; Jones, 2002). The linear process was never useful as a predictive model of policymaking. The Garbage Can Model of policy (Cohen et al., 1972) takes the opposite assumptions, and successfully challenged rational choice as an appropriate set of assumptions for policy theorists. The Garbage Can model explains the policy process as inherently chaotic and unpredictable, a mix of problems, ideas, technology, and solutions, all flowing around in an amorphous soup, from which a policy eventually congeals when the right components interact with one another. While Garbage Can modeling has not proven useful as a theoretical framework in the long-run, it is important for the theories it inspired, particularly multiple streams analysis (Kingdon, 1995; Zahariadis, 2014) and the advocacy coalition framework (Sabatier &amp; Weible, 2007). 6.3.3 Punctuated Equilibrium Punctuated equilibrium (PE) (Baumgartner &amp; Jones, 2009; True, Jones, &amp; Baumgartner, 1999) is a policy theory which borrows from biological science to describe long periods of policy status quo, suddenly interrupted by significant shifts in the policy landscape. Baumgartner and Jones recognized that the slow incremental policy changes predicted by the base linear policy model were not reflected in the empirical policy evidence. Rather than slow, steady policy progress, they saw long periods of policy stability which were then suddenly disrupted by sharp changes in short periods of instability. This, to the authors, seemed to reflect the sudden evolutionary adaptations seen in the biological sciences, as species maintain long periods of stability, with sudden natural adaptations (Gersick, 1991; Gould &amp; Eldredge, 1977). Though more useful than its simplistic predecessor, PE is still at its root a theory of linear change, though with generally more relaxed assumptions about the rational nature of the individuals involved. For instance, PE assumes that people are boundedly rational (Simon, 1976) rather than perfectly so. Similarly, PE recognizes that policymakers have limited attention capacity, and cannot know everything about a policy issue. Another critical concept in PE is that of framing (Chong &amp; Druckman, 2007b; Zaller, 1991, 1992), which groups use to define how a policy problem is understood, in order to better position their preferred policy solution. Similar to both multiple streams theory and advocacy coalition framework (covered later), the PE framework attempts to understand how policy groups operate to bring about policy change. PE uses concepts such as agenda setting, policy monopolies, and venue shopping to explain how these groups overcome the natural tendency towards stability and continuity in the policy environment. With agenda setting, groups make strategic choices about how much attention to bring to their preferred policy solutions. If they worry that attention will risk derailing the policy they will work to minimize attention, while at other times, particularly with lawmakers reluctant to pay attention, the policy groups actively manage attention around a policy problem and solution in order to generate political momentum. Policy monopolies, which are reminiscent of the iron triangles of earlier policy studies (Jordan, 1981) develop in specific policy areas, and like in the advocacy coalition framework (Sabatier &amp; Weible, 2014), these monopolies can persist for long periods of time, as they work to continue passing policy which reinforces their access to resources and thus policy influence. The answer to policy groups that are locked out of a policy monopoly is what Baumgartner and Jones (2009) refer to as venue shopping. If a group is locked out of the legislative policy arena, for instance, they may choose to change venues and begin looking for ways to pass their preferred policies at the executive or judicial levels of government. Punctuated equilibrium policy theory was developed in the United States, and it provided a useful explanation of empirical policy changes there. Early use of PE theory (Baumgartner &amp; Jones, 1993; 2010) was used to explain US nuclear policy, which existed mostly out of public sight in the post-war period. Following decades of that stability, where the policy was primarily left to technical experts and legislative subcommittees, anti-nuclear power advocates were successful in challenging the positive image of the nuclear industry, and venue shopped their policy ideas to courts and the public. The existing policy monopoly was broken, and heavy regulation of the nuclear industry effectively halted the expansion that had been seen in the post-WWII period. The US government is structured in a divided power arrangement, which tended to reinforce status quo arrangements, and was seen as responsible for the periods of policy stability. However, the PE theory has been usefully applied in non-US contexts as well. A comparative study of policy regimes in the US, Denmark, and Belgium (Baumgartner et al., 2009, p. 615) using data from dozens of processes across three nations and covering hundreds of thousands of observations found the same non-normal distribution of policy inputs and effects. This study provides strong evidence that it is not necessarily the US constitutional system which is providing friction in policy development and thus favoring status quo. While all three countries in the study are democracies, there are enough structural differences to suggest that a General Punctuation Hypothesis can be applied in comparative contexts. Punctuated equilibrium theory is robust and takes its place, alongside multiple streams analysis and advocacy coalition framework, as one of the most cited (Baumgartner et al., 2009) and useful modern theories of the policy process. It provides a framework that allows even non-scholars to immediately connect with the relatively simple idea  things tend to stay the same, until they do not. At the same time, it has enough complexity and flexibility to be adopted in varied political contexts. 6.3.4 Multiple Streams Analysis The appeal of the linear policy process theory was its one-dimensional, straight path construction of policy development. However, scholars have long recognized that the linear process is far more normative than descriptive. John Kingdon attempted to lay out a more realistic, descriptive model (Kingdon, 1995), in what is known as Multiple Streams Analysis (MSA). While on the surface MSA has similarities to punctuated equilibrium theory (Baumgartner &amp; Jones, 2009), it does differ in its departure from the linear process assumptions which punctuated equilibrium held. MSA takes the path between the utter chaos of the garbage can and the too-linear punctuated equilibrium frameworks, and in doing so presents a more compelling theoretical structure than either. MSA recognizes that policy is complex, like the social problems it attempts to address. Ambiguity is at the heart of why policy is so difficult to study (Zahariadis, 2014), because policy actors can never really know the root cause of a social problem, and even problem definition  the start of the linear process model  is ultimately a contestable, political step. Rather than assume policy actors are purely rational beings, MSA holds that humans are boundedly rational (H. A. Simon, 1976), and so operate with limited information capacity, selective attention, and imperfect cognition. Further, there are significant time constraints which limit the ability of policy makers to ever know enough, let alone know all the facts that perfect decision making would require. In the end, MSA seeks to answer the question: In a universe of nearly limitless policy problems and solutions, how do the relatively few new policies rise above the rest? MSA is one of the most cited academic theories of the policy process and key influence on the study of public policy (Cairney &amp; Jones, 2016, p. 1) with over 12,000 citations as of 2015. The appeal of Kingdons framework lies in its flexibility. MSA posits three streams in the policy process  the problem, political, and policy streams. How these three streams come together, or fail to, is a useful metaphor for thinking about why certain policies are implemented, while other, similarly good policies, fail. Understanding the three streams is key to understanding MSA. While the streams are discussed in a certain order here (problem/political/policy), in practice the analysis is much more about how the streams interact than about their temporal order. In the problem stream, attention is paid to how attention is gathered around a policy problem. Attention in this frame can be mean many things, none of which are necessarily objective indicators. Attention might be statistical information which point to a problem, or in some cases a crisis gathers immediate and widespread attention to a problem. Problems exist whether or not attention is being paid to them, and MSA recognizes that policy makers are only ever paying attention to a very small number of the universe of problems which they could be minding. The political stream refers to the many people, advocacy groups, and political bodies such as legislatures, interested and involved in policy making. The partisan composition of a US Congress, for example, will have an impact on whether or not a policy solution which is perceived as increasing tax burdens has any chance of being implemented. Similarly, the national mood in the wake of a financial crisis must be considered when considering whether complex regulatory policy might be implemented. The political stream is about the actors who must pay attention to a problem, and possible solutions, before a policy can be implemented. During some time periods, the political stream dictates that some problems in the problem stream wont gather attentions, while ideas from the policy stream wont be considered. In the US context, periods of divided government, when one party controls Congress while the other party controls the presidency, are predicted to have relatively little policy movement. Conversely, periods where one-party controls both the executive and legislative functions are predicted to have a better chance of implementing larger policy changes. The policy stream is described as a policy primeval soup by Kingdon, where potential policy ideas from a variety of policy actors conceive of potential policy ideas in policy communities. At any point in time, the policy stream contains a large number of possible policy solutions, but not all of them are feasible, supported, or available. While a policy idea may originate with a single actor, the ideas change as they are exposed to and considered by other actors in the policy stream. The ideas that eventually become policy are the result of a large number of participants modifying the original idea, and is often a much wider solution than the original, narrower solution. Some of these actors are so-called policy entrepreneurs who recognize an opportunity to insert their own policy solutions into one which is gaining support. Policy entrepreneurs are important to MSA. These are the people and organizations who recognize that the politics and policy streams are often not in sync. A policy entrepreneur waits for, and recognizes, when the two streams offer an opportunity for their preferred policy idea to be implemented. These policy ideas are developed before the actual streams coincide, and the preferred policy is offered as a solution to a problem which has garnered attention. At the same time, these policy entrepreneurs will work to bring the streams together, for example by attempting to bring greater attention to a problem while the politics stream is perceived as favorable to their already developed policy solution. Metaphors to think about the stream process in MSA are numerous (Cairney &amp; Zahariadis, 2016), and that flexibility has been key to its success. Some think of the streams as literal rivers, which once mixed or merged, are difficult to unentangle. Kingdon himself suggests a space launch metaphor in which all factors must be perfect for launch, implying that policy makers will abort a policy before implementation if all the factors in the streams are not ideal. MSA assumes that when the problem, policy, and political streams come together, there is opportunity for policy change, but most of the time the streams are not in synchrony. Policy entrepreneurs are thus critical to policy change, as they work to align timing in the streams to create the window of opportunity for their preferred policy change. They work to gather critical mass attention to a problem, so that a solution is demanded. They work with other policy actors in the policy stream to develop their preferred solution to the identified problem. They work to shift the political landscape so that policy and law makers are persuaded to adopt their solution. In the end, the flexibility of the MSA metaphor, and the relatively low barrier-to-entry for scholars to understand policy through the MSA framework has made it one of the most popular and useful ways to examine policy (Cairney &amp; Jones, 2016). The ease of use of MSA, and the associated limited empirical usefulness, will stand in stark contrast to the advocacy coalition framework (Sabatier &amp; Weible, 2007). 6.3.5 Advocacy Coalition Framework The advocacy coalition framework (ACF) was developed by Paul Sabatier and Hank Jenkins-Smith (Sabatier, 1988; Sabatier &amp; Jenkins-Smith, 1993), and from the beginning has been defined by defining the role of belief systems in the policy process, especially their role in shaping policy-oriented learning. The most complex of the mainline policy theories covered in this essay, ACF attempts to develop a holistic theory of policymaking. Because it is designed to be applicable across a variety of policy contexts, and because it assumes that each policy environment is inherently complex, the ACF framework is itself quite complex. In the ACF framework, policymaking takes place in a complicated environment which contains multiple actors across multiple levels of government (Weible, Sabatier, &amp; McQueen, 2009). Policymakers have very high levels of uncertainty, and their decisions are always made with inherent ambiguity. Policy decisions take years to produce policy outcomes, and those outcomes are difficult to ascertain with any certainty. ACF recognizes that there are also different types of policies at play, with some policies being fairly straightforward, others being very technical and complex and done outside public notice, while some policies are incredibly political, controversial, and evoke national partisan fights. Beliefs are a key concept in ACF, as individuals and coalitions compete in politics to turn their beliefs into implemented policy. In ACF, there are three types of basic beliefs. Core beliefs are those that are so rooted in the individual that they are unlikely to change, or be changed by external events. Core beliefs tend to be so broad that they are unlikely to provide meticulous rules for policy. Conversely, policy core beliefs are more likely to be changeable, and more likely to influence how an individual believes policy should be constructed. The third type, secondary aspect beliefs are far less important to the definition of the individual, and much more likely to shape their views on policy implementation, while being more easily shaped than the other types of belief by learning new information about a policy. Individuals with shared belief systems are likely to be found together in coalitions, which form policy subsystems in ACF analysis. ACF treats policy subsystems as the unit of analysis. These subsystems are comprised of politicians, policy experts, advocates, and professionals. These subsystems are similar to the policy stream in the multiple streams framework (Kingdon, 1995), and in ACF the policy subsystem has within it coalitions of associated members all focused on a specific policy issue. These coalitions are epistemic communities (Haas, 1989)  systems of shared belief and activity  and networks within the subsystem can cooperate or compete to bring their preferred policy solutions to the forefront during policy debates. Strong coalitions often dominate policy issues for long periods of time, and because ACF is concerned with policy cycles, the periods examined often stretch out a decade or more. Law makers, who are constrained in attention and time, often assign responsibility in a policy area to senior public administrators, who in turn rely on the advice and consultation from policy subsystems, who are framed as the experts in the area. Within a policy subsystem, coalitions compete in the policy space. In a simple hypothetical, Coalition A and Coalition B each have a preferred policy solution. Between the two coalitions is are policy brokers who are also part of the policy subsystem, and who work between coalitions and lawmakers. Each coalition has its own policy beliefs and resources to compete with the other with, and policy brokers help structure that competition. Eventually, a decision is taken by the governmental authority with jurisdiction in the policy space at question. The governmental decision has outcomes for new institutional rules (or removal of old rules), new resource allocations, and appointments to new institutional bodies. There are also policy outputs from the policy decision, which in turn lead to policy impacts. The new rules, resources, appointments, outputs, and impacts all exist in a feedback loop which in turn alter the existing coalition arrangements. In extreme cases, a policy coalition may cease to exist as the winning coalition solidifies itself as the dominant voice in the policy subsystem for years to come. More commonly, there is simply a shifting of resources and policy strategy among the advocacy groups which comprise the coalitions, and the game plays on. There are factors in the ACF framework outside of the policy subsystem, all of which have effects on the subsystems. There are relatively stable factors, reminiscent of the forces in punctuated equilibrium theory, which serve to produce a policy environment which favors the status quo against change. These stable parameters include the core and policy core beliefs of the policy actors, social values, the distribution of resources, the social structure in which the subsystems exist, and the core structures of the government (i.e. a constitutional democracy versus a communist state). The common theme of the stable factors is they tend to be exogenous to the subsystem and other influencing factors. These stable factors influence the rest of the framework, but tend not to be influenced themselves. Unlike the relatively stable factors, ACF also recognizes that there are endogenous factors which both significantly alter, and are altered by, the policy environment; these are events which are reminiscent of the shocks in punctuated equilibrium theory. These changes can include systemic changes in the governing coalition of a subsystem, socio-economic changes such as large financial crises, sudden shifts in public opinion (such as those seen in the last decade on gay rights and marijuana legalization), and finally, decisions in other policy subsystems which have large impact on the subsystem being analyzed. Rarely, like in punctuated equilibrium theory, these external events can be linked to a very large shift in the policy environment, most likely by providing a shift in the internal environment of the policy subsystem. An example of this can be seen in the policy environments following both World War I (a move towards US isolationism), WWII (a move towards international organizations to prevent widespread war), and the Great Depression (a move towards a social safety net). Also external to the policy subsystem are the opportunities for long-term coalitions to take advantage of. These opportunities are themselves influenced by the stable factors described earlier, but also directly affect how policy subsystems operate. These factors are related to the political systems in which policies are considered, such as the difference between divided party control of the executive and legislative branches of the US government. These factors will dictate whether, and how much, consensus is needed before a policy can be adopted. In broadly democratic political systems, the amount of consensus is relatively high compared to systems with politics which allow for a single governmental actor to take drastic policy action. The final structure in ACF theory to be considered are the short-term constraints in which policy subsystem actors operate. These constraints are affected by both the opportunities factors and the external events, but the constraints also operate directly upon the policy subsystem as well. For example, in a policy environment where there has recently been significant policy shifts, the coalitions within a policy subsystem are all constrained from further action as law makers turn their attention to other policy subsystems. ACF theory is considered to be the creation initially of Paul Sabatier, but upon his passing the theory has been continuously refined and adapted to the policy realities of the different contexts within which it continues to be applied. ACF has proven resilient, as it maintains the theoretical flexibility of the theory systems that preceded it, while recognizing the feedback loops (Soss &amp; Schram, 2007) that incorporate the influence of stability, shocks, constraints, and opportunities in the policy and political systems. The drawback of ACF theory is that it remains a difficult proposition to translate effectively for non-academic audiences, whereas multiple streams analysis and punctuated equilibrium theory both benefit from the ability to construct easily understood metaphors around policy problems and proposals. Recent work linking the streams framework of MSA with the stages analysis of the advocacy coalition framework (Howlett, McConnell, &amp; Perl, 2017) shows a path forwards for researchers who want a more robust system for analyzing policy, particularly in the comparative policy literature. Howlett and his colleagues formulate a five-stream framework, adding a program stream and a process stream, all of which proceeds along the traditional linear policy stage path. Though too soon to judge whether such a combined model will prove any more useful in both theoretical and empirical contexts  and it must, given the additional complexity the model has compared to more parsimonious models  there is at least an attempt to synthesize the main policy theories, most of which are at least several decades old. 6.3.6 Social Construction of Target Populations To this point, this essay has concentrated on the large theories and frameworks, which all aim to explain the policy process as a whole. This proves to be a difficult goal for policy theory to meet, given the extreme complexity in policy types, political environments, and policy problems. However, not all theory must be so comprehensive, and in some ways theories with more restricted aims, like the social construction of target populations (SCTP), are more able to give clear theoretical explanations coupled with the ability to offer predictive and empirical power, because they examine smaller pieces of the larger policy environment. SCTP was first developed by Schneider and Ingram (1993), and defeats another assumption of the linear process, that policy makers, and policy itself, are neutral or unbiased actors. Their argument is not itself post-modern, but builds on post-modernist critiques of language which deconstruct the power relationships inherent in language (Foucault, 1991, 2005; Yanow, 2003). Foucauldian discourse analysis has been effectively used by researchers to understand how different approaches to language contain critical assumptions about how changes in policy relate to broader social change (Sharp &amp; Richardson, 2001, p. 193). The central role of language in policy debates (Schmidt, 2000) reflects how important language is to the human experience more generally: The limits of my language mean the limits of my world, (Wittgenstein, 2013, pt. 5.6). Schneider and Ingram show that elected policy makers adopt value judgements about the social groups which are impacted by policy programs, and that those value judgements have an impact on the policies they create and implement. In this framing of political statements, some politicians will for instance, use language which implies that individuals living in poverty are lazy and have created their own situation, that may justify policies which withhold government benefits from that group. But just as language can justify under benefitting certain social classes, it can also over-benefit others. The same politician may use language which confers noble, worthy qualities on business owners, which would then serve to justify policies which shift resources to that social class. Moreover, this type of construction is not limited only to politicians, and front-line, street-level bureaucrats (Lipsky, 1983). Police officers and teachers have been found to construct their own identities of the citizens they serve, sometimes to the detriment of those citizens (Maynard-Moody, Musheno, &amp; Musheno, 2003). Construction of target populations is not as simple as positive and negative populations though in the SCTP theory, and Schneider and Ingram illustrate this (1993, p. 336) through their use of a two-axis notional figure, where measures of positive and negative constructions are paired with high and low perceived power constructions. Power in this use is the ability of a social group to accept or reject the image painted onto them. This gives a four-category scheme of advantaged (high power/positive), contenders (high power/negative), dependents (low power/positive), and deviants (low power/negative) social groups. These simplistic categorizations of complex populations make it easier for politicians and governments to implement policies which over-benefit the advantaged, while making it extremely difficult for deviant populations to even challenge their disadvantaged status in policy debates. This creates a policy feedback loop (Larsen, 2018; Pierson, 2000), as an advantaged group like homeowners not only are over-benefitted in terms of resources granted by policy, but then are able to reify their position in the social hierarchy, leaving to more opportunity to implement even more policies which will benefit them. This creates asymmetries of participation and power, and those asymmetries are reinforced by the system creating and accepting social constructions of the deserving and undeserving. This flaw in the system has long been recognized in political studies (Schattschneider, 1960; Schlozman, 1984; Stone, 2002), but SCTP offers a useful empirical starting point for understanding how particular social groups have been affected by policy choices influenced by social construction. One of the most powerful critiques offered by SCTP is showing how these constructed beliefs about social classes not only has immediate effects on resource allocation, but has effects on those social classes long after the policy maker has left office. This phenomenon is known as a feed-forward effect, or in other literatures as path dependence (Pierson, 2000). Path dependence recognizes that the timing of policy choices matters, and policy makers select policies which have self-reinforcing feedback processes (Soss &amp; Schram, 2007). These processes represent the resiliency of institutions which are far longer lived than the policy makers tenure (Sanders, 2006). Path dependency imposes a cost to going back to a previous point, and the longer a policy scheme has lived, the higher the cost. In this way, earlier choices have greater impact than later ones, as the policies themselves shape the institutions which house the policies (Mettler, 2002). SCTP offers a compelling critique of policy studies itself, as it uncovers how the language involved in policy can compel certain beliefs and narratives which can hinder, harm, or help certain classes of individuals (Sharp &amp; Richardson, 2001), even as policy scholars unthinkingly use the same language. Further, SCTP critiques the underlying, formative ideals of early public administration and political science, that of the neutral and unbiased bureaucrat, or public administration scholar. From the founding of the American political system, the ideal of competing factions balancing the power of any one faction (Robert Alan Dahl, 1982; Madison, 1787) has provided powerful argument that the US constitution and division of power among the federal branches would protect minority interests from the powerful machinations of the majority. However, the justifications of the pluralist federalist system was largely imputed by Madison and Hamilton into the Federalist Papers in a post-hoc manner intended to justify ratification of the US Constitution (Peterson, 2012). VO Key (1963) was ahead of his time in noting the effects of sectionalist national politics on state politics and parties, noting that national political tides spill into local politics. Party cleavages at the national level are projected into state elections, with the national party need to retain control used to justify the racist practices of the Southern Democrats of Keys time. This can reduce the incentive for local and state politicians to perform well, as they justify their control  and pardon their own structurally biased practices  in the name of national party priorities. So, rather than the administrative and policy state providing an intricate balancing wheel (Madison, 1787; Rohr, 1986) against the predations of a majority, at least in some cases SCTP theory allows us to see how policy and law makers are able to use the concealed power of language to prolong and protect the interests of the already powerful. One limit of SCTP is that it is less concerned with comprehensive theoretical explanations of policy process, and so in cases where there are not clear-cut social classes at play, SCTP may be less useful. A second limit is that, at least in the original construction of the theory, there is little said about how social classes might contest how theyve been constructed by policy makers and the public. SCTP has little to say about how, or more importantly why, one social group may attempt to help challenge the social construction of a less powerful one. Why for instance, would a feminist group  hypothetically located as a challenger in SCTP  want to help restore the voting rights of an ex-prisoner class? SCTP still has buried assumptions of rational choice, presenting the actions of the powerful as merely, or purely, self-interested. A final limit of early SCTP theory was a lack of direction  what should individuals and advocates do with this knowledge. That critique has been substantially, though not wholly, blunted as more researchers have become interested in critical policy theories, and extended the original insights into examining the ill effects of economic policy concentrated on women and blacks (Andersen, 2001), food justice (Billings &amp; Cabbil, 2011), and Native American school children (Quijada Cerecer, 2013). 6.3.7 Conclusion Policy studies are clearly much more than mere journalism. To engage properly with policy studies requires a canvassing of many complex policy process theories, and understanding both what they are capable of answering as well as what research questions they are not well equipped to address. This essay has covered only five of the theories available, with an eye towards selecting those that have survived at least several decades of empirical testing. There are more approaches available, and more continue to be added even as the most established theories continue to be honed in the pages of academic journals every month. Good theory is portable  it can be carried across contexts, and when contexts differtheory is required to generalize from one to another (Coppock, 2018, p. 11). Kingdons (1995) multiple streams framework allows for the identification of universal concepts (Cairney &amp; Jones, 2016) which can be applied in multiple contexts. At this time in policy studies, the advocacy coalition framework is still the most flexible and explanatory theory available, and though far from perfect, allows for a broad examination of policy in many contexts. The adaptability of the ACF framework means it can fold in even critical theory insights, which by themselves do not produce a fully satisfactory explanation of how policy is conceived, adopted, and implemented. This essay has strived to make clear that attempts to delegitimize policy studies as journalistic, unscientific, or unfalsifiable are misguided. The policy theory landscape is vast and active, and offers a compelling host of approaches to studying policy problems, proposals, and outcomes. There is no single best theory, though every scholar is likely to be drawn to one or two that fit their skills and interests. More important is to remain methodologically and theoretically pragmatic rather than programmatic. As policy itself evolves, so must the tools that we bring to the study of it. An excellent example of such reactivity is the Narrative Policy Framework covered in some detail in the first essay of this collection, which moves from the axiomatic  stories count in the policy process  to the scientific  how do we count stories in the policy process? But NPF is not the end of policy history, and the policy process theories covered in this final essay are all representative of active scientific communities that investigate public policy. The best evidence that policy theories are scientific is the willingness of the scholars within it to continue to look for better scientific methods to improve our understanding of the many facets of public policy. "],["building-a-question-list-for-american-politics.html", "Chapter 7 Building a Question List for American Politics 7.1 Required Questions 7.2 Short Questions", " Chapter 7 Building a Question List for American Politics In this chapter, I present some of the themes you might encounter across subfields of American Politics and Public Administration, along with potential citation sources to investigate as you prepare. The questions are grouped into potential required questions, and those that I see more often as optional, or shorter essays. I suggest you dont read all these until youve taken some time to read up in other sections. Sometimes seeing this large of a list can be overwhelming! But rest assured, each of the questions has a lot of interplay with at least a few other questions, and so the same pre-written technique I suggest can be used to answer many different questions. 7.1 Required Questions These are the types of questions that generally require the student to demonstrate a broad grasp of the entire subfield, and the main arguments within that field. To some degree, exam graders are often looking for the student to not just cover the biggest controversies and unanswered questions in the field, but to also declare where they stand. For this, I will usually start my outline with a declarative statement, i.e. I say presidents are fundamentally weak. This is definitely a preference and even personality-driven option, however, so use what works best for your voice. These questions usually require 6500 words or more to satisfactorily resolve, because they require writing across multiple sub-sub-fields. In many cases, for example, you would need to cover congressional studies, institutionalism, and the Presidency to address questions of how restrained a US President is. 7.1.1 Presidential Power, Constitutional Theory, Executive Branch Constraints Much has been made over the years of the American Constitutions structure as a mechanism to guard against tyranny. The Constitutions resilience has been touted as an example of excellent institutional design that has made manifest Madisons theory of separating powers and using each to check the other. Imagine that the American people elect a president with little respect for this system and for the specific theory of a restrained presidency. Leaving aside theory, what is the empirical evidence for the ability of the system to resist a president lacking self-restraint? To what extent does the larger Executive Branch restrain the presidents actions? Assess the ability to Congress, the courts, political parties, federalism and other institutions to restrain the Chief Executive. Does Madisons theory hold up to what we know about modern American government? 7.1.2 Political Elites and Public Influence; Public opinion and elites; behavior American politics plays out among two sets of actors: political elites and the public. Thinking about American politics and policymaking as a whole, discuss the relative influence of political elites and the American public. Does the public drive our national politics and policymaking? Or do political elites have most of the power in our political system? Critically evaluate American politics scholarship relevant to these questions. Be sure to identify which authors and the specific literature are most important to our understanding of this dynamic. 7.1.3 Is political science relevant? An irony of modern political discussion is that political scientists rarely appear as experts on American politics in the media, where they are far outnumbered by journalists, professional pundits, and political operatives. Make the case that political science has generated specific insights into American politics that simply cannot be gleaned from close journalistic coverage of current events. What distinguishes political science from popular discourse about American politics and what findings should political scientists emphasize to correct popular misunderstandings about American politics? Using several examples from contemporary politics (possibly including, but not limited to, the current election, Congressional gridlock, recent court cases, trends in policymaking), how does political science provide a distinctive understanding of American politics? 7.1.4 Elitists versus Pluralists The study of American politics has often been marked by disputes over theory or method. For example, the debate over elitist and pluralist explanations of political power in America or the debate over the value of rational choice as a general theoretical approach to the study of American politics. In your response, first, identify an important debate over theory and/or method in at least two different substantive areas of study in American politics (e.g., Congress, the bureaucracy, voting, the courts, or economic policy) and explain what the scholarly debate was about. Second, discuss whether these debates have served to advance or hinder our understanding of politics in these areas of study. 7.1.5 Are academics part of the political elite? It can be argued that American politics plays out among two different classes of actors: political elites and the general public. Thinking about American politics and policymaking as a whole, discuss the relative influence of political elites and the broader American public. Does the public drive our national politics and policymaking? Or do political elites have most of the power in our political system and control both the agenda and much of the decision-making? What larger theories, and which scholars, help us understand the tensions between mass democracy and elite politics, and the paradox of a normative commitment to political equality coexisting with unequal influence of elite, organized, and well-funded groups in modern American politics? 7.1.6 Recent Classics What recent works in the study of American politics already are or are destined to become classics that will be cited by scholars and studied by future generations of graduate students? To answer this question, identify at least five (5) recent scholarly works  books or journal articles published in the last 10 years or so  on different topics within American politics that you believe will be regarded as classic works by future political scientists. For each, explain why the work you have chosen will become a classic by assessing how that work relates to prior research on the topic and advances our understanding of some significant aspect of American politics. 7.1.7 Essential Themes &amp; Controversies Undergraduate students taking American Government will typically use a text covering the Constitution, the branches of government, and political participation. Based on your graduate work, make an argument for the essential themes and controversies that an instructor should communicate to these undergraduates. Cite relevant authors in support of your choices. 7.2 Short Questions These shorter questions can usually be resolved within 4,500 words or so. 7.2.1 Congress 1 What do scholars know about how Congress actually works? Using your knowledge of the scholarly literature on Congress, what pieces of research would you identify as the best for understanding how Congress functions? In your response be sure to delineate the various functions that Congress performs, and identify and briefly describe the various foci of scholars who study how Congress functions. Be sure to cite specific works to support your argument. 7.2.2 Congress 2 What are the most important scholarly studies on Congress? To answer this question, identify at least 5, but no more than 10 books or articles written on some aspect of Congress that you believe are the most important scholarly works in the field. Be sure to explain what these works tell us about Congress and why they are so important to scholars seeking to understand Congress. 7.2.3 Electoral Connection In Federalist 51, James Madison observes that the electoral connection is the publics primary control on government. Thinking broadly about political science scholarship on American political institutions, and focusing on at least two national governmental institutions (e.g., Congress, the Presidency, the bureaucracy, the courts), answer the following: Does the reelection incentive induce our national governmental institutions, and the actors within them, to be responsive to the public and public interests? Does the electoral connection create systematic biases in governmental action? Please provide a critical look at the scholarship underlying your answers. 7.2.4 Electoral Connection 2 In Federalist 51, James Madison observes that the electoral connection is the primary control on government. Does the reelection incentive induce members of Congress to respond to constituents policy preferences? Does the electoral connection create systematic biases in congressional policymaking that undermine Congresss capacities as a legislative institution? 7.2.5 Party politics, polarization, Congress In recent years, party polarization has increased significantly and many commentators have bemoaned this trend. The increase of partisan polarization in congressional roll-call voting has been of particular concern. How does the literature on Congress shed light on the likely effects of such polarization? What do models of congressional leadership tell us about the causes of polarization and its likely consequences? And, with unified government for the first time in a decade, does strong party government yield any benefits? What are its costs? 7.2.6 Political Participation 1 In the November 2016 elections, as in all American elections, we observed dramatically large differences in the levels of participation of different groups of people among the broader American public. What does the political science scholarship tell us about why some people participate in their political system more than others? What does the scholarship tell us about the consequences of such differential participation for American politics and policymaking? Should action be taken to address these differential participation rates? If so, what remedies might help? 7.2.7 Participate Meaningfully? One prerequisite of a truly democratic nation would be that average citizens are able to participate in politics in a meaningful fashion. Based on your knowledge of the research literature on political participation in the United States, how would you assess American democracy? That is, does the research on political participation suggest that all American citizens are able to participate effectively or are there serious problems with the nature of political participation in the U.S.? Be sure to discuss key scholarly works on political participation in your response. 7.2.8 Voter Suppression, Voter Participation, Election Rules and Reform, Electoral Behavior Undergirding much of the discussion of the behavior of the American electorate in the past few decades has been sizeable argumentation over existing election rules and reform. From gerrymandering to nonpartisan primaries, motor voter registration to voter ID laws, what does the political science literature tell us about the links between electoral rules and electoral behavior? Are claims that recent changes in election rules have led to skewed participation or unrepresentative results overblown or under theorized? 7.2.9 What do Americans know about Politics? Survey after survey has shown that Americans are often at a loss to recall basic facts about their government and politics. Less definitively understood is the degree to which this lack of political knowledge matters. Are people able to make reasonable political decisions despite their ignorance? Does the lack of information possessed by most Americans affect our politics? Provide an overview of the scholarly debates that exist regarding these questions and bases on which scholars agree and disagree. Ultimately, should we conclude that a healthy democracy depends on a well-informed electorate, or not? 7.2.10 Voter Knowledge, Voter Choice Surely, one of the prerequisites of a truly democratic polity would be that average citizens know enough about their own policy preferences and the functioning of the political system to be able to participate in politics in a meaningful way. Yet, many studies of American citizens have raised doubts about how much Americans know about politics or even how firmly they hold their own opinions. Based on the scholarly research, what would you conclude about how well the average American is able to participate effectively in our political system? In your response, be sure to discuss specific scholarly works and explain how these works have influenced your conclusions about American citizens. 7.2.11 Voter Choice, Voter Decision Making, Electoral Behavior In November 2016, Americans elected a new president. In your judgment, how well do we as scholars of American politics understand how individuals make voting decisions? What are the major theories used to explain individual vote choice and how well are these theories supported by the empirical evidence? 7.2.12 Why did Trump win? Political scientists and political observers alike were surprised by Trumps political rise and his electoral success in 2016. Scholars first expected that he would lose the nomination contest, and then that he would lose the general election. Looking at the scholarship on political behavior and U.S. elections, explain why political scientists were, for the most part, surprised by Trumps success. What scholarship led us to believe he would fail? At the same time, what scholarship can help explain Trumps rise and his success in 2016? 7.2.13 How Democratic are We? Public interests, Public will, Theories of Democracy Truly democratic political institutions are designed such that they reflect the public interest, and the diversity of public perspectives and interests, in their actions. How democratic are American political institutions? Focusing on TWO specific institutions or institutional structures (e.g., Congress, the Presidency, the Bureaucracy, the Courts, Federalism, etc.) explain what political science scholarship tell us about how well each meets a democratic ideal, and how and in what ways each falls short. Ultimately, should we describe our institutions as sufficiently democratic or not? 7.2.14 Bureaucratic Responsiveness While the courts are often described as reactive, other institutions, such as Congress and the bureaucracy are assumed to be more proactive. Given the large and constantly growing literature on agenda-setting in the policy process as well as the various frameworks explaining interest group activity and Congressional action, how true is it that the bureaucracy in particular can be seen as truly proactive? Do bureaucrats shape their policy domains or do they primarily attempt to balance and accommodate outside pressures? 7.2.15 Bureaucracy, Administrative State Scholars of American politics often neglect the single largest element in U.S. government, the bureaucracy, leaving it to scholars of public administration as if less important. However, there have been some Americanists who have taken an active interest in explaining how the need to control and even motivate the enormous federal bureaucracy has shaped such constitutional branches as Congress and the Presidency. Explain how the development of large and complex federal bureaucracy in the post-World War II (and perhaps especially post Great Society) era has led to new understandings of Congress and the Presidency. How has the regulatory welfare state changed the nature of political leadership, the different roles of legislators and chief executives, and the relationship between the constitutional branches? 7.2.16 Bureaucratic Autonomy Perhaps unsurprisingly, the Trump Administration has already prompted great attention to the scope of bureaucratic autonomy and discretion in policy making and implementation. What does the scholarly literature tell us about the nature, sources, and degree of bureaucratic autonomy in the policy process? Will this be an Achilles heel for the Trump Administration or a source of strength? 7.2.17 Approaches to Presidential Scholarship There are numerous ways to study the presidency. For example, some scholars study institutional powers of the executive, while others focus on the characteristics of the particular individuals who have been elected president. Based upon your knowledge of the scholarly literature on the presidency, what approach (or set of approaches) do you regard as the most fruitful for explaining the nature of the American presidency? 7.2.18 Three Major Trends in Presidential Scholarship The study of the presidency has changed considerably over the past fifty years. Identify three major trends in the study of the presidency since the 1950s. Cite at least one major book or article to illustrate the unique approaches embraced during each of these three trends. Evaluate the strengths and weaknesses of each trend. 7.2.19 Imperial Presidency &amp; Congress In 1885, Woodrow Wilson published Congressional Government, his description of a contemporary American politics dominated by Congress. In 1973, Arthur Schlesinger published The Imperial Presidency, in which he described the Presidency as dominant. Today, neither branch seems particularly capable of making the other yield to its own agenda. Drawing on the literature on both the Congress and the Presidency, explain how each branch has developed advantages over the other as well as the restraints that have developed over the years that limit each branch. A proper answer will include attention to both external and internal mechanisms that both enable and restrain each branches powers. 7.2.20 Power of the Presidency: How powerful is the American presidency? Some contend that the office is inherently weak and presidential power significantly limited. Others contend the office is incredibly strong, possessing institutional powers to transform American politics and policy. First, provide a thorough overview of scholarship on the power of the American presidency, including an assessment of the empirical evidence in support of different perspectives. Second, in your judgment, is the presidency a very powerful office, or is the office inherently weak, and why? 7.2.21 Presidential Power: Unilateral action in policymaking President Obama has received both praise from his allies and criticism from his opponents for his use of unilateral action in policymaking. What does the political science literature tell us about presidential power and unilateral action? Are Obamas actions part of the tradition of presidential politics or a significant shift? What does Obamas use of unilateral action in the White House tell us about the power of the modern presidency? 7.2.22 Pluralism, interest groups, and policy process In Federalist 10, James Madison famously argued that pluralism could save America from factionalism. Yet, today it seems as if the policy process is both typified by pluralism and sometimes dominated by factionalism. Drawing on the scholarship on both interest groups and the policy process, what conclusions can be drawn regarding how pluralism influences the policy process? Make sure to review both the history of thinking about interest groups and how several different models of the policy process understand the role of interest groups. 7.2.23 Racial and ethnic progress in American public policy Throughout U.S. history the dominant group (i.e. WASPs during the majority of U.S. history) has tried to adopt public policies to institutionalize racial or ethnic inequality to gain political advantages over minority groups. Examples of such institutional domination include slavery imposed on African Americans, the forced relocation of American Indians, the exclusionary immigration laws such as the 1882 Chines Exclusion Act, and the 1924 National Origin Act against Southern and Eastern Europeans and Jews. But the dominant WASPs also sometimes passed legislations in an attempt to protect the rights of the minority groups. Examples of such equality-oriented legislation includes the 13th  15th Constitutional Amendments, the Civil Rights Act of 1964 and Voting Rights Acts of 1965, which were all passed by majority-white Congresses. Discuss how and why these policy changes took place in the U.S. history. Is there a trend toward racial and ethnic progress in terms of American public policies over time? Identify the most important political science literature in this area. 7.2.24 Rational and Irrational Voting: From Aristotle of classic Greece to John Rawls of modern America, countless first-rate scholars have put their keen eyes on how humans behave in the political arenas. Still there are too many questions unanswered. Based on your understanding of the American politics, do humans act rationally when it comes to the issues of voting for a party? If so, why do they sometimes make decisions that seem utterly irrational in politics? Are they attracted to certain candidates special qualities that are difficult to quantify in rational terms? Are voters for the most part calculating for their own economic gains when they decide politically? 7.2.25 Institutionalism The study of institutions as institutions has had a significant revival in the last 30 years as new institutionalisms have emerged. Identify and describe these new forms of institutionalism and explain how they have changed the study of American politics? How have we come to recognize that institutions matter? How have these new versions of institutionalism added value to political science? 7.2.26 Biology, political behavior, socialization, race? Recently there has been a renewed interest in the relationship between biology and political behavior. Based on the new findings reported in the political science journals and scholarly books, does biology count at all when it comes to the decision of voting, participation in mass movements, or simply forming a political opinion? Can citizens political behaviors be inherited from their parents? Or are they actually a product of their own socialization process? Does race matter? Why or why not? 7.2.27 Major Approaches to Policy Analysis Discuss approaches taken to public policy analysis. What are the major theoretical approaches? What are the forms of evidence used? How should public policy analysis be conducted? For whom? 7.2.28 Two Policy Frameworks A number of frameworks have been used to analyze the process and outcomes of American public policy. Among these frameworks are elitism, pluralism, neopluralism, incrementalism, feminism, subgovernments, policy process models, issue networks, advocacy coalitions, and others. Identify two frameworks that you regard as especially useful for the study of public policy. For each, explain how the framework approaches the study of public policy and evaluate its strengths and weaknesses as tool for understanding the process and substance of public policy. 7.2.29 Three frameworks/theories/models of policy-making &amp; collective choice Scholars make use of frameworks, theories, and models in their attempts to explain the politics of policy-making processes and the collective authoritative public choices that come from them. Distinguish among these three approaches to empirical inquiry, and discuss how they are interrelated, if at all; then describe the extent to which researchers have improved our understanding by applying them to specific substantive areas of public policy. 7.2.30 One substantive area of public policy Choose one substantive area of American public policy, e.g., education, health care, criminal justice, or economic policy. How have scholars attempted to explain public policy in this area? Is there a consensus among scholars about how policy is made in this area or are there competing theories that seek to explain how policy is made and why we have the substantive outcomes we do in this policy area? Based on your knowledge of the scholarly research in this policy area, how complete is our understanding and what additional information should scholars seek to learn? 7.2.31 Lecturing on public policy Imagine that you have a representative sample of Americans captive for a single lecture on public policy. What are they least likely to know about public policy making and implementation? What would be most important to communicate to them? Choose two different policy areas in your answer and support your decisions about what to emphasize with references to the public policy literature. 7.2.32 Responsiveness of institutions, public - collective will (can it even be known or assumed): Political scholars are often concerned with the democratic responsiveness of political institutions; in other words, how well government reflects the will of the people. How representative are our national American political institutions and our national government? Focusing on two specific institutions (e.g., Congress, the Presidency, the Courts, the political parties, the bureaucracy), provide an overview of scholarly evidence suggesting our national institutions respond well to the public will, as well as scholarly evidence that they are less responsive. On the whole, would you say American government is responsive to the people, or are there forces and structures that undermine this democratic responsiveness? 7.2.33 Policy process field making progress? Critics argue that the public policy field has made little theoretical progress, finding itself mired in description and journalistic analysis. Critique this assessment, evaluating the extent to which the major theoretical approaches to the study of public policy meet the standards for theory. In doing so, identify the competing theoretical frameworks and their chief proponents, discuss their contributions and limitations, and suggest what is needed for them to make the transition from framework to theory. 7.2.34 Political Parties and American Politics  Institutions &amp; Behavior E.E. Schattschneider (1942) famously suggested that modern democracy is unthinkable save in terms of political parties, yet there is scholarly debate about the role parties play in American politics. First, provide an overview of what we know about political parties and American politics  both its institutions and the behavior of the public. Is American democracy unthinkable without political parties? 7.2.35 What do Americans know about politics? Survey after survey has shown that Americans are often at a loss to recall basic facts about their government and politics. Less definitely understood is the degree to which this lack of political knowledge matters. Are people able to make reasonable political decision despite their ignorance? Does the lack of information possessed by most Americans affect our politics? What scholarly debates exist regarding these questions and on what bases do scholars disagree? In your response, be sure to discuss specific scholarly works and explain whether the American public is capable of true self-governance? 7.2.36 How do Americans decide how to vote? How do American voters decide how to vote? This question has been central to the study of political behavior in the U.S. for at least 50 years. How would you assess what political scientists know about vote choice? Discuss the various theoretical explanation that have been offered as well as the evidence supporting these explanations. 7.2.37 Political Campaigns Political campaigns are exciting, fascinating events that draw a significant amount of media and public interest. Yet, to what degree can we say that campaigns matter? Surveying the existing scholarship on public opinions, voting campaigns, and elections, what campaign effects have political scientists identified? To what degree can we say that campaigns influence votes and election outcomes? Ultimately, can we conclude that campaigns are a fundamentally important part of our democracy, or are they simply an intriguing sideshow? 7.2.38 Link between Public Opinion and Public Policy How important are the attitudes and policy preferences of American citizens in determining what American governments at the state or national level actually do? How have political scientists studied the linkage between public opinion and public policy and what have they found? How well do political scientists understand the effect that public opinion has on public policy? 7.2.39 Judicial Decision-Making I Compare and contrast the major theoretical approaches to understanding judicial decision-making, citing the relevant scholarly studies. Make an argument for which approach you believe offers the best explanation of how judges actually make decisions. 7.2.40 Judicial Decision Making II Compare and contract the major theoretical approaches to understanding judicial decision-making, citing relevant authors. Make an argument for which approach you believe offers the best explanation of how judges make decisions and support your argument with concrete examples from any court setting with which you are familiar. "],["summary.html", "Chapter 8 Final Words", " Chapter 8 Final Words I wish nothing more than for these examples to have helped settle your mind a bit before you go through what every Ph.D. holder has gone through before you. "],["strategies.html", "Chapter 9 Strategies for Writing Exams", " Chapter 9 Strategies for Writing Exams To be continued "],["references.html", "References", " References Adams, Ian T. 2019. Public Administration Review 0 (0). https://doi.org/10.1111/puar.13096. Adams, Ian, and Sharon Mastracci. 2017. Visibility Is a Trap: The Ethics of Police Body-Worn Cameras and Control. Administrative Theory &amp; Praxis 39 (4): 31328. . 2019. Police Body-Worn Cameras: Development of the Perceived Intensity of Monitoring Scale. Criminal Justice Review 44 (3): 386405. https://doi.org/10.1177/0734016819846219. . 2019. Police Body-Worn Cameras: Development of the Perceived Intensity of Monitoring Scale. Criminal Justice Review 44 (3): 386405. https://doi.org/10.1177/0734016819846219. Agarwal, P. K. 2018. Public Administration Challenges in the World of AI and Bots. Public Administration Review, October. Aldrich, John H. 1976. Rational Choice and Turnout. American Journal of Political Science 37: 24678. Allaire, JJ, Yihui Xie, Jonathan McPherson, Javier Luraschi, Kevin Ushey, Aron Atkins, Hadley Wickham, Joe Cheng, Winston Chang, and Richard Iannone. 2020. Rmarkdown: Dynamic Documents for r. https://github.com/rstudio/rmarkdown. Ammons, David N., and William C. Rivenbark. 2008. Factors Influencing the Use of Performance Data to Improve Municipal Services: Evidence from the North Carolina Benchmarking Project. Public Administration Review 68 (2): 30418. Andersen, Margaret L. 2001. Restructuring for Whom? Race, Class, Gender, and the Ideology of Invisibility. Sociological Forum 16 (2): 181201. https://doi.org/10.1023/A:1011003316831. . 2001. Restructuring for Whom? Race, Class, Gender, and the Ideology of Invisibility. Sociological Forum 16 (2): 181201. https://doi.org/10.1023/A:1011003316831. Appleby, Paul H. 1945. Government Is Different. New York. Ariel, Barak, William A. Farrar, and Alex Sutherland. 2015. The Effect of Police Body-Worn Cameras on Use of Force and Citizens Complaints Against the Police: A Randomized Controlled Trial. Journal of Quantitative Criminology 31 (3): 50935. Baldassarri, Delia, and Andrew Gelman. 2008. Partisans Without Constraint: Political Polarization and Trends in American Public Opinion. American Journal of Sociology 114 (2): 40846. https://doi.org/10.1086/590649. Balfour, Danny L., Guy B. Adams, and Guy B. Adams. 2014. Unmasking Administrative Evil. Routledge. https://www.taylorfrancis.com/books/9781315716640. Barnard, Chester I. 1938. Informal Organizations and Their Relation to Formal Organizations. Classics of Public Administration, 9599. Bartels, Larry M. 2010. Unequal Democracy: The Political Economy of the New Gilded Age. Princeton, NJ: Princeton University Press. Barzelay, Michael. 1992. Breaking Through Bureaucracy: A New Vision for Managing in Government. Univ of California Press. . 2005. Origins of the New Public Management: An International View from Public Administration/Political Science. In New Public Management, 2745. Routledge. Battaglio, R. Paul, and Jeremy L. Hall. 2018. Trinity Is Still My Name: Renewed Appreciation for Triangulation and Methodological Diversity in Public Administration. Public Administration Review 78 (6): 82527. https://doi.org/10.1111/puar.13010. Baum, Matthew A. 2002. Sex, Lies, and War: How Soft News Brings Foreign Policy to the Inattentive Public. The American Political Science Review 96 (1): 91109. Baumgartner, Frank R., Christian Breunig, Christoffer Green-Pedersen, Bryan D. Jones, Peter B. Mortensen, Michiel Nuytemans, and Stefaan Walgrave. 2009. Punctuated Equilibrium in Comparative Perspective. American Journal of Political Science 53 (3): 60320. . 2009. Punctuated Equilibrium in Comparative Perspective. American Journal of Political Science 53 (3): 60320. Baumgartner, Frank R., and Bryan D. Jones. 2009. Agendas and Instability in American Politics. Chicago: University of Chicago Press. . 2009. Agendas and Instability in American Politics. Chicago: University of Chicago Press. Billings, David, and Lila Cabbil. 2011. Food Justice: Whats Race Got to Do with It? Race/Ethnicity: Multidisciplinary Global Contexts 5 (1): 10312. https://doi.org/10.2979/racethmulglocon.5.1.103. . 2011. Food Justice: Whats Race Got to Do with It? Race/Ethnicity: Multidisciplinary Global Contexts 5 (1): 10312. https://doi.org/10.2979/racethmulglocon.5.1.103. Bimber, Bruce. 1998. The Internet and Political Transformation: Populism, Community, and Accelerated Pluralism. Polity 31 (1): 13360. Boker, Steven M., and Jean-Philippe Laurenceau. 2006. Dynamical Systems Modeling: An Application to the Regulation of Intimacy and Disclosure in Marriage. Models for Intensive Longitudinal Data 63: 195218. Bolsen, Toby, James N. Druckman, and Fay Lomax Cook. 2014. The Influence of Partisan Motivated Reasoning on Public Opinion. Political Behavior 36 (2): 23562. Brewer, Gene A., and Sally Coleman Selden. 1998. Whistle Blowers in the Federal Civil Service: New Evidence of the Public Service Ethic. Journal of Public Administration Research and Theory 8 (3): 41340. Cairney, Paul, and Michael D. Jones. 2016. Kingdons Multiple Streams Approach: What Is the Empirical Impact of This Universal Theory? Policy Studies Journal 44 (1): 3758. https://doi.org/10.1111/psj.12111. . 2016. Kingdons Multiple Streams Approach: What Is the Empirical Impact of This Universal Theory? Policy Studies Journal 44 (1): 3758. https://doi.org/10.1111/psj.12111. Cairney, Paul, and Nikolaos Zahariadis. 2016. Multiple Streams Approach: A Flexible Metaphor Presents an Opportunity to Operationalize Agenda-Setting Processes. Handbook of Public Policy Agenda Setting, 87105. . 2016. Multiple Streams Approach: A Flexible Metaphor Presents an Opportunity to Operationalize Agenda-Setting Processes. Handbook of Public Policy Agenda Setting, 87105. Caldero, Michael A., Jeffrey D. Dailey, and Brian L. Withrow. 2018. Police Ethics: The Corruption of Noble Cause. Routledge. Campbell, Angus, Philip E. Converse, Warren E. Miller, and Donald E. Stokes. 1960. The American Voter. Chicago: University of Chicago Press. Chadwick, Andrew, and Philip N. Howard. 2009. Routledge Handbook of Internet Politics. In Technological Change and the Shifting Nature of Political Organization, edited by Andrew Bimber CynthiaFlanagin, 7285. New York: Routledge. Chernow, Ron. 2005. Alexander Hamilton. Penguin. Chong, Dennis, and James N. Druckman. 2007a. A Theory of Framing and Opinion Formation in Competitive Elite Environments. Journal of Communication 57 (1): 99118. . 2007b. Framing Public Opinion in Competitive Democracies. American Political Science Review 101 (4): 63755. . 2007b. Framing Public Opinion in Competitive Democracies. American Political Science Review 101 (4): 63755. . 2007b. Framing Public Opinion in Competitive Democracies. American Political Science Review 101 (4): 63755. Christodoulou, Callum, Helen Paterson, and Richard Kemp. 2019. Body-Worn Cameras: Evidence-Base and Implications. Current Issues in Criminal Justice, 112. Clinton, Hillary. 2015. Criminal Justice Reform. The Office of Hillary Rodham Clinton. https://www.hillaryclinton.com/issues/criminal-justice-reform/. Coglianese, Cary, and David Lehr. 2016. Regulating by Robot: Administrative Decision Making in the Machine-Learning Era. Geo. LJ 105: 1147. . 2018. Transparency and Algorithmic Governance. Administrative Law Review 71: 1. Cohen, Michael D., James G. March, and Johan P. Olsen. 1972. A Garbage Can Model of Organizational Choice. Administrative Science Quarterly, 125. . 1972. A Garbage Can Model of Organizational Choice. Administrative Science Quarterly, 125. Converse, Philip, ed. 1964. Ideology and Discontent. In The Nature of Belief Systems in Mass Publics, 20661. New York: Free Press. Cook, Scott A., and William Earle Klay. 2015. George Washingtons Precedents: The Institutional Legacy of the American Republics Founding Public Administrator. Administration &amp; Society 47 (1): 7595. Coppock, Alexander. 2018. Generalizing from Survey Experiments Conducted on Mechanical Turk: A Replication Approach. Political Science Research and Methods, March, 116. https://doi.org/10.1017/psrm.2018.10. . 2018. Generalizing from Survey Experiments Conducted on Mechanical Turk: A Replication Approach. Political Science Research and Methods, March, 116. https://doi.org/10.1017/psrm.2018.10. Coppock, Alexander Edwards. 2016. Positive, Small, Homogeneous, and Durable: Political Persuasion in Response to Information. PhD thesis, Columbia University. https://doi.org/10.7916/D8J966CS. Correll, Joshua, Sean M. Hudson, Steffanie Guillermo, and Debbie S. Ma. 2014. The Police Officers Dilemma: A Decade of Research on Racial Bias in the Decision to Shoot. Social and Personality Psychology Compass 8 (5): 20113. Cowper, Thomas J. 2000. The Myth of the Military Model of Leadership in Law Enforcement. Police Quarterly 3 (3): 22846. Dahl, Robert A. 1961. Who Governs? Democracy and Power in an American City. New Haven, CT: Yale University Press. Dahl, Robert Alan. 1982. Dilemmas of Pluralist Democracy: Autonomy Vs. Control. Vol. 31. Yale University Press. . 1982. Dilemmas of Pluralist Democracy: Autonomy Vs. Control. Vol. 31. Yale University Press. Deboeck, Pascal R., Jody Nicholson, Chrystyna Kouros, Todd D. Little, and Judy Garber. 2015. Integrating Developmental Theory and Methodology: Using Derivatives to Articulate Change Theories, Models, and Inferences. Applied Developmental Science 19 (4): 21731. https://doi.org/10.1080/10888691.2015.1021924. Delli Carpini, Michael X., and Scott Keeter. 1996. What Americans Know about Politics and Why It Matters. New Haven, CT: Yale University Press. Democrats, Senate. 2019. Senate Majority Leader Mitch McConnell Has Never Taken Seriously the Threat Russia Poses to Our Elections. Senate Democrats. https://www.democrats.senate.gov/newsroom/press-releases/senate-majority-leader-mitch-mcconnell-has-never-taken-seriously-the-threat-russia-poses-to-our-elections. Dewey, John. 1915. German Philosophy and Politics. H. Holt. Dickson, Marcus W., Renee S. BeShears, and Vipin Gupta. 2004. The Impact of Societal Culture and Industry on Organizational Culture: Theoretical Explanations. Culture, Leadership, and Organizations: The GLOBE Study of 62: 493. Dilulio Jr, John D. 1994. Principled Agents: The Cultural Bases of Behavior in a Federal Government Bureaucracy. Journal of Public Administration Research and Theory 4 (3): 277318. Downs, Anthony. 1957. An Economic Theory of Democracy. New York: Harper. . 1967. The Life Cycle of Bureaus. Inside Bureaucracy 296: 309. Edwards, Julia. 2015. Reuters. https://www.reuters.com/article/us-usa-police-cameras-idUSKBN0NM3PL20150501. Edy, Jill, Scott Althaus, and Patricia Phalen. 2005. Using News Abstracts to Represent News Agendas. Journalism &amp; Mass Communication Quarterly 82 (2): 43446. Elazar, Daniel J. 1984. American Federalism: A View from the States. New York: HarperCollins. Elliott, Odus V., and Lester M. Salamon. 2002. The Tools of Government: A Guide to the New Governance. Oxford University Press. Emmerich, Herbert. 1971. Federal Organization and Administration Management. Engel, Robin Shepard, and Robert E. Worden. 2003. POLICE OFFICERSATTITUDES, BEHAVIOR, AND SUPERVISORY INFLUENCES: AN ANALYSIS OF PROBLEM SOLVING. Criminology 41 (1): 13166. Epp, Charles R., Steven Maynard-Moody, and Donald P. Haider-Markel. 2014. Pulled over: How Police Stops Define Race and Citizenship. Chicago, IL: University of Chicago Press. Erikson, Robert S., Gerald C. Wright, and John P. McIver. 1989. Political Parties, Public Opinion, and State Policy in the United States. American Political Science Review 83 (3): 72950. https://doi.org/10.2307/1962058. Feldheim, Mary Ann. 2003. Mary Parker Follett Lost and Found-Again, and Again, and Again. International Journal of Organization Theory &amp; Behavior 7 (3): 34162. Feldman, Stanley. 1988. Structure and Consistency in Public Opinion: The Role of Core Beliefs and Values. American Journal of Political Science 32 (2): 41640. https://doi.org/10.2307/2111130. Ferguson, Andrew Guthrie. 2017. The Rise of Big Data Policing: Surveillance, Race, and the Future of Law Enforcement. NYU Press. Finer, Herman. 1941. Administrative Responsibility in Democratic Government. Classics of Administrative Ethics, 526. Follett, Mary Parker. 2016. The Giving of Orders. In Classics of Public Administration, edited by Jay M. Shafritz and Albert C. Hyde. Nelson Education. Force, Presidents Task. 2015. Presidents Task Force on 21st Century Policing Implementation Guide: Moving from Recommendations to Action. Office of Community Oriented Policing Services Washington, DC. Foucault, Michel. 1991. Politics and the Study of Discourse. The Foucault Effect: Studies in Governmentality 53: 72. . 1991. Politics and the Study of Discourse. The Foucault Effect: Studies in Governmentality 53: 72. . 2005. The Discourse on Language. Truth: Engagements Across Philosophical Traditions, 31535. . 2005. The Discourse on Language. Truth: Engagements Across Philosophical Traditions, 31535. Frederickson, H. George. 1971. Toward a New Public Administration. Toward a New Public Administration: The Minnowbrook Perspective, 30931. Frederickson, H. George, Kevin B. Smith, Christopher Larimer, and Michael J. Licari. 2018. The Public Administration Theory Primer. Routledge. Fredriksson, Cecilia, Farooq Mubarak, Marja Tuohimaa, and Ming Zhan. 2017. Big Data in the Public Sector: A Systematic Literature Review. Scandinavian Journal of Public Administration 21 (3): 3962. Friedler, Sorelle A., Carlos Scheidegger, Suresh Venkatasubramanian, Sonam Choudhary, Evan P. Hamilton, and Derek Roth. 2019. A Comparative Study of Fairness-Enhancing Interventions in Machine Learning. In Proceedings of the Conference on Fairness, Accountability, and Transparency, 32938. FAT* 19. New York, NY, USA: ACM. https://doi.org/10.1145/3287560.3287589. Friedrich, Carl J. 1940. Public Policy and the Nature of Administrative Responsibility. Public, 324. Funk, McKenzie. 2016. Should We See Everything a Cop Sees? New York Times, October. https://www.nytimes.com/2016/10/23/magazine/police-body-cameras.html. Gamson, William, and Andre Modigliani, eds. 1987. Research in Political Sociology. In The Changing Culture of Affirmative Action, 3:13777. Greenwich, CT: JAI Press. . 1994. The Changing Culture of Affirmative Action. Equal Employment Opportunity: Labor Market Discrimination and Public Policy, 37394. Gersick, Connie JG. 1991. Revolutionary Change Theories: A Multilevel Exploration of the Punctuated Equilibrium Paradigm. Academy of Management Review 16 (1): 1036. . 1991. Revolutionary Change Theories: A Multilevel Exploration of the Punctuated Equilibrium Paradigm. Academy of Management Review 16 (1): 1036. Gokaslan, Aaron, and Vanya Cohen. 2019. OpenGPT-2: We Replicated GPT-2 Because You Can Too. Medium, August. https://medium.com/@vanya_cohen/opengpt-2-we-replicated-gpt-2-because-you-can-too-45e34e6d36dc. Goodnow, Frank J. 2017. Politics and Administration: A Study in Government. Routledge. Goss, Kristin A. 2010. Disarmed: The Missing Movement for Gun Control in America. Vol. 120. Princeton University Press. Gould, Stephen Jay, and Niles Eldredge. 1977. Punctuated Equilibria: The Tempo and Mode of Evolution Reconsidered. Paleobiology 3 (2): 11551. . 1977. Punctuated Equilibria: The Tempo and Mode of Evolution Reconsidered. Paleobiology 3 (2): 11551. Green, Donald, Bradley Palmquist, and Eric Schickler. 2002. Partisan Hearts and Minds: Political Parties and the Social Identities of Voters. New Haven, CT: Yale University Press. Green, Donald, and Ian Shapiro. 1996. Pathologies of Rational Choice Theory: A Critique of Applications in Political Science. Yale University Press. . 1996. Pathologies of Rational Choice Theory: A Critique of Applications in Political Science. Yale University Press. Green, Richard T. 2019. Alexander Hamiltons Public Administration. University of Alabama Press. Greenstein, Fred I. 1960. The Benevolent Leader: Childrens Images of Political Authority. The American Political Science Review 54 (4): 93443. https://doi.org/10.2307/1952644. Group, Lafayette. 2015. Major Cities Chiefs and Major County Sheriffs Survey of Technology NeedsBody Worn Cameras. https://assets.bwbx.io/documents/users/iqjWHBFdfxIU/rvnT.EAJQwK4/v0. Gulick, Luther. 1937. Notes on the Theory of Organization. Classics of Organization Theory 3 (1937): 8795. Guy, Mary E. 2003. Ties That Bind: The Link Between Public Administration and Political Science. The Journal of Politics 65 (3): 64155. https://doi.org/10.1111/1468-2508.00205. Haas, Peter M. 1989. Do Regimes Matter? Epistemic Communities and Mediterranean Pollution Control. International Organization 43 (3): 377403. . 1989. Do Regimes Matter? Epistemic Communities and Mediterranean Pollution Control. International Organization 43 (3): 377403. Haller, Max, Roger Jowell, and Tom Smith. 2009. The International Social Survey Programme, 19842009: Charting the Globe. New York: Routledge. Hamilton, Alexander, James Madison, and John Jay. 2009. The Federalist Papers. New Haven, CT: Yale University Press. Hammond, T. H., and C. W. Bonneau. 2009. Strategic Behavior and Policy Choice in the u.s. Supreme Court. Palo Alto, CA: Stanford University Press. Harmon, Michael M. 1989. The Simon/Waldo Debate: A Review and Update. Public Administration Quarterly 12 (4): 43751. Hood, Christopher. 1991. A Public Management for All Seasons? Public Administration 69 (1): 319. Howlett, Michael, Allan McConnell, and Anthony Perl. 2017. Moving Policy Theory Forward: Connecting Multiple Stream and Advocacy Coalition Frameworks to Policy Cycle Models of Analysis. Australian Journal of Public Administration 76 (1): 6579. . 2017. Moving Policy Theory Forward: Connecting Multiple Stream and Advocacy Coalition Frameworks to Policy Cycle Models of Analysis. Australian Journal of Public Administration 76 (1): 6579. Huber, John D., and Charles R. Shipan. 2002. Deliberate Discretion?: The Institutional Foundations of Bureaucratic Autonomy. Cambridge University Press. Inglehart, Ronald. 1990. Culture Shift in Advanced Industrial Society. Princeton, NJ: Princeton University Press. Inglehart, Ronald, and Paul R. Abramson. 1994. Economic Security and Value Change. The American Political Science Review 88 (2): 33654. https://doi.org/10.2307/2944708. Inglehart, Ronald, and Pippa Norris. 2017. Trump and the Populist Authoritarian Parties: The Silent Revolution in Reverse. Perspectives on Politics 15 (2): 44354. https://doi.org/10.1017/S1537592717000111. Intelligence, Permanent Select Committee on. 2019. Exposing Russias Effort to Sow Discord Online: The Internet Research Agency and Advertisements Permanent Select Committee on Intelligence. US House of Representatives. https://intelligence.house.gov/social-media-content/. Iyengar, Shanto, Yphtach Lelkes, Matthew Levendusky, Neil Malhotra, and Sean J. Westwood. 2019. The Origins and Consequences of Affective Polarization in the United States. Annual Review of Political Science 22 (1): 12946. https://doi.org/10.1146/annurev-polisci-051117-073034. Jacobs, Ben. 2015. Donald Trump Tells the Guardian Police Body Cameras Need Federal Funding. The Guardian, October. https://www.theguardian.com/us-news/2015/oct/13/donald-trump-police-body-cameras-federal-funding. Jenkins-Smith, Hank, Carol L. Silva, Kuhika Gupta, and Joseph T. Ripberger. 2014. Belief System Continuity and Change in Policy Advocacy Coalitions: Using Cultural Theory to Specify Belief Systems, Coalitions, and Sources of Change. Policy Studies Journal 42 (4): 484508. Jennings, M. Kent, and Richard G. Niemi. 1968. The Transmission of Political Values from Parent to Child. The American Political Science Review 62 (1): 16984. https://doi.org/10.2307/1953332. Jones, Bryan D. 2002. Bounded Rationality and Public Policy: Herbert a. Simon and the Decisional Foundation of Collective Choice. Policy Sciences 35 (3): 26984. https://doi.org/10.1023/A:1021341309418. . 2002. Bounded Rationality and Public Policy: Herbert a. Simon and the Decisional Foundation of Collective Choice. Policy Sciences 35 (3): 26984. https://doi.org/10.1023/A:1021341309418. Jones, Michael D. 2018. Advancing the Narrative Policy Framework? The Musings of a Potentially Unreliable Narrator. Policy Studies Journal 46 (4): 72446. . 2018. Advancing the Narrative Policy Framework? The Musings of a Potentially Unreliable Narrator. Policy Studies Journal 46 (4): 72446. Jones, Michael D., and Mark K. McBeth. 2010. A Narrative Policy Framework: Clear Enough to Be Wrong? Policy Studies Journal 38 (2): 32953. . 2010. A Narrative Policy Framework: Clear Enough to Be Wrong? Policy Studies Journal 38 (2): 32953. Jordan, A. Grant. 1981. Iron Triangles, Woolly Corporatism and Elastic Nets: Images of the Policy Process. Journal of Public Policy 1 (1): 95123. . 1981. Iron Triangles, Woolly Corporatism and Elastic Nets: Images of the Policy Process. Journal of Public Policy 1 (1): 95123. Jordan, Sara R. 2014. Beneficence and the Expert Bureaucracy: Ethics for the Future of Big Data Governance. Public Integrity 16 (4): 37594. Joseph, Matthew, Michael Kearns, Jamie H. Morgenstern, and Aaron Roth. 2016. Fairness in Learning: Classic and Contextual Bandits. In Advances in Neural Information Processing Systems, 32533. Kahneman, D., and T. Tversky. 1984. Choices, Values, and Frames. American Psychologist 39: 34150. Kahneman, Daniel. 2003. Maps of Bounded Rationality: Psychology for Behavioral Economics. The American Economic Review 93 (5): 144975. Karanasiou, Argyro, and Dimitris Pinotsis. 2017. Towards a Legal Definition of Machine Intelligence: The Argument for Artificial Personhood in the Age of Deep Learning. In Proceedings of the 16th Edition of the International Conference on Articial Intelligence and Law, 11928. ACM. Katz, Charles M., David E. Choate, Justin R. Ready, and Lidia NuÃ±o. 2014. Evaluating the Impact of Officer Worn Body Cameras in the Phoenix Police Department. Phoenix, AZ: Center for Violence Prevention &amp; Community Safety, Arizona State University. Katz, Daniel, and Robert L. Kahn. 1978. Organizations and the System Concept. Classics of Organization Theory, 16172. Kaufman, Herbert. 1969. Administrative Decentralization and Political Power. Public Administration Review 29 (1): 315. Keohane, Robert O. 2009. Political Science as a Vocation. PS: Political Science &amp; Politics 42 (2): 35963. https://doi.org/10.1017/S1049096509090489. Kerrison, Erin M., Jennifer Cobbina, and Kimberly Bender. 2018. Stop-Gaps, Lip Service, and the Perceived Futility of Body-Worn Police Officer Cameras in Baltimore City. Journal of Ethnic &amp; Cultural Diversity in Social Work, 118. Kettl, Donald F. 2015. The Transformation of Governance: Public Administration for the Twenty-First Century. JHU Press. Key, V. O. 1961. Public Opinion and American Democracy. New York: Alfred Knopf. . 1963. American State Politics: An Introduction. Knopf. Kingdon, John W. 1995. Agendas, Alternatives, and Public Policies. New York: New York: Harper Collins. . 1995. Agendas, Alternatives, and Public Policies. New York: New York: Harper Collins. Kirkpatrick, Kellee J., and James W. Stoutenborough. 2018. Strategy, Narratives, and Reading the Public: Developing a Micro-Level Theory of Political Strategies Within the Narrative Policy Framework. Policy Studies Journal 46 (4): 94977. Kline, Rex B. 2015. Principles and Practice of Structural Equation Modeling. New York City, NY: Guilford publications. Kreps, Sarah, and Miles McCain. 2019. Not Your Fathers Bots, August. https://www.foreignaffairs.com/articles/2019-08-02/not-your-fathers-bots. Kuhn, Thomas S. 1970. Logic of Discovery or Psychology. In Criticism and the Growth of Knowledge: Volume 4: Proceedings of the International Colloquium in the Philosophy of Science, London, 1965, 4:1. Cambridge University Press. . 1974. Second Thoughts on Paradigms. The Structure of Scientific Theories 2: 45982. Lake, David A. 2011. Why Isms Are Evil: Theory, Epistemology, and Academic Sects as Impediments to Understanding and Progress. International Studies Quarterly 55 (2): 46580. Larsen, Erik Gahner. 2018. Policy Feedback Effects on Mass Publics: A Quantitative Review. Policy Studies Journal. . 2018. Policy Feedback Effects on Mass Publics: A Quantitative Review. Policy Studies Journal. Lasswell, Harold. 1936. Politics: Who Gets What, When, How. New York: McGraw-Hill. Lau, Richard, and David Redlawsk. 2006. How Voters Decide: Information Processing During Election Campaigns. New York: Cambridge University Press. Laughland, Oliver, and Lauren Gambino. 2015. Hillary Clinton Meets with Prominent Leaders of New Civil Rights Movement. The Guardian, October. https://www.theguardian.com/us-news/2015/oct/09/hillary-clinton-meets-civil-rights-movement-leaders. Lecheler, S., and C. H. de Vreese. 2012. News Framing and Public Opinion: A Mediation Analysis of Framing Effects on Political Attitudes. Journalism &amp; Mass Communication Quarterly 89 (2): 185204. Lee, Frances E. 2009. Beyond Ideology: Politics, Principles, and Partisanship in the u.s. Senate. Chicago: University of Chicago Press. . 2009. Beyond Ideology: Politics, Principles, and Partisanship in the u.s. Senate. Chicago: University of Chicago Press. . 2016. Insecure Majorities: Congress and the Perpetual Campaign. Chicago: University of Chicago Press. . 2016. Insecure Majorities: Congress and the Perpetual Campaign. Chicago: University of Chicago Press. Lewis-Beck, Michael S., William S. Jacoby, Helmut Norpoth, and Herbert F. Weisberg. 2008. The American Voter Revisited. Ann Arbor: University of Michigan Press. Lipsky, Michael. 1983. Street-Level Bureaucracy: The Dilemmas of the Individual in Public Service. Russell Sage Foundation. . 1983. Street-Level Bureaucracy: The Dilemmas of the Individual in Public Service. Russell Sage Foundation. Lodge, Milton, and Ruth Hamill. 1986. A Partisan Schema for Political Information Processing. The American Political Science Review 80 (2): 50520. https://doi.org/10.2307/1958271. Lohr, Steve. 2012. Big Datas Impact in the World. The New York Times, February. https://www.nytimes.com/2012/02/12/sunday-review/big-datas-impact-in-the-world.html. Lum, Cynthia, and Christopher S. Koper. 2017. Evidence-Based Policing. New York: Oxford Univ. Press. Lum, Cynthia, Megan Stoltz, Christopher S. Koper, and J. Amber Scherer. 2019. Research on Body-Worn Cameras: What We Know, What We Need to Know. Criminology &amp; Public Policy 18 (1): 93118. Lupia, Arthur. 1994. Shortcuts Versus Encyclopedias: Information and Voting Behavior in California Insurance Reform Elections. The American Political Science Review 88 (1): 6376. https://doi.org/10.2307/2944882. MacGregor, Douglas. 1960. The Human Side of Enterprise. Vol. 21. New York McGraw-Hill. Madison, James. 1787. Federalist No. 10. November 22 (1787): 178788. . 1787. Federalist No. 10. November 22 (1787): 178788. Maier, Charles S. 1970. Between Taylorism and Technocracy: European Ideologies and the Vision of Industrial Productivity in the 1920s. Journal of Contemporary History 5 (2): 2761. March, James G. 1978. The 1978 Nobel Prize in Economics. Science 202 (4370): 85861. Marini, Frank. 2000. Public Administration. In Defining Public Administration: Selections from the International Encyclopedia of Public Policiy and Administration, edited by Jay M. Shafritz, 316. Westview Press. Maslow, Abraham Harold. 1943. A Theory of Human Motivation. Psychological Review 50 (4): 370. Mastracci, Sharon H., and Ian Tyler Adams. 2019. Understanding Emotional Labor at the Cultural Level. In The Palgrave Handbook of Global Perspectives on Emotional Labor in Public Service, edited by Mary E. Guy, Sharon H. Mastracci, and Seung-Bum Yang, 11948. Cham: Springer International Publishing. https://doi.org/10.1007/978-3-030-24823-9_6. Mastracci, Sharon H., Ian Tyler Adams, and Ning Kang. 2019. The UK. In The Palgrave Handbook of Global Perspectives on Emotional Labor in Public Service, edited by Mary E. Guy, Sharon H. Mastracci, and Seung-Bum Yang, 42353. Cham: Springer International Publishing. https://doi.org/10.1007/978-3-030-24823-9_19. Mastracci, Sharon H., and Mary E. Guy. 2019. From Data Dashboards to Human Hearts. In The Palgrave Handbook of Global Perspectives on Emotional Labor in Public Service, edited by Mary E. Guy, Sharon H. Mastracci, and Seung-Bum Yang, 51133. Cham: Springer International Publishing. https://doi.org/10.1007/978-3-030-24823-9_22. Mastracci, Sharon, and Ian Adams. 2018. Thats What the Moneys for: Alienation and Emotional Labor in Public Service. Administrative Theory &amp; Praxis 40 (4): 30419. https://doi.org/10.1080/10841806.2018.1485449. Matthes, J. 2009. Whats in a Frame? A Content Analysis of Media-Framing Studies in the Worlds Leading Communication Journals, 19902005. Journalism and Mass Communication Quarterly 86: 34967. Mayhew, David R. 1974. Congress: The Electoral Connection. New Haven, CT: Yale University Press. Maynard-Moody, Steven Williams, Michael Musheno, and Michael Craig Musheno. 2003. Cops, Teachers, Counselors: Stories from the Front Lines of Public Service. University of Michigan Press. . 2003. Cops, Teachers, Counselors: Stories from the Front Lines of Public Service. University of Michigan Press. Maynard-Moody, Steven, and Michael Musheno. 2000. State Agent or Citizen Agent: Two Narratives of Discretion. Journal of Public Administration Research and Theory 10 (2): 32958. . 2012. Social Equities and Inequities in Practice: Street-Level Workers as Agents and Pragmatists. Public Administration Review 72 (s1): S1623. . 2012. Social Equities and Inequities in Practice: Street-Level Workers as Agents and Pragmatists. Public Administration Review 72 (s1): S1623. McBeth, Mark K., Michael D. Jones, and Elizabeth A. Shanahan. 2014. The Narrative Policy Framework. Theories of the Policy Process 3: 22566. . 2014. The Narrative Policy Framework. Theories of the Policy Process 3: 22566. McBeth, Mark K., and Donna L. Lybecker. 2018. The Narrative Policy Framework, Agendas, and Sanctuary Cities: The Construction of a Public Problem. Policy Studies Journal 46 (4): 86893. McGinnis, Michael D., and Elinor Ostrom. 2012. Reflections on Vincent Ostrom, Public Administration, and Polycentricity. Public Administration Review 72 (1): 1525. Menzel, Donald C. 2015. Research on Ethics and Integrity in Public Administration: Moving Forward, Looking Back. Public Integrity 17 (4): 34370. Merry, Melissa K. 2018. Narrative Strategies in the Gun Policy Debate: Exploring Proximity and Social Construction. Policy Studies Journal 46 (4): 74770. Merton, Robert K. 1939. Bureaucratic Structure and Personality. Soc. F. 18: 560. Mettler, Suzanne. 2002. Bringing the State Back in to Civic Engagement: Policy Feedback Effects of the GI Bill for World War II Veterans. American Political Science Review 96 (2): 35165. . 2002. Bringing the State Back in to Civic Engagement: Policy Feedback Effects of the GI Bill for World War II Veterans. American Political Science Review 96 (2): 35165. Monroe, Alan D. 1998. Public Opinion and Public Policy: 198093. Public Opinion Quarterly 62: 628. Morgan, Douglas F., and Brian Cook. 2015. New Public Governance: A Regime-Centered Perspective. Routledge. Morgan, Douglas F., Richard T. Green, Craig W. Shinn, and Kent S. Robinson. 2013. Foundations of Public Service. ME Sharpe. Morgan, Douglas F., and Craig W. Shinn. 2014. The Foundations of New Public Governance. In New Public Governance, edited by Douglas F. Morgan and Brian J. Cook, 312. Routledge. Mosher, Frederick C. 1968. Democracy and the Public Service. Oxford: Oxford University Press. . 1974. Watergate: Implications for Responsible Government. Mourtgos, Scott M., and Ian T. Adams. 2019a. The Effect of Prosecutorial Actions on Deterrence: A County-Level Analysis. Criminal Justice Policy Review, February, 0887403419829201. https://doi.org/10.1177/0887403419829201. . 2019b. The Rhetoric of de-Policing: Evaluating Open-Ended Survey Responses from Police Officers with Machine Learning-Based Structural Topic Modeling. Journal of Criminal Justice, August, 101627. https://doi.org/10.1016/j.jcrimjus.2019.101627. Mourtgos, Scott, and Ian Adams. n.d. Assessing Unreasonable Public Perceptions of Reasonable Police Use of Force. ResearchGate. https://www.researchgate.net/publication/327513011_Assessing_Unreasonable_Public_Perceptions_of_Reasonable_Police_Use_of_Force. Moynihan, Donald P., and Sanjay K. Pandey. 2007. The Role of Organizations in Fostering Public Service Motivation. Public Administration Review 67 (1): 4053. Murray, Shailagh. 2008. Obamas Reagan Comparison Sparks Debate. Washington Post, January. http://voices.washingtonpost.com/44/2008/01/obamas-reagan-comparison-spark-1.html. Nesselroade, John R., and Paul B. Baltes. 1979. Longitudinal Research in the Study of Behavior and Development. Academic Pr. Nesselroade, John R., and Raymond B. Cattell. 2013. Handbook of Multivariate Experimental Psychology. Springer Science &amp; Business Media. Newell, Bryce, and Ruben Greidanus. 2018. Officer Discretion and the Choice to Record: Officer Attitudes Towards Body-Worn Camera Activation. North Carolina Law Review 96: 144. Newsom, Jason T. 2015. Longitudinal Structural Equation Modeling: A Comprehensive Introduction. Routledge. Nix, Justin, Bradley A. Campbell, Edward H. Byers, and Geoffrey P. Alpert. 2017. A Birds Eye View of Civilians Killed by Police in 2015: Further Evidence of Implicit Bias. Criminology &amp; Public Policy 16 (1): 30940. Nozick, Robert. 1974. Anarchy, State, and Utopia. New York: Basic Books. OLeary, Rosemary. 2010. Guerrilla Employees: Should Managers Nurture, Tolerate, or Terminate Them? Public Administration Review 70 (1): 819. . 2013. The Ethics of Dissent: Managing Guerrilla Government. Cq Press. OToole, Laurence J. 1987. Doctrines and Developments: Separation of Powers, the Politics-Administration Dichotomy, and the Rise of the Administrative State. Public Administration Review 47 (1): 1725. https://doi.org/10.2307/975468. Olson, Mancur. 1965. The Logic of Collective Action: Public Goods and the Theory of Groups. Cambridge, MA: Harvard University Press. Oppel, Richard A., Jr. 2012. Romneys View of Russia Stirs Debate. The New York Times, May. https://www.nytimes.com/2012/05/12/us/politics/romneys-view-of-russia-sparks-debate.html. Osborne, Stephen P. 2006. The New Public Governance? Taylor &amp; Francis. Ostrom, E. 1982. Polycentric Games and Institutions. In The Three Worlds of Action: A Metatheoretical Synthesis of Institutional Approaches, edited by L.Ostrom Kiser E., 5688. Ann Arbor: University of Michigan Press. Ostrom, Elinor. 1990. Governing the Commons: The Evolution of Institutions for Collective Action. Political Economy of Institutions and Decisions. Cambridge, UK: Cambridge Univ. Press. . 2011. Background on the Institutional Analysis and Development Framework. Policy Studies Journal 39 (1): 727. Ostrom, Vincent. 1987. The Political Theory of a Compound Republic: Designing the American Experiment. Lincoln: University of Nebraska Press. Pachon, Harry P., and Nicholas P. Lovrich Jr. 1977. The Consolidation of Urban Public Services: A Focus on the Police. Public Administration Review, 3847. Page, Benjamin I., and Robert Y. Shapiro. 1983. Effects of Public Opinion on Public Policy. American Political Science Review 77 (March): 17590. Panagopoulos, Costas. 2011. Timing Is Everything? Primacy and Recency Effects in Voter Mobilization Campaigns. Political Behavior 33 (1): 7993. Pandey, Sanjay K., and Donald Moynihan. 2006. Bureaucratic Red Tape and Organizational Performance: Testing. Public Service Performance: Perspectives on Measurement and Management, 130. Parks, Roger B., Paula C. Baker, Larry Kiser, Ronald Oakerson, Elinor Ostrom, Vincent Ostrom, Stephen L. Percy, Martha B. Vandivort, Gordon P. Whitaker, and Rick Wilson. 1981. Consumers as Coproducers of Public Services: Some Economic and Institutional Considerations. Policy Studies Journal 9 (7): 100111. Parks, Roger B., and Elinor Ostrom. 1999. Complex Models of Urban Service Systems. In Polycentricity and Local Public Economies: Readings from the Workshop in Political Theory and Policy Analysis, edited by Michael Dean McGinnis, 35580. University of Michigan Press. Pestoff, Victor, Taco Brandsen, and Bram Verschuere. 2013. New Public Governance, the Third Sector, and Co-Production. Routledge. Peterson, Paul E. 2012. The Price of Federalism. Brookings Institution Press. . 2012. The Price of Federalism. Brookings Institution Press. Pierson, Paul. 2000. Increasing Returns, Path Dependence, and the Study of Politics. American Political Science Review 94 (2): 25167. . 2000. Increasing Returns, Path Dependence, and the Study of Politics. American Political Science Review 94 (2): 25167. Polyakova, Alina. 2018. Weapons of the Weak: Russia and AI-Driven Asymmetric Warfare. Brookings, November. https://www.brookings.edu/research/weapons-of-the-weak-russia-and-ai-driven-asymmetric-warfare/. Popper, Karl. 1959. The Logic of Scientific Discovery. Routledge. Pressman, Jeffrey L., and Aaron Wildavsky. 1984. Implementation: How Great Expectations in Washington Are Dashed in Oakland; or, Why Its Amazing That Federal Programs Work at All, This Being a Saga of the Economic Development Administration as Told by Two Sympathetic Observers Who Seek to Build Morals on a Foundation. Univ of California Press. Prior, Markus. 2009. Improving Media Effects Research Through Better Measurement of News Exposure. Journal of Politics 71 (3): 893908. . 2013. Media and Political Polarization. Annual Review of Political Science 16 (1): 10127. https://doi.org/10.1146/annurev-polisci-100711-135242. Public Affairs, Office of. 2015. https://www.justice.gov/opa/pr/justice-department-awards-over-23-million-funding-body-worn-camera-pilot-program-support-law. Quijada Cerecer, Patricia D. 2013. The Policing of Native Bodies and Minds: Perspectives on Schooling from American Indian Youth. American Journal of Education 119 (4): 591616. . 2013. The Policing of Native Bodies and Minds: Perspectives on Schooling from American Indian Youth. American Journal of Education 119 (4): 591616. R Core Team. 2020. R: A Language and Environment for Statistical Computing. Vienna, Austria: R Foundation for Statistical Computing. https://www.R-project.org/. Rabinbach, Anson. 1992. The Human Motor: Energy, Fatigue, and the Origins of Modernity. University of California Press. Radford, Alec, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, and Ilya Sutskever. 2019. Language Models Are Unsupervised Multitask Learners. OpenAI Blog 1 (8). Radford, Alec, Jeffrey Wu, Jack Clark, Amanda Askell, David Lansky, Danny Hernandez, Daniela Amodei, and David Luan. 2019. Better Language Models and Their Implications. OpenAI. https://openai.com/blog/better-language-models/. Ragosta, John. 2010. Wellspring of Liberty: How Virginias Religious Dissenters Helped Win the American Revolution and Secured Religious Liberty. New York: Oxford University Press. Reeves, Shane, and David Wallace. 2016. Can US Service Members Disobey an Order to Waterboard a Terrorist? Lawfare. https://www.lawfareblog.com/can-us-service-members-disobey-order-waterboard-terrorist. Riccucci, Norma M. 2010. Public Administration: Traditions of Inquiry and Philosophies of Knowledge. Georgetown University Press. Riccucci, Norma M., and Gregg G. Van Ryzin. 2017. Representative Bureaucracy: A Lever to Enhance Social Equity, Coproduction, and Democracy. Public Administration Review 77 (1): 2130. https://doi.org/10.1111/puar.12649. Ripberger, Joseph T. 2011. Capturing Curiosity: Using Internet Search Trends to Measure Public Attentiveness. Policy Studies Journal 39 (2): 23959. Roberts, Margaret E., Brandon M. Stewart, and Dustin Tingley. 2014. Structural Topic Models for Openended Survey Responses. American Journal of Political Science 58 (4): 106482. Rohr, John Anthony. 1986. To Run a Constitution: The Legitimacy of the Administrative State. University Press of Kansas. . 1986. To Run a Constitution: The Legitimacy of the Administrative State. University Press of Kansas. Rorty, Richard. 1982. Consequences of Pragmatism: Essays, 1972-1980. U of Minnesota Press. Rosenbloom, David H. 2016. Public Administrative Theory and the Separation of Powers. In The Constitutional School of American Public Administration, 7894. Routledge. Sabatier, Paul A. 1988. An Advocacy Coalition Framework of Policy Change and the Role of Policy-Oriented Learning Therein. Policy Sciences 21 (2/3): 12968. . 1988. An Advocacy Coalition Framework of Policy Change and the Role of Policy-Oriented Learning Therein. Policy Sciences 21 (2/3): 12968. . 1999. The Need for Better Theories. Theories of the Policy Process 2: 317. Sabatier, Paul A., and Hank C. Jenkins-Smith. 1993. The Advocacy Coalition Framework: Assessment, Revisions, and Implications for Scholars and Practitioners. Policy Change and Learning: An Advocacy Coalition Approach, 21136. . 1993. The Advocacy Coalition Framework: Assessment, Revisions, and Implications for Scholars and Practitioners. Policy Change and Learning: An Advocacy Coalition Approach, 21136. Sabatier, Paul A., and Christopher M. Weible. 2007. The Advocacy Coalition Framework. Theories of the Policy Process 2: 189220. . 2007. The Advocacy Coalition Framework. Theories of the Policy Process 2: 189220. . 2014. Theories of the Policy Process. Westview Press. . 2014. Theories of the Policy Process. Westview Press. Sanders, Elizabeth. 2006. Historical Institutionalism. In The Oxford Handbook of Political Institutions. . 2006. Historical Institutionalism. In The Oxford Handbook of Political Institutions. Sanger, David, and Catie Edmondson. 2019. Russia Targeted Election Systems in All 50 States, Report Finds - the New York Times. The New York Times, July. https://www.nytimes.com/2019/07/25/us/politics/russian-hacking-elections.html. Schattschneider, E. E. 1960. The Semisovereign People: A Realists View of Democracy in America. New York: Holt, Rinehart; Winston. Schattschneider, Elmer E. 1960. The Semi-Sovereign People (Holt, Rhinehart and Winston, New York). Google Scholar. . 1960. The Semi-Sovereign People (Holt, Rhinehart and Winston, New York). Google Scholar. Scheufele, D. A. 1999. Framing as a Theory of Media Effects. Journal of Communication 49 (1): 10322. Schlozman, Kay Lehman. 1984. What Accent the Heavenly Chorus? Political Equality and the American Pressure System. The Journal of Politics 46 (4): 100632. . 1984. What Accent the Heavenly Chorus? Political Equality and the American Pressure System. The Journal of Politics 46 (4): 100632. Schmidt, Ronald. 2000. Language Policy and Identity Politics in the United States. Philadelphia: Temple University Press. . 2000. Language Policy and Identity Politics in the United States. Philadelphia: Temple University Press. Schneider, Anne, and Helen Ingram. 1993. Social Construction of Target Populations: Implications for Politics and Policy. The American Political Science Review 87 (2): 33447. https://doi.org/10.2307/2939044. . 1993. Social Construction of Target Populations: Implications for Politics and Policy. The American Political Science Review 87 (2): 33447. https://doi.org/10.2307/2939044. Scott, James. 1999. Seeing Like a State: How Certain Schemes to Improve the Human Condition Have Failed. New Haven, CT: Yale University Press. . 1999. Seeing Like a State: How Certain Schemes to Improve the Human Condition Have Failed. New Haven, CT: Yale University Press. Sears, David O., and Nicholas A. Valentino. 1997. Politics Matters: Political Events as Catalysts for Preadult Socialization. The American Political Science Review 91 (1): 4565. https://doi.org/10.2307/2952258. Shanahan, Elizabeth A., Michael D. Jones, and Mark K. McBeth. 2018. How to Conduct a Narrative Policy Framework Study. The Social Science Journal 55 (3): 33245. Shanahan, Elizabeth A., Mark K. McBeth, and Paul L. Hathaway. 2011. Narrative Policy Framework: The Influence of Media Policy Narratives on Public Opinion. Politics &amp; Policy 39 (3): 373400. Shanahan, Elizabeth A., Mark K. McBeth, Paul L. Hathaway, and Ruth J. Arnell. 2008. Conduit or Contributor? The Role of Media in Policy Change Theory. Policy Sciences 41 (2): 115. https://doi.org/10.1007/s11077-008-9058-y. Shannon, Brooke N., Zachary A. McGee, and Bryan D. Jones. 2019. Bounded Rationality and Cognitive Limits in Political Decision Making. Oxford Research Encyclopedia of Politics, June. https://doi.org/10.1093/acrefore/9780190228637.013.961. Sharp, Liz, and Tim Richardson. 2001. Reflections on Foucauldian Discourse Analysis in Planning and Environmental Policy Research. Journal of Environmental Policy and Planning 3 (3): 193209. . 2001. Reflections on Foucauldian Discourse Analysis in Planning and Environmental Policy Research. Journal of Environmental Policy and Planning 3 (3): 193209. Shepsle, Kenneth A. 2006. Rational Choice Institutionalism. The Oxford Handbook of Political Institutions 23: 2426. Sherman, Lawrence W. 2015. A Tipping Point for Totally Evidenced Policing Ten Ideas for Building an Evidence-Based Police Agency. International Criminal Justice Review 25 (1): 1129. Simon, H. A. 1976. Administrative Behavior; a Study of Decision-Making Processes in Administrative Organization-3. . 1976. Administrative Behavior; a Study of Decision-Making Processes in Administrative Organization-3. Simon, Herbert A. 1946. The Proverbs of Administration. Classics of Organization Theory 3: 10113. . 1972. Theories of Bounded Rationality. Decision and Organization 1 (1): 16176. . 1990. Bounded Rationality. In Utility and Probability, 1518. Springer. . 2019. The Sciences of the Artificial. MIT Press. Simon, Herbert A., Peter F. Drucker, and Dwight Waldo. 1952. Development of Theory of Democratic Administration: Replies and Comments. American Political Science Review 46 (2): 494503. Skowronek, Stephen. 1997. The Politics Presidents Make: Leadership from John Adams to Bill Clinton. Cambridge, MA: Harvard University Press. . 2008. Presidential Leadership in Political Time: Reprise and Reappraisal. University Press of Kansas Lawrence. Smith, Rogers M. 2015. Political Science and the Public Sphere Today. Perspectives on Politics 13 (2): 36676. https://doi.org/10.1017/S1537592715000225. Soss, Joe, and Sanford F. Schram. 2007. A Public Transformed? Welfare Reform as Policy Feedback. American Political Science Review 101 (1): 11127. . 2007. A Public Transformed? Welfare Reform as Policy Feedback. American Political Science Review 101 (1): 11127. Spicer, Michael W. 2005. Public Administration and the State: A Postmodern Perspective. University of Alabama Press. Stivers, Camilla. 1995. Settlement Women and Bureau Men: Constructing a Usable Past for Public Administration. Public Administration Review, 52229. . 2002. Bureau Men, Settlement Women: Constructing Public Administration in the Progressive Era (Studies in Government &amp; Public Policy). University Press of Kansas. Stone, Deborah. 2002. Policy Paradox (Rev. Ed.). . 2002. Policy Paradox (Rev. Ed.). Sunstein, Cass R. 2003. Why Societies Need Dissent. Cambridge, MA: Harvard University Press. Taber, Charles S., and Milton Lodge. 2006. Motivated Skepticism in the Evaluation of Political Beliefs. American Journal of Political Science 50 (3): 75569. https://doi.org/10.1111/j.1540-5907.2006.00214.x. Tarka, Piotr. 2018. An Overview of Structural Equation Modeling: Its Beginnings, Historical Development, Usefulness and Controversies in the Social Sciences. Quality &amp; Quantity 52 (1): 31354. https://doi.org/10.1007/s11135-017-0469-8. Taylor, Frederick W. 1914. Scientific Management: Reply from Mr. FW Taylor. The Sociological Review 7 (3): 26669. Theriault, Sean M. 2003. Patronage, the Pendleton Act, and the Power of the People. The Journal of Politics 65 (1): 5068. Thomas, John Clayton. 2013. Citizen, Customer, Partner: Rethinking the Place of the Public in Public Management. Public Administration Review 73 (6): 78696. Thompson, Dennis F. 1985. The Possibility of Administrative Ethics. Public Administration Review, 55561. Thompson, James D. 1967. Organizations in Action. New York: McGraw-Hill. ThompsonOrganizations in Action1967. True, James L., Bryan D. Jones, and Frank R. Baumgartner. 1999. Punctuated Equilibrium Theory. Theories of the Policy Process, 175202. . 1999. Punctuated Equilibrium Theory. Theories of the Policy Process, 175202. UCMJ. 1956. Failure to Obey Order or Regulation. 10 U.S. Code Â§892. https://www.law.cornell.edu/uscode/text/10/892. Verba, Sidney, and Norman Nie. 1972. Participation in America. New York: Harper &amp; Row. Wagner, M. W., and M. Gruszczynski. 2016. When Framing Matters: How Partisan and Journalistic Frames Affect Individual Opinions and Party Identification. Journalism &amp; Communication Monographs 18 (1): 548. Waldo, Dwight. 1952. Development of Theory of Democratic Administration. American Political Science Review 46 (1): 81103. . 2017. The Administrative State: A Study of the Political Theory of American Public Administration. Routledge. . 2017. The Administrative State: A Study of the Political Theory of American Public Administration. Routledge. Wattenberg, Martin P. 2019. The Changing Nature of Mass Belief Systems: The Rise of Concept Ideologues &amp; Policy Wonks. In, 131. Washington, D.C.: American Political Science Association. https://convention2.allacademic.com/one/apsa/apsa19/index.php?cmd=Online+Program+Download+Document&amp;document_type=document&amp;key=online_program_view_paper_downloads&amp;document_key=c22149c0da905e244244b6c51cb36655&amp;filename=apsa19_proceeding_1491361.pdf&amp;PHPSESSID=bvcgp5ig75hu1hok5vhuakihp7. Weber, Max. 1946. Characteristics of Bureaucracy. From Max Weber: Essays in Sociology, 32734. . 1947. Legitimate Authority and Bureaucracy. The Theory of Social and Economic Organisation, 32840. . 2015. Bureaucracy. In Working in America, 2934. Routledge. Weible, Christopher M., Paul A. Sabatier, and Kelly McQueen. 2009. Themes and Variations: Taking Stock of the Advocacy Coalition Framework. Policy Studies Journal 37 (1): 12140. . 2009. Themes and Variations: Taking Stock of the Advocacy Coalition Framework. Policy Studies Journal 37 (1): 12140. White, Leonard Dupee. 1955. Introduction to the Study of Public Administration. Wholey, Joseph S., and Harry P. Hatry. 1992. The Case for Performance Monitoring. Public Administration Review 52 (6): 604. Wilson, James Q. 1989. Bureaucracy: What Government Agencies Do and Why They Do It. Wilson, Woodrow. 1887. The Study of Administration. Political Science Quarterly 2 (2): 197222. Wittgenstein, Ludwig. 2013. Tractatus Logico-Philosophicus. Routledge. . 2013. Tractatus Logico-Philosophicus. Routledge. Wolfinger, Raymond E., and Steven J. Rosenstone. 1980. Who Votes? New Haven, CT: Yale University Press. Xie, Yihui. 2014. Knitr: A Comprehensive Tool for Reproducible Research in R. In Implementing Reproducible Computational Research, edited by Victoria Stodden, Friedrich Leisch, and Roger D. Peng. Chapman; Hall/CRC. http://www.crcpress.com/product/isbn/9781466561595. . 2015b. Dynamic Documents with R and Knitr. 2nd ed. Boca Raton, Florida: Chapman; Hall/CRC. http://yihui.org/knitr/. . 2015a. Dynamic Documents with R and Knitr. 2nd ed. Boca Raton, Florida: Chapman; Hall/CRC. https://yihui.org/knitr/. . 2016. Bookdown: Authoring Books and Technical Documents with R Markdown. Boca Raton, Florida: Chapman; Hall/CRC. https://github.com/rstudio/bookdown. . 2020a. Bookdown: Authoring Books and Technical Documents with r Markdown. https://github.com/rstudio/bookdown. . 2020b. Knitr: A General-Purpose Package for Dynamic Report Generation in r. https://yihui.org/knitr/. Xie, Yihui, J. J. Allaire, and Garrett Grolemund. 2018. R Markdown: The Definitive Guide. Boca Raton, Florida: Chapman; Hall/CRC. https://bookdown.org/yihui/rmarkdown. Xie, Yihui, Christophe Dervieux, and Emily Riederer. 2020. R Markdown Cookbook. Boca Raton, Florida: Chapman; Hall/CRC. https://bookdown.org/yihui/rmarkdown-cookbook. Yanow, Dvora. 2003. Constructing Race and Ethnicity. America: Category-Making in Public Policy and Administration. . 2003. Constructing Race and Ethnicity. America: Category-Making in Public Policy and Administration. Zahariadis, Nikolaos. 2014. Ambiguity and Multiple Streams. Theories of the Policy Process 3: 2559. . 2014. Ambiguity and Multiple Streams. Theories of the Policy Process 3: 2559. Zaller, John. 1991. Information, Values, and Opinion. American Political Science Review 85 (4): 121537. . 1991. Information, Values, and Opinion. American Political Science Review 85 (4): 121537. . 1992. The Nature and Origins of Mass Opinion. Cambridge, UK: Cambridge University Press. . 1992. The Nature and Origins of Mass Opinion. Cambridge, UK: Cambridge University Press. Zanocco, Chad, Geoboo Song, and Michael Jones. 2018. Fracking Bad Guys: The Role of Narrative Character Affect in Shaping Hydraulic Fracturing Policy Preferences. Policy Studies Journal 46 (4): 97899. "]]
